#!/usr/bin/env python3
# coding: utf-8

import contextlib
import os
import json
import re
import sqlite3
import subprocess
import tempfile
import time
import shutil
import random
import unicodedata
import shlex
from pathlib import Path
from datetime import datetime, date
from dataclasses import dataclass
from typing import Any, Callable, Dict, Iterable, List, Tuple, Optional, Union, Awaitable, Set
from collections import defaultdict
import math
import wave
from array import array

from shutil import which

import zipfile
import urllib.request
import importlib.util
import asyncio
import sys
import types
from bisect import bisect_left, bisect_right
import heapq

try:
    import private_settings  # type: ignore
except ModuleNotFoundError:
    private_settings = types.SimpleNamespace()

_PRIVATE_SETTING_SENTINEL = object()


def _get_private_setting(name: str, default: Any = None) -> Any:
    value = getattr(private_settings, name, _PRIVATE_SETTING_SENTINEL)
    if value is not _PRIVATE_SETTING_SENTINEL:
        return value
    value = os.environ.get(name, _PRIVATE_SETTING_SENTINEL)
    if value is not _PRIVATE_SETTING_SENTINEL:
        return value
    return default


def _coerce_int(value: Any, default: int) -> int:
    try:
        return int(value)
    except (TypeError, ValueError):
        return default

def _coerce_bool(value: Any, default: bool) -> bool:
    """
    ????????? ???????? ???????? ? bool, ??????????? ?????? ???? true/false, 1/0 ? ?.?.
    """
    if value in (_PRIVATE_SETTING_SENTINEL, None):
        return default
    if isinstance(value, bool):
        return value
    if isinstance(value, (int, float)):
        return bool(value)
    text = str(value).strip().lower()
    if text in {"1", "true", "yes", "on", "y"}:
        return True
    if text in {"0", "false", "no", "off", "n"}:
        return False
    return default


from telegram import (
    Update,
    InlineKeyboardButton,
    InlineKeyboardMarkup,
    KeyboardButton,
    ReplyKeyboardMarkup,
)
from telegram.ext import (
    ApplicationBuilder,
    CommandHandler,
    CallbackQueryHandler,
    MessageHandler,
    ContextTypes,
    filters,
)

from scan import ScanEnvironment, run_scan
from reports import ReportEnvironment, build_color_group_report

# =========================
# Ð“Ð›ÐžÐ‘ÐÐ›Ð¬ÐÐ«Ð• ÐÐÐ¡Ð¢Ð ÐžÐ™ÐšÐ˜
# =========================

BUILD_NAME = "build3444"

SCRIPT_DIR = Path(__file__).resolve().parent

FFMPEG_ZIP_URL = "https://www.gyan.dev/ffmpeg/builds/ffmpeg-release-essentials.zip"


def _ensure_ffmpeg_binaries() -> None:
    """
    ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÑ‚, ÐµÑÑ‚ÑŒ Ð»Ð¸ ffmpeg.exe Ð¸ ffprobe.exe Ñ€ÑÐ´Ð¾Ð¼ ÑÐ¾ ÑÐºÑ€Ð¸Ð¿Ñ‚Ð¾Ð¼.
    Ð•ÑÐ»Ð¸ Ð½ÐµÑ‚ â€” ÑÐºÐ°Ñ‡Ð¸Ð²Ð°ÐµÑ‚ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÑŽÑŽ ÑÐ±Ð¾Ñ€ÐºÑƒ FFmpeg (release-essentials),
    Ð²Ñ‹Ñ‚Ð°ÑÐºÐ¸Ð²Ð°ÐµÑ‚ Ð±Ð¸Ð½Ð°Ñ€Ð½Ð¸ÐºÐ¸ Ð¸ ÐºÐ»Ð°Ð´Ñ‘Ñ‚ Ð² SCRIPT_DIR.
    """
    ffmpeg_path = SCRIPT_DIR / "ffmpeg.exe"
    ffprobe_path = SCRIPT_DIR / "ffprobe.exe"

    if ffmpeg_path.exists() and ffprobe_path.exists():
        # Ð£Ð¶Ðµ ÐµÑÑ‚ÑŒ â€” Ð½Ð¸Ñ‡ÐµÐ³Ð¾ Ð½Ðµ Ð´ÐµÐ»Ð°ÐµÐ¼
        return

    print("[FFMPEG] ffmpeg.exe Ð¸Ð»Ð¸ ffprobe.exe Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ñ‹. Ð¡ÐºÐ°Ñ‡Ð¸Ð²Ð°ÑŽ FFmpeg...")

    import tempfile
    import shutil

    try:
        with tempfile.TemporaryDirectory() as tmpdir:
            tmpdir = Path(tmpdir)
            zip_path = tmpdir / "ffmpeg.zip"

            # Ð¡ÐºÐ°Ñ‡Ð¸Ð²Ð°ÐµÐ¼ Ð°Ñ€Ñ…Ð¸Ð²
            print(f"[FFMPEG] Ð¡ÐºÐ°Ñ‡Ð¸Ð²Ð°Ð½Ð¸Ðµ {FFMPEG_ZIP_URL} ...")
            urllib.request.urlretrieve(FFMPEG_ZIP_URL, zip_path)

            # Ð Ð°ÑÐ¿Ð°ÐºÐ¾Ð²Ñ‹Ð²Ð°ÐµÐ¼
            print("[FFMPEG] Ð Ð°ÑÐ¿Ð°ÐºÐ¾Ð²ÐºÐ° Ð°Ñ€Ñ…Ð¸Ð²Ð°...")
            with zipfile.ZipFile(zip_path, "r") as zf:
                members = zf.namelist()

                # Ð˜Ñ‰ÐµÐ¼ ffmpeg.exe Ð¸ ffprobe.exe Ð²Ð½ÑƒÑ‚Ñ€Ð¸ Ð°Ñ€Ñ…Ð¸Ð²Ð°
                ffmpeg_member = None
                ffprobe_member = None

                for m in members:
                    lower = m.lower()
                    if lower.endswith("bin/ffmpeg.exe"):
                        ffmpeg_member = m
                    elif lower.endswith("bin/ffprobe.exe"):
                        ffprobe_member = m

                if not ffmpeg_member or not ffprobe_member:
                    raise RuntimeError("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð½Ð°Ð¹Ñ‚Ð¸ ffmpeg.exe Ð¸Ð»Ð¸ ffprobe.exe Ð² Ð°Ñ€Ñ…Ð¸Ð²Ðµ FFmpeg")

                # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ Ð²Ð¾ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½ÑƒÑŽ Ð¿Ð°Ð¿ÐºÑƒ
                zf.extract(ffmpeg_member, tmpdir)
                zf.extract(ffprobe_member, tmpdir)

                # ÐšÐ¾Ð¿Ð¸Ñ€ÑƒÐµÐ¼ Ñ€ÑÐ´Ð¾Ð¼ ÑÐ¾ ÑÐºÑ€Ð¸Ð¿Ñ‚Ð¾Ð¼
                extracted_ffmpeg = tmpdir / ffmpeg_member
                extracted_ffprobe = tmpdir / ffprobe_member

                shutil.copy2(extracted_ffmpeg, ffmpeg_path)
                shutil.copy2(extracted_ffprobe, ffprobe_path)

            print("[FFMPEG] ffmpeg.exe Ð¸ ffprobe.exe ÑÐºÐ°Ñ‡Ð°Ð½Ñ‹ Ð¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ñ‹ Ñ€ÑÐ´Ð¾Ð¼ ÑÐ¾ ÑÐºÑ€Ð¸Ð¿Ñ‚Ð¾Ð¼.")
    except Exception as e:
        raise RuntimeError(
            f"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ ÑÐºÐ°Ñ‡Ð°Ñ‚ÑŒ Ð¸ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ FFmpeg: {e}\n"
            f"ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ FFmpeg Ð²Ñ€ÑƒÑ‡Ð½ÑƒÑŽ Ð¸Ð»Ð¸ Ñ‡ÐµÑ€ÐµÐ· winget."
        )



def _locate_bin(name: str) -> str:
    """
    Ð˜Ñ‰ÐµÐ¼ Ð±Ð¸Ð½Ð°Ñ€Ð½Ð¸Ðº Ð² Ñ‚Ð°ÐºÐ¾Ð¼ Ð¿Ð¾Ñ€ÑÐ´ÐºÐµ:
    1) Ð’ Ð¿Ð°Ð¿ÐºÐµ ÑÐ¾ ÑÐºÑ€Ð¸Ð¿Ñ‚Ð¾Ð¼ (SCRIPT_DIR/ffmpeg.exe Ð¸ Ñ‚.Ð¿.)
    2) Ð”Ð»Ñ ffmpeg/ffprobe â€” Ð¿Ñ‹Ñ‚Ð°ÐµÐ¼ÑÑ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ ÑÐºÐ°Ñ‡Ð°Ñ‚ÑŒ
    3) Ð’ ÑÐ¸ÑÑ‚ÐµÐ¼Ð½Ð¾Ð¼ PATH (which)
    """
    exe_name = name + ".exe" if os.name == "nt" else name

    # 1. Ð›Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾, Ñ€ÑÐ´Ð¾Ð¼ ÑÐ¾ ÑÐºÑ€Ð¸Ð¿Ñ‚Ð¾Ð¼
    local_path = SCRIPT_DIR / exe_name
    if local_path.exists():
        return str(local_path)

    # 2. Ð”Ð»Ñ ffmpeg/ffprobe â€” Ð°Ð²Ñ‚Ð¾Ð´Ð¾ÐºÐ°Ñ‡ÐºÐ°
    if name in ("ffmpeg", "ffprobe"):
        _ensure_ffmpeg_binaries()
        if local_path.exists():
            return str(local_path)

    # 3. Ð’ PATH
    found = which(name)
    if found:
        return found

    raise FileNotFoundError(f"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð½Ð°Ð¹Ñ‚Ð¸ Ð±Ð¸Ð½Ð°Ñ€Ð½Ð¸Ðº '{name}'. "
                            f"ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ ÐµÐ³Ð¾ Ð² PATH Ð¸Ð»Ð¸ Ð¿Ð¾Ð»Ð¾Ð¶Ð¸Ñ‚ÑŒ {exe_name} Ñ€ÑÐ´Ð¾Ð¼ ÑÐ¾ ÑÐºÑ€Ð¸Ð¿Ñ‚Ð¾Ð¼.")

DB_PATH = SCRIPT_DIR / "pmv_bot.db"
OUTPUT_DIR = SCRIPT_DIR / "output"
_network_output_root_value = _get_private_setting("NETWORK_OUTPUT_ROOT")
_enable_network_copy_value = _get_private_setting("ENABLE_NETWORK_COPY")
ENABLE_NETWORK_COPY = _coerce_bool(_enable_network_copy_value, False)
NETWORK_OUTPUT_ROOT = (
    Path(str(_network_output_root_value))
    if _network_output_root_value
    else OUTPUT_DIR
)
MEDIA_PLAYER_EXECUTABLE = Path(r"C:\Program Files (x86)\K-Lite Codec Pack\MPC-HC64\mpc-hc64.exe")
TEMP_DIRS = [
    SCRIPT_DIR / "tmp",
    OUTPUT_DIR,
]
MUSIC_PROJECTS_DIR = SCRIPT_DIR / "music_projects"
MUSIC_INPUT_DIR = SCRIPT_DIR / "Music"

_music_generator_module = None
MUSIC_INPUT_DIR = SCRIPT_DIR / "Music"

DEFAULT_EXTS = {".mp4", ".mov", ".mkv", ".m4v"}

# Ð“Ð›ÐžÐ‘ÐÐ›Ð¬ÐÐ«Ð• ÐŸÐ£Ð¢Ð˜ Ðš FFMPEG/FFPROBE
FFMPEG_BIN = _locate_bin("ffmpeg")
FFPROBE_BIN = _locate_bin("ffprobe")

LOGS_DIR = SCRIPT_DIR / "logs"
RANDOMPMV_LOG_PATH = LOGS_DIR / "randompmv_history.jsonl"
CODEX_FEEDBACK_LOG_PATH = LOGS_DIR / "codex_feedback.jsonl"


# ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð½Ð°Ñ€ÐµÐ·ÐºÐ¸ Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ
DEFAULT_TARGET_MINUTES = 30       # ÐµÑÐ»Ð¸ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ Ð²Ð²ÐµÐ´Ñ‘Ñ‚ Ñ‡ÑƒÑˆÑŒ â€” Ð¿Ð¾Ð´ÑÑ‚Ñ€Ð°Ñ…ÑƒÐµÐ¼ÑÑ
PER_FILE_MIN_SECONDS = 300        # 5 Ð¼Ð¸Ð½ÑƒÑ‚ (Ð¼Ð¸Ð½Ð¸Ð¼ÑƒÐ¼, ÐÐž Ñ‚ÐµÐ¿ÐµÑ€ÑŒ Ð½Ðµ Ð»Ð¾Ð¼Ð°ÐµÑ‚ Ñ‚Ð°Ñ€Ð³ÐµÑ‚)
PER_FILE_MAX_SECONDS = 600        # 10 Ð¼Ð¸Ð½ÑƒÑ‚
RANDOM_SEED = 42
USE_TS_CONCAT = True              # ÐºÐ°Ðº Ð¸ Ñ€Ð°Ð½ÑŒÑˆÐµ
MAX_OUTPUT_BYTES = 100 * 1024**3  # Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¸Ðµ Ð½Ð° Ñ€Ð°Ð·Ð¼ÐµÑ€ Ð¸Ñ‚Ð¾Ð³Ð¾Ð²Ð¾Ð³Ð¾ Ñ„Ð°Ð¹Ð»Ð° (~100 Ð“Ð‘)
SNAP_TO_KEYFRAMES = True          # Ð¿Ð¾Ð´ÑÑ‚Ñ€Ð°Ð¸Ð²Ð°Ñ‚ÑŒ ÑÑ‚Ð°Ñ€Ñ‚ ÐºÐ»Ð¸Ð¿Ð¾Ð² Ðº Ð¿Ñ€ÐµÐ´Ñ‹Ð´ÑƒÑ‰ÐµÐ¼Ñƒ ÐºÐ»ÑŽÑ‡ÐµÐ²Ð¾Ð¼Ñƒ ÐºÐ°Ð´Ñ€Ñƒ
PER_DIR_MAX_FIRST_PASS = 1        # Ð½Ð° Ð¿ÐµÑ€Ð²Ð¾Ð¼ Ð¿Ñ€Ð¾Ñ…Ð¾Ð´Ðµ Ð±Ñ€Ð°Ñ‚ÑŒ Ð½Ðµ Ð±Ð¾Ð»ÐµÐµ N Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² Ð¸Ð· Ð¿Ð°Ð¿ÐºÐ¸
MIN_SMALL_CLIP_SECONDS = 3        # Ð¼Ð¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð°Ñ Ð´Ð»Ð¸Ð½Ð° Ð¼Ð°Ð»ÐµÐ½ÑŒÐºÐ¾Ð³Ð¾ ÐºÐ»Ð¸Ð¿Ð° (ÑÐµÐº)
ALLOWED_STRATEGIES = ["max_group", "weighted_random", "random"]
CURRENT_STRATEGY = "max_group"
GLITCH_EFFECTS_PER_VIDEO = 0      # ÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð³Ð»Ð¸Ñ‚Ñ‡-Ð²ÑÑ‚Ð°Ð²Ð¾Ðº Ð´ÐµÐ»Ð°Ñ‚ÑŒ Ð½Ð° Ð²Ð¸Ð´ÐµÐ¾
TRANSITION_EFFECTS_PER_VIDEO = 0  # ÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð¿ÐµÑ€ÐµÑ…Ð¾Ð´Ð¾Ð² Ð´Ð¾Ð±Ð°Ð²Ð»ÑÑ‚ÑŒ Ð¼ÐµÐ¶Ð´Ñƒ ÐºÐ»Ð¸Ð¿Ð°Ð¼Ð¸
FX_GLITCH_DURATION = 0.25         # Ð´Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð³Ð»Ð¸Ñ‚Ñ‡-Ð²ÑÑ‚Ð°Ð²ÐºÐ¸ (ÑÐµÐº)
FX_TRANSITION_DURATION = 0.35     # Ð´Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð¿ÐµÑ€ÐµÑ…Ð¾Ð´Ð° (ÑÐµÐº)
XFADE_TRANSITIONS = [
    "fade",
    "fadeblack",
    "fadewhite",
    "wipeleft",
    "wiperight",
    "wipeup",
    "wipedown",
    "smoothleft",
    "smoothright",
    "circleopen",
    "circleclose",
]
POI_POINTS_PER_MIN_RANGE = (1, 3)
POI_SPREAD_SECONDS = 2.0
POI_ANALYSIS_RESET = 1.0
POI_MAX_POINTS = 120
RATEGRP_PMV_MAX_QUEUE = 250
CLIP_HEAD_GUARD_SECONDS = 60
CLIP_TAIL_GUARD_SECONDS = 60
NAS_SSH_HOST = _get_private_setting("NAS_SSH_HOST", "")
NAS_SSH_PORT = _coerce_int(_get_private_setting("NAS_SSH_PORT", 22), 22)
NAS_SSH_USER = _get_private_setting("NAS_SSH_USER", "")
NAS_SSH_PASSWORD = _get_private_setting("NAS_SSH_PASSWORD", "")
NAS_SHARE_PREFIX = _get_private_setting("NAS_SHARE_PREFIX", "")
NAS_SHARE_ROOT = _get_private_setting("NAS_SHARE_ROOT", "")
NAS_SIM_REMOTE_ROOT = _get_private_setting("NAS_SIM_REMOTE_ROOT", "")
NAS_SYMLINK_COLOR_FOLDERS = {
    "green": "green",
    "yellow": "yellow",
    "red": "red",
    "pink": "pink",
    "blue": "blue",
    "favorite": "favorite",
    "inspect": "inspect",
    "delete": "delete",
}
NAS_SSH_TIMEOUT = _coerce_int(_get_private_setting("NAS_SSH_TIMEOUT", 30), 30)
NEWCOMPMUSIC_DURATION_BUCKETS = [
    ("short", "1â€“4 Ð¼Ð¸Ð½", 0, 4 * 60 + 59),
    ("medium", "5â€“8 Ð¼Ð¸Ð½", 5 * 60, 8 * 60 + 59),
    ("long", "9+ Ð¼Ð¸Ð½", 9 * 60, None),
]
NEWCOMPMUSIC_DURATION_LABELS = {key: label for key, label, _, _ in NEWCOMPMUSIC_DURATION_BUCKETS}

RANDOMPMV_COUNT_OPTIONS = [5, 10, 15, 20, 25, 30]
RANDOMPMV_MIN_BATCH = 1
RANDOMPMV_MAX_BATCH = 30
RANDOMPMV_SOURCES_PER_MINUTE = 5.0  # Ð±Ð°Ð·Ð¾Ð²Ð¾Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ, Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð¾ Ð´Ð»Ñ ÑÐ¾Ð²Ð¼ÐµÑÑ‚Ð¸Ð¼Ð¾ÑÑ‚Ð¸
RANDOMPMV_MIN_SOURCES_PER_MINUTE = 2.0
RANDOMPMV_MAX_SOURCES_PER_MINUTE = 5.0
RANDOMPMV_FULL_RATIO_MINUTES = 10.0
RANDOMPMV_NEW_SOURCE_CHOICES = [5, 10, 15, 20, 30, 40, 50, 60]
BADCLIP_MAX_MATCHES = 10

# =========================
# Telegram Ð´Ð¾ÑÑ‚ÑƒÐ¿
# =========================
# Ð’ÐŸÐ˜Ð¨Ð˜ Ð¡Ð’ÐžÐ˜ Ð—ÐÐÐ§Ð•ÐÐ˜Ð¯:
TELEGRAM_BOT_TOKEN = _get_private_setting("TELEGRAM_BOT_TOKEN", "")
_allowed_user_id_value = _get_private_setting("ALLOWED_USER_ID")
ALLOWED_USER_ID = _coerce_int(_allowed_user_id_value, 0)  # Ñ‚Ð²Ð¾Ð¹ Telegram user id (Ñ†ÐµÐ»Ð¾Ðµ Ñ‡Ð¸ÑÐ»Ð¾)

if not TELEGRAM_BOT_TOKEN:
    raise RuntimeError("ÐÐµ Ð·Ð°Ð´Ð°Ð½ TELEGRAM_BOT_TOKEN")
if not ALLOWED_USER_ID:
    raise RuntimeError("ÐÐµ Ð·Ð°Ð´Ð°Ð½ ALLOWED_USER_ID")

# =========================
# Ð‘ÐÐ—Ð Ð”ÐÐÐÐ«Ð¥ (SQLite)
# =========================

def get_conn() -> sqlite3.Connection:
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    return conn


def init_db() -> None:
    conn = get_conn()
    cur = conn.cursor()

    # Ð¢Ð°Ð±Ð»Ð¸Ñ†Ð° Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð²
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS sources (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            video_path TEXT NOT NULL UNIQUE,
            video_name TEXT NOT NULL,
            size_bytes INTEGER NOT NULL,
            codec TEXT,
            resolution TEXT,
            pmv_list TEXT DEFAULT '',
            comments TEXT DEFAULT '',
            date_added TEXT NOT NULL
        )
        """
    )

    # Ð¢Ð°Ð±Ð»Ð¸Ñ†Ð° ÐºÐ¾Ð¼Ð¿Ð¸Ð»ÑÑ†Ð¸Ð¹
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS compilations (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            video_path TEXT NOT NULL,
            pmv_date TEXT NOT NULL,
            source_ids TEXT NOT NULL,
            comments TEXT DEFAULT ''
        )
        """
    )

    # Ð¢Ð°Ð±Ð»Ð¸Ñ†Ð° ÐºÐ½Ð¾Ð¿Ð¾Ðº (Ñ‚ÐµÐ³Ð¸)
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS buttons (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            short_name TEXT NOT NULL UNIQUE,
            description TEXT NOT NULL
        )
        """
    )

    # Ð¢Ð°Ð±Ð»Ð¸Ñ†Ð° Ð¿Ð°Ð¿Ð¾Ðº Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS upload_folders (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            folder_path TEXT NOT NULL UNIQUE,
            date_added TEXT NOT NULL,
            ignored INTEGER NOT NULL DEFAULT 0
        )
        """
    )
    cur.execute("PRAGMA table_info(upload_folders)")
    upload_cols = [row[1] for row in cur.fetchall()]
    if "ignored" not in upload_cols:
        cur.execute(
            "ALTER TABLE upload_folders ADD COLUMN ignored INTEGER NOT NULL DEFAULT 0"
        )

    # Ð¢Ð°Ð±Ð»Ð¸Ñ†Ð° Ñ Ñ€Ð°Ð½Ð´Ð¾Ð¼Ð½Ñ‹Ð¼Ð¸ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸ÑÐ¼Ð¸ Ð´Ð»Ñ PMV
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS random_names (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            adjective TEXT NOT NULL,
            noun TEXT NOT NULL,
            verb TEXT NOT NULL,
            number INTEGER NOT NULL
        )
        """
    )

    # Ð—Ð°Ð¿Ð¾Ð»Ð½ÑÐµÐ¼ random_names, ÐµÑÐ»Ð¸ Ð¿ÑƒÑÑ‚Ð¾ (10 ÑÑ‚Ñ€Ð¾Ðº)
    cur.execute("SELECT COUNT(*) AS cnt FROM random_names")
    cnt = cur.fetchone()["cnt"]
    if cnt == 0:
        rows = [
            ("Ñ‚Ð¸Ñ…Ð¸Ð¹", "Ð¾ÐºÐµÐ°Ð½", "Ð´Ñ€ÐµÐ¹Ñ„ÑƒÐµÑ‚", 1),
            ("ÑÑ€ÐºÐ¸Ð¹", "Ð²ÐµÑ‚ÐµÑ€", "Ð¿Ð¾Ñ‘Ñ‚", 7),
            ("Ð±Ñ‹ÑÑ‚Ñ€Ñ‹Ð¹", "Ð¿ÑƒÐ»ÑŒÑ", "Ð·Ð°Ð¼Ð¸Ñ€Ð°ÐµÑ‚", 3),
            ("Ð½Ð¾Ñ‡Ð½Ð¾Ð¹", "Ð³Ð¾Ñ€Ð¾Ð´", "Ð´Ñ‹ÑˆÐ¸Ñ‚", 9),
            ("Ð¼ÐµÐ´Ð»ÐµÐ½Ð½Ñ‹Ð¹", "Ð¾Ð³Ð¾Ð½ÑŒ", "Ñ‚Ð°Ð½Ñ†ÑƒÐµÑ‚", 5),
            ("Ð·Ð¾Ð»Ð¾Ñ‚Ð¾Ð¹", "Ð·Ð°ÐºÐ°Ñ‚", "Ñ‚Ð°ÐµÑ‚", 2),
            ("Ð»Ñ‘Ð³ÐºÐ¸Ð¹", "Ð´Ñ‹Ð¼", "ÑÐºÐ¾Ð»ÑŒÐ·Ð¸Ñ‚", 8),
            ("Ð³Ð»ÑƒÐ±Ð¾ÐºÐ¸Ð¹", "Ñ€Ð¸Ñ‚Ð¼", "ÐºÐ°Ñ‡Ð°ÐµÑ‚", 4),
            ("ÑÑƒÐ¼Ñ€Ð°Ñ‡Ð½Ñ‹Ð¹", "ÑÐ²ÐµÑ‚", "Ð¼Ð°Ð½Ð¸Ñ‚", 6),
            ("Ð½ÐµÐ¶Ð½Ñ‹Ð¹", "ÑˆÑ‚Ð¾Ñ€Ð¼", "ÑˆÐµÐ¿Ñ‡ÐµÑ‚", 10),
        ]
        cur.executemany(
            "INSERT INTO random_names (adjective, noun, verb, number) VALUES (?, ?, ?, ?)",
            rows,
        )

    conn.commit()
    conn.close()

def db_get_all_compilations() -> List[sqlite3.Row]:
    conn = get_conn()
    cur = conn.cursor()
    # ÑÐ²ÐµÐ¶Ð¸Ðµ ÑÐ²ÐµÑ€Ñ…Ñƒ
    cur.execute(
        """
        SELECT id, video_path, pmv_date, source_ids, comments
        FROM compilations
        ORDER BY pmv_date DESC, id DESC
        """
    )
    rows = cur.fetchall()
    conn.close()
    return rows


def db_append_compilation_comment(comp_id: int, new_piece: str) -> None:
    conn = get_conn()
    cur = conn.cursor()
    cur.execute("SELECT comments FROM compilations WHERE id = ?", (comp_id,))
    row = cur.fetchone()
    if not row:
        conn.close()
        return
    current = (row["comments"] or "").strip()
    if not current:
        updated = new_piece
    else:
        updated = current + " | " + new_piece
    cur.execute("UPDATE compilations SET comments = ? WHERE id = ?", (updated, comp_id))
    conn.commit()
    conn.close()


def db_append_source_comment(source_id: int, new_piece: str) -> None:
    conn = get_conn()
    cur = conn.cursor()
    cur.execute("SELECT comments FROM sources WHERE id = ?", (source_id,))
    row = cur.fetchone()
    if not row:
        conn.close()
        return
    current = (row["comments"] or "").strip()
    if not current:
        updated = new_piece
    else:
        updated = current + " | " + new_piece
    cur.execute("UPDATE sources SET comments = ? WHERE id = ?", (updated, source_id))
    conn.commit()
    conn.close()


def combine_comments(*pieces: Optional[str]) -> str:
    parts = [p.strip() for p in pieces if p and p.strip()]
    return " | ".join(parts)


def _append_jsonl(path: Path, payload: Dict[str, Any]) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    with path.open("a", encoding="utf-8") as fh:
        json.dump(payload, fh, ensure_ascii=False)
        fh.write("\n")


def log_randompmv_event(event: Dict[str, Any]) -> None:
    payload = dict(event)
    payload.setdefault("timestamp", datetime.now().isoformat(timespec="seconds"))
    _append_jsonl(RANDOMPMV_LOG_PATH, payload)


def _randompmv_compute_target_sources(duration_minutes: float) -> Tuple[int, float]:
    minutes = max(1.0, float(duration_minutes))
    if minutes >= RANDOMPMV_FULL_RATIO_MINUTES:
        per_minute = RANDOMPMV_MAX_SOURCES_PER_MINUTE
    else:
        span = max(1.0, RANDOMPMV_FULL_RATIO_MINUTES - 1.0)
        progress = max(0.0, min(1.0, (minutes - 1.0) / span))
        per_minute = RANDOMPMV_MIN_SOURCES_PER_MINUTE + (
            (RANDOMPMV_MAX_SOURCES_PER_MINUTE - RANDOMPMV_MIN_SOURCES_PER_MINUTE) * progress
        )
    per_minute = max(
        RANDOMPMV_MIN_SOURCES_PER_MINUTE,
        min(per_minute, RANDOMPMV_MAX_SOURCES_PER_MINUTE),
    )
    return max(1, math.ceil(minutes * per_minute)), per_minute


def log_codex_feedback(thought: str, assumption: str, actions: Optional[str] = None, meta: Optional[Dict[str, Any]] = None) -> None:
    entry: Dict[str, Any] = {
        "timestamp": datetime.now().isoformat(timespec="seconds"),
        "thought": thought,
        "assumption": assumption,
    }
    if actions:
        entry["actions"] = actions
    if meta:
        entry["meta"] = meta
    _append_jsonl(CODEX_FEEDBACK_LOG_PATH, entry)


def parse_source_id_list(field: str) -> List[int]:
    result: List[int] = []
    if not field:
        return result
    for token in field.replace(";", ",").split(","):
        token = token.strip()
        if token.isdigit():
            result.append(int(token))
    return result


def merge_pmv_lists(*values: Optional[str]) -> str:
    """
    ÐžÐ±ÑŠÐµÐ´Ð¸Ð½ÑÐµÑ‚ ÑÐ¿Ð¸ÑÐºÐ¸ PMV-ÑƒÑ‡Ð°ÑÑ‚Ð¸Ð¹ Ð±ÐµÐ· Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ð¾Ð², ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÑ Ð¿Ð¾Ñ€ÑÐ´Ð¾Ðº Ð¿Ð¾ÑÐ²Ð»ÐµÐ½Ð¸Ñ.
    """
    merged: List[str] = []
    seen: Set[str] = set()
    for value in values:
        if not value:
            continue
        for piece in value.split(","):
            cleaned = piece.strip()
            if cleaned and cleaned not in seen:
                seen.add(cleaned)
                merged.append(cleaned)
    return ", ".join(merged)


def db_add_upload_folder(folder_path: str, ignored: bool = False) -> None:
    conn = get_conn()
    cur = conn.cursor()
    cur.execute(
        """
        INSERT INTO upload_folders (folder_path, date_added, ignored)
        VALUES (?, ?, ?)
        ON CONFLICT(folder_path) DO UPDATE SET ignored = excluded.ignored
        """,
        (folder_path, date.today().isoformat(), int(ignored)),
    )
    conn.commit()
    conn.close()


def db_add_scan_ignore(folder_path: str) -> None:
    db_add_upload_folder(folder_path, ignored=True)


def db_get_upload_folders(include_ignored: bool = False) -> List[sqlite3.Row]:
    conn = get_conn()
    cur = conn.cursor()
    if include_ignored:
        cur.execute("SELECT * FROM upload_folders ORDER BY id")
    else:
        cur.execute("SELECT * FROM upload_folders WHERE ignored = 0 ORDER BY id")
    rows = cur.fetchall()
    conn.close()
    return rows


def db_get_scan_ignored_folders() -> List[sqlite3.Row]:
    conn = get_conn()
    cur = conn.cursor()
    cur.execute("SELECT * FROM upload_folders WHERE ignored = 1 ORDER BY id")
    rows = cur.fetchall()
    conn.close()
    return rows


def db_insert_source(
    video_path: Path,
    codec: str,
    resolution: str,
    size_bytes: Optional[int] = None,
    video_name: Optional[str] = None,
) -> Optional[int]:
    p = video_path.resolve()
    size_bytes = size_bytes if size_bytes is not None else p.stat().st_size
    video_name = video_name or p.name
    conn = get_conn()
    cur = conn.cursor()
    try:
        cur.execute(
            """
            INSERT INTO sources (video_path, video_name, size_bytes, codec, resolution, date_added)
            VALUES (?, ?, ?, ?, ?, ?)
            """,
            (
                str(p),
                video_name,
                size_bytes,
                codec,
                resolution,
                date.today().isoformat(),
            ),
        )
        conn.commit()
        return int(cur.lastrowid)
    except sqlite3.IntegrityError:
        return None
    finally:
        conn.close()


def db_get_unused_sources_grouped() -> Dict[Tuple[str, str], List[sqlite3.Row]]:
    conn = get_conn()
    cur = conn.cursor()
    cur.execute(
        """
        SELECT * FROM sources
        WHERE pmv_list IS NULL OR pmv_list = ''
        """
    )
    rows = cur.fetchall()
    conn.close()

    groups: Dict[Tuple[str, str], List[sqlite3.Row]] = {}
    for r in rows:
        codec = r["codec"] or "?"
        resolution = r["resolution"] or "??x??"
        key = (codec, resolution)
        groups.setdefault(key, []).append(r)
    return groups


def db_search_sources_by_term(term: str, limit: int = 50) -> List[sqlite3.Row]:
    conn = get_conn()
    cur = conn.cursor()
    pattern = f"%{term.lower()}%"
    cur.execute(
        """
        SELECT *
        FROM sources
        WHERE lower(video_name) LIKE ? OR lower(video_path) LIKE ?
        ORDER BY date_added DESC, id DESC
        LIMIT ?
        """,
        (pattern, pattern, int(limit)),
    )
    rows = cur.fetchall()
    conn.close()
    return rows

def db_get_all_sources_grouped() -> Dict[Tuple[str, str], List[sqlite3.Row]]:
    """
    Ð‘ÐµÑ€Ñ‘Ñ‚ Ð’Ð¡Ð• Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¸ (Ð¸ ÑƒÐ¶Ðµ ÑƒÑ‡Ð°ÑÑ‚Ð²Ð¾Ð²Ð°Ð²ÑˆÐ¸Ðµ, Ð¸ Ð½ÐµÑ‚)
    Ð¸ Ð³Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€ÑƒÐµÑ‚ Ð¿Ð¾ (codec, resolution).
    """
    conn = get_conn()
    cur = conn.cursor()
    cur.execute("SELECT * FROM sources")
    rows = cur.fetchall()
    conn.close()

    groups: Dict[Tuple[str, str], List[sqlite3.Row]] = {}
    for r in rows:
        codec = r["codec"] or "?"
        resolution = r["resolution"] or "??x??"
        key = (codec, resolution)
        groups.setdefault(key, []).append(r)
    return groups


def load_music_projects() -> List[Dict[str, Any]]:
    projects: List[Dict[str, Any]] = []
    if not MUSIC_PROJECTS_DIR.exists():
        return projects

    usage_map = collect_music_project_usage()

    for entry in MUSIC_PROJECTS_DIR.iterdir():
        if not entry.is_dir():
            continue
        manifest_path = entry / "manifest.json"
        audio_path = entry / "audio.mp3"
        usage_info = usage_map.get(entry.name, {"count": 0, "last_date": None})
        try:
            manifest_data: Dict[str, Any] = {}
            segments_count = 0
            total_duration = None
            if manifest_path.exists():
                manifest_data = json.loads(manifest_path.read_text(encoding="utf-8"))
                segments = (manifest_data.get("analysis") or {}).get("segments") or []
                segments_count = len(segments)
                if segments:
                    total_duration = float(segments[-1].get("end", 0.0) or 0.0)
            projects.append(
                {
                    "slug": entry.name,
                    "name": manifest_data.get("name") or entry.name,
                    "dir": entry,
                    "manifest_path": manifest_path,
                    "audio_path": audio_path if audio_path.exists() else None,
                    "segments_count": segments_count,
                    "duration": total_duration,
                    "manifest_data": manifest_data or None,
                    "usage_count": usage_info.get("count", 0),
                    "last_used": usage_info.get("last_date"),
                }
            )
        except Exception as exc:
            projects.append(
                {
                    "slug": entry.name,
                    "name": f"{entry.name} (Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð¼Ð°Ð½Ð¸Ñ„ÐµÑÑ‚Ð°: {exc})",
                    "dir": entry,
                    "manifest_path": manifest_path,
                    "audio_path": audio_path if audio_path.exists() else None,
                    "segments_count": 0,
                    "duration": None,
                    "manifest_data": None,
                    "usage_count": usage_info.get("count", 0),
                    "last_used": usage_info.get("last_date"),
                }
            )

    projects.sort(key=lambda p: (p.get("usage_count", 0), p["name"].lower()))
    return projects


def collect_music_project_usage() -> Dict[str, Dict[str, Any]]:
    usage: Dict[str, Dict[str, Any]] = {}
    conn = get_conn()
    cur = conn.cursor()
    cur.execute("SELECT pmv_date, comments FROM compilations WHERE comments LIKE '%music_project=%'")
    rows = cur.fetchall()
    conn.close()

    for row in rows:
        comments = row["comments"] or ""
        date_str = row["pmv_date"]
        try:
            pmv_date = datetime.strptime(date_str, "%Y-%m-%d").date()
        except Exception:
            pmv_date = None
        for match in re.findall(r"music_project=([\w\-]+)", comments):
            info = usage.setdefault(match, {"count": 0, "last_date": None})
            info["count"] += 1
            if pmv_date and (info["last_date"] is None or pmv_date > info["last_date"]):
                info["last_date"] = pmv_date
    return usage


def _normalize_path_str(path_like: Union[str, Path]) -> str:
    if isinstance(path_like, Path):
        raw = path_like
    else:
        raw = Path(str(path_like))
    try:
        return str(raw.resolve(strict=False)).lower()
    except Exception:
        return str(raw).lower()


def _normalize_path_prefix(path_like: Union[str, Path]) -> str:
    normalized = _normalize_path_str(path_like)
    normalized = normalized.replace("\\", "/").rstrip("/")
    return normalized


def _is_path_under_prefixes(
    target_path: Union[str, Path], prefixes: Iterable[str]
) -> bool:
    target = _normalize_path_prefix(target_path)
    for prefix in prefixes:
        if not prefix:
            continue
        check = prefix.rstrip("/")
        if target == check or target.startswith(check + "/"):
            return True
    return False


def collect_music_track_usage() -> Dict[str, int]:
    usage: Dict[str, int] = {}
    if not MUSIC_PROJECTS_DIR.exists():
        return usage

    input_by_name: Dict[str, str] = {
        p.name.lower(): _normalize_path_str(p) for p in list_music_input_files()
    }

    for entry in MUSIC_PROJECTS_DIR.iterdir():
        if not entry.is_dir():
            continue
        manifest_path = entry / "manifest.json"
        if not manifest_path.exists():
            continue
        try:
            data = json.loads(manifest_path.read_text(encoding="utf-8"))
        except Exception:
            continue
        source_file = data.get("source_file") or data.get("original_audio")
        if not source_file:
            audio_path = data.get("audio_path")
            if audio_path:
                # Backward compatibility: older manifests did not store source_file.
                candidate = input_by_name.get(Path(audio_path).name.lower())
                if candidate:
                    source_file = candidate
        if not source_file:
            continue
        norm = _normalize_path_str(source_file)
        if not norm:
            continue
        usage[norm] = usage.get(norm, 0) + 1
    return usage


TRACK_SPLIT_RE = re.compile(r"\s*[-â€“â€”]\s*")
SLUG_TOKEN_RE = re.compile(r"[^a-z0-9]+")


def truncate_button_label(text: str, max_len: int = 30) -> str:
    text = text.strip()
    if len(text) <= max_len:
        return text
    return text[: max_len - 1] + "â€¦"


def truncate_label_keep_suffix(text: str, max_len: int = 30) -> str:
    text = text.strip()
    if len(text) <= max_len:
        return text
    return "â€¦" + text[-(max_len - 1):]


def extract_track_title_components(path: Path) -> Tuple[str, str]:
    stem = path.stem.strip()
    normalized = stem.replace("â€”", "-").replace("â€“", "-")
    parts = [p.strip() for p in normalized.split("-", 1)]
    if len(parts) == 2:
        artist, title = parts
    else:
        artist, title = "", stem
    return artist, title or stem


def slugify_token(value: str) -> str:
    if not value:
        return "project"
    normalized = unicodedata.normalize("NFKD", value).encode("ascii", "ignore").decode("ascii")
    slug = SLUG_TOKEN_RE.sub("_", normalized.lower()).strip("_")
    return slug or "project"


def build_main_reply_keyboard() -> ReplyKeyboardMarkup:
    """
    ÐŸÐ¾ÑÑ‚Ð¾ÑÐ½Ð½Ð¾Ðµ Ð¼ÐµÐ½ÑŽ ÑÐ½Ð¸Ð·Ñƒ Ñ Ð¾ÑÐ½Ð¾Ð²Ð½Ñ‹Ð¼Ð¸ ÐºÐ¾Ð¼Ð°Ð½Ð´Ð°Ð¼Ð¸.
    """
    rows = [
        [KeyboardButton("musicprep"), KeyboardButton("newcompmusic")],
        [KeyboardButton("rategrp"), KeyboardButton("ÐÐ°Ð¹Ñ‚Ð¸")],
        [KeyboardButton("CreateRandomPMV"), KeyboardButton("ÐžÑ‚Ñ‡Ñ‘Ñ‚Ñ‹")],
        [KeyboardButton("scan")],
    ]
    return ReplyKeyboardMarkup(rows, resize_keyboard=True, one_time_keyboard=False)


def build_reports_keyboard() -> InlineKeyboardMarkup:
    rows = [
        [InlineKeyboardButton("ðŸŸ¢ + Ð“Ñ€ÑƒÐ¿Ð¿Ñ‹", callback_data="report_group:green")],
        [InlineKeyboardButton("ðŸŸ¡ + Ð“Ñ€ÑƒÐ¿Ð¿Ñ‹", callback_data="report_group:yellow")],
        [InlineKeyboardButton("ðŸ”´ + Ð“Ñ€ÑƒÐ¿Ð¿Ñ‹", callback_data="report_group:red")],
        [InlineKeyboardButton("ðŸ©· + Ð“Ñ€ÑƒÐ¿Ð¿Ñ‹", callback_data="report_group:pink")],
    ]
    return InlineKeyboardMarkup(rows)


def build_newcomp_duration_keyboard() -> InlineKeyboardMarkup:
    rows = [
        [InlineKeyboardButton(label, callback_data=f"newcomp_bucket:{key}")]
        for key, label, _, _ in NEWCOMPMUSIC_DURATION_BUCKETS
    ]
    rows.append([InlineKeyboardButton("â†©ï¸ ÐÐ¾Ð²Ñ‹Ðµ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ñ‹", callback_data="newcomp_show:unused")])
    return InlineKeyboardMarkup(rows)


def project_duration_seconds(project: Dict[str, Any]) -> Optional[int]:
    duration = project.get("duration")
    if duration is not None:
        try:
            return max(0, int(float(duration)))
        except Exception:
            pass
    manifest = project.get("manifest_data") or {}
    manifest_dur = manifest.get("duration")
    if manifest_dur:
        try:
            return max(0, int(float(manifest_dur)))
        except Exception:
            pass
    segments = project.get("parsed_segments") or []
    if segments:
        try:
            return max(0, int(float(segments[-1].end)))
        except Exception:
            pass
    return None


def project_matches_duration(project: Optional[Dict[str, Any]], bucket_key: Optional[str]) -> bool:
    if not bucket_key:
        return True
    if not project:
        return False
    seconds = project_duration_seconds(project)
    if seconds is None:
        return bucket_key == "long"
    for key, _, min_sec, max_sec in NEWCOMPMUSIC_DURATION_BUCKETS:
        if key != bucket_key:
            continue
        if max_sec is None:
            return seconds >= min_sec
        return min_sec <= seconds <= max_sec
    return True


def filter_project_tokens_by_duration(
    session: Dict[str, Any],
    tokens: List[str],
    bucket_key: Optional[str],
) -> List[str]:
    if not bucket_key:
        return tokens
    project_map: Dict[str, Dict[str, Any]] = session.get("music_projects_map") or {}
    filtered: List[str] = []
    for token in tokens:
        project = project_map.get(token)
        if project_matches_duration(project, bucket_key):
            filtered.append(token)
    return filtered


def build_musicprep_track_keyboard(
    session: Dict[str, Any],
    show_used: bool,
) -> Tuple[str, InlineKeyboardMarkup]:
    track_map: Dict[str, Dict[str, Any]] = session.get("music_tracks") or {}
    tokens = session.get("music_tracks_used" if show_used else "music_tracks_unused") or []
    def sort_key(token: str) -> Tuple[int, str]:
        info = track_map.get(token) or {}
        count = int(info.get("usage") or 0)
        path = Path(info.get("path") or "")
        _, title = extract_track_title_components(path)
        return (count, title.lower())
    tokens = sorted(tokens, key=sort_key)
    rows: List[List[InlineKeyboardButton]] = []
    for token in tokens:
        info = track_map.get(token)
        if not info:
            continue
        path = Path(info["path"])
        _, title = extract_track_title_components(path)
        count = int(info.get("usage") or 0)
        base_label = f"{count} Â· {title}"
        label = truncate_button_label(base_label)
        rows.append([InlineKeyboardButton(label or "?", callback_data=f"musicprep_track:{token}")])

    toggle_target = "unused" if show_used else "used"
    toggle_label = "ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ Ð½Ð¾Ð²Ñ‹Ðµ" if show_used else "ÐŸÐ¾ÑÐ¼Ð¾Ñ‚Ñ€ÐµÑ‚ÑŒ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ"
    rows.append([InlineKeyboardButton(toggle_label, callback_data=f"musicprep_show:{toggle_target}")])

    if not tokens:
        text = (
            "Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ñ‚Ñ€ÐµÐºÐ¾Ð² Ð¿Ð¾ÐºÐ° Ð½ÐµÑ‚." if show_used else "ÐÐ¾Ð²Ñ‹Ñ… Ñ‚Ñ€ÐµÐºÐ¾Ð² Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾."
        )
    else:
        text = "ðŸŽµ Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ñ‚Ñ€ÐµÐºÐ¸:" if show_used else "ðŸŽµ Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ðµ Ñ‚Ñ€ÐµÐºÐ¸ (Ð½Ð¾Ð²Ñ‹Ðµ):"
    return text, InlineKeyboardMarkup(rows)


def build_musicprep_seconds_keyboard() -> InlineKeyboardMarkup:
    zero_row = [InlineKeyboardButton("0", callback_data="musicprep_seconds:0")]
    first_row = [InlineKeyboardButton(str(i), callback_data=f"musicprep_seconds:{i}") for i in range(1, 6)]
    second_row = [InlineKeyboardButton(str(i), callback_data=f"musicprep_seconds:{i}") for i in range(6, 11)]
    third_row = [InlineKeyboardButton(str(i), callback_data=f"musicprep_seconds:{i}") for i in range(11, 15)]
    fourth_row = [InlineKeyboardButton("15", callback_data="musicprep_seconds:15")]
    return InlineKeyboardMarkup([zero_row, first_row, second_row, third_row, fourth_row])


def build_musicprep_mode_keyboard() -> InlineKeyboardMarkup:
    row = [
        InlineKeyboardButton("beat", callback_data="musicprep_mode:beat"),
        InlineKeyboardButton("onset", callback_data="musicprep_mode:onset"),
        InlineKeyboardButton("uniform", callback_data="musicprep_mode:uniform"),
    ]
    return InlineKeyboardMarkup([row])


MUSICPREP_SENSITIVITY_PRESETS: Dict[str, List[Dict[str, Any]]] = {
    "beat": [
        {
            "key": "soft",
            "label": "Ð§ÑƒÐ²ÑÑ‚Ð²Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ (Ð»Ð¾Ð²Ð¸Ñ‚ÑŒ Ñ…ÑÑ‚Ñ‹)",
            "description": "Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÑ‚ ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ñ‹ Ð½Ð° Ñ‚Ð¸Ñ…Ð¸Ñ… Ð´Ð¾Ð»ÑÑ….",
            "analysis_kwargs": {"beat_tightness": 0.6, "sensitivity_scale": 1.4},
        },
        {
            "key": "default",
            "label": "Ð¡Ñ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ñ‹Ð¹",
            "description": "Ð¡Ð±Ð°Ð»Ð°Ð½ÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼.",
            "analysis_kwargs": {},
        },
        {
            "key": "tight",
            "label": "Ð¢Ð¾Ð»ÑŒÐºÐ¾ ÑÐ¸Ð»ÑŒÐ½Ñ‹Ðµ Ð´Ð¾Ð»Ð¸",
            "description": "ÐŸÑ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÑ‚ ÑÐ»Ð°Ð±Ñ‹Ðµ ÑƒÐ´Ð°Ñ€Ñ‹ Ð¸ Ñ‚Ð¸ÑˆÐ¸Ð½Ñƒ.",
            "analysis_kwargs": {"beat_tightness": 2.0, "sensitivity_scale": 0.85},
        },
    ],
    "onset": [
        {
            "key": "soft",
            "label": "Ð‘Ð¾Ð»ÑŒÑˆÐµ Ð²ÑÐ¿Ð»ÐµÑÐºÐ¾Ð²",
            "description": "Ð§ÑƒÐ²ÑÑ‚Ð²Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ðº Ñ…Ð°Ð¹-Ñ…ÑÑ‚Ð°Ð¼.",
            "analysis_kwargs": {"onset_delta": 0.02, "sensitivity_scale": 1.5},
        },
        {
            "key": "default",
            "label": "Ð¡Ñ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ñ‹Ð¹",
            "description": "Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹.",
            "analysis_kwargs": {},
        },
        {
            "key": "tight",
            "label": "Ð¢Ð¾Ð»ÑŒÐºÐ¾ Ð³Ñ€Ð¾Ð¼ÐºÐ¸Ðµ Ð¿Ð¸ÐºÐ¸",
            "description": "Ð¤Ð¾ÐºÑƒÑ Ð½Ð° Ð¼Ð¾Ñ‰Ð½Ñ‹Ñ… ÑƒÐ´Ð°Ñ€Ð°Ñ….",
            "analysis_kwargs": {"onset_delta": 0.12, "sensitivity_scale": 0.8},
        },
    ],
}


def get_musicprep_sensitivity_options(mode: str) -> List[Dict[str, Any]]:
    return MUSICPREP_SENSITIVITY_PRESETS.get(mode, [])


def build_musicprep_sensitivity_keyboard(mode: str) -> InlineKeyboardMarkup:
    options = get_musicprep_sensitivity_options(mode)
    rows: List[List[InlineKeyboardButton]] = []
    for opt in options:
        rows.append(
            [
                InlineKeyboardButton(
                    opt["label"], callback_data=f"musicprep_sens:{mode}:{opt['key']}"
                )
            ]
        )
    if not rows:
        rows = [[InlineKeyboardButton("Ð¡Ñ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚", callback_data="musicprep_sens:auto:default")]]
    return InlineKeyboardMarkup(rows)


async def finalize_musicprep_project(
    send_func: Callable[[str], Awaitable[None]],
    sess: Dict[str, Any],
    user_id: int,
    mode: str,
    analysis_kwargs: Optional[Dict[str, Any]] = None,
) -> None:
    file_str = sess.get("musicprep_file")
    if not file_str:
        return await send_func("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ñ‚ÑŒ Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð½Ñ‹Ð¹ Ñ‚Ñ€ÐµÐº.")

    file_path = Path(file_str)
    mod = load_music_generator_module()

    segment_len = sess.get("musicprep_segment")
    if segment_len is None:
        segment_len = getattr(mod, "DEFAULT_TARGET_SEGMENT", 1.0)

    project_partial = sess.get("musicprep_project_partial")
    if project_partial:
        project_name = f"{project_partial}_{mode}"
    else:
        project_name = sess.get("musicprep_name")

    try:
        manifest = mod.create_music_project(
            mp3_path=file_path,
            name=project_name,
            target_segment=float(segment_len),
            segment_mode=mode,
            analysis_kwargs=analysis_kwargs or {},
        )
    except Exception as exc:
        user_sessions.pop(user_id, None)
        return await send_func(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ð¸ Ð¼ÑƒÐ·Ñ‹ÐºÐ°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°: {exc}")

    user_sessions.pop(user_id, None)
    await send_func(
        "âœ… ÐœÑƒÐ·Ñ‹ÐºÐ°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¿Ñ€Ð¾ÐµÐºÑ‚ ÑÐ¾Ð·Ð´Ð°Ð½.\n"
        f"Ð˜Ð¼Ñ: {manifest.name}\n"
        f"Slug: {manifest.slug}\n"
        f"Ð¤Ð°Ð¹Ð»: {manifest.audio_path}\n"
        f"Ð¡ÐµÐ³Ð¼ÐµÐ½Ñ‚Ð¾Ð²: {len(manifest.analysis.segments)}\n"
        f"Ð ÐµÐ¶Ð¸Ð¼: {manifest.analysis.mode}"
    )


def build_musicprepcheck_keyboard(projects: List[Dict[str, Any]]) -> InlineKeyboardMarkup:
    buttons: List[List[InlineKeyboardButton]] = []
    sorted_projects = sorted(
        projects,
        key=lambda proj: proj.get("manifest_data", {}).get("created_at")
        or proj.get("created_at")
        or "",
        reverse=True,
    )
    rows: List[List[InlineKeyboardButton]] = []
    for proj in sorted_projects:
        slug = proj.get("slug") or sanitize_filename(proj.get("name") or "project")
        name = proj.get("name") or proj.get("slug")
        segs = proj.get("segments_count") or 0
        label = truncate_label_keep_suffix(f"{name} ({segs} ÑÐµÐ³)")
        rows.append(
            [InlineKeyboardButton(label or slug or "?", callback_data=f"musicprepcheck_project:{slug}")]
        )
    return InlineKeyboardMarkup(rows or [[InlineKeyboardButton("ÐÐµÑ‚ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð¾Ð²", callback_data="noop")]])


def build_newcomp_project_keyboard(session: Dict[str, Any], show_used: bool) -> Tuple[str, InlineKeyboardMarkup]:
    projects_map: Dict[str, Dict[str, Any]] = session.get("music_projects_map") or {}
    tokens = session.get("music_projects_used" if show_used else "music_projects_unused") or []
    duration_filter = session.get("music_projects_duration_filter") if show_used else None
    if show_used:
        tokens = filter_project_tokens_by_duration(session, tokens, duration_filter)
    rows: List[List[InlineKeyboardButton]] = []

    for token in tokens:
        proj = projects_map.get(token)
        if not proj:
            continue
        label = truncate_button_label(proj["name"])
        usage = proj.get("usage_count") or 0
        if show_used and usage:
            label = truncate_button_label(f"{label} ({usage})")
        rows.append([InlineKeyboardButton(label or token, callback_data=f"newcomp_project:{token}")])

    toggle_target = "unused" if show_used else "used"
    toggle_label = "ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ Ð½Ð¾Ð²Ñ‹Ðµ" if show_used else "ÐŸÐ¾ÑÐ¼Ð¾Ñ‚Ñ€ÐµÑ‚ÑŒ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ"
    if show_used:
        rows.append([InlineKeyboardButton("Ð˜Ð·Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ Ð´Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ", callback_data="newcomp_bucket_menu")])
    rows.append([InlineKeyboardButton(toggle_label, callback_data=f"newcomp_show:{toggle_target}")])

    if not tokens:
        if show_used:
            label = NEWCOMPMUSIC_DURATION_LABELS.get(duration_filter or "", "Ð»ÑŽÐ±Ð¾Ð¹ Ð´Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸")
            text = f"Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼Ñ‹Ñ… Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð¾Ð² ({label}) Ð¿Ð¾ÐºÐ° Ð½ÐµÑ‚."
        else:
            text = "ÐÐ¾Ð²Ñ‹Ñ… Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð¾Ð² Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾."
    else:
        if show_used:
            label = NEWCOMPMUSIC_DURATION_LABELS.get(duration_filter or "", "Ð»ÑŽÐ±Ð¾Ð¹ Ð´Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸")
            text = f"ðŸŽµ Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼Ñ‹Ðµ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ñ‹ ({label}):"
        else:
            text = "ðŸŽµ Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ðµ Ð½Ð¾Ð²Ñ‹Ðµ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ñ‹:"
    return text, InlineKeyboardMarkup(rows)


async def prompt_newcomp_duration(
    session: Dict[str, Any],
    send_fn: Callable[[str, Optional[InlineKeyboardMarkup]], Awaitable[Any]],
) -> None:
    session["state"] = "newcompmusic_choose_duration"
    await send_fn("Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð´Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼Ñ‹Ñ… Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð¾Ð²:", build_newcomp_duration_keyboard())


def build_numeric_keyboard(prefix: str, total: int, per_row: int = 5) -> InlineKeyboardMarkup:
    rows: List[List[InlineKeyboardButton]] = []
    row: List[InlineKeyboardButton] = []
    for i in range(1, total + 1):
        row.append(InlineKeyboardButton(str(i), callback_data=f"{prefix}:{i}"))
        if len(row) >= per_row:
            rows.append(row)
            row = []
    if row:
        rows.append(row)
    return InlineKeyboardMarkup(rows or [[InlineKeyboardButton("1", callback_data=f"{prefix}:1")]])


NEWCOMPMUSIC_SOURCE_CHOICES = [5, 10, 20, 30, 50, 60, 80, 100]
NEWCOMPMUSIC_ORIENTATION_CHOICES = ("VR", "HOR", "VER")
RATEGRP_COLOR_CHOICES: Dict[str, Dict[str, str]] = {
    "green": {"emoji": "ðŸŸ¢", "label": "Ð·ÐµÐ»Ñ‘Ð½Ð°Ñ"},
    "yellow": {"emoji": "ðŸŸ¡", "label": "Ð¶Ñ‘Ð»Ñ‚Ð°Ñ"},
    "red": {"emoji": "ðŸ”´", "label": "ÐºÑ€Ð°ÑÐ½Ð°Ñ"},
    "pink": {"emoji": "ðŸ©·", "label": "Ñ€Ð¾Ð·Ð¾Ð²Ð°Ñ"},
    "blue": {"emoji": "ðŸ”µ", "label": "ÑÐ¸Ð½ÑÑ"},
    "favorite": {"emoji": "â­", "label": "Ð¸Ð·Ð±Ñ€Ð°Ð½Ð½Ð¾Ðµ"},
    "inspect": {"emoji": "ðŸ‘", "label": "Ð¿Ñ€Ð¸ÑÐ¼Ð¾Ñ‚Ñ€ÐµÑ‚ÑŒÑÑ"},
    "delete": {"emoji": "âŒ", "label": "ÑƒÐ´Ð°Ð»Ð¸Ñ‚ÑŒ"},
}
RATEGRP_COLOR_EMOJIS = tuple(choice["emoji"] for choice in RATEGRP_COLOR_CHOICES.values())
RATEGRP_COLOR_PROMPT = " / ".join(choice["emoji"] for choice in RATEGRP_COLOR_CHOICES.values())

# Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð² NAS_SYMLINK_COLOR_FOLDERS Ð°Ð»Ð¸Ð°ÑÑ‹ Ð¿Ð¾ ÑÐ¼Ð¾Ð´Ð·Ð¸, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð½Ðµ Ð·Ð°Ð²Ð¸ÑÐµÑ‚ÑŒ
# Ð¾Ñ‚ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ñ… ÐºÐ»ÑŽÑ‡ÐµÐ¹ Ñ†Ð²ÐµÑ‚Ð¾Ð².
for _color_key, _color_info in RATEGRP_COLOR_CHOICES.items():
    _emoji = _color_info["emoji"]
    _folder = NAS_SYMLINK_COLOR_FOLDERS.get(_color_key)
    if _folder and _emoji not in NAS_SYMLINK_COLOR_FOLDERS:
        NAS_SYMLINK_COLOR_FOLDERS[_emoji] = _folder


def extract_color_emoji(text: Optional[str]) -> Optional[str]:
    if not text:
        return None
    for emoji in RATEGRP_COLOR_EMOJIS:
        if emoji in text:
            return emoji
    return None


def db_set_source_color(source_id: int, emoji: str) -> Optional[str]:
    conn = get_conn()
    cur = conn.cursor()
    cur.execute("SELECT comments FROM sources WHERE id = ?", (source_id,))
    row = cur.fetchone()
    if not row:
        conn.close()
        return None
    current = (row["comments"] or "").strip()
    parts = [part.strip() for part in current.split("|") if part.strip()]
    parts = [
        part
        for part in parts
        if not any(color_emoji in part for color_emoji in RATEGRP_COLOR_EMOJIS)
    ]
    parts.append(f"color={emoji}")
    updated = " | ".join(parts)
    cur.execute("UPDATE sources SET comments = ? WHERE id = ?", (updated, source_id))
    conn.commit()
    conn.close()
    return updated


def build_newcomp_sources_keyboard() -> InlineKeyboardMarkup:
    rows: List[List[InlineKeyboardButton]] = []
    row: List[InlineKeyboardButton] = []
    for count in NEWCOMPMUSIC_SOURCE_CHOICES:
        row.append(InlineKeyboardButton(str(count), callback_data=f"newcomp_sources:{count}"))
        if len(row) == 4:
            rows.append(row)
            row = []
    if row:
        rows.append(row)
    return InlineKeyboardMarkup(rows)


def build_newcomp_orientation_keyboard() -> InlineKeyboardMarkup:
    buttons = [
        InlineKeyboardButton(label, callback_data=f"newcomp_orient:{label}")
        for label in NEWCOMPMUSIC_ORIENTATION_CHOICES
    ]
    return InlineKeyboardMarkup([buttons])


def build_rategrp_orientation_keyboard() -> InlineKeyboardMarkup:
    buttons = [
        InlineKeyboardButton(label, callback_data=f"rategrp_orient:{label}")
        for label in NEWCOMPMUSIC_ORIENTATION_CHOICES
    ]
    extra = [InlineKeyboardButton("Ð˜Ð— PMV", callback_data="rategrp_from_pmv")]
    return InlineKeyboardMarkup([buttons, extra])


def build_rategrp_color_keyboard() -> InlineKeyboardMarkup:
    rows: List[List[InlineKeyboardButton]] = []
    row: List[InlineKeyboardButton] = []
    for idx, (key, choice) in enumerate(RATEGRP_COLOR_CHOICES.items(), 1):
        row.append(InlineKeyboardButton(choice["emoji"], callback_data=f"rategrp_color:{key}"))
        if len(row) == 4:
            rows.append(row)
            row = []
    if row:
        rows.append(row)
    return InlineKeyboardMarkup(rows)


def build_rategrp_rerate_keyboard(
    available: List[Tuple[str, str, int]]
) -> InlineKeyboardMarkup:
    rows: List[List[InlineKeyboardButton]] = []
    for color_key, emoji, count in available:
        label = f"{emoji} ({count})"
        rows.append([InlineKeyboardButton(label, callback_data=f"rategrp_rerate_color:{color_key}")])
    rows.append([InlineKeyboardButton("â†©ï¸ ÐÐ°Ð·Ð°Ð´", callback_data="rategrp_rerate_back")])
    return InlineKeyboardMarkup(rows)


def build_newcomp_groupmode_keyboard() -> InlineKeyboardMarkup:
    return InlineKeyboardMarkup(
        [
            [InlineKeyboardButton("ðŸ“ ÐŸÐ¾ Ð¿Ð°Ð¿ÐºÐ°Ð¼", callback_data="newcomp_groupmode:folders")],
            [InlineKeyboardButton("ðŸŽ¨ ÐŸÐ¾ Ð¾Ñ†ÐµÐ½ÐºÐ°Ð¼", callback_data="newcomp_groupmode:colors")],
        ]
    )


def build_newcomp_color_keyboard(
    color_counts: Dict[str, int],
    unrated_count: int,
    combo_counts: Optional[Dict[str, int]] = None,
) -> InlineKeyboardMarkup:
    rows: List[List[InlineKeyboardButton]] = []
    single_row: List[InlineKeyboardButton] = []
    for key, info in RATEGRP_COLOR_CHOICES.items():
        emoji = info["emoji"]
        count = color_counts.get(emoji, 0)
        single_row.append(
            InlineKeyboardButton(f"{emoji} ({count})", callback_data=f"newcomp_color:{key}")
        )
    if single_row:
        rows.append(single_row)
    combo_counts = combo_counts or {}
    green = RATEGRP_COLOR_CHOICES["green"]["emoji"]
    yellow = RATEGRP_COLOR_CHOICES["yellow"]["emoji"]
    red = RATEGRP_COLOR_CHOICES["red"]["emoji"]
    green_new_total = combo_counts.get(
        "green_new", color_counts.get(green, 0) + unrated_count
    )
    green_yellow_total = combo_counts.get(
        "green_yellow", color_counts.get(green, 0) + color_counts.get(yellow, 0)
    )
    green_yellow_red_total = combo_counts.get(
        "green_yellow_red",
        color_counts.get(green, 0)
        + color_counts.get(yellow, 0)
        + color_counts.get(red, 0),
    )
    combo_row: List[InlineKeyboardButton] = []
    combo_row.append(
        InlineKeyboardButton(
            f"{green}+ðŸ†• ({green_new_total})",
            callback_data="newcomp_color:green_new",
        )
    )
    combo_row.append(
        InlineKeyboardButton(
            f"{green}+{yellow} ({green_yellow_total})",
            callback_data="newcomp_color:green_yellow",
        )
    )
    combo_row.append(
        InlineKeyboardButton(
            f"{green}+{yellow}+{red} ({green_yellow_red_total})",
            callback_data="newcomp_color:green_yellow_red",
        )
    )
    rows.append(combo_row)
    rows.append([InlineKeyboardButton("â¬… ÐÐ°Ð·Ð°Ð´", callback_data="newcomp_color_back")])
    return InlineKeyboardMarkup(rows)


def build_newcomp_algo_keyboard() -> InlineKeyboardMarkup:
    row = [
        InlineKeyboardButton("CAR", callback_data="newcomp_algo:car"),
        InlineKeyboardButton("WAV", callback_data="newcomp_algo:wav"),
        InlineKeyboardButton("BST", callback_data="newcomp_algo:bst"),
        InlineKeyboardButton("POI", callback_data="newcomp_algo:poi"),
        InlineKeyboardButton("LAY", callback_data="newcomp_algo:strata"),
    ]
    return InlineKeyboardMarkup([row])


def build_randompmv_count_keyboard() -> InlineKeyboardMarkup:
    buttons: List[List[InlineKeyboardButton]] = []
    row: List[InlineKeyboardButton] = []
    for idx, value in enumerate(RANDOMPMV_COUNT_OPTIONS, 1):
        row.append(InlineKeyboardButton(str(value), callback_data=f"randompmv_count:{value}"))
        if idx % 3 == 0:
            buttons.append(row)
            row = []
    if row:
        buttons.append(row)
    return InlineKeyboardMarkup(buttons)


def build_randompmv_newcount_keyboard() -> InlineKeyboardMarkup:
    buttons: List[List[InlineKeyboardButton]] = []
    row: List[InlineKeyboardButton] = []
    for idx, value in enumerate(RANDOMPMV_NEW_SOURCE_CHOICES, 1):
        row.append(InlineKeyboardButton(str(value), callback_data=f"randompmv_newcount:{value}"))
        if idx % 4 == 0:
            buttons.append(row)
            row = []
    if row:
        buttons.append(row)
    return InlineKeyboardMarkup(buttons)


def build_newcomp_folder_keyboard(
    options: List[Dict[str, Any]],
    unused_only: bool = False,
) -> InlineKeyboardMarkup:
    buttons: List[List[InlineKeyboardButton]] = []
    row: List[InlineKeyboardButton] = []
    for opt in options:
        label = truncate_button_label(f"{opt['label']} ({opt['count']})", 28)
        row.append(
            InlineKeyboardButton(label or "?", callback_data=f"newcomp_folder:{opt['token']}")
        )
        if len(row) >= 2:
            buttons.append(row)
            row = []
    if row:
        buttons.append(row)
    controls: List[List[InlineKeyboardButton]] = []
    if not buttons:
        controls.append([InlineKeyboardButton("Ð’ÑÐµ Ð¿Ð°Ð¿ÐºÐ¸", callback_data="newcomp_folder:all")])
    else:
        controls.extend(buttons)
    toggle_label = "Ð’ÑÐµ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¸" if unused_only else "ðŸ†• Ð¢Ð¾Ð»ÑŒÐºÐ¾ Ð½Ð¾Ð²Ð¾Ðµ"
    toggle_target = "all" if unused_only else "new"
    controls.append([InlineKeyboardButton(toggle_label, callback_data=f"newcomp_folder_mode:{toggle_target}")])
    controls.append([InlineKeyboardButton("ÐÐ°Ð·Ð°Ð´ Ðº Ð³Ñ€ÑƒÐ¿Ð¿Ð°Ð¼", callback_data="newcomp_folder_back")])
    return InlineKeyboardMarkup(controls)


def build_ratepmv_pmv_keyboard(rows: List[sqlite3.Row]) -> InlineKeyboardMarkup:
    buttons: List[List[InlineKeyboardButton]] = []
    for idx, row in enumerate(rows, 1):
        path = Path(row["video_path"])
        label = truncate_button_label(f"{idx}. {path.stem}", max_len=35)
        if not label:
            label = f"#{idx}"
        buttons.append([InlineKeyboardButton(label, callback_data=f"ratepmv_select:{idx}")])
    if not buttons:
        return InlineKeyboardMarkup([[InlineKeyboardButton("ÐÐµÑ‚ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ñ… PMV", callback_data="noop")]])

    bulk_row = [
        InlineKeyboardButton(f"{score} -> Ð²ÑÐµÐ¼", callback_data=f"ratepmv_bulk:{score}")
        for score in range(1, 6)
    ]
    buttons.append(bulk_row)
    return InlineKeyboardMarkup(buttons)


def build_ratepmv_score_keyboard() -> InlineKeyboardMarkup:
    row = [
        InlineKeyboardButton(str(score), callback_data=f"ratepmv_rate:{score}")
        for score in range(1, 6)
    ]
    return InlineKeyboardMarkup([row])


async def run_newcompmusic_generation(
    send_fn: Callable[[str], Awaitable[None]],
    sess: Dict[str, Any],
    resolved_key: str,
    user_id: int,
) -> None:
    resolved_key, algo_meta = resolve_clip_algorithm(resolved_key)
    selected = sess.get("music_selected") or {}
    parsed_segments: List[MusicSegment] = selected.get("parsed_segments") or []
    if not parsed_segments:
        return await send_fn("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð½Ð°Ð¹Ñ‚Ð¸ ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ñ‹ Ð² Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð½Ð¾Ð¼ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ðµ.")

    audio_path_str = selected.get("audio_path")
    if not audio_path_str:
        return await send_fn("Ð’ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ðµ Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ audio.mp3. ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ Ð¿Ð°Ð¿ÐºÑƒ music_projects.")

    sources_count = int(sess.get("music_sources") or 0)
    if sources_count <= 0:
        return await send_fn("ÐÐµ ÑƒÐºÐ°Ð·Ð°Ð½Ð¾ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð².")

    await send_fn("Ð—Ð°Ð¿ÑƒÑÐºÐ°ÑŽ Ð¼ÑƒÐ·Ñ‹ÐºÐ°Ð»ÑŒÐ½ÑƒÑŽ ÐºÐ¾Ð¼Ð¿Ð¸Ð»ÑÑ†Ð¸ÑŽ. Ð­Ñ‚Ð¾ Ð¼Ð¾Ð¶ÐµÑ‚ Ð·Ð°Ð½ÑÑ‚ÑŒ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð¼Ð¸Ð½ÑƒÑ‚...")

    move_comment = ""
    try:
        preferred_group = None
        if sess.get("music_group_choice"):
            preferred_group = tuple(sess["music_group_choice"]["key"])
        group_choice = sess.get("music_group_choice") or {}
        preferred_folder = group_choice.get("folder_path")
        orientation_label = (group_choice.get("orientation") or "HOR").upper()
        color_rows = sess.get("music_color_rows")
        group_number = group_choice.get("group_number")
        min_new_required = max(0, int(sess.get("music_min_new_sources") or 0))
        if color_rows:
            source_rows = pick_specific_source_rows(
                list(color_rows),
                sources_count,
                min_new_required=min_new_required,
            )
        else:
            source_rows = choose_random_source_rows(
                sources_count,
                group_strategy=CURRENT_STRATEGY,
                preferred_group=preferred_group,
                preferred_folder=preferred_folder,
            )
        out_path, source_ids, (resolved_key, algo_meta) = make_music_synced_pmv(
            selected.get("name") or selected.get("slug") or "music",
            parsed_segments,
            Path(audio_path_str),
            source_rows,
            resolved_key,
            orientation=orientation_label,
            group_number=group_number,
        )
        out_path, move_comment = move_output_to_network_storage(out_path)
    except Exception as exc:
        user_sessions.pop(user_id, None)
        await send_fn(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸: {exc}")
        if sess.get("_raise_on_newcomp_error"):
            raise
        return

    pmv_tag = Path(out_path).name
    comments = combine_comments(f"music_project={selected.get('slug')}", move_comment)
    db_insert_compilation(
        out_path,
        source_ids,
        comments=comments,
    )
    db_update_sources_pmv_list(source_ids, pmv_tag)
    autotag = sess.get("music_color_autotag")
    if autotag:
        emoji = autotag.get("emoji")
        autotag_ids = set(int(i) for i in autotag.get("ids") or [])
        if emoji and autotag_ids:
            for sid in source_ids:
                if sid in autotag_ids:
                    db_append_source_comment(sid, f"color={emoji}")

    user_sessions.pop(user_id, None)

    duration = selected.get("duration")
    minutes = (duration / 60.0) if duration else None
    msg_lines = [
        "âœ… ÐœÑƒÐ·Ñ‹ÐºÐ°Ð»ÑŒÐ½Ð°Ñ ÐºÐ¾Ð¼Ð¿Ð¸Ð»ÑÑ†Ð¸Ñ Ð³Ð¾Ñ‚Ð¾Ð²Ð°!",
        f"Ð¤Ð°Ð¹Ð»: {out_path}",
        f"ÐŸÑ€Ð¾ÐµÐºÑ‚: {selected.get('name')} (slug: {selected.get('slug')}).",
        f"ÐÐ»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼ ÐºÐ»Ð¸Ð¿Ð¾Ð²: {algo_meta['title']} ({resolved_key}/{algo_meta.get('short')}).",
        f"Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¾ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð²: {len(source_ids)}.",
        f"Ð¡ÐµÐ³Ð¼ÐµÐ½Ñ‚Ð¾Ð² Ð¿Ð¾ Ð¼Ð°Ð½Ð¸Ñ„ÐµÑÑ‚Ñƒ: {len(parsed_segments)}.",
    ]
    if minutes:
        msg_lines.append(f"Ð”Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð° â‰ˆ {minutes:.1f} Ð¼Ð¸Ð½.")
    await send_fn("\n".join(msg_lines))


def _prepare_randompmv_session(
    used_group_keys: Optional[Set[Tuple[str, str]]] = None,
    min_new_sources: int = 0,
) -> Tuple[Dict[str, Any], str, Dict[str, Any]]:
    projects = load_music_projects()
    if not projects:
        raise RuntimeError("ÐÐµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð¾Ð² Ð² music_projects.")

    unused_projects = [p for p in projects if not p.get("usage_count")]
    unused_ids = {id(p) for p in unused_projects}
    other_projects = [p for p in projects if id(p) not in unused_ids]
    project_candidates = unused_projects + other_projects

    groups_raw = get_source_groups_prefer_unused()
    if not groups_raw:
        raise RuntimeError("ÐÐµÑ‚ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ñ… Ð³Ñ€ÑƒÐ¿Ð¿ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð². Ð’Ñ‹Ð¿Ð¾Ð»Ð½Ð¸Ñ‚Ðµ /scan.")
    group_entries = [
        SourceGroupEntry(key=key, rows=list(rows), unused_count=unused)
        for key, rows, unused in groups_raw
    ]
    sorted_entries, orientation_map = sort_group_entries_with_orientation(group_entries)
    prepared_groups = [(entry.key, list(entry.rows), entry.unused_count) for entry in sorted_entries]

    fallback_result: Optional[Tuple[Dict[str, Any], str, Dict[str, Any]]] = None
    last_error: Optional[Exception] = None

    for project in project_candidates:
        try:
            strict_result = _prepare_randompmv_from_project(
                project,
                used_group_keys,
                prepared_groups,
                orientation_map,
                require_target=True,
                min_new_sources=min_new_sources,
            )
        except Exception as exc:
            last_error = exc
            continue

        if strict_result:
            return strict_result

        if fallback_result is not None:
            continue

        try:
            fallback_result = _prepare_randompmv_from_project(
                project,
                used_group_keys,
                prepared_groups,
                orientation_map,
                require_target=False,
                min_new_sources=min_new_sources,
            )
        except Exception as exc:
            last_error = exc
            continue

    if fallback_result:
        return fallback_result
    if last_error:
        raise last_error
    raise RuntimeError("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð´Ð¾Ð±Ñ€Ð°Ñ‚ÑŒ Ð³Ñ€ÑƒÐ¿Ð¿Ñƒ Ñ Ð´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ñ‹Ð¼ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾Ð¼ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð².")


def _prepare_randompmv_from_project(
    project: Dict[str, Any],
    used_group_keys: Optional[Set[Tuple[str, str]]],
    prepared_groups: List[Tuple[Tuple[str, str], List[sqlite3.Row], int]],
    orientation_map: Dict[Tuple[str, str], str],
    require_target: bool,
    min_new_sources: int = 0,
) -> Optional[Tuple[Dict[str, Any], str, Dict[str, Any]]]:
    manifest_data = project.get("manifest_data")
    manifest_path = project.get("manifest_path")
    if not manifest_data and manifest_path and Path(manifest_path).exists():
        manifest_data = json.loads(Path(manifest_path).read_text(encoding="utf-8"))
        project["manifest_data"] = manifest_data
    parsed_segments = parse_manifest_segments(manifest_data or {})
    if not parsed_segments:
        raise RuntimeError(f"Ð”Ð»Ñ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð° {project.get('name')} Ð½Ðµ Ð½Ð°ÑˆÐ»Ð¾ÑÑŒ Ð²Ð°Ð»Ð¸Ð´Ð½Ñ‹Ñ… ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ð¾Ð².")

    audio_path = project.get("audio_path")
    audio_path_path = Path(audio_path) if audio_path else None
    if not audio_path_path or not audio_path_path.exists():
        raise RuntimeError(f"Ð£ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð° {project.get('name')} Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ audio.mp3.")

    duration_seconds = float(project.get("duration") or 0.0)
    if duration_seconds <= 0 and parsed_segments:
        duration_seconds = float(parsed_segments[-1].end)
    duration_minutes = max(duration_seconds / 60.0, 1.0)
    target_sources, target_ratio = _randompmv_compute_target_sources(duration_minutes)
    required_total_sources = max(target_sources, max(0, min_new_sources))

    orientation_cycle = list(NEWCOMPMUSIC_ORIENTATION_CHOICES)
    random.shuffle(orientation_cycle)

    def pick_group(
        forbid_used: bool,
        require_target_count: bool,
    ) -> Optional[Tuple[Tuple[str, str], List[sqlite3.Row], int, List[sqlite3.Row], str]]:
        for orient in orientation_cycle:
            filtered = filter_groups_by_orientation(prepared_groups, orientation_map, orient)
            if not filtered:
                continue
            shuffled = filtered[:]
            random.shuffle(shuffled)
            for key, rows, unused in shuffled:
                if forbid_used and used_group_keys and key in used_group_keys:
                    continue
                color_rows = _filter_green_new_rows(rows)
                if not color_rows:
                    continue
                new_available = sum(1 for row in color_rows if _is_unused_source_row(row))
                if min_new_sources > 0 and new_available < min_new_sources:
                    continue
                if require_target_count:
                    if len(color_rows) < required_total_sources:
                        continue
                else:
                    if len(color_rows) < max(min_new_sources, 1):
                        continue
                return (key, list(rows), unused, list(color_rows), orient)
        return None

    search_plan = [(True, True), (False, True)]
    if not require_target:
        search_plan.extend([(True, False), (False, False)])

    chosen: Optional[
        Tuple[Tuple[str, str], List[sqlite3.Row], int, List[sqlite3.Row], str]
    ] = None
    for forbid_used, need_target in search_plan:
        candidate = pick_group(forbid_used, need_target)
        if candidate:
            chosen = candidate
            break

    if not chosen:
        if require_target:
            return None
        raise RuntimeError("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð´Ð¾Ð±Ñ€Ð°Ñ‚ÑŒ Ð³Ñ€ÑƒÐ¿Ð¿Ñƒ Ñ Ð·ÐµÐ»Ñ‘Ð½Ñ‹Ð¼Ð¸ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ°Ð¼Ð¸.")

    key, rows, unused_count, color_rows, chosen_orientation = chosen
    if not color_rows:
        raise RuntimeError("Ð’Ñ‹Ð±Ñ€Ð°Ð½Ð½Ð°Ñ Ð³Ñ€ÑƒÐ¿Ð¿Ð° Ð½Ðµ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² Ñ Ð½ÑƒÐ¶Ð½Ñ‹Ð¼Ð¸ Ñ‚ÐµÐ³Ð°Ð¼Ð¸.")
    group_idx = next(
        (idx for idx, (group_key, _, _) in enumerate(prepared_groups, 1) if group_key == key),
        None,
    )
    orientation_label = (orientation_map.get(key) or _resolution_orientation(key[1] or "")[0]).upper()
    green_emoji = RATEGRP_COLOR_CHOICES["green"]["emoji"]
    color_label = f"{green_emoji}+ðŸ†•"

    new_sources_available = sum(1 for row in color_rows if _is_unused_source_row(row))
    if min_new_sources > 0 and new_sources_available < min_new_sources:
        raise RuntimeError("ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð½Ð¾Ð²Ñ‹Ñ… Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² Ð´Ð»Ñ Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ñ.")

    total_required = max(target_sources, min_new_sources)
    sources_count = min(len(color_rows), total_required)
    if sources_count <= 0:
        raise RuntimeError("ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸.")

    autotag_ids: List[int] = []
    for row in color_rows:
        if _rategrp_row_color(row) is None:
            try:
                autotag_ids.append(int(row["id"]))
            except Exception:
                continue
    autotag = {"emoji": green_emoji, "ids": autotag_ids} if autotag_ids else None

    algo_key = random.choice(list(CLIP_SEQUENCE_ALGORITHMS.keys()))

    music_selected = {
        "slug": project.get("slug"),
        "name": project.get("name"),
        "duration": project.get("duration"),
        "segments": len(parsed_segments),
        "manifest": manifest_data,
        "audio_path": str(audio_path_path),
        "parsed_segments": parsed_segments,
    }
    group_choice = {
        "key": key,
        "count": len(color_rows),
        "orientation": orientation_label,
        "total_count": len(rows),
        "unused_count": unused_count,
        "group_number": group_idx,
    }
    session = {
        "state": "newcompmusic_wait_algo",
        "music_selected": music_selected,
        "music_group_choice": group_choice,
        "music_group_rows": list(rows),
        "music_groups_all": prepared_groups,
        "music_group_orientations": orientation_map,
        "music_orientation_preference": chosen_orientation,
        "music_color_rows": list(color_rows),
        "music_color_choice": color_label,
        "music_color_autotag": autotag,
        "music_sources": sources_count,
        "music_folder_only_new": False,
        "_raise_on_newcomp_error": True,
        "music_min_new_sources": max(0, min_new_sources),
    }
    meta = {
        "project": project.get("name") or project.get("slug"),
        "orientation": chosen_orientation or orientation_label,
        "group": f"{key[0]} {key[1]}",
        "group_key": [key[0], key[1]],
        "sources": sources_count,
        "color": color_label,
        "algo_key": algo_key,
        "duration_minutes": duration_minutes,
        "target_sources": target_sources,
        "target_ratio": target_ratio,
        "available_color_sources": len(color_rows),
        "limited_sources": len(color_rows) < target_sources,
        "min_new_sources": max(0, min_new_sources),
        "new_sources_available": new_sources_available,
    }
    return session, algo_key, meta


async def run_randompmv_batch(
    send_fn: Callable[[str], Awaitable[None]],
    user_id: int,
    total_runs: int,
    min_new_sources: int = 0,
) -> None:
    total = max(RANDOMPMV_MIN_BATCH, min(int(total_runs), RANDOMPMV_MAX_BATCH))
    created = 0
    used_groups: Set[Tuple[str, str]] = set()
    for idx in range(1, total + 1):
        try:
            session, algo_key, meta = _prepare_randompmv_session(used_groups, min_new_sources=min_new_sources)
        except Exception as exc:
            log_randompmv_event(
                {
                    "run_index": idx,
                    "total_runs": total,
                    "status": "prepare_error",
                    "error": str(exc),
                }
            )
            await send_fn(f"âŒ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²Ð¸Ñ‚ÑŒ Random PMV #{idx}: {exc}")
            break

        algo_meta = CLIP_SEQUENCE_ALGORITHMS.get(algo_key, {})
        base_event = {
            "run_index": idx,
            "total_runs": total,
            **meta,
        }
        log_randompmv_event({**base_event, "status": "start"})

        source_line = f"{meta['sources']} Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð²."
        if meta.get("target_sources") and meta["sources"] < meta["target_sources"]:
            source_line += f" (Ð½ÑƒÐ¶Ð½Ð¾ â‰ˆ {meta['target_sources']})"
        if min_new_sources > 0:
            source_line += f", Ð½Ð¾Ð²Ñ‹Ñ… â‰¥ {min_new_sources}"
        await send_fn(
            f"â–¶ï¸ Random PMV #{idx}/{total}: Ð¿Ñ€Ð¾ÐµÐºÑ‚ {meta['project']}, "
            f"{meta['orientation']} / {meta['group']}, {source_line} ({meta['color']}), "
            f"Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼ {algo_meta.get('short', algo_key)}."
        )
        try:
            user_sessions[user_id] = session
            await run_newcompmusic_generation(send_fn, session, algo_key, user_id)
        except Exception as exc:
            log_randompmv_event({**base_event, "status": "generation_error", "error": str(exc)})
            break
        else:
            created += 1
            log_randompmv_event({**base_event, "status": "success"})
            group_key = session.get("music_group_choice", {}).get("key")
            if group_key:
                used_groups.add(tuple(group_key))

    user_sessions.pop(user_id, None)
    if created:
        await send_fn(f"âœ… Random PMV Ð·Ð°Ð²ÐµÑ€ÑˆÑ‘Ð½. Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¾ {created} Ð¸Ð· {total}.")
    else:
        await send_fn("âš ï¸ Random PMV Ð½Ðµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ ÑÐ¾Ð·Ð´Ð°Ñ‚ÑŒ.")


def load_music_generator_module():
    global _music_generator_module
    if _music_generator_module is not None:
        return _music_generator_module
    module_path = SCRIPT_DIR / "music_guided_generator.py"
    if not module_path.exists():
        raise RuntimeError("music_guided_generator.py Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½ Ñ€ÑÐ´Ð¾Ð¼ ÑÐ¾ ÑÐºÑ€Ð¸Ð¿Ñ‚Ð¾Ð¼.")
    spec = importlib.util.spec_from_file_location("music_guided_generator", module_path)
    if spec is None or spec.loader is None:
        raise RuntimeError("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ music_guided_generator.py")
    module = types.ModuleType("music_guided_generator")
    module.__file__ = str(module_path)
    sys.modules["music_guided_generator"] = module
    spec.loader.exec_module(module)
    _music_generator_module = module
    return module


def list_music_input_files() -> List[Path]:
    MUSIC_INPUT_DIR.mkdir(parents=True, exist_ok=True)
    files = []
    for path in sorted(MUSIC_INPUT_DIR.iterdir(), key=lambda p: p.name.lower()):
        if path.is_file() and path.suffix.lower() in {".mp3", ".wav", ".flac", ".m4a"}:
            files.append(path)
    return files


RESOLUTION_RE = re.compile(r"(\d+)\s*[xÑ…XÐ¥]\s*(\d+)")
ORIENTATION_ORDER = {"VR": 0, "HOR": 1, "VER": 2}


@dataclass
class SourceGroupEntry:
    key: Tuple[str, str]
    rows: List[sqlite3.Row]
    unused_count: int = 0


def _resolution_pixels(res: str) -> int:
    if not res:
        return 0
    match = RESOLUTION_RE.search(res)
    if not match:
        return 0
    try:
        width = int(match.group(1))
        height = int(match.group(2))
        return width * height
    except ValueError:
        return 0


def _resolution_orientation(res: str) -> Tuple[str, int]:
    """
    ÐŸÑ€Ð¸Ð±Ð»Ð¸Ð·Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ñ‚Ð¸Ð¿ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ð°:
    VR (~2:1), Ð³Ð¾Ñ€Ð¸Ð·Ð¾Ð½Ñ‚, Ð²ÐµÑ€Ñ‚Ð¸ÐºÐ°Ð»ÑŒ.
    """
    match = RESOLUTION_RE.search(res or "")
    if not match:
        return "HOR", ORIENTATION_ORDER["HOR"]
    try:
        width = int(match.group(1))
        height = int(match.group(2))
    except ValueError:
        return "HOR", ORIENTATION_ORDER["HOR"]
    if width <= 0 or height <= 0:
        return "HOR", ORIENTATION_ORDER["HOR"]
    if width >= height:
        ratio = width / height if height else float("inf")
        if ratio >= 1.8:
            return "VR", ORIENTATION_ORDER["VR"]
        return "HOR", ORIENTATION_ORDER["HOR"]
    else:
        return "VER", ORIENTATION_ORDER["VER"]


def _friendly_folder_label(folder: Path, roots: Optional[List[Path]] = None) -> str:
    roots = roots or []
    try:
        folder_resolved = folder.resolve(strict=False)
    except Exception:
        folder_resolved = folder
    for root in roots:
        try:
            root_resolved = root.resolve(strict=False)
        except Exception:
            root_resolved = root
        try:
            rel = folder_resolved.relative_to(root_resolved)
            rel_str = str(rel).replace("\\", "/")
            base = root_resolved.name or str(root_resolved)
            if not rel_str:
                return base
            return f"{base}/{rel_str}"
        except ValueError:
            continue
    label = folder_resolved.name or str(folder_resolved)
    return label.replace("\\", "/")


def _is_unused_source_row(row: sqlite3.Row) -> bool:
    try:
        pmv_list = row["pmv_list"]
    except Exception:
        pmv_list = None
    return not (pmv_list or "").strip()


def compute_group_folder_options(
    rows: List[sqlite3.Row],
    unused_only: bool = False,
) -> Tuple[List[Dict[str, Any]], Dict[str, Dict[str, Any]]]:
    folder_map: Dict[str, Dict[str, Any]] = {}
    for row in rows:
        if unused_only and not _is_unused_source_row(row):
            continue
        try:
            parent = Path(row["video_path"]).resolve(strict=False).parent
        except Exception:
            parent = Path(row["video_path"]).parent
        folder_key = _normalize_path_prefix(parent)
        info = folder_map.setdefault(
            folder_key,
            {"rows": [], "count": 0, "path": parent},
        )
        info["rows"].append(row)
        info["count"] += 1

    sorted_folders = sorted(
        folder_map.items(),
        key=lambda item: (-item[1]["count"], item[0]),
    )
    roots = [Path(r["folder_path"]) for r in db_get_upload_folders(include_ignored=True)]

    options: List[Dict[str, Any]] = []
    token_map: Dict[str, Dict[str, Any]] = {}
    for idx, (folder_key, info) in enumerate(sorted_folders, 1):
        token = f"folder{idx}"
        label = _friendly_folder_label(Path(info["path"]), roots)
        option = {
            "token": token,
            "label": label,
            "count": info["count"],
            "path": str(Path(info["path"])),
        }
        options.append(option)
        token_map[token] = {
            **info,
            "label": label,
            "path": option["path"],
        }

    total_rows = [row for row in rows if (not unused_only or _is_unused_source_row(row))]
    token_map["all"] = {
        "rows": total_rows,
        "count": len(total_rows),
        "path": None,
        "label": "Ð’ÑÐµ Ð¿Ð°Ð¿ÐºÐ¸",
    }
    options.insert(
        0,
        {
            "token": "all",
            "label": "Ð’ÑÐµ Ð¿Ð°Ð¿ÐºÐ¸",
            "count": len(total_rows),
            "path": None,
        },
    )
    return options, token_map


def filter_groups_by_orientation(
    groups: List[Tuple[Tuple[str, str], List[sqlite3.Row], int]],
    orientation_map: Dict[Tuple[str, str], str],
    target: str,
) -> List[Tuple[Tuple[str, str], List[sqlite3.Row], int]]:
    normalized = (target or "").upper()
    if normalized not in NEWCOMPMUSIC_ORIENTATION_CHOICES:
        return []
    filtered: List[Tuple[Tuple[str, str], List[sqlite3.Row], int]] = []
    for key, rows, unused in groups:
        label = (orientation_map.get(key) or "").upper()
        if not label:
            label = _resolution_orientation(key[1] or "")[0]
        if label.upper() == normalized:
            filtered.append((key, rows, unused))
    return filtered


def _build_group_selection_lines(
    sess: Dict[str, Any],
    group_entries: List[SourceGroupEntry],
    orientation: str,
    prompt_kind: str = "text",
) -> List[str]:
    orientation_map = sess.get("music_group_orientations") or {}

    def orientation_prefix(entry: SourceGroupEntry) -> str:
        return orientation_map.get(entry.key, "")

    project_info = sess.get("music_selected") or {}
    lines: List[str] = []
    if project_info.get("name"):
        lines.append(f"ÐŸÑ€Ð¾ÐµÐºÑ‚: {project_info.get('name')} (slug: {project_info.get('slug')}).")
    segs = project_info.get("segments")
    if segs is not None:
        lines.append(f"Ð¡Ð¼ÐµÐ½ ÐºÐ»Ð¸Ð¿Ð¾Ð²: {segs}")
    duration = project_info.get("duration")
    if duration:
        lines.append(f"ÐŸÑ€Ð¾Ð´Ð¾Ð»Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ â‰ˆ {(duration / 60.0):.1f} Ð¼Ð¸Ð½ÑƒÑ‚.")
    lines.append(f"ÐžÑ€Ð¸ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ñ: {orientation}.")
    lines.append("")
    lines.extend(
        format_source_group_lines(
            group_entries,
            "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð³Ñ€ÑƒÐ¿Ð¿Ñƒ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² (codec + Ñ€Ð°Ð·Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ):",
            prefix_func=orientation_prefix,
        )
    )
    lines.append("")
    if prompt_kind == "inline":
        lines.append("ÐÐ°Ð¶Ð¼Ð¸Ñ‚Ðµ Ð½Ð¾Ð¼ÐµÑ€ Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹ Ð½Ð° ÐºÐ»Ð°Ð²Ð¸Ð°Ñ‚ÑƒÑ€Ðµ Ð½Ð¸Ð¶Ðµ.")
    else:
        lines.append("ÐŸÑ€Ð¸ÑˆÐ»Ð¸Ñ‚Ðµ Ð½Ð¾Ð¼ÐµÑ€ Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€: 3).")
    return lines


def format_folder_selection_message(
    codec: str,
    resolution: str,
    project_info: Dict[str, Any],
    options: List[Dict[str, Any]],
    max_listed: int = 20,
    unused_only: bool = False,
) -> str:
    project_name = project_info.get("name") or project_info.get("slug") or ""
    lines = [
        f"Ð“Ñ€ÑƒÐ¿Ð¿Ð° Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð°: {codec} {resolution} (Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð²: {options[0]['count']}).",
    ]
    if project_name:
        lines.append(f"ÐŸÑ€Ð¾ÐµÐºÑ‚: {project_name}.")
    if unused_only:
        lines.append("Ð¤Ð¸Ð»ÑŒÑ‚Ñ€ Ð²ÐºÐ»ÑŽÑ‡ÐµÐ½: Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½Ð¾Ð²Ñ‹Ðµ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¸.")
    lines.append("Ð¢ÐµÐ¿ÐµÑ€ÑŒ Ð²Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¿Ð¾Ð´Ð¿Ð°Ð¿ÐºÑƒ (Ð¸Ð»Ð¸ Â«Ð’ÑÐµ Ð¿Ð°Ð¿ÐºÐ¸Â»):")
    listed = 0
    for idx, opt in enumerate(options, 1):
        if listed >= max_listed:
            break
        label = opt["label"]
        lines.append(f"{idx}. {label} ({opt['count']})")
        listed += 1
    remaining = len(options) - listed
    if remaining > 0:
        lines.append(f"... Ð¸ ÐµÑ‰Ñ‘ {remaining} Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ð¾Ð². Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ ÐºÐ½Ð¾Ð¿ÐºÐ¸ Ð½Ð¸Ð¶Ðµ.")
    return "\n".join(lines)


def compose_newcomp_folder_prompt(
    sess: Dict[str, Any],
) -> Tuple[str, InlineKeyboardMarkup]:
    rows = sess.get("music_group_rows") or []
    options, folder_map = compute_group_folder_options(
        rows,
        unused_only=sess.get("music_folder_only_new", False),
    )
    sess["music_folder_options"] = options
    sess["music_folder_map"] = folder_map
    codec, res = sess.get("music_group_choice", {}).get("key") or ("?", "?")
    project_info = sess.get("music_selected") or {}
    msg_text = format_folder_selection_message(
        codec,
        res,
        project_info,
        options,
        unused_only=sess.get("music_folder_only_new", False),
    )
    msg_text += "\n\nÐ•ÑÐ»Ð¸ Ð½ÑƒÐ¶Ð½Ð¾ Ð²Ñ‹Ð±Ñ€Ð°Ñ‚ÑŒ Ð´Ñ€ÑƒÐ³ÑƒÑŽ Ð³Ñ€ÑƒÐ¿Ð¿Ñƒ, Ð½Ð°Ð¶Ð¼Ð¸Ñ‚Ðµ ÐºÐ½Ð¾Ð¿ÐºÑƒ Â«ÐÐ°Ð·Ð°Ð´ Ðº Ð³Ñ€ÑƒÐ¿Ð¿Ð°Ð¼Â» Ð½Ð¸Ð¶Ðµ."
    keyboard = build_newcomp_folder_keyboard(
        options, unused_only=sess.get("music_folder_only_new", False)
    )
    return msg_text, keyboard


def _rategrp_row_has_color(row: sqlite3.Row) -> bool:
    comments = ""
    try:
        comments = row["comments"] or ""
    except Exception:
        comments = ""
    return any(emoji in comments for emoji in RATEGRP_COLOR_EMOJIS)


def _rategrp_row_color(row: sqlite3.Row) -> Optional[str]:
    comments = ""
    try:
        comments = row["comments"] or ""
    except Exception:
        comments = ""
    for info in RATEGRP_COLOR_CHOICES.values():
        if info["emoji"] in comments:
            return info["emoji"]
    return None


def _rategrp_balanced_shuffle(rows: List[sqlite3.Row]) -> List[sqlite3.Row]:
    pool = list(rows)
    if len(pool) <= 1:
        return pool

    def pick_index(length: int, zone: str) -> int:
        if length <= 1:
            return 0
        third = max(1, length // 3)
        if zone == "front":
            return random.randint(0, max(0, third - 1))
        if zone == "back":
            start = max(0, length - third)
            return random.randint(start, length - 1)
        mid_start = max(0, (length // 2) - (third // 2))
        mid_end = min(length - 1, mid_start + third - 1)
        return random.randint(mid_start, max(mid_start, mid_end))

    pattern = ["front", "back", "middle"]
    idx = 0
    result: List[sqlite3.Row] = []
    while pool:
        zone = pattern[idx % len(pattern)]
        pick = pick_index(len(pool), zone)
        result.append(pool.pop(pick))
        idx += 1
    return result


def _rategrp_rows_to_queue(rows: List[sqlite3.Row], shuffle: bool = True) -> List[Dict[str, Any]]:
    shuffled_rows = _rategrp_balanced_shuffle(rows) if shuffle else rows
    queue: List[Dict[str, Any]] = []
    for row in shuffled_rows:
        try:
            sid = int(row["id"])
            path_str = str(row["video_path"])
        except Exception:
            continue
        queue.append({"id": sid, "path": path_str, "name": Path(path_str).name})
    return queue


def _fetch_unrated_pmv_rows(limit: int = RATEGRP_PMV_MAX_QUEUE) -> List[sqlite3.Row]:
    rows = db_get_used_sources_list()
    if not rows:
        return []
    usage = collect_source_usage_stats()
    scored: List[Tuple[int, float, sqlite3.Row]] = []
    for row in rows:
        if _rategrp_row_has_color(row):
            continue
        try:
            sid = int(row["id"])
        except Exception:
            continue
        info = usage.get(sid) or {}
        last_date = info.get("last_date")
        ordinal = last_date.toordinal() if last_date else 0
        scored.append((ordinal, random.random(), row))
    scored.sort(key=lambda item: (-item[0], item[1]))
    ordered = [item[2] for item in scored]
    if limit > 0:
        ordered = ordered[:limit]
    return ordered


async def _start_rategrp_from_pmv(
    session: Dict[str, Any],
    send_fn: Callable[[str, Optional[InlineKeyboardMarkup]], Awaitable[Any]],
) -> bool:
    rows = _fetch_unrated_pmv_rows()
    if not rows:
        await send_fn("ÐÐµ Ð½Ð°ÑˆÑ‘Ð» ÑƒÑ‡Ð°ÑÑ‚Ð²Ð¾Ð²Ð°Ð²ÑˆÐ¸Ñ… Ð² PMV Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² Ð±ÐµÐ· Ð¾Ñ†ÐµÐ½ÐºÐ¸.", None)
        return False
    queue = _rategrp_rows_to_queue(rows, shuffle=True)
    session["rategrp_queue"] = queue
    session["rategrp_total"] = len(queue)
    session["rategrp_processed"] = 0
    session["rategrp_queue_origin"] = "pmv"
    session["state"] = "rategrp_rate_source"

    await send_fn(
        f"Ð˜Ð· Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ñ… PMV Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ {len(queue)} Ð½ÐµÐ¾Ñ†ÐµÐ½Ñ‘Ð½Ð½Ñ‹Ñ… Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð². ÐžÑ†ÐµÐ½Ð¸Ð¼ Ð¸Ñ…!",
        None,
    )
    await rategrp_send_next_prompt(session, send_fn)
    return True


def _search_find_matches(term: str, limit: int = BADCLIP_MAX_MATCHES) -> List[Dict[str, Any]]:
    normalized = term.strip().lower()
    if not normalized:
        return []
    rows = db_get_all_compilations()
    today = datetime.now().strftime("%Y-%m-%d")
    pmv_primary: List[Dict[str, Any]] = []
    pmv_secondary: List[Dict[str, Any]] = []
    for row in rows:
        path = Path(row["video_path"])
        haystack = f"{path.name.lower()} {str(path).lower()}"
        if normalized not in haystack:
            continue
        entry = {
            "type": "pmv",
            "id": int(row["id"]),
            "video_path": str(path),
            "pmv_date": row["pmv_date"],
            "source_ids": row["source_ids"],
            "stem": path.stem,
        }
        container = (
            pmv_primary
            if (today in str(path.parent) or (row["pmv_date"] or "").startswith(today))
            else pmv_secondary
        )
        container.append(entry)

    source_rows = db_search_sources_by_term(normalized, limit * 2)
    source_entries: List[Dict[str, Any]] = []
    for row in source_rows:
        try:
            resolved = str(Path(row["video_path"]))
        except Exception:
            resolved = str(row["video_path"])
        source_entries.append(
            {
                "type": "source",
                "id": int(row["id"]),
                "video_path": resolved,
                "video_name": row["video_name"],
                "codec": row["codec"],
                "resolution": row["resolution"],
                "comments": row["comments"],
            }
        )

    combined = pmv_primary + pmv_secondary + source_entries
    results: List[Dict[str, Any]] = []
    seen_keys: Set[Tuple[str, int]] = set()
    for entry in combined:
        key = (entry["type"], entry["id"])
        if key in seen_keys:
            continue
        seen_keys.add(key)
        results.append(entry)
        if len(results) >= limit:
            break
    return results


def build_find_keyboard(matches: List[Dict[str, Any]]) -> InlineKeyboardMarkup:
    rows: List[List[InlineKeyboardButton]] = []
    for idx, entry in enumerate(matches, 1):
        if entry.get("type") == "pmv":
            label = truncate_label_keep_suffix(f"PMV Â· {entry.get('stem')}", 48)
        else:
            color = extract_color_emoji(entry.get("comments"))
            prefix = f"{color} " if color else ""
            label = truncate_label_keep_suffix(f"{prefix}{entry.get('video_name')}", 48)
        rows.append([InlineKeyboardButton(label or str(idx), callback_data=f"find_pick:{idx - 1}")])
    rows.append([InlineKeyboardButton("â†©ï¸ ÐÐ¾Ð²Ñ‹Ð¹ Ð¿Ð¾Ð¸ÑÐº", callback_data="find_retry")])
    return InlineKeyboardMarkup(rows)


async def _start_find_pmv_queue(
    session: Dict[str, Any],
    match: Dict[str, Any],
    send_fn: Callable[[str, Optional[InlineKeyboardMarkup]], Awaitable[Any]],
) -> bool:
    source_ids = parse_source_id_list(match.get("source_ids") or "")
    if not source_ids:
        await send_fn("Ð£ Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð½Ð¾Ð³Ð¾ PMV Ð½ÐµÑ‚ ÑÐ¾Ñ…Ñ€Ð°Ð½Ñ‘Ð½Ð½Ñ‹Ñ… Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð².", None)
        return False
    rows = db_get_sources_by_ids(source_ids)
    if not rows:
        await send_fn("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð½Ð°Ð¹Ñ‚Ð¸ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¸ Ð² Ð±Ð°Ð·Ðµ.", None)
        return False
    rows_map = {int(row["id"]): row for row in rows}
    ordered_rows = [rows_map[sid] for sid in source_ids if sid in rows_map]
    queue = _rategrp_rows_to_queue(ordered_rows, shuffle=False)
    if not queue:
        await send_fn("ÐžÑ‡ÐµÑ€ÐµÐ´ÑŒ Ð¿ÑƒÑÑ‚Ð°Ñ â€” Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ Ñ„Ð°Ð¹Ð»Ñ‹ ÑƒÐ´Ð°Ð»ÐµÐ½Ñ‹.", None)
        return False
    session["rategrp_queue"] = queue
    session["rategrp_total"] = len(queue)
    session["rategrp_processed"] = 0
    session["rategrp_queue_origin"] = "find_pmv"
    session["state"] = "rategrp_rate_source"
    session["find_current"] = match
    session["find_mode"] = True
    session["find_rows"] = ordered_rows
    session["rategrp_rerate_rows"] = ordered_rows
    session["rategrp_group_choice"] = {
        "label": truncate_button_label(match.get("stem") or Path(match.get("video_path", "?")).stem),
        "orientation": match.get("pmv_date") or "PMV",
        "key": ("PMV", match.get("stem") or "?"),
        "count": len(queue),
    }
    await send_fn(
        f"PMV Â«{match.get('stem')}Â» Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð°. Ð˜ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð²: {len(queue)}. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ Ñ†Ð²ÐµÑ‚Ð½Ñ‹Ðµ ÐºÐ½Ð¾Ð¿ÐºÐ¸ Ð½Ð¸Ð¶Ðµ.",
        None,
    )
    await rategrp_send_next_prompt(session, send_fn)
    return True


async def _start_find_single_source(
    session: Dict[str, Any],
    row: sqlite3.Row,
    send_fn: Callable[[str, Optional[InlineKeyboardMarkup]], Awaitable[Any]],
) -> bool:
    try:
        sid = int(row["id"])
    except Exception:
        await send_fn("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ñ‚ÑŒ ID Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ°.", None)
        return False
    path = str(row["video_path"])
    queue = [{"id": sid, "path": path, "name": Path(path).name}]
    session["rategrp_queue"] = queue
    session["rategrp_total"] = len(queue)
    session["rategrp_processed"] = 0
    session["rategrp_queue_origin"] = "find_single"
    session["state"] = "rategrp_rate_source"
    session["find_mode"] = True
    session["find_single_row"] = row
    session["rategrp_rerate_rows"] = [row]
    session["rategrp_group_choice"] = {
        "label": row["video_name"],
        "orientation": row["codec"] or "SRC",
        "key": ("SRC", row["resolution"] or "?"),
    }
    color = extract_color_emoji(row["comments"])
    prefix = f"{color} " if color else ""
    await send_fn(f"Ð˜ÑÑ…Ð¾Ð´Ð½Ð¸Ðº Ð½Ð°Ð¹Ð´ÐµÐ½: {prefix}{row['video_name']}.", None)
    await rategrp_send_next_prompt(session, send_fn)
    return True


def _count_rategrp_unrated(rows: List[sqlite3.Row]) -> int:
    return sum(1 for row in rows if not _rategrp_row_has_color(row))


def _count_rows_for_folder_mode(rows: List[sqlite3.Row], unused_only: bool) -> int:
    if not unused_only:
        return len(rows)
    return sum(1 for row in rows if _is_unused_source_row(row))


def format_rategrp_group_prompt(
    session: Dict[str, Any],
    group_entries: List[SourceGroupEntry],
    orientation: str,
    prompt_kind: str = "text",
) -> List[str]:
    orientation_map = session.get("rategrp_group_orientations") or {}

    def prefix_func(entry: SourceGroupEntry) -> str:
        return orientation_map.get(entry.key, "")

    display_entries: List[SourceGroupEntry] = []
    for entry in group_entries:
        rows = list(entry.rows)
        display_entries.append(
            SourceGroupEntry(
                key=entry.key,
                rows=rows,
                unused_count=_count_rategrp_unrated(rows),
            )
        )

    lines = [
        f"ÐžÑ€Ð¸ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ñ: {orientation}.",
        "",
    ]
    lines.extend(
        format_source_group_lines(
            display_entries,
            "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð³Ñ€ÑƒÐ¿Ð¿Ñƒ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² (ðŸ†• = Ð±ÐµÐ· Ð¾Ñ†ÐµÐ½ÐºÐ¸):",
            prefix_func=prefix_func,
        )
    )
    lines.append("")
    if prompt_kind == "inline":
        lines.append("ÐÐ°Ð¶Ð¼Ð¸Ñ‚Ðµ Ð½Ð¾Ð¼ÐµÑ€ Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹ Ð½Ð° ÐºÐ»Ð°Ð²Ð¸Ð°Ñ‚ÑƒÑ€Ðµ Ð½Ð¸Ð¶Ðµ.")
    else:
        lines.append("ÐŸÑ€Ð¸ÑˆÐ»Ð¸Ñ‚Ðµ Ð½Ð¾Ð¼ÐµÑ€ Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€: 3).")
    return lines


def _compute_rategrp_color_counts(rows: List[sqlite3.Row]) -> Tuple[Dict[str, int], int]:
    counts = {info["emoji"]: 0 for info in RATEGRP_COLOR_CHOICES.values()}
    unrated = 0
    for row in rows:
        emoji = _rategrp_row_color(row)
        if emoji and emoji in counts:
            counts[emoji] += 1
        else:
            unrated += 1
    return counts, unrated


def _rategrp_available_colors(rows: List[sqlite3.Row]) -> List[Tuple[str, str, int]]:
    counts, _ = _compute_rategrp_color_counts(rows)
    available: List[Tuple[str, str, int]] = []
    for key, info in RATEGRP_COLOR_CHOICES.items():
        emoji = info["emoji"]
        count = counts.get(emoji, 0)
        if count > 0:
            available.append((key, emoji, count))
    return available


def _filter_rows_by_color(
    rows: List[sqlite3.Row],
    allowed: Set[str],
    include_unrated: bool = False,
) -> List[sqlite3.Row]:
    filtered: List[sqlite3.Row] = []
    for row in rows:
        emoji = _rategrp_row_color(row)
        if emoji:
            if emoji in allowed:
                filtered.append(row)
        else:
            if include_unrated:
                filtered.append(row)
    return filtered


def _filter_green_new_rows(rows: List[sqlite3.Row]) -> List[sqlite3.Row]:
    """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð²ÑÐµ Ð·ÐµÐ»Ñ‘Ð½Ñ‹Ðµ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¸ Ð¸ Ð»ÑŽÐ±Ñ‹Ðµ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¸ Ð±ÐµÐ· PMV-Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸."""
    filtered: List[sqlite3.Row] = []
    green_emoji = RATEGRP_COLOR_CHOICES["green"]["emoji"]
    for row in rows:
        emoji = _rategrp_row_color(row)
        if emoji == green_emoji or _is_unused_source_row(row):
            filtered.append(row)
    return filtered


def _prepare_rategrp_queue(rows: List[sqlite3.Row]) -> List[Dict[str, Any]]:
    unrated_rows = [row for row in rows if not _rategrp_row_has_color(row)]
    return _rategrp_rows_to_queue(unrated_rows)


def _rategrp_update_cached_row_color(
    session: Dict[str, Any],
    source_id: int,
    updated_comments: Optional[str],
) -> None:
    if not updated_comments:
        return
    rows = session.get("rategrp_rerate_rows") or []
    for row in rows:
        try:
            row_id = int(row.get("id") if isinstance(row, dict) else row["id"])
        except Exception:
            continue
        if row_id == source_id:
            try:
                row["comments"] = updated_comments  # type: ignore[index]
            except Exception:
                pass
            break


async def rategrp_send_next_prompt(
    session: Dict[str, Any],
    send_fn: Callable[[str, Optional[InlineKeyboardMarkup]], Awaitable[Any]],
    prefix: Optional[str] = None,
) -> None:
    queue: List[Dict[str, Any]] = session.get("rategrp_queue") or []
    total = int(session.get("rategrp_total", len(queue) or 0))
    processed = int(session.get("rategrp_processed", 0))
    if not queue:
        origin = session.get("rategrp_queue_origin")
        session["rategrp_queue_origin"] = None
        if origin == "find_pmv":
            session["state"] = "find_wait_term"
            session["find_matches"] = []
            lines = [prefix] if prefix else []
            lines.append("Ð˜ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¸ Ð¸Ð· Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð½Ð¾Ð³Ð¾ PMV Ð·Ð°ÐºÐ¾Ð½Ñ‡Ð¸Ð»Ð¸ÑÑŒ. ÐŸÑ€Ð¸ÑˆÐ»Ð¸Ñ‚Ðµ Ñ‡Ð°ÑÑ‚ÑŒ Ð¸Ð¼ÐµÐ½Ð¸ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÐµÐ³Ð¾ Ñ„Ð°Ð¹Ð»Ð°.")
            await send_fn("\n".join(line for line in lines if line), None)
        elif origin == "find_single":
            session["state"] = "find_wait_term"
            session["find_matches"] = []
            lines = [prefix] if prefix else []
            lines.append("Ð˜ÑÑ…Ð¾Ð´Ð½Ð¸Ðº Ð¾Ñ†ÐµÐ½Ñ‘Ð½. ÐœÐ¾Ð¶ÐµÑ‚Ðµ Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶Ð¸Ñ‚ÑŒ Ð¿Ð¾Ð¸ÑÐº Ð¸Ð»Ð¸ Ð²Ð²ÐµÑÑ‚Ð¸ Ð´Ñ€ÑƒÐ³ÑƒÑŽ Ñ‡Ð°ÑÑ‚ÑŒ Ð¸Ð¼ÐµÐ½Ð¸.")
            await send_fn("\n".join(line for line in lines if line), None)
        elif origin == "rerate":
            rows = session.get("rategrp_rerate_rows") or []
            available = _rategrp_available_colors(rows)
            if available:
                session["state"] = "rategrp_choose_rerate_color"
                lines = [prefix] if prefix else []
                lines.append("Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ñ†Ð²ÐµÑ‚, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ñ…Ð¾Ñ‚Ð¸Ñ‚Ðµ Ð¿ÐµÑ€ÐµÐ¾Ñ†ÐµÐ½Ð¸Ñ‚ÑŒ ÐµÑ‰Ñ‘ Ñ€Ð°Ð·.")
                await send_fn(
                    "\n".join(line for line in lines if line),
                    build_rategrp_rerate_keyboard(available),
                )
            else:
                session["state"] = "rategrp_choose_group"
                lines = [prefix] if prefix else []
                lines.append("Ð’ ÑÑ‚Ð¾Ð¹ Ð³Ñ€ÑƒÐ¿Ð¿Ðµ Ð±Ð¾Ð»ÑŒÑˆÐµ Ð½ÐµÑ‚ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² Ð´Ð»Ñ Ð¿ÐµÑ€ÐµÐ¾Ñ†ÐµÐ½ÐºÐ¸. Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð´Ñ€ÑƒÐ³ÑƒÑŽ Ð³Ñ€ÑƒÐ¿Ð¿Ñƒ.")
                await send_fn("\n".join(line for line in lines if line), None)
        else:
            session["state"] = "rategrp_choose_group"
            lines = [prefix] if prefix else []
            lines.append("Ð’ ÑÑ‚Ð¾Ð¹ Ð³Ñ€ÑƒÐ¿Ð¿Ðµ Ð½Ðµ Ð¾ÑÑ‚Ð°Ð»Ð¾ÑÑŒ Ð½ÐµÐ¾Ñ†ÐµÐ½Ñ‘Ð½Ð½Ñ‹Ñ… Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð². Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð´Ñ€ÑƒÐ³ÑƒÑŽ Ð³Ñ€ÑƒÐ¿Ð¿Ñƒ.")
            await send_fn("\n".join(line for line in lines if line), None)
        return
    current = queue[0]
    idx = processed + 1
    group_choice = session.get("rategrp_group_choice") or {}
    codec, res = group_choice.get("key") or ("?", "?")
    group_label = group_choice.get("label") or f"{codec} {res}"
    orientation = group_choice.get("orientation") or session.get("rategrp_orientation_preference") or "?"
    lines = []
    if prefix:
        lines.append(prefix)
    lines.append(f"Ð“Ñ€ÑƒÐ¿Ð¿Ð°: {group_label} ({orientation}).")
    if total:
        lines.append(f"Ð˜ÑÑ…Ð¾Ð´Ð½Ð¸Ðº {idx}/{max(total, idx)}")
    else:
        lines.append(f"Ð˜ÑÑ…Ð¾Ð´Ð½Ð¸Ðº {idx}")
    path = current["path"]
    lines.append("ÐŸÑƒÑ‚ÑŒ:")
    lines.append(f"```\n{path}\n```")
    lines.append(f"ÐžÑ†ÐµÐ½Ð¸Ñ‚Ðµ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸Ðº ÐºÐ½Ð¾Ð¿ÐºÐ°Ð¼Ð¸ Ð½Ð¸Ð¶Ðµ: {RATEGRP_COLOR_PROMPT}")
    await send_fn("\n".join(lines), build_rategrp_color_keyboard())
    launch_media_preview(path)


async def rategrp_apply_rating(
    session: Dict[str, Any],
    color_key: str,
    send_fn: Callable[[str, Optional[InlineKeyboardMarkup]], Awaitable[Any]],
) -> None:
    queue: List[Dict[str, Any]] = session.get("rategrp_queue") or []
    if not queue:
        await send_fn("ÐžÑ‡ÐµÑ€ÐµÐ´ÑŒ Ð¿ÑƒÑÑ‚Ð°Ñ. Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð´Ñ€ÑƒÐ³ÑƒÑŽ Ð³Ñ€ÑƒÐ¿Ð¿Ñƒ.", None)
        return
    choice = RATEGRP_COLOR_CHOICES.get(color_key)
    if not choice:
        await send_fn("ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ Ñ†Ð²ÐµÑ‚. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ ÐºÐ½Ð¾Ð¿ÐºÐ¸.", None)
        return
    current = queue.pop(0)
    session["rategrp_queue"] = queue
    session["rategrp_processed"] = int(session.get("rategrp_processed", 0)) + 1
    emoji = choice["emoji"]
    try:
        updated_comments = db_set_source_color(current["id"], emoji)
        _rategrp_update_cached_row_color(session, current["id"], updated_comments)
    except Exception as exc:
        await send_fn(f"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ ÑÐ¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ð¾Ñ†ÐµÐ½ÐºÑƒ: {exc}", None)
        return
    prefix = f"{emoji} Ð˜ÑÑ…Ð¾Ð´Ð½Ð¸Ðº {current['name']} Ð¾Ñ‚Ð¼ÐµÑ‡ÐµÐ½ ({choice['label']})."
    await rategrp_send_next_prompt(session, send_fn, prefix=prefix)


async def _rategrp_start_rerate(
    session: Dict[str, Any],
    color_key: str,
    send_fn: Callable[[str, Optional[InlineKeyboardMarkup]], Awaitable[Any]],
) -> bool:
    info = RATEGRP_COLOR_CHOICES.get(color_key)
    rows = session.get("rategrp_rerate_rows") or []
    if not info:
        await send_fn("ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ Ñ†Ð²ÐµÑ‚.", None)
        return False
    if not rows:
        await send_fn("ÐÐµÑ‚ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² Ð´Ð»Ñ Ð¿ÐµÑ€ÐµÐ¾Ñ†ÐµÐ½ÐºÐ¸. Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð´Ñ€ÑƒÐ³ÑƒÑŽ Ð³Ñ€ÑƒÐ¿Ð¿Ñƒ.", None)
        return False
    emoji = info["emoji"]
    filtered = [row for row in rows if _rategrp_row_color(row) == emoji]
    if not filtered:
        available = _rategrp_available_colors(rows)
        msg = "ÐÐµ Ð½Ð°ÑˆÑ‘Ð» Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² ÑÑ‚Ð¾Ð³Ð¾ Ñ†Ð²ÐµÑ‚Ð°. Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð´Ñ€ÑƒÐ³Ð¾Ð¹."
        markup = build_rategrp_rerate_keyboard(available) if available else None
        await send_fn(msg, markup)
        return False
    queue = _rategrp_rows_to_queue(filtered)
    session["rategrp_queue"] = queue
    session["rategrp_total"] = len(queue)
    session["rategrp_processed"] = 0
    session["state"] = "rategrp_rate_source"
    session["rategrp_queue_origin"] = "rerate"
    await send_fn(
        f"ÐŸÐµÑ€ÐµÐ¾Ñ†ÐµÐ½ÐºÐ° Ñ†Ð²ÐµÑ‚Ð° {emoji} ({info['label']}). Ð˜ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð²: {len(queue)}.", None
    )
    await rategrp_send_next_prompt(session, send_fn)
    return True


def normalize_rategrp_color_input(text: str) -> Optional[str]:
    lowered = text.strip().lower()
    mapping = {
        "green": "green",
        "Ð·ÐµÐ»": "green",
        "Ð·ÐµÐ»ÐµÐ½": "green",
        "Ð·ÐµÐ»ÐµÐ½Ð°Ñ": "green",
        "ðŸŸ¢": "green",
        "yellow": "yellow",
        "Ð¶Ñ‘Ð»Ñ‚": "yellow",
        "Ð¶ÐµÐ»Ñ‚": "yellow",
        "Ð¶ÐµÐ»Ñ‚Ð°Ñ": "yellow",
        "ðŸŸ¡": "yellow",
        "red": "red",
        "ÐºÑ€Ð°ÑÐ½": "red",
        "ÐºÑ€Ð°ÑÐ½Ð°Ñ": "red",
        "ðŸ”´": "red",
        "pink": "pink",
        "Ñ€Ð¾Ð·Ð¾Ð²": "pink",
        "Ñ€Ð¾Ð·Ð¾Ð²Ð°Ñ": "pink",
        "ðŸ©·": "pink",
        "blue": "blue",
        "ÑÐ¸Ð½": "blue",
        "ÑÐ¸Ð½ÑÑ": "blue",
        "ðŸ”µ": "blue",
        "favorite": "favorite",
        "fav": "favorite",
        "Ð·Ð²ÐµÐ·Ð´": "favorite",
        "Ð¸Ð·Ð±Ñ€": "favorite",
        "â­": "favorite",
        "inspect": "inspect",
        "Ð³Ð»Ð°Ð·": "inspect",
        "Ð¸Ð½Ñ‚ÐµÑ€ÐµÑ": "inspect",
        "ðŸ‘": "inspect",
        "delete": "delete",
        "ÑƒÐ´Ð°Ð»": "delete",
        "ÐºÑ€ÐµÑÑ‚": "delete",
        "âŒ": "delete",
    }
    for key, target in mapping.items():
        if lowered.startswith(key):
            return target
    return None


def _source_limit_message(sess: Dict[str, Any], available: int) -> str:
    if sess.get("music_color_rows"):
        return f"Ð”Ð»Ñ Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð½Ð¾Ð³Ð¾ Ñ†Ð²ÐµÑ‚Ð° Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ {available} Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð². Ð’Ð¾Ð·ÑŒÐ¼Ñ‘Ð¼ Ð¸Ñ… Ð²ÑÐµ."
    return f"Ð’ Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð½Ð¾Ð¹ Ð¿Ð¾Ð´Ð¿Ð°Ð¿ÐºÐµ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ {available} Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð². Ð’Ð¾Ð·ÑŒÐ¼Ñ‘Ð¼ Ð¸Ñ… Ð²ÑÐµ."


def launch_media_preview(file_path: Union[str, Path]) -> None:
    if not MEDIA_PLAYER_EXECUTABLE.exists():
        return
    try:
        target = Path(file_path)
    except Exception:
        return
    if not target.exists():
        return
    try:
        subprocess.Popen([str(MEDIA_PLAYER_EXECUTABLE), str(target)])
    except Exception:
        pass


def apply_newcomp_folder_choice(
    sess: Dict[str, Any],
    token: str,
    next_state: str,
) -> Tuple[int, str]:
    folder_map: Dict[str, Dict[str, Any]] = sess.get("music_folder_map") or {}
    info = folder_map.get(token)
    if not info:
        raise ValueError("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð½Ð°Ð¹Ñ‚Ð¸ Ñ‚Ð°ÐºÑƒÑŽ Ð¿Ð¾Ð´Ð¿Ð°Ð¿ÐºÑƒ.")
    rows = list(info.get("rows") or [])
    if not rows:
        raise ValueError("Ð’ Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð½Ð¾Ð¹ Ð¿Ð¾Ð´Ð¿Ð°Ð¿ÐºÐµ Ð½ÐµÑ‚ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð².")
    folder_label = info.get("label") or "Ð’ÑÐµ Ð¿Ð°Ð¿ÐºÐ¸"
    folder_path = info.get("path")
    choice = sess.setdefault("music_group_choice", {})
    choice["count"] = len(rows)
    choice["folder_path"] = folder_path
    choice["folder_label"] = folder_label
    sess["music_folder_choice"] = {
        "token": token,
        "label": folder_label,
        "path": folder_path,
        "count": len(rows),
    }
    sess["state"] = next_state
    return len(rows), folder_label


def _shorten_codec(codec: str) -> str:
    codec = (codec or "").strip().lower()
    if not codec:
        return "??"
    clean = "".join(ch for ch in codec if ch.isalnum())
    if not clean:
        clean = codec
    return clean[:2].ljust(2, "?")


def _format_compact_date(value: Optional[date]) -> str:
    if not value:
        return "------"
    return value.strftime("%d%m%y")


def collect_source_usage_stats() -> Dict[int, Dict[str, Any]]:
    """
    Ð¡Ñ‚Ñ€Ð¾Ð¸Ñ‚ Ð¸Ð½Ð´ÐµÐºÑ Ð¿Ð¾ source_id -> {count, last_date} Ð¸Ð· Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹ compilations.
    """
    usage: Dict[int, Dict[str, Any]] = {}
    conn = get_conn()
    cur = conn.cursor()
    cur.execute("SELECT pmv_date, source_ids FROM compilations")
    rows = cur.fetchall()
    conn.close()

    for row in rows:
        date_str = row["pmv_date"]
        try:
            last_date = datetime.strptime(date_str, "%Y-%m-%d").date()
        except Exception:
            last_date = None
        source_field = row["source_ids"] or ""
        for part in source_field.replace(";", ",").split(","):
            part = part.strip()
            if not part.isdigit():
                continue
            sid = int(part)
            info = usage.setdefault(sid, {"count": 0, "last_date": None})
            info["count"] += 1
            if last_date and (info["last_date"] is None or last_date > info["last_date"]):
                info["last_date"] = last_date
    return usage


def _group_last_used_date(entry: SourceGroupEntry, usage_index: Dict[int, Dict[str, Any]]) -> Optional[date]:
    last: Optional[date] = None
    for row in entry.rows:
        sid = int(row["id"])
        info = usage_index.get(sid)
        if not info:
            continue
        dt = info.get("last_date")
        if dt and (last is None or dt > last):
            last = dt
    return last


def format_source_group_lines(
    entries: List[SourceGroupEntry],
    header: str,
    prefix_func: Optional[Callable[[SourceGroupEntry], str]] = None,
) -> List[str]:
    usage_index = collect_source_usage_stats()
    lines = [header]
    for idx, entry in enumerate(entries, 1):
        codec, res = entry.key
        codec_short = _shorten_codec(codec)
        resolution_label = f"{(res or '??x??')}{codec_short}"
        total = len(entry.rows)
        new_block = f"(ðŸ†•{entry.unused_count})" if entry.unused_count else ""
        count_label = f"{total}{new_block}"
        last_date = _format_compact_date(_group_last_used_date(entry, usage_index))
        prefix = ""
        if prefix_func:
            custom = (prefix_func(entry) or "").strip()
            if custom:
                prefix = f"{custom} "
        lines.append(f"{idx}. {prefix}{resolution_label} - {count_label} {last_date}")
    return lines


def sort_group_entries_with_orientation(
    entries: List[SourceGroupEntry],
) -> Tuple[List[SourceGroupEntry], Dict[Tuple[str, str], str]]:
    orientation_map: Dict[Tuple[str, str], str] = {}
    annotated: List[Tuple[SourceGroupEntry, str, int]] = []
    for entry in entries:
        label, order = _resolution_orientation(entry.key[1] or "")
        orientation_map[entry.key] = label
        annotated.append((entry, label, order))
    annotated.sort(
        key=lambda item: (
            item[2],
            -_resolution_pixels(item[0].key[1] or ""),
            -len(item[0].rows),
            f"{(item[0].key[0] or '').lower()}_{(item[0].key[1] or '').lower()}",
        )
    )
    sorted_entries = [item[0] for item in annotated]
    return sorted_entries, orientation_map


def sort_source_group_entries(entries: List[SourceGroupEntry]) -> List[SourceGroupEntry]:
    return sorted(
        entries,
        key=lambda e: (
            -_resolution_pixels(e.key[1] or ""),
            -len(e.rows),
            f"{(e.key[0] or '').lower()}_{(e.key[1] or '').lower()}",
        ),
    )

def db_get_used_sources_grouped() -> Dict[Tuple[str, str], List[sqlite3.Row]]:
    """
    Ð‘ÐµÑ€Ñ‘Ñ‚ Ð¢ÐžÐ›Ð¬ÐšÐž ÑƒÐ¶Ðµ ÑƒÑ‡Ð°ÑÑ‚Ð²Ð¾Ð²Ð°Ð²ÑˆÐ¸Ðµ Ð² ÐºÐ¾Ð¼Ð¿Ð¸Ð»ÑÑ†Ð¸ÑÑ… Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¸ (pmv_list Ð½Ðµ Ð¿ÑƒÑÑ‚Ð¾Ð¹)
    Ð¸ Ð³Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€ÑƒÐµÑ‚ Ð¿Ð¾ (codec, resolution).
    """
    conn = get_conn()
    cur = conn.cursor()
    cur.execute(
        """
        SELECT * FROM sources
        WHERE pmv_list IS NOT NULL AND pmv_list != ''
        """
    )
    rows = cur.fetchall()
    conn.close()

    groups: Dict[Tuple[str, str], List[sqlite3.Row]] = {}
    for r in rows:
        codec = r["codec"] or "?"
        resolution = r["resolution"] or "??x??"
        key = (codec, resolution)
        groups.setdefault(key, []).append(r)
    return groups


def db_get_used_sources_list() -> List[sqlite3.Row]:
    conn = get_conn()
    cur = conn.cursor()
    cur.execute(
        """
        SELECT * FROM sources
        WHERE pmv_list IS NOT NULL AND pmv_list != ''
        """
    )
    rows = cur.fetchall()
    conn.close()
    return rows



def db_update_sources_pmv_list(source_ids: List[int], pmv_tag: str) -> None:
    if not source_ids:
        return
    conn = get_conn()
    cur = conn.cursor()
    for sid in source_ids:
        cur.execute("SELECT pmv_list FROM sources WHERE id = ?", (sid,))
        row = cur.fetchone()
        if not row:
            continue
        current = (row["pmv_list"] or "").strip()
        if not current:
            new_val = pmv_tag
        else:
            parts = [p.strip() for p in current.split(",") if p.strip()]
            if pmv_tag not in parts:
                parts.append(pmv_tag)
            new_val = ", ".join(parts)
        cur.execute("UPDATE sources SET pmv_list = ? WHERE id = ?", (new_val, sid))
    conn.commit()
    conn.close()


def db_insert_compilation(
    video_path: Path,
    source_ids: List[int],
    comments: str = "",
) -> None:
    conn = get_conn()
    cur = conn.cursor()
    cur.execute(
        """
        INSERT INTO compilations (video_path, pmv_date, source_ids, comments)
        VALUES (?, ?, ?, ?)
        """,
        (
            str(video_path.resolve()),
            date.today().isoformat(),
            ",".join(str(sid) for sid in source_ids),
            comments,
        ),
    )
    conn.commit()
    conn.close()

def db_get_all_sources() -> List[sqlite3.Row]:
    conn = get_conn()
    cur = conn.cursor()
    cur.execute(
        """
        SELECT id, video_name, video_path, comments
        FROM sources
        ORDER BY id
        """
    )
    rows = cur.fetchall()
    conn.close()
    return rows


def db_get_sources_full() -> List[Dict[str, Any]]:
    conn = get_conn()
    cur = conn.cursor()
    cur.execute(
        """
        SELECT id, video_name, video_path, size_bytes, codec, resolution,
               pmv_list, comments, date_added
        FROM sources
        ORDER BY id
        """
    )
    rows = [dict(row) for row in cur.fetchall()]
    conn.close()
    return rows


def db_update_source_fields(source_id: int, **fields: Any) -> None:
    if not fields:
        return
    columns = ", ".join(f"{key} = ?" for key in fields.keys())
    params = list(fields.values())
    params.append(source_id)
    conn = get_conn()
    cur = conn.cursor()
    cur.execute(f"UPDATE sources SET {columns} WHERE id = ?", params)
    conn.commit()
    conn.close()


def db_delete_sources_by_ids(ids: Iterable[int]) -> int:
    ids_list = [int(i) for i in ids]
    if not ids_list:
        return 0
    placeholders = ", ".join("?" for _ in ids_list)
    conn = get_conn()
    cur = conn.cursor()
    cur.execute(f"DELETE FROM sources WHERE id IN ({placeholders})", ids_list)
    deleted = cur.rowcount
    conn.commit()
    conn.close()
    return deleted


def db_get_sources_with_comments() -> List[sqlite3.Row]:
    conn = get_conn()
    cur = conn.cursor()
    cur.execute(
        """
        SELECT id, video_name, video_path, comments
        FROM sources
        WHERE comments IS NOT NULL AND comments != ''
        ORDER BY id
        """
    )
    rows = cur.fetchall()
    conn.close()
    return rows


def db_get_compilations_with_comments() -> List[sqlite3.Row]:
    conn = get_conn()
    cur = conn.cursor()
    cur.execute(
        """
        SELECT id, video_path, pmv_date, comments
        FROM compilations
        WHERE comments IS NOT NULL AND comments != ''
        ORDER BY pmv_date DESC, id DESC
        """
    )
    rows = cur.fetchall()
    conn.close()
    return rows


def db_get_compilation_by_video_path(video_path: Path) -> Optional[sqlite3.Row]:
    conn = get_conn()
    cur = conn.cursor()
    resolved = str(video_path.resolve())
    cur.execute("SELECT * FROM compilations WHERE video_path = ?", (resolved,))
    row = cur.fetchone()
    if not row:
        cur.execute(
            "SELECT * FROM compilations WHERE video_path LIKE ? ORDER BY id DESC LIMIT 1",
            (f"%{video_path.name}",),
        )
        row = cur.fetchone()
    conn.close()
    return row


def _normalize_windows_share_path(path: str) -> str:
    normalized = path.replace("\\", "/")
    while "//" in normalized:
        normalized = normalized.replace("//", "/")
    return normalized.rstrip("/")


def convert_windows_path_to_nas(path: Optional[str]) -> Optional[str]:
    if not path or not NAS_SHARE_PREFIX or not NAS_SHARE_ROOT:
        return None
    normalized = _normalize_windows_share_path(path)
    prefix = _normalize_windows_share_path(NAS_SHARE_PREFIX)
    if not normalized.lower().startswith(prefix.lower()):
        return None
    suffix = normalized[len(prefix):].lstrip("/")
    if not suffix:
        return None
    root = NAS_SHARE_ROOT.rstrip("/")
    return f"{root}/{suffix}"


def collect_symlink_plan() -> Tuple[Dict[str, List[Tuple[int, str, str]]], int]:
    """
    Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ {folder: [(source_id, target_path, safe_name), ...]}, Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ°Ñ
    Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¸ Ð±ÐµÐ· Ð¾Ñ†ÐµÐ½ÐºÐ¸ Ð¸Ð»Ð¸ Ð±ÐµÐ· ÑÐ¾Ð¿Ð¾ÑÑ‚Ð°Ð²Ð¸Ð¼Ð¾Ð³Ð¾ Ð¿ÑƒÑ‚Ð¸.
    """
    plan: Dict[str, List[Tuple[int, str, str]]] = defaultdict(list)
    skipped = 0
    conn = get_conn()
    conn.row_factory = sqlite3.Row
    cur = conn.cursor()
    cur.execute("SELECT id, video_path, comments FROM sources")
    for row in cur.fetchall():
        color_key = _rategrp_row_color(row)
        if not color_key:
            continue
        folder = NAS_SYMLINK_COLOR_FOLDERS.get(color_key)
        if not folder:
            continue
        video_path = row["video_path"]
        remote_target = convert_windows_path_to_nas(video_path)
        if not remote_target:
            skipped += 1
            continue
        try:
            source_id = int(row["id"])
        except Exception:
            skipped += 1
            continue
        safe_name = sanitize_filename(Path(video_path).name or f"source_{source_id}")
        plan[folder].append((source_id, remote_target, safe_name))
    conn.close()
    return plan, skipped


def sync_nas_symlinks() -> List[str]:
    if not NAS_SSH_HOST or not NAS_SIM_REMOTE_ROOT:
        return []
    plan, skipped = collect_symlink_plan()
    total_links = sum(len(v) for v in plan.values())
    if total_links == 0:
        if skipped:
            return [f"â„¹ï¸ Ð¡Ð¸Ð¼Ð»Ð¸Ð½ÐºÐ¸: Ð½ÐµÑ‚ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ñ… Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² (Ð¿Ñ€Ð¾Ð¿ÑƒÑ‰ÐµÐ½Ð¾ {skipped})."]
        return ["â„¹ï¸ Ð¡Ð¸Ð¼Ð»Ð¸Ð½ÐºÐ¸: Ð½ÐµÑ‚ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² Ñ Ð¾Ñ†ÐµÐ½ÐºÐ°Ð¼Ð¸ â€” ÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¿Ñ€Ð¾Ð¿ÑƒÑ‰ÐµÐ½Ð°."]
    try:
        import paramiko
    except ImportError:
        return [
            "âš ï¸ Ð£ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚Ðµ Ð¿Ð°ÐºÐµÑ‚ paramiko (`pip install paramiko`), Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¾Ð±Ð½Ð¾Ð²Ð»ÑÑ‚ÑŒ ÑÐ¸Ð¼Ð»Ð¸Ð½ÐºÐ¸ Ð½Ð° NAS."
        ]

    root = NAS_SIM_REMOTE_ROOT.rstrip("/")
    script_lines = [
        "set -e",
        f"ROOT={shlex.quote(root)}",
        "mkdir -p \"$ROOT\"",
        "if [ -d \"$ROOT\" ]; then find \"$ROOT\" -mindepth 1 -maxdepth 1 -exec rm -rf {} +; fi",
    ]

    for folder, entries in plan.items():
        folder_path = f"{root}/{folder}"
        script_lines.append(f"mkdir -p {shlex.quote(folder_path)}")
        for source_id, target_path, safe_name in entries:
            link_path = f"{folder_path}/{source_id}_{safe_name}"
            script_lines.append(
                f"ln -sf {shlex.quote(target_path)} {shlex.quote(link_path)}"
            )

    script = "\n".join(script_lines) + "\n"

    client = paramiko.SSHClient()
    client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
    messages: List[str] = []
    try:
        client.connect(
            NAS_SSH_HOST,
            port=NAS_SSH_PORT,
            username=NAS_SSH_USER,
            password=NAS_SSH_PASSWORD or None,
            timeout=NAS_SSH_TIMEOUT,
        )
        stdin, stdout, stderr = client.exec_command("bash -s", timeout=NAS_SSH_TIMEOUT)
        stdin.write(script)
        stdin.channel.shutdown_write()
        out = stdout.read().decode("utf-8", errors="ignore").strip()
        err = stderr.read().decode("utf-8", errors="ignore").strip()
        exit_code = stdout.channel.recv_exit_status()
    finally:
        client.close()

    if exit_code != 0:
        return [
            f"âš ï¸ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ð¸ ÑÐ¸Ð¼Ð»Ð¸Ð½ÐºÐ¾Ð² Ð½Ð° NAS (ÐºÐ¾Ð´ {exit_code}).",
            err or out or "Ð‘ÐµÐ· Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ Ð²Ñ‹Ð²Ð¾Ð´Ð°.",
        ]

    msg = f"âœ… ÐÐ° NAS ÑÐ¾Ð·Ð´Ð°Ð½Ð¾ {total_links} ÑÐ¸Ð¼Ð»Ð¸Ð½ÐºÐ¾Ð² Ð² {len(plan)} Ð¿Ð°Ð¿ÐºÐ°Ñ…."
    if skipped:
        msg += f" ÐŸÑ€Ð¾Ð¿ÑƒÑ‰ÐµÐ½Ð¾ Ð¿ÑƒÑ‚ÐµÐ¹: {skipped}."
    messages.append(msg)
    if out:
        messages.append(out)
    if err:
        messages.append(err)
    return messages


def db_get_sources_by_ids(ids: Iterable[int]) -> List[sqlite3.Row]:
    ids_list = [int(i) for i in ids if int(i) > 0]
    if not ids_list:
        return []
    placeholders = ",".join("?" for _ in ids_list)
    conn = get_conn()
    cur = conn.cursor()
    cur.execute(f"SELECT * FROM sources WHERE id IN ({placeholders})", ids_list)
    rows = cur.fetchall()
    conn.close()
    return rows


def db_get_random_name() -> str:
    conn = get_conn()
    cur = conn.cursor()
    cur.execute("SELECT id, adjective, noun, verb, number FROM random_names")
    rows = cur.fetchall()
    conn.close()
    if not rows:
        return "PMV_from_files"
    row = random.choice(rows)
    adj = row["adjective"]
    noun = row["noun"]
    verb = row["verb"]
    num = row["number"]
    # Ð±ÐµÐ· Ð¿Ñ€Ð¾Ð±ÐµÐ»Ð¾Ð², Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¸Ð¼Ñ Ñ„Ð°Ð¹Ð»Ð° Ð±Ñ‹Ð»Ð¾ Ð°ÐºÐºÑƒÑ€Ð°Ñ‚Ð½Ñ‹Ð¼
    return f"{adj}_{noun}_{verb}{num}"


# Ð”Ð¾Ð¿. DB-Ñ…ÐµÐ»Ð¿ÐµÑ€Ñ‹ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð½Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð²

def db_get_source_id_by_path(video_path: Path) -> Optional[int]:
    conn = get_conn()
    cur = conn.cursor()
    cur.execute("SELECT id FROM sources WHERE video_path = ?", (str(video_path.resolve()),))
    row = cur.fetchone()
    conn.close()
    return int(row["id"]) if row else None


def db_mark_source_problem(source_id: int, reason: str) -> None:
    reason = reason.strip()
    if not reason:
        reason = "unknown"
    ts = datetime.now().strftime("%Y-%m-%d")
    db_append_source_comment(source_id, f"problem={reason};date={ts}")


def db_get_problem_sources() -> List[sqlite3.Row]:
    conn = get_conn()
    cur = conn.cursor()
    cur.execute(
        """
        SELECT id, video_name, video_path, comments
        FROM sources
        WHERE comments LIKE '%problem=%'
        ORDER BY id
        """
    )
    rows = cur.fetchall()
    conn.close()
    return rows

# =========================
# FFPROBE / FFMPEG Ð£Ð¢Ð˜Ð›Ð˜Ð¢Ð«
# =========================


def ffprobe_available() -> bool:
    try:
        subprocess.check_output([FFPROBE_BIN, "-version"], stderr=subprocess.STDOUT)
        return True
    except Exception:
        return False



def ffmpeg_probe_duration_seconds(path: Path) -> float:
    try:
        out = subprocess.run(
            [FFMPEG_BIN, "-hide_banner", "-i", str(path)],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
        )
        m = re.search(r"Duration:\s*(\d{2}):(\d{2}):(\d{2}\.\d+)", out.stderr or "")
        if not m:
            return 0.0
        hh, mm, ss = m.groups()
        return int(hh) * 3600 + int(mm) * 60 + float(ss)
    except Exception:
        return 0.0


def ffprobe_duration_seconds(path: Path) -> float:
    if not ffprobe_available():
        return ffmpeg_probe_duration_seconds(path)
    try:
        out = subprocess.check_output(
            [
                FFPROBE_BIN,
                "-v", "error",
                "-show_entries", "format=duration",
                "-of", "default=noprint_wrappers=1:nokey=1",
                str(path),
            ],
            text=True,
        ).strip()
        return float(out)
    except Exception:
        return ffmpeg_probe_duration_seconds(path)



def normalize_codec(codec: str) -> str:
    codec = (codec or "").lower()
    if codec in ("avc1", "h264"):
        return "h264"
    if codec in ("hvc1", "hev1", "hevc"):
        return "hevc"
    return codec


def video_info_sort(path: Path) -> Tuple[str, str]:
    if ffprobe_available():
        try:
            out = subprocess.check_output(
                [
                    FFPROBE_BIN,
                    "-v", "error",
                    "-select_streams", "v:0",
                    "-show_entries", "stream=codec_name,width,height",
                    "-of", "default=nw=1:nk=1",
                    str(path),
                ],
                text=True,
            ).strip().splitlines()
            codec = normalize_codec(out[0] if len(out) > 0 else "")
            w = out[1] if len(out) > 1 else ""
            h = out[2] if len(out) > 2 else ""
            wh = f"{w}x{h}" if w and h else ""
            return codec, wh
        except Exception:
            pass

    try:
        pr = subprocess.run(
            [FFMPEG_BIN, "-hide_banner", "-i", str(path)],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
        )
        stderr = pr.stderr or ""
        m = re.search(r"Video:\s*([a-z0-9_]+)", stderr, re.I)
        codec = normalize_codec(m.group(1)) if m else ""
        m2 = re.search(r"(\d{2,5})x(\d{2,5})", stderr)
        wh = f"{m2.group(1)}x{m2.group(2)}" if m2 else ""
        return codec, wh
    except Exception:
        return "", ""



def detect_video_info(path: Path) -> Dict[str, str]:
    info = {"codec_name": "", "width": "", "height": "", "fps": "", "pix_fmt": ""}
    if ffprobe_available():
        try:
            out = subprocess.check_output(
                [
                    FFPROBE_BIN,
                    "-v", "error",
                    "-select_streams", "v:0",
                    "-show_entries", "stream=codec_name,width,height,avg_frame_rate,pix_fmt",
                    "-of", "default=nw=1:nk=1",
                    str(path),
                ],
                text=True,
            ).strip().splitlines()
            vals = (out + [""] * 5)[:5]
            info["codec_name"], info["width"], info["height"], fps, info["pix_fmt"] = vals
            if "/" in fps and fps != "0/0":
                try:
                    a, b = fps.split("/")
                    fps = str(round(float(a) / float(b), 3))
                except Exception:
                    pass
            info["fps"] = fps
            return info
        except Exception:
            pass

    try:
        pr = subprocess.run(
            [FFMPEG_BIN, "-hide_banner", "-i", str(path)],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
        )
        stderr = pr.stderr or ""
        m = re.search(
            r"Video:\s*([a-z0-9_]+)\s*(\([^)]+\))?,\s*([0-9a-z_]+)?\s*,\s*(\d{2,5})x(\d{2,5})",
            stderr,
            re.I,
        )
        if m:
            info["codec_name"] = m.group(1).lower()
            info["pix_fmt"] = (m.group(3) or "").lower()
            info["width"] = m.group(4) or ""
            info["height"] = m.group(5) or ""
        m2 = re.search(r"(\d+(?:\.\d+)?|\d+/\d+)\s*fps", stderr, re.I)
        if m2:
            info["fps"] = m2.group(1)
    except Exception:
        pass
    return info



def pick_temp_dir(candidates: List[Path], min_free_bytes: int = 5 * 1024**3) -> Path:
    for d in candidates:
        try:
            d.mkdir(parents=True, exist_ok=True)
            total, used, free = shutil.disk_usage(str(d))
            if free > min_free_bytes:
                return d
        except Exception:
            continue
    d0 = candidates[0]
    d0.mkdir(parents=True, exist_ok=True)
    return d0


# =========================
# Ð›ÐžÐ“Ð˜ÐšÐ ÐŸÐ›ÐÐÐ˜Ð ÐžÐ’ÐÐÐ˜Ð¯ ÐšÐ›Ð˜ÐŸÐžÐ’
# =========================

def allocate_equalish(
    target_sec: int,
    files: List[Path],
    durations: Dict[Path, int],
    per_min: int = PER_FILE_MIN_SECONDS,
    per_max: int = PER_FILE_MAX_SECONDS,
) -> Dict[Path, int]:
    """
    Ð Ð°Ð²Ð½Ð¾Ð¼ÐµÑ€Ð½Ð¾Ðµ Ñ€Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸ Ð¼ÐµÐ¶Ð´Ñƒ Ñ„Ð°Ð¹Ð»Ð°Ð¼Ð¸.

    Ð’ÐÐ–ÐÐž: Ñ‚ÐµÐ¿ÐµÑ€ÑŒ ÐÐ• Ñ„Ð¾Ñ€ÑÐ¸Ð¼ per_min, ÐµÑÐ»Ð¸ target ÑÐ»Ð¸ÑˆÐºÐ¾Ð¼ Ð¼Ð°Ð»ÐµÐ½ÑŒÐºÐ¸Ð¹,
    Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð½Ðµ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ ÑÐ¸Ñ‚ÑƒÐ°Ñ†Ð¸ÑŽ, ÐºÐ¾Ð³Ð´Ð° 15 Ð¼Ð¸Ð½ÑƒÑ‚ â†’ 45 Ð¼Ð¸Ð½ÑƒÑ‚.
    """
    n = len(files)
    if n == 0 or target_sec <= 0:
        return {f: 0 for f in files}

    total_dur = sum(durations.get(f, 0) for f in files)
    if total_dur <= 0:
        return {f: 0 for f in files}

    ideal = max(1, target_sec // n)
    # Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð²ÐµÑ€Ñ…Ð½Ð¸Ð¹ Ð¿Ñ€ÐµÐ´ÐµÐ», Ð±ÐµÐ· Ð½Ð¸Ð¶Ð½ÐµÐ³Ð¾
    ideal_clamped = min(per_max, ideal)

    alloc: Dict[Path, int] = {}
    for f in files:
        dur = durations.get(f, 0)
        alloc[f] = min(ideal_clamped, dur)

    max_total = min(target_sec, total_dur)
    current = sum(alloc.values())
    leftover = max_total - current
    if leftover <= 0:
        return alloc

    order = sorted(files, key=lambda f: durations.get(f, 0), reverse=True)

    while leftover > 0:
        progressed = False
        for f in order:
            dur = durations.get(f, 0)
            # Ð²ÑÑ‘ ÐµÑ‰Ñ‘ ÑƒÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ð¿ÐµÑ€-Ñ„Ð°Ð¹Ð» Ð¼Ð°ÐºÑÐ¸Ð¼ÑƒÐ¼
            if alloc[f] >= min(per_max, dur):
                continue
            alloc[f] += 1
            leftover -= 1
            progressed = True
            if leftover <= 0:
                break
        if not progressed:
            break

    return alloc


def split_into_big_parts(file_len: int, parts: int) -> List[Tuple[int, int]]:
    parts = max(1, parts)
    base = file_len // parts
    rem = file_len - base * parts
    res = []
    cur = 0
    for i in range(parts):
        L = base + (1 if i < rem else 0)
        res.append((cur, L))
        cur += L
    return res


def jittered_partition(total_len: int, count: int, min_each: int = 1) -> List[int]:
    """Ð”ÐµÐ»Ð¸Ñ‚ total_len Ð½Ð° count Ñ‡Ð°ÑÑ‚ÐµÐ¹ Ñ ÑˆÑƒÐ¼Ð¾Ð¼, ÑÐ¾Ð±Ð»ÑŽÐ´Ð°Ñ min_each.
    Ð“Ð°Ñ€Ð°Ð½Ñ‚Ð¸Ñ€ÑƒÐµÑ‚ ÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ñ‹Ðµ Ð³Ñ€Ð°Ð½Ð¸Ñ†Ñ‹ Ð´Ð»Ñ randint Ð´Ð°Ð¶Ðµ Ð¿Ñ€Ð¸ Ð¼Ð°Ð»Ñ‹Ñ… total_len.
    """
    rng = random.Random(RANDOM_SEED)
    total_len = max(0, int(total_len))
    min_each = max(1, int(min_each))

    # ÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ñ‡Ð°ÑÑ‚ÐµÐ¹ Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾ Ð¼Ð¾Ð¶ÐµÐ¼ ÑÐ´ÐµÐ»Ð°Ñ‚ÑŒ, ÑƒÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°Ñ Ð¼Ð¸Ð½Ð¸Ð¼ÑƒÐ¼
    max_count = max(1, total_len // min_each) if total_len > 0 else 1
    count = max(1, min(int(count), max_count))

    base = max(min_each, total_len // count) if count > 0 else total_len
    jitter = max(1, int(base * 0.3))

    lens: List[int] = []
    remain = total_len
    left = count
    for _ in range(count):
        if left == 1:
            x = remain
        else:
            low = max(min_each, base - jitter)
            # Ð²ÐµÑ€Ñ…Ð½ÑÑ Ð³Ñ€Ð°Ð½Ð¸Ñ†Ð° Ñ ÑƒÑ‡Ñ‘Ñ‚Ð¾Ð¼ Ð¾ÑÑ‚Ð°Ð²ÑˆÐµÐ³Ð¾ÑÑ Ð¼Ð¸Ð½Ð¸Ð¼ÑƒÐ¼Ð° Ð½Ð° Ñ…Ð²Ð¾ÑÑ‚
            upper_cap = remain - (left - 1) * min_each
            high = max(low, min(base + jitter, upper_cap))
            if high < low:
                x = max(min_each, min(upper_cap, low))
            else:
                x = rng.randint(low, high)
        lens.append(x)
        remain -= x
    left -= 1
    return lens


def _clip_guard_limits(duration: int) -> Tuple[bool, int, int]:
    head = max(0, int(CLIP_HEAD_GUARD_SECONDS))
    tail = max(0, int(CLIP_TAIL_GUARD_SECONDS))
    if duration <= head + tail:
        return False, 0, duration
    guard_start = min(head, duration)
    guard_end = max(guard_start + 1, duration - tail)
    guard_end = min(guard_end, duration)
    return True, guard_start, guard_end



def _plan_for_file_default(
    file_path: Path,
    file_alloc: int,
    big_parts: int,
    small_per_big: int,
) -> List[Tuple[int, int]]:
    dur = int(ffprobe_duration_seconds(file_path))
    if dur <= 0 or file_alloc <= 0:
        return []

    guard_active, guard_start, guard_end = _clip_guard_limits(dur)

    windows = split_into_big_parts(dur, big_parts)
    base = file_alloc // len(windows)
    rem = file_alloc - base * len(windows)

    clips: List[Tuple[int, int]] = []

    for idx, (wstart, wlen) in enumerate(windows):
        if guard_active:
            eff_start = max(wstart, guard_start)
            eff_end = min(wstart + wlen, guard_end)
            wstart_eff = eff_start
            wlen_eff = max(0, eff_end - eff_start)
        else:
            wstart_eff = wstart
            wlen_eff = wlen
        alloc = min(wlen_eff, base + (1 if idx < rem else 0))
        if alloc <= 0:
            continue
        
        spb = min(small_per_big, max(1, alloc // MIN_SMALL_CLIP_SECONDS))
        lengths = jittered_partition(alloc, spb, min_each=MIN_SMALL_CLIP_SECONDS)

        total_clips_len = sum(lengths)
        slack = max(0, wlen_eff - total_clips_len)
        gaps = spb + 1
        base_gap = slack // gaps
        extra = slack - base_gap * gaps
        cur = wstart_eff + base_gap + (1 if extra > 0 else 0)
        extra_left = max(0, extra - 1)
        for L in lengths:
            clips.append((cur, L))
            cur = cur + L + base_gap + (1 if extra_left > 0 else 0)
            if extra_left > 0:
                extra_left -= 1

    clips.sort(key=lambda x: x[0])
    total = sum(d for _, d in clips)
    if total > file_alloc and clips:
        overflow = total - file_alloc
        s, d = clips[-1]
        d2 = max(1, d - overflow)
        clips[-1] = (s, d2)
    return clips


def plan_for_file(
    file_path: Path,
    file_alloc: int,
    big_parts: int,
    small_per_big: int,
    algo_key: str = "default",
) -> List[Tuple[int, int]]:
    if algo_key == "poi":
        clips = plan_for_file_poi(file_path, file_alloc)
        if clips:
            return clips
    return _plan_for_file_default(file_path, file_alloc, big_parts, small_per_big)


def _extract_audio_energy_profile(path: Path) -> List[Tuple[float, float]]:
    cmd = [
        FFMPEG_BIN,
        "-hide_banner",
        "-nostats",
        "-loglevel",
        "error",
        "-i",
        str(path),
        "-af",
        f"astats=metadata=1:reset={POI_ANALYSIS_RESET},ametadata=print:file=-",
        "-f",
        "null",
        "-",
    ]
    try:
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            check=False,
        )
    except Exception:
        return []
    output = (result.stdout or "") + (result.stderr or "")
    samples: List[Tuple[float, float]] = []
    for raw in output.splitlines():
        line = raw.strip()
        if not line or "pts_time" not in line:
            continue
        parts: Dict[str, str] = {}
        for token in line.split("|"):
            if "=" in token:
                key, value = token.split("=", 1)
                parts[key.strip()] = value.strip()
        try:
            timestamp = float(parts.get("pts_time", "0"))
        except ValueError:
            continue
        key_name = parts.get("key") or ""
        if "Peak_level" not in key_name:
            continue
        try:
            db_val = float(parts.get("value", "-120"))
        except ValueError:
            continue
        amplitude = 10 ** (db_val / 20.0)
        if math.isfinite(amplitude):
            samples.append((timestamp, amplitude))
    return samples


def _select_audio_poi_points(
    duration: float,
    samples: List[Tuple[float, float]],
) -> List[Tuple[float, float]]:

    if not samples or duration <= 0:
        return []
    samples.sort(key=lambda x: x[0])
    minutes = max(1, math.ceil(duration / 60.0))
    per_minute: Dict[int, List[Tuple[float, float]]] = {}
    for ts, amp in samples:
        idx = min(minutes - 1, int(ts // 60))
        per_minute.setdefault(idx, []).append((amp, ts))
    points: List[Tuple[float, float]] = []
    for minute in range(minutes):
        candidates = per_minute.get(minute, [])
        if not candidates:
            continue
        low, high = POI_POINTS_PER_MIN_RANGE
        want = random.randint(low, high)
        want = max(1, min(want, len(candidates)))
        top = heapq.nlargest(want, candidates)
        for amp, ts in top:
            points.append((ts, amp))
    if not points:
        top_global = heapq.nlargest(min(len(samples), POI_MAX_POINTS), samples, key=lambda x: x[1])
        points = [(ts, amp) for ts, amp in top_global]
    points.sort(key=lambda x: x[0])
    return points


def plan_for_file_poi(file_path: Path, file_alloc: int) -> List[Tuple[int, int]]:
    duration = float(ffprobe_duration_seconds(file_path))
    if duration <= 0 or file_alloc <= 0:
        return []
    duration_seconds = max(1, int(duration))
    file_alloc = min(int(file_alloc), duration_seconds)
    if file_alloc <= 0:
        return []
    samples = _extract_audio_energy_profile(file_path)
    poi_points = _select_audio_poi_points(duration, samples)
    if not poi_points:
        return []
    max_points = max(1, min(len(poi_points), max(1, file_alloc // MIN_SMALL_CLIP_SECONDS)))
    if len(poi_points) > max_points:
        poi_points = heapq.nlargest(max_points, poi_points, key=lambda x: x[1])
    poi_points.sort(key=lambda x: x[0])
    per_clip_min = min(
        MIN_SMALL_CLIP_SECONDS,
        max(1, file_alloc // len(poi_points)),
    )
    lengths = jittered_partition(file_alloc, len(poi_points), min_each=per_clip_min)
    guard_active, guard_start, guard_end = _clip_guard_limits(duration_seconds)
    clips: List[Tuple[int, int]] = []
    for (ts, _), clip_len in zip(poi_points, lengths):
        jitter = random.uniform(-POI_SPREAD_SECONDS, POI_SPREAD_SECONDS)
        center = ts + jitter
        start = int(max(0, round(center - clip_len / 2)))
        if guard_active:
            safe_window = max(1, guard_end - guard_start)
            clip_len = min(clip_len, safe_window)
            min_start = guard_start
            max_start = max(min_start, guard_end - clip_len)
            start = max(min_start, min(start, max_start))
        else:
            max_start = max(0, duration_seconds - clip_len)
            if start > max_start:
                start = max_start
        clips.append((start, clip_len))
    clips.sort(key=lambda x: x[0])
    return clips


ClipQueue = Dict[Path, List[Tuple[int, int]]]
ClipSequence = List[Tuple[Path, int, int]]


def _clone_clip_queue(per_file: ClipQueue) -> ClipQueue:
    return {path: clips[:] for path, clips in per_file.items() if clips}


def _sequence_carousel(per_file: ClipQueue) -> ClipSequence:
    queues = _clone_clip_queue(per_file)
    out: ClipSequence = []
    while queues:
        for path in list(queues.keys()):
            clips = queues.get(path, [])
            if not clips:
                queues.pop(path, None)
                continue
            start, dur = clips.pop(0)
            out.append((path, start, dur))
            if not clips:
                queues.pop(path, None)
    return out


def _sequence_group_waves(per_file: ClipQueue) -> ClipSequence:
    queues = _clone_clip_queue(per_file)
    files = list(queues.keys())
    random.shuffle(files)
    out: ClipSequence = []
    idx = 0
    total = len(files)
    while idx < total:
        remaining = total - idx
        if remaining == 1:
            group_size = 1
        else:
            group_size = random.randint(2, min(4, remaining))
        group_files = files[idx: idx + group_size]
        idx += group_size
        group_map: ClipQueue = {f: queues.pop(f, []) for f in group_files if queues.get(f)}
        # ÐµÑÐ»Ð¸ Ñ„Ð°Ð¹Ð» Ð¾ÐºÐ°Ð·Ð°Ð»ÑÑ Ð¿ÑƒÑÑ‚Ñ‹Ð¼, Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼
        group_files = [f for f in group_files if group_map.get(f)]
        while group_files:
            for f in list(group_files):
                clips = group_map.get(f)
                if not clips:
                    group_files.remove(f)
                    continue
                start, dur = clips.pop(0)
                out.append((f, start, dur))
                if not clips:
                    group_files.remove(f)
    # ÐµÑÐ»Ð¸ Ñ‡Ñ‚Ð¾-Ñ‚Ð¾ Ð¾ÑÑ‚Ð°Ð»Ð¾ÑÑŒ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, Ñ„Ð°Ð¹Ð»Ñ‹ Ð±ÐµÐ· Ð³Ñ€ÑƒÐ¿Ð¿) â€” Ð´Ð¾Ð±Ð¸Ð²Ð°ÐµÐ¼ ÐºÐ°Ñ€ÑƒÑÐµÐ»ÑŒÑŽ
    if queues:
        out.extend(_sequence_carousel(queues))
    return out


def _sequence_burst_shuffle(per_file: ClipQueue) -> ClipSequence:
    queues = _clone_clip_queue(per_file)
    out: ClipSequence = []
    while True:
        candidates = [(f, len(clips)) for f, clips in queues.items() if clips]
        if not candidates:
            break
        total = sum(cnt for _, cnt in candidates)
        pick = random.randint(1, max(1, total))
        acc = 0
        chosen = candidates[0][0]
        for f, cnt in candidates:
            acc += cnt
            if pick <= acc:
                chosen = f
                break
        burst = random.randint(1, max(1, min(3, len(queues[chosen]))))
        for _ in range(burst):
            if not queues[chosen]:
                break
            start, dur = queues[chosen].pop(0)
            out.append((chosen, start, dur))
        if not queues[chosen]:
            queues.pop(chosen)
    return out


def _sequence_poi(per_file: ClipQueue) -> ClipSequence:
    out: ClipSequence = []
    for path, clips in per_file.items():
        for start, dur in sorted(clips, key=lambda x: x[0]):
            out.append((path, start, dur))
    return out


def _sequence_strata(per_file: ClipQueue) -> ClipSequence:
    """Ð’Ñ‹Ð´Ð°Ñ‘Ñ‚ Ð²ÑÐµ ÐºÐ»Ð¸Ð¿Ñ‹ Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ñ„Ð°Ð¹Ð»Ð° Ð¿Ð¾Ð´Ñ€ÑÐ´, Ð·Ð°Ñ‚ÐµÐ¼ Ð¿ÐµÑ€ÐµÑ…Ð¾Ð´Ð¸Ñ‚ Ðº ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÐµÐ¼Ñƒ."""
    out: ClipSequence = []
    for path, clips in per_file.items():
        for start, dur in sorted(clips, key=lambda x: x[0]):
            out.append((path, start, dur))
    return out


SequenceBuilder = Callable[[ClipQueue], ClipSequence]


CLIP_SEQUENCE_ALGORITHMS: Dict[str, Dict[str, Any]] = {
    "carousel": {
        "short": "CAR",
        "title": "ÐšÐ°Ñ€ÑƒÑÐµÐ»ÑŒ",
        "description": "Ð§ÐµÑ€ÐµÐ´ÑƒÐµÑ‚ ÐºÐ»Ð¸Ð¿Ñ‹ Ð²ÑÐµÑ… Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² Ð¿Ð¾ ÐºÑ€ÑƒÐ³Ñƒ.",
        "builder": _sequence_carousel,
    },
    "waves": {
        "short": "WAV",
        "title": "Ð’Ð¾Ð»Ð½Ñ‹",
        "description": "Ð¡Ð¾Ð±Ð¸Ñ€Ð°ÐµÑ‚ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¸ Ð² Ð½ÐµÐ±Ð¾Ð»ÑŒÑˆÐ¸Ðµ Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹ Ð¸ Ð¿ÐµÑ€ÐµÐ¼ÐµÑˆÐ¸Ð²Ð°ÐµÑ‚ Ð²Ð½ÑƒÑ‚Ñ€Ð¸ ÐºÐ°Ð¶Ð´Ð¾Ð¹ Ð²Ð¾Ð»Ð½Ñ‹.",
        "builder": _sequence_group_waves,
    },
    "bursts": {
        "short": "BST",
        "title": "Ð‘Ñ‘Ñ€ÑÑ‚Ñ‹",
        "description": "Ð”ÐµÐ»Ð°ÐµÑ‚ ÑÐ»ÑƒÑ‡Ð°Ð¹Ð½Ñ‹Ðµ ÑÐµÑ€Ð¸Ð¸ ÐºÐ»Ð¸Ð¿Ð¾Ð² Ð¸Ð· Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ°, Ð·Ð°Ñ‚ÐµÐ¼ Ð¿ÐµÑ€ÐµÑÐºÐ°ÐºÐ¸Ð²Ð°ÐµÑ‚ Ð½Ð° Ð´Ñ€ÑƒÐ³Ð¾Ð¹.",
        "builder": _sequence_burst_shuffle,
    },
    "poi": {
        "short": "POI",
        "title": "Points of Interest",
        "description": "Ð˜Ñ‰ÐµÑ‚ Ð³Ñ€Ð¾Ð¼ÐºÐ¸Ðµ ÑƒÑ‡Ð°ÑÑ‚ÐºÐ¸ Ð°ÑƒÐ´Ð¸Ð¾ Ð¸ Ð²Ñ‹Ñ€ÐµÐ·Ð°ÐµÑ‚ ÐºÐ»Ð¸Ð¿Ñ‹ Ñ€ÑÐ´Ð¾Ð¼ Ñ Ð½Ð¸Ð¼Ð¸, ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÑ Ñ…Ñ€Ð¾Ð½Ð¾Ð»Ð¾Ð³Ð¸ÑŽ.",
        "builder": _sequence_poi,
    },
    "strata": {
        "short": "LAY",
        "title": "Ð¡Ð»Ð¾Ð¸ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ñ… Ñ‚Ð¾Ñ‡ÐµÐº",
        "description": "Ð¡Ð¾Ð±Ð¸Ñ€Ð°ÐµÑ‚ Ð±Ð»Ð¾ÐºÐ°Ð¼Ð¸: Ð²Ñ‹Ð´Ð°Ñ‘Ñ‚ Ð²ÑÐµ ÐºÐ»Ð¸Ð¿Ñ‹ Ð¿ÐµÑ€Ð²Ð¾Ð³Ð¾ Ð²Ð¸Ð´ÐµÐ¾, Ð¿Ð¾Ñ‚Ð¾Ð¼ Ð²Ñ‚Ð¾Ñ€Ð¾Ð³Ð¾ Ð¸ Ñ‚.Ð´.",
        "builder": _sequence_strata,
    },
}

DEFAULT_CLIP_ALGO = "carousel"

CLIP_ALGO_CHOICE_MAP: Dict[str, str] = {}
for _key, _meta in CLIP_SEQUENCE_ALGORITHMS.items():
    CLIP_ALGO_CHOICE_MAP[_key.lower()] = _key
    short = (_meta.get("short") or "").lower()
    if short:
        CLIP_ALGO_CHOICE_MAP[short] = _key


def normalize_clip_algo_choice(choice: str) -> Optional[str]:
    if not choice:
        return None
    return CLIP_ALGO_CHOICE_MAP.get(choice.strip().lower())


def resolve_clip_algorithm(key: Optional[str]) -> Tuple[str, Dict[str, Any]]:
    if not key or key not in CLIP_SEQUENCE_ALGORITHMS:
        key = DEFAULT_CLIP_ALGO
    return key, CLIP_SEQUENCE_ALGORITHMS[key]


class ClipAlgorithmPicker:
    def __init__(self, total_slots: int):
        self.total_slots = max(1, total_slots)
        self.keys = list(CLIP_SEQUENCE_ALGORITHMS.keys())
        if not self.keys:
            raise RuntimeError("ÐÐµ Ð·Ð°Ð´Ð°Ð½Ñ‹ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ñ‹ Ð½Ð°Ñ€ÐµÐ·ÐºÐ¸.")
        self.unique_quota = min(self.total_slots, len(self.keys))
        self.unique_deck = random.sample(self.keys, len(self.keys))
        self.unique_index = 0
        self.recycle: List[str] = []
        self._current: Optional[str] = None

    def _next_from_pool(self) -> str:
        if self.unique_index < self.unique_quota:
            key = self.unique_deck[self.unique_index]
            self.unique_index += 1
            return key
        if not self.recycle:
            self.recycle = random.sample(self.keys, len(self.keys))
        return self.recycle.pop()

    def current(self) -> str:
        if self._current is None:
            self._current = self._next_from_pool()
        return self._current

    def commit(self) -> None:
        self._current = None


@dataclass
class MusicSegment:
    index: int
    start: float
    end: float
    duration: float
    intensity: float


CLICK_SAMPLE_RATE = 44100
CLICK_DURATION_SECONDS = 0.05
CLICK_FREQUENCY_HZ = 1200.0
CLICK_AMPLITUDE = 12000


def sanitize_filename(text: str) -> str:
    clean = re.sub(r"[^\w\-. ]+", "_", text.strip())
    return clean or "music_project"


def parse_manifest_segments(manifest: Dict[str, Any]) -> List[MusicSegment]:
    analysis = manifest.get("analysis") or {}
    raw_segments = analysis.get("segments") or []
    segments: List[MusicSegment] = []
    for idx, seg in enumerate(raw_segments):
        try:
            start = float(seg.get("start") or 0.0)
            end = float(seg.get("end") or 0.0)
            duration = float(seg.get("duration") or (end - start))
            intensity = float(seg.get("intensity") or 0.0)
        except Exception:
            continue
        if duration <= 0:
            duration = max(0.5, end - start)
        segments.append(
            MusicSegment(
                index=idx,
                start=max(0.0, start),
                end=max(end, start),
                duration=max(0.1, duration),
                intensity=max(0.0, min(1.0, intensity)),
            )
        )
    return segments


def _build_click_track_samples(starts: List[float], total_duration: float) -> array:
    max_time = max(total_duration, max(starts or [0.0])) + CLICK_DURATION_SECONDS + 0.5
    total_samples = max(1, int(math.ceil(max_time * CLICK_SAMPLE_RATE)))
    buf = array("h", [0]) * total_samples
    click_len = max(1, int(CLICK_DURATION_SECONDS * CLICK_SAMPLE_RATE))
    for start in starts:
        if start < 0:
            continue
        start_sample = int(start * CLICK_SAMPLE_RATE)
        if start_sample >= total_samples:
            continue
        for i in range(click_len):
            idx = start_sample + i
            if idx >= total_samples:
                break
            sample_val = int(
                math.sin(2.0 * math.pi * CLICK_FREQUENCY_HZ * (i / CLICK_SAMPLE_RATE))
                * CLICK_AMPLITUDE
            )
            mixed = buf[idx] + sample_val
            if mixed > 32767:
                mixed = 32767
            elif mixed < -32768:
                mixed = -32768
            buf[idx] = mixed
    return buf


def _write_wave_file(path: Path, samples: array, sample_rate: int = CLICK_SAMPLE_RATE) -> None:
    with wave.open(str(path), "wb") as wf:
        wf.setnchannels(1)
        wf.setsampwidth(2)
        wf.setframerate(sample_rate)
        wf.writeframes(samples.tobytes())


def mix_audio_with_click_track(audio_path: Path, click_path: Path, output_path: Path) -> None:
    cmd = [
        FFMPEG_BIN,
        "-y",
        "-i",
        str(audio_path),
        "-i",
        str(click_path),
        "-filter_complex",
        "amix=inputs=2:normalize=0",
        "-c:a",
        "libmp3lame",
        str(output_path),
    ]
    subprocess.check_call(cmd)


def generate_musicprep_click_preview(project: Dict[str, Any]) -> Path:
    manifest_data = project.get("manifest_data")
    manifest_path = Path(project.get("manifest_path") or "")
    if not manifest_data and manifest_path.exists():
        manifest_data = json.loads(manifest_path.read_text(encoding="utf-8"))
        project["manifest_data"] = manifest_data
    segments = parse_manifest_segments(manifest_data or {})
    if not segments:
        raise ValueError("Ð’ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ðµ Ð½ÐµÑ‚ ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ð¾Ð² Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°.")
    audio_path = project.get("audio_path")
    if not audio_path:
        candidate = Path(project.get("dir") or MUSIC_PROJECTS_DIR)
        audio_path = candidate / "audio.mp3"
    audio_path = Path(audio_path)
    if not audio_path.exists():
        raise FileNotFoundError(f"ÐÐµ Ð½Ð°Ð¹Ð´ÐµÐ½ audio.mp3 Ð² Ð¿Ñ€Ð¾ÐµÐºÑ‚Ðµ {project.get('slug')}.")

    starts = [seg.start for seg in segments]
    duration = max(ffprobe_duration_seconds(audio_path), segments[-1].end)
    tmp_parent = pick_temp_dir(TEMP_DIRS, min_free_bytes=500 * 1024**2)
    with tempfile.TemporaryDirectory(prefix="click_", dir=str(tmp_parent)) as tmpdir:
        tmp_root = Path(tmpdir)
        click_wav = tmp_root / "click_track.wav"
        samples = _build_click_track_samples(starts, duration)
        _write_wave_file(click_wav, samples)
        slug = sanitize_filename(project.get("slug") or project.get("name") or "project").replace(" ", "_")
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        out_dir = Path(project.get("dir") or (MUSIC_PROJECTS_DIR / slug))
        out_dir.mkdir(parents=True, exist_ok=True)
        output_path = out_dir / f"{slug}_clickcheck_{timestamp}.mp3"
        mix_audio_with_click_track(audio_path, click_wav, output_path)
    return output_path


def build_music_source_sequence(
    source_paths: List[Path],
    algo_key: str,
    total_segments: int,
) -> List[Path]:
    if not source_paths:
        raise ValueError("ÐÐµÑ‚ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² Ð´Ð»Ñ Ð¼ÑƒÐ·Ñ‹ÐºÐ°Ð»ÑŒÐ½Ð¾Ð¹ ÐºÐ¾Ð¼Ð¿Ð¸Ð»ÑÑ†Ð¸Ð¸.")
    if total_segments <= 0:
        return []
    seq: List[Path] = []
    key = algo_key or DEFAULT_CLIP_ALGO
    files = source_paths[:]

    if key == "waves":
        random.shuffle(files)
        idx = 0
        while len(seq) < total_segments:
            group_size = random.randint(2, min(4, len(files)))
            group = files[idx:idx + group_size]
            if not group:
                random.shuffle(files)
                idx = 0
                continue
            for path in group:
                seq.append(path)
                if len(seq) >= total_segments:
                    break
            idx += group_size
            if idx >= len(files):
                idx = 0
                random.shuffle(files)
    elif key == "bursts":
        while len(seq) < total_segments:
            path = random.choice(source_paths)
            burst = random.randint(2, 4)
            for _ in range(burst):
                seq.append(path)
                if len(seq) >= total_segments:
                    break
    elif key == "strata":
        if not files:
            return []
        base = total_segments // len(files)
        rem = total_segments % len(files)
        for idx, path in enumerate(files):
            share = base + (1 if idx < rem else 0)
            if share <= 0:
                continue
            seq.extend([path] * share)
    else:
        idx = 0
        while len(seq) < total_segments:
            seq.append(files[idx % len(files)])
            idx += 1
    return seq[:total_segments]


def choose_random_source_rows(
    count: int,
    group_strategy: str = "max_group",
    preferred_group: Optional[Tuple[str, str]] = None,
    preferred_folder: Optional[str] = None,
) -> List[sqlite3.Row]:
    if count <= 0:
        raise ValueError("ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² Ð´Ð¾Ð»Ð¶Ð½Ð¾ Ð±Ñ‹Ñ‚ÑŒ > 0")

    folder_norm = _normalize_path_prefix(preferred_folder) if preferred_folder else None

    def row_matches_folder(row: sqlite3.Row) -> bool:
        if not folder_norm:
            return True
        try:
            parent = Path(row["video_path"]).resolve(strict=False).parent
        except Exception:
            parent = Path(row["video_path"]).parent
        return _normalize_path_prefix(parent) == folder_norm

    unused = db_get_unused_sources_grouped()
    all_groups = db_get_all_sources_grouped()

    def fetch_group_rows(key: Tuple[str, str]) -> List[sqlite3.Row]:
        rows = all_groups.get(key)
        if not rows:
            rows = unused.get(key, [])
        filtered = [row for row in (rows or []) if row_matches_folder(row)]
        return filtered

    if preferred_group:
        rows = fetch_group_rows(preferred_group)
        if len(rows) < count:
            raise RuntimeError(
                f"Ð’ Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð½Ð¾Ð¹ Ð³Ñ€ÑƒÐ¿Ð¿Ðµ Ð½ÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² (ÐµÑÑ‚ÑŒ {len(rows)}, Ð½ÑƒÐ¶Ð½Ð¾ {count})."
            )
        random.shuffle(rows)
        return rows[:count]

    grouped = unused if unused else all_groups
    groups = list(grouped.items())
    if not groups:
        raise RuntimeError("Ð’ Ð±Ð°Ð·Ðµ Ð½ÐµÑ‚ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ÑÑ‰Ð¸Ñ… Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð².")

    if group_strategy == "random":
        random.shuffle(groups)
    else:
        groups.sort(key=lambda kv: -len(kv[1]))

    selected: List[sqlite3.Row] = []
    seen_dirs: Dict[Path, int] = {}

    for _, rows in groups:
        if len(selected) >= count:
            break
        random.shuffle(rows)
        for row in rows:
            if not row_matches_folder(row):
                continue
            try:
                path = Path(row["video_path"]).resolve()
                parent = path.parent
            except Exception:
                continue
            if not path.exists():
                continue
            if seen_dirs.get(parent, 0) >= PER_DIR_MAX_FIRST_PASS:
                continue
            selected.append(row)
            seen_dirs[parent] = seen_dirs.get(parent, 0) + 1
            if len(selected) >= count:
                break

    if len(selected) < count:
        leftovers: List[sqlite3.Row] = []
        for _, rows in groups:
            leftovers.extend(rows)
        random.shuffle(leftovers)
        for row in leftovers:
            if len(selected) >= count:
                break
            try:
                path = Path(row["video_path"])
            except Exception:
                continue
            if not path.exists():
                continue
            selected.append(row)

    if len(selected) < count:
        raise RuntimeError("ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² Ð´Ð»Ñ Ð¼ÑƒÐ·Ñ‹ÐºÐ°Ð»ÑŒÐ½Ð¾Ð¹ ÐºÐ¾Ð¼Ð¿Ð¸Ð»ÑÑ†Ð¸Ð¸.")
    return selected[:count]


def pick_specific_source_rows(
    rows: List[sqlite3.Row],
    count: int,
    min_new_required: int = 0,
) -> List[sqlite3.Row]:
    if count <= 0:
        raise ValueError("ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¾Ð² Ð´Ð¾Ð»Ð¶Ð½Ð¾ Ð±Ñ‹Ñ‚ÑŒ > 0")
    existing: List[sqlite3.Row] = []
    for row in rows:
        try:
            path = Path(row["video_path"]).resolve()
        except Exception:
            continue
        if not path.exists():
            continue
        existing.append(row)
    if len(existing) < count:
        raise RuntimeError("ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ñ… Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð².")

    min_new_required = max(0, int(min_new_required))
    new_rows = [row for row in existing if _is_unused_source_row(row)]
    if min_new_required and len(new_rows) < min_new_required:
        raise RuntimeError("ÐœÐµÐ½ÑŒÑˆÐµ Ð½Ð¾Ð²Ñ‹Ñ… Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð², Ñ‡ÐµÐ¼ Ð·Ð°Ð¿Ñ€Ð¾ÑˆÐµÐ½Ð¾.")

    random.shuffle(new_rows)
    selected: List[sqlite3.Row] = []
    needed_new = min(min_new_required, count)
    if needed_new:
        selected.extend(new_rows[:needed_new])
    remaining = [row for row in existing if row not in selected]
    random.shuffle(remaining)
    while len(selected) < count and remaining:
        selected.append(remaining.pop())

    if len(selected) < count:
        raise RuntimeError("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð´Ð¾Ð±Ñ€Ð°Ñ‚ÑŒ Ð½ÑƒÐ¶Ð½Ð¾Ðµ Ñ‡Ð¸ÑÐ»Ð¾ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¾Ð².")

    random.shuffle(selected)
    return selected[:count]


def make_music_output_name(
    manifest_name: str,
    segments_count: int,
    algo_tag: str,
    orientation: str = "HOR",
    sources_count: int = 0,
    group_number: Optional[int] = None,
) -> Path:
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M")
    safe_name = sanitize_filename(manifest_name or "music")
    safe_name = safe_name.replace(" ", "_")
    orientation_tag = (orientation or "HOR").upper()
    segments_part = f"{segments_count}seg"
    sources_part = f"{max(1, sources_count)}fil"
    group_part = "??grp"
    if group_number is not None:
        try:
            group_idx = int(group_number)
            group_part = f"{group_idx}grp"
        except (TypeError, ValueError):
            pass
    base = (
        f"{timestamp}_{orientation_tag}_{group_part}_"
        f"{safe_name}_{segments_part}_{sources_part}_{algo_tag.upper()}"
    )
    candidate = OUTPUT_DIR / f"{base}.mp4"
    idx = 2
    while candidate.exists():
        candidate = OUTPUT_DIR / f"{base} ({idx}).mp4"
        idx += 1
    return candidate


def move_output_to_network_storage(local_path: Path, date_folder: Optional[str] = None) -> Tuple[Path, str]:
    resolved = local_path.resolve()
    if not resolved.exists():
        raise FileNotFoundError(f"Ð˜Ñ‚Ð¾Ð³Ð¾Ð²Ñ‹Ð¹ Ñ„Ð°Ð¹Ð» Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½: {resolved}")

    if not ENABLE_NETWORK_COPY:
        comment = (
            f"network_copy=disabled;original_path={resolved};"
            f"timestamp={datetime.now().isoformat(timespec='seconds')}"
        )
        return resolved, comment

    if not date_folder:
        date_folder = date.today().isoformat()
    target_dir = NETWORK_OUTPUT_ROOT / date_folder
    target_dir.mkdir(parents=True, exist_ok=True)

    destination = target_dir / resolved.name
    suffix = resolved.suffix
    stem = resolved.stem
    idx = 2
    while destination.exists():
        destination = target_dir / f"{stem} ({idx}){suffix}"
        idx += 1

    if resolved == destination:
        print(f"[OUTPUT] Ð¤Ð°Ð¹Ð» ÑƒÐ¶Ðµ Ð½Ð°Ñ…Ð¾Ð´Ð¸Ñ‚ÑÑ Ð² Ñ†ÐµÐ»ÐµÐ²Ð¾Ð¹ Ð¿Ð°Ð¿ÐºÐµ: {destination}")
    else:
        print(f"[OUTPUT] ÐŸÐµÑ€ÐµÐ½Ð¾ÑˆÑƒ Ñ„Ð°Ð¹Ð» {resolved} -> {destination}")
        shutil.move(str(resolved), str(destination))

    comment = (
        f"network_path={destination};date_folder={date_folder};"
        f"moved_from={resolved};moved_at={datetime.now().isoformat(timespec='seconds')}"
    )
    return destination, comment


def mux_audio_with_video(video_path: Path, audio_path: Path, out_path: Path) -> None:
    cmd = [
        FFMPEG_BIN,
        "-y",
        "-i", str(video_path),
        "-i", str(audio_path),
        "-c:v", "copy",
        "-c:a", "aac",
        "-map", "0:v:0",
        "-map", "1:a:0",
        "-shortest",
        "-movflags", "+faststart",
        str(out_path),
    ]
    subprocess.check_call(cmd)


def make_music_synced_pmv(
    manifest_name: str,
    segments: List[MusicSegment],
    audio_path: Path,
    source_rows: List[sqlite3.Row],
    clip_algo_key: str,
    orientation: str = "HOR",
    group_number: Optional[int] = None,
) -> Tuple[Path, List[int], Tuple[str, Dict[str, Any]]]:
    if not segments:
        raise RuntimeError("Ð’ Ð¼Ð°Ð½Ð¸Ñ„ÐµÑÑ‚Ðµ Ð½ÐµÑ‚ ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ð¾Ð² Ð´Ð»Ñ Ð½Ð°Ñ€ÐµÐ·ÐºÐ¸.")
    if not audio_path.exists():
        raise FileNotFoundError(f"MP3 Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½: {audio_path}")

    source_paths: List[Path] = []
    source_ids: List[int] = []
    for row in source_rows:
        try:
            sid = int(row["id"])
            path = Path(row["video_path"])
        except Exception:
            continue
        if not path.exists():
            continue
        source_paths.append(path)
        source_ids.append(sid)
    if not source_paths:
        raise RuntimeError("ÐÐµÑ‚ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð².")

    resolved_key, algo_meta = resolve_clip_algorithm(clip_algo_key)
    total_segments = len(segments)
    sequence_sources = build_music_source_sequence(source_paths, resolved_key, total_segments)
    durations: Dict[Path, float] = {}
    for path in source_paths:
        durations[path] = float(ffprobe_duration_seconds(path))

    print(
        f"[MUSIC] Start sync render: project='{manifest_name}', segments={total_segments}, "
        f"sources={len(source_paths)}, algo={resolved_key}"
    )

    tmp_parent = pick_temp_dir(TEMP_DIRS, min_free_bytes=5 * 1024**3)
    tmp_root = Path(tempfile.mkdtemp(prefix="music_", dir=str(tmp_parent)))
    clip_meta: List[Dict[str, Any]] = []

    try:
        base_sequence = list(zip(segments, sequence_sources))
        for idx, (segment, primary_src) in enumerate(base_sequence, 1):
            seg_dur = max(0.3, segment.duration)
            candidate_sources = [primary_src] + [p for p in source_paths if p != primary_src]
            clip_created = False
            ext = ".ts" if USE_TS_CONCAT else ".mp4"
            clip_path = tmp_root / f"music_clip_{idx:04d}{ext}"

            for src_path in candidate_sources:
                video_dur = durations.get(src_path, 0.0)
                if video_dur <= 0.5:
                    continue

                max_start = max(0.0, video_dur - seg_dur - 0.5)
                if max_start <= 0:
                    actual_dur = min(seg_dur, max(0.3, video_dur - 0.2))
                    if actual_dur <= 0:
                        continue
                    start_pos = 0.0
                else:
                    actual_dur = seg_dur
                    start_pos = random.uniform(0.0, max_start)

                try:
                    extract_clip(src_path, start_pos, actual_dur, clip_path)
                    print(
                        f"[MUSIC] [{idx}/{total_segments}] {src_path.name} start={start_pos:.2f}s "
                        f"dur={actual_dur:.2f}s target={segment.duration:.2f}s intensity={segment.intensity:.2f}"
                    )
                    clip_meta.append(
                        {
                            "path": clip_path,
                            "duration": float(actual_dur),
                        }
                    )
                    clip_created = True
                    break
                except subprocess.CalledProcessError as err:
                    if clip_path.exists():
                        clip_path.unlink(missing_ok=True)
                    print(f"[MUSIC][WARN] extract failed on {src_path.name}: {err}")
                    try:
                        sid = db_get_source_id_by_path(src_path)
                        if sid is not None:
                            db_mark_source_problem(sid, f"music_extract_error")
                    except Exception:
                        pass
                    continue

            if not clip_created:
                print(f"[MUSIC][WARN] Segment {idx} skipped: Ð½Ðµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð²Ñ‹Ñ€ÐµÐ·Ð°Ñ‚ÑŒ ÐºÐ»Ð¸Ð¿ Ð½Ð¸ Ð¸Ð· Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ°.")
                continue

        if not clip_meta:
            raise RuntimeError("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð²Ñ‹Ñ€ÐµÐ·Ð°Ñ‚ÑŒ ÐºÐ»Ð¸Ð¿Ñ‹ Ð¿Ð¾ Ð¼ÑƒÐ·Ñ‹ÐºÐ°Ð»ÑŒÐ½Ñ‹Ð¼ ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ð°Ð¼.")
        if GLITCH_EFFECTS_PER_VIDEO > 0 or TRANSITION_EFFECTS_PER_VIDEO > 0:
            processed_clips, video_profile = apply_video_fx(clip_meta, tmp_root)
            uniform_clips = transcode_clips_to_profile(
                processed_clips, tmp_root, video_profile
            )
        else:
            uniform_clips = [Path(meta["path"]) for meta in clip_meta]
        raw_video_path = tmp_root / "music_raw.mp4"
        print(f"[MUSIC] ÐšÐ¾Ð½ÐºÐ°Ñ‚ÐµÐ½Ð°Ñ†Ð¸Ñ {len(uniform_clips)} ÐºÐ»Ð¸Ð¿Ð¾Ð²...")
        concat_via_list(uniform_clips, raw_video_path)
        if raw_video_path.with_suffix(".mp4").exists():
            raw_video_path = raw_video_path.with_suffix(".mp4")

        algo_tag = algo_meta.get("short") or resolved_key
        final_path = make_music_output_name(
            manifest_name,
            len(segments),
            algo_tag,
            orientation=orientation,
            sources_count=len(source_paths),
            group_number=group_number,
        )
        print("[MUSIC] ÐÐ°ÐºÐ»Ð°Ð´Ñ‹Ð²Ð°ÑŽ Ð°ÑƒÐ´Ð¸Ð¾Ð´Ð¾Ñ€Ð¾Ð¶ÐºÑƒ...")
        mux_audio_with_video(raw_video_path, audio_path, final_path)
        print(f"[MUSIC] Ð“Ð¾Ñ‚Ð¾Ð²Ð¾: {final_path}")
        return final_path, source_ids, (resolved_key, algo_meta)
    finally:
        shutil.rmtree(tmp_root, ignore_errors=True)


def extract_clip(src: Path, start: float, dur: int, dst: Path) -> None:
    """Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ ÐºÐ»Ð¸Ð¿Ð° Ð±ÐµÐ· Ð¿ÐµÑ€ÐµÐºÐ¾Ð´Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ. Ð”Ð»Ñ TS Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð½ÑƒÐ¶Ð½Ñ‹Ð¹ bitstream-Ñ„Ð¸Ð»ÑŒÑ‚Ñ€.
    Start Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ float. Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½ -avoid_negative_ts make_zero Ð´Ð»Ñ ÑÑ‚Ð°Ð±Ð¸Ð»ÑŒÐ½Ñ‹Ñ… Ñ‚Ð°Ð¹Ð¼ÑÑ‚ÐµÐ¼Ð¿Ð¾Ð²."""
    if USE_TS_CONCAT and dst.suffix.lower() != ".ts":
        dst = dst.with_suffix(".ts")

    if USE_TS_CONCAT:
        vinfo = detect_video_info(src)
        vcodec = (vinfo.get("codec_name") or "").lower()
        if vcodec.startswith("h264") or vcodec == "avc1":
            bsf_v = "h264_mp4toannexb"
        elif vcodec in ("hevc", "h265") or vcodec.startswith(("hev1", "hvc1")):
            bsf_v = "hevc_mp4toannexb"
        else:
            # Ð½ÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ ÐºÐ¾Ð´ÐµÐº â€” ÐºÐ¾Ð¿Ð¸Ñ€ÑƒÐµÐ¼ ÑÑ€Ð°Ð·Ñƒ Ð² MP4
            cmd = [
                FFMPEG_BIN,
                "-v", "error",
                "-y",
                "-ss", str(start),
                "-t", str(dur),
                "-i", str(src),
                "-c", "copy",
                "-avoid_negative_ts", "make_zero",
                "-movflags", "+faststart",
                str(dst.with_suffix(".mp4")),
            ]
            subprocess.check_call(cmd)
            return

        cmd = [
            FFMPEG_BIN,
            "-v", "error",
            "-y",
            "-ss", str(start),
            "-t", str(dur),
            "-i", str(src),
            "-c", "copy",
            "-bsf:v", bsf_v,
            "-avoid_negative_ts", "make_zero",
            "-f", "mpegts",
            str(dst),
        ]
        try:
            subprocess.check_call(cmd)
        except subprocess.CalledProcessError:
            fallback_cmd = [
                FFMPEG_BIN,
                "-v", "error",
                "-y",
                "-ss", str(start),
                "-t", str(dur),
                "-i", str(src),
                "-c", "copy",
                "-avoid_negative_ts", "make_zero",
                "-f", "mpegts",
                str(dst),
            ]
            try:
                subprocess.check_call(fallback_cmd)
            except subprocess.CalledProcessError:
                raise
    else:
        cmd = [
            FFMPEG_BIN,
            "-v", "error",
            "-y",
            "-ss", str(start),
            "-t", str(dur),
            "-i", str(src),
            "-c", "copy",
            "-avoid_negative_ts", "make_zero",
            "-movflags", "+faststart",
            str(dst),
        ]
        subprocess.check_call(cmd)


def concat_via_list(clips_paths: List[Path], out_path: Path) -> None:
    """
    Ð¡ÐºÐ»ÐµÐ¸Ð²Ð°ÐµÑ‚ ÐºÐ»Ð¸Ð¿Ñ‹ Ð² Ð¾Ð´Ð¸Ð½ Ñ„Ð°Ð¹Ð».

    Ð¤Ð¸ÑˆÐºÐ¸:
    - Ð‘Ð¾Ð»ÑŒÑˆÐµ ÐÐ• Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð´Ð»Ð¸Ð½Ð½Ñ‹Ð¹ Ð°Ñ€Ð³ÑƒÐ¼ÐµÐ½Ñ‚ Ð²Ð¸Ð´Ð° concat:...|...|...
      (Ð½Ð° Windows Ð¾Ð½ Ð»ÐµÐ³ÐºÐ¾ Ð»Ð¾Ð¼Ð°ÐµÑ‚ÑÑ).
    - Ð”ÐµÐ»Ð°ÐµÐ¼ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ð¹ ÑÐ¿Ð¸ÑÐ¾Ðº (concat demuxer), Ð¿ÑƒÑ‚Ð¸ Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´Ð¸Ð¼ Ð² Ð²Ð¸Ð´ Ñ '/'.
    - Ð•ÑÐ»Ð¸ Ð¾Ð¶Ð¸Ð´Ð°ÐµÐ¼Ð°Ñ .ts Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°, Ð¸Ñ‰ÐµÐ¼ .mp4 (Ñ„Ð¾Ð»Ð±ÐµÐº Ð¸Ð· extract_clip).
    """
    # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð¸Ð¼Ñ Ð²Ñ‹Ð²Ð¾Ð´Ð°
    if out_path.suffix.lower() != ".mp4":
        out_mp4 = out_path.with_suffix(".mp4")
    else:
        out_mp4 = out_path

    real_paths: List[Path] = []

    for p in clips_paths:
        # Ð±Ð°Ð·Ð¾Ð²Ñ‹Ð¹ ÐºÐ°Ð½Ð´Ð¸Ð´Ð°Ñ‚ â€” ÐºÐ°Ðº Ð½Ð°Ð¼ ÐµÐ³Ð¾ Ð¿ÐµÑ€ÐµÐ´Ð°Ð»Ð¸
        cand = p

        if not cand.exists():
            # ÐµÑÐ»Ð¸ Ñ‚Ð°ÐºÐ¾Ð³Ð¾ Ð½ÐµÑ‚, Ð¿Ñ€Ð¾Ð±ÑƒÐµÐ¼ .ts / .mp4 Ñ€ÑÐ´Ð¾Ð¼
            alt_ts = p.with_suffix(".ts")
            alt_mp4 = p.with_suffix(".mp4")

            if alt_ts.exists():
                cand = alt_ts
            elif alt_mp4.exists():
                cand = alt_mp4
            else:
                raise FileNotFoundError(
                    f"ÐÐµ Ð½Ð°Ð¹Ð´ÐµÐ½ ÐºÐ»Ð¸Ð¿ Ð´Ð»Ñ ÐºÐ¾Ð½ÐºÐ°Ñ‚ÐµÐ½Ð°Ñ†Ð¸Ð¸: {p} "
                    f"(Ð¿Ñ€Ð¾Ð±Ð¾Ð²Ð°Ð»Ð¸ {alt_ts} Ð¸ {alt_mp4})"
                )

        real_paths.append(cand)

    if not real_paths:
        raise RuntimeError("Ð¡Ð¿Ð¸ÑÐ¾Ðº ÐºÐ»Ð¸Ð¿Ð¾Ð² Ð´Ð»Ñ ÐºÐ¾Ð½ÐºÐ°Ñ‚ÐµÐ½Ð°Ñ†Ð¸Ð¸ Ð¿ÑƒÑÑ‚.")

    # Ð¤Ð°Ð¹Ð»-ÑÐ¿Ð¸ÑÐ¾Ðº Ð´Ð»Ñ concat demuxer
    list_file = out_mp4.parent / f"{out_mp4.stem}_concat_list.txt"

    with open(list_file, "w", encoding="utf-8") as f:
        for c in real_paths:
            # ffmpeg Ð½Ð° Windows Ð½Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ð¾ Ð¿Ð¾Ð½Ð¸Ð¼Ð°ÐµÑ‚ Ð¿Ñ€ÑÐ¼Ñ‹Ðµ ÑÐ»ÑÑˆÐ¸
            p_str = str(c.resolve()).replace("\\", "/")
            f.write(f"file '{p_str}'\n")

    # Ð¡Ð¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñƒ ffmpeg
    cmd = [
        FFMPEG_BIN,
        "-v", "error",
        "-y",
        "-fflags", "+genpts",
        "-max_interleave_delta", "0",
        "-f", "concat",
        "-safe", "0",
        "-i", str(list_file),
        "-c", "copy",
        "-movflags", "+faststart",
    ]

    # Ð•ÑÐ»Ð¸ Ð¼Ñ‹ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÐ¼ Ñ TS-ÐºÐ»Ð¸Ð¿Ð°Ð¼Ð¸ (USE_TS_CONCAT=True),
    # Ð¾ÑÑ‚Ð°Ð²Ð»ÑÐµÐ¼ Ð±Ð¸Ñ‚ÑÑ‚Ñ€Ð¸Ð¼-Ñ„Ð¸Ð»ÑŒÑ‚Ñ€ Ð´Ð»Ñ AAC â†’ MP4.
    if USE_TS_CONCAT:
        cmd.extend(["-bsf:a", "aac_adtstoasc"])

    cmd.append(str(out_mp4))

    try:
        subprocess.check_call(cmd)
    finally:
        try:
            list_file.unlink()
        except OSError:
            pass


def pick_evenly_spaced_indices(total: int, count: int) -> List[int]:
    if count <= 0 or total <= 0:
        return []
    result: List[int] = []
    used: set[int] = set()
    step = total / (count + 1)
    for i in range(count):
        idx = int(round(step * (i + 1)))
        idx = max(0, min(total - 1, idx))
        while idx in used and idx < total - 1:
            idx += 1
        while idx in used and idx > 0:
            idx -= 1
        if idx not in used:
            used.add(idx)
            result.append(idx)
    return sorted(result)


def pick_positions_from_pool(pool: List[int], count: int) -> List[int]:
    if count <= 0 or not pool:
        return []
    sorted_pool = sorted(pool)
    positions = pick_evenly_spaced_indices(len(sorted_pool), count)
    return [sorted_pool[i] for i in positions if i < len(sorted_pool)]


def determine_fx_encoding_profile(sample_path: Path) -> Dict[str, str]:
    info = detect_video_info(sample_path)
    codec = (info.get("codec_name") or "").lower()
    pix_fmt = info.get("pix_fmt") or ""
    if not pix_fmt or not re.fullmatch(r"[A-Za-z0-9_]+", pix_fmt):
        pix_fmt = "yuv420p"
    fps_val = info.get("fps")
    try:
        fps = float(fps_val) if fps_val else 30.0
    except (TypeError, ValueError):
        fps = 30.0
    fps = fps if fps > 0 else 30.0
    if codec in {"hevc", "h265", "hvc1", "hev1"}:
        video_encoder = "libx265"
    else:
        video_encoder = "libx264"
    return {"video_encoder": video_encoder, "pix_fmt": pix_fmt, "fps": fps}


def create_glitch_clip(
    clip_meta: Dict[str, Any],
    tmp_root: Path,
    profile: Dict[str, str],
    duration: float = FX_GLITCH_DURATION,
) -> Optional[Path]:
    src_path = Path(clip_meta["path"])
    clip_dur = float(clip_meta.get("duration") or duration)
    duration = float(max(0.15, min(duration, clip_dur)))
    start = max(clip_dur - duration, 0.0)
    filters = [
        "rgbashift=rh=5:rv=-5:gh=-4:gv=4:bh=3:bv=-3,noise=alls=20:allf=t+u,eq=contrast=1.2:saturation=1.4",
        "tblend=all_mode='xor',hue=s=0,format=yuv420p",
        "noise=alls=30:allf=t+u,edgedetect=mode=colormix:high=0.2:low=0.05",
    ]
    vf = random.choice(filters)
    out_path = tmp_root / f"{src_path.stem}_glitch_{random.randrange(1_000_000)}.mp4"
    filter_complex = (
        f"[0:v]trim=start={start:.3f}:end={clip_dur:.3f},setpts=PTS-STARTPTS,"
        f"{vf},fps={profile.get('fps') or 30.0},format={profile.get('pix_fmt') or 'yuv420p'}[vout]"
    )
    cmd = [
        FFMPEG_BIN,
        "-v",
        "error",
        "-y",
        "-i",
        str(src_path),
        "-filter_complex",
        filter_complex,
        "-c:v",
        profile.get("video_encoder") or "libx264",
        "-preset",
        "veryfast",
        "-crf",
        "18",
        "-movflags",
        "+faststart",
        "-map",
        "[vout]",
        "-an",
        str(out_path),
    ]
    try:
        subprocess.check_call(cmd)
        return out_path
    except subprocess.CalledProcessError:
        if out_path.exists():
            out_path.unlink(missing_ok=True)
        return None


def create_transition_clip(
    prev_meta: Dict[str, Any],
    next_meta: Dict[str, Any],
    tmp_root: Path,
    profile: Dict[str, str],
    duration: float = FX_TRANSITION_DURATION,
) -> Optional[Path]:
    prev_path = Path(prev_meta["path"])
    next_path = Path(next_meta["path"])
    prev_dur = float(prev_meta.get("duration") or duration)
    next_dur = float(next_meta.get("duration") or duration)
    duration = float(min(duration, prev_dur, next_dur, 1.0))
    if duration < 0.15:
        return None
    start_prev = max(prev_dur - duration, 0.0)
    transition = random.choice(XFADE_TRANSITIONS) if XFADE_TRANSITIONS else "fade"
    out_path = tmp_root / f"transition_{prev_path.stem}_{next_path.stem}_{random.randrange(1_000_000)}.mp4"
    fps = profile.get("fps") or 30.0
    video_fmt = profile.get("pix_fmt") or "yuv420p"
    filter_complex = (
        f"[0:v]trim=start={start_prev:.3f}:end={prev_dur:.3f},setpts=PTS-STARTPTS,"
        f"fps={fps},format={video_fmt}[v0];"
        f"[1:v]trim=start=0:end={duration:.3f},setpts=PTS-STARTPTS,fps={fps},format={video_fmt}[v1];"
        f"[v0][v1]xfade=transition={transition}:duration={duration:.3f}:offset=0[vout]"
    )
    cmd = [
        FFMPEG_BIN,
        "-v",
        "error",
        "-y",
        "-i",
        str(prev_path),
        "-i",
        str(next_path),
        "-filter_complex",
        filter_complex,
        "-c:v",
        profile.get("video_encoder") or "libx264",
        "-preset",
        "veryfast",
        "-crf",
        "18",
        "-movflags",
        "+faststart",
        "-map",
        "[vout]",
        "-an",
        str(out_path),
    ]
    try:
        subprocess.check_call(cmd)
        return out_path
    except subprocess.CalledProcessError:
        if out_path.exists():
            out_path.unlink(missing_ok=True)
        return None


def apply_video_fx(
    clips_meta: List[Dict[str, Any]], tmp_root: Path
) -> Tuple[List[Path], Dict[str, str]]:
    if not clips_meta:
        return [], {"video_encoder": "libx264", "pix_fmt": "yuv420p", "fps": 30.0}
    total_seams = max(0, len(clips_meta) - 1)
    profile = determine_fx_encoding_profile(Path(clips_meta[0]["path"]))

    transition_positions = pick_evenly_spaced_indices(
        total_seams, min(TRANSITION_EFFECTS_PER_VIDEO, total_seams)
    )
    remaining_seams = [i for i in range(total_seams) if i not in transition_positions]
    glitch_positions = pick_positions_from_pool(
        remaining_seams, min(GLITCH_EFFECTS_PER_VIDEO, len(remaining_seams))
    )

    result_paths: List[Path] = []
    for idx, meta in enumerate(clips_meta):
        result_paths.append(Path(meta["path"]))
        if idx >= total_seams:
            continue
        seam_index = idx
        if seam_index in transition_positions:
            clip = create_transition_clip(
                meta, clips_meta[idx + 1], tmp_root, profile, FX_TRANSITION_DURATION
            )
            if clip:
                result_paths.append(clip)
        elif seam_index in glitch_positions:
            clip = create_glitch_clip(meta, tmp_root, profile, FX_GLITCH_DURATION)
            if clip:
                result_paths.append(clip)
    return result_paths, profile


def transcode_clips_to_profile(
    clips: List[Path],
    tmp_root: Path,
    profile: Dict[str, Any],
) -> List[Path]:
    uniform_paths: List[Path] = []
    fps = float(profile.get("fps") or 30.0)
    pix_fmt = profile.get("pix_fmt") or "yuv420p"
    video_encoder = profile.get("video_encoder") or "libx264"

    for idx, clip in enumerate(clips, 1):
        out_path = tmp_root / f"uniform_{idx:04d}.mp4"
        cmd = [
            FFMPEG_BIN,
            "-v",
            "error",
            "-y",
            "-i",
            str(clip),
            "-vf",
            f"fps={fps},format={pix_fmt}",
            "-c:v",
            video_encoder,
            "-preset",
            "veryfast",
            "-crf",
            "18",
            "-an",
            "-movflags",
            "+faststart",
            str(out_path),
        ]
        subprocess.check_call(cmd)
        uniform_paths.append(out_path)
    return uniform_paths


def make_output_name(
    selected_files: List[Path],
    target_seconds: int,
    big_parts: int,
    small_per_big: int,
    run_seed: Optional[int] = None,
    algo_tag: Optional[str] = None,
) -> Path:
    """
    Ð˜Ð¼Ñ Ð²Ð¸Ð´Ð°:
    YYYYMMDD - random_title - BUILD_NAME - <N>files - <M>min - <big_parts>big - <small_per_big>small - seed<seed>.mp4

    + Ð“ÐÐ ÐÐÐ¢Ð˜Ð¯: ÐµÑÐ»Ð¸ Ñ„Ð°Ð¹Ð» Ñ Ñ‚Ð°ÐºÐ¸Ð¼ Ð¸Ð¼ÐµÐ½ÐµÐ¼ ÑƒÐ¶Ðµ ÐµÑÑ‚ÑŒ, Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ " (2)", " (3)" Ð¸ Ñ‚.Ð´.
    """
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    today = datetime.now().strftime("%Y%m%d")
    random_title = db_get_random_name()

    # ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð²
    files_count = len(selected_files)

    # ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐµÐ¼ Ñ†ÐµÐ»ÐµÐ²Ñ‹Ðµ ÑÐµÐºÑƒÐ½Ð´Ñ‹ Ð² Ð¼Ð¸Ð½ÑƒÑ‚Ñ‹ (Ð¼Ð¸Ð½Ð¸Ð¼ÑƒÐ¼ 1)
    minutes = max(1, int(round(target_seconds / 60.0)))

    algo_part = f" - {algo_tag}" if algo_tag else ""
    seed_part = f" - seed{run_seed}" if run_seed is not None else ""

    base_stem = (
        f"{today} - {random_title} - {BUILD_NAME} - "
        f"{files_count}files - {minutes}min - {big_parts}big - {small_per_big}small{algo_part}{seed_part}"
    )

    candidate = OUTPUT_DIR / f"{base_stem}.mp4"
    if not candidate.exists():
        return candidate

    idx = 2
    while True:
        candidate = OUTPUT_DIR / f"{base_stem} ({idx}).mp4"
        if not candidate.exists():
            return candidate
        idx += 1



def estimate_required_bytes(total_seconds: int, assumed_mbps: int = 15) -> int:
    """Ð“Ñ€ÑƒÐ±Ð°Ñ Ð¾Ñ†ÐµÐ½ÐºÐ° Ñ‚Ñ€ÐµÐ±ÑƒÐµÐ¼Ð¾Ð³Ð¾ Ð¼ÐµÑÑ‚Ð° (Ð±Ð°Ð¹Ñ‚Ñ‹) Ð¸ÑÑ…Ð¾Ð´Ñ Ð¸Ð· ÑÑ€ÐµÐ´Ð½ÐµÐ³Ð¾ Ð±Ð¸Ñ‚Ñ€ÐµÐ¹Ñ‚Ð° (~15 ÐœÐ±Ð¸Ñ‚/Ñ Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ)."""
    return int(total_seconds * (assumed_mbps * 1_000_000 / 8))


def make_pmv_from_files(
    selected_paths: List[Path],
    target_seconds: int,
    big_parts: int,
    small_per_big: int,
    clip_algo_key: Optional[str] = None,
) -> Path:
    if not selected_paths:
        raise ValueError("ÐÐµÑ‚ Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð´Ð»Ñ PMV")

    # Ð¡Ð¸Ð´ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ â€” Ð¼ÐµÐ½ÑÐµÑ‚ÑÑ ÐºÐ°Ð¶Ð´Ñ‹Ð¹ Ð·Ð°Ð¿ÑƒÑÐº; Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð² Ð¸Ð¼Ñ Ñ„Ð°Ð¹Ð»Ð°
    global RANDOM_SEED
    run_seed = int(time.time())
    random.seed(run_seed)
    RANDOM_SEED = run_seed

    durations: Dict[Path, int] = {}
    valid_paths: List[Path] = []
    for p in selected_paths:
        try:
            if not p.exists():
                # Ð¿Ð¾Ð¼ÐµÑ‡Ð°ÐµÐ¼ ÐºÐ°Ðº Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð½Ñ‹Ð¹ Ð¸ Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼
                try:
                    sid = db_get_source_id_by_path(p)
                    if sid is not None:
                        db_mark_source_problem(sid, "missing_file")
                except Exception:
                    pass
                continue
            d = int(ffprobe_duration_seconds(p))
            if d > 0:
                durations[p] = d
                valid_paths.append(p)
            else:
                try:
                    sid = db_get_source_id_by_path(p)
                    if sid is not None:
                        db_mark_source_problem(sid, "zero_duration")
                except Exception:
                    pass
        except Exception:
            try:
                sid = db_get_source_id_by_path(p)
                if sid is not None:
                    db_mark_source_problem(sid, "probe_error")
            except Exception:
                pass
            continue

    # Ð·Ð°Ð¼ÐµÐ½ÑÐµÐ¼ ÑÐ¿Ð¸ÑÐ¾Ðº Ð½Ð° Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð²Ð°Ð»Ð¸Ð´Ð½Ñ‹Ðµ Ð¿ÑƒÑ‚Ð¸
    selected_paths = valid_paths

    sum_dur = sum(durations.values())
    effective_target = min(target_seconds, sum_dur)
    if effective_target <= 0:
        raise RuntimeError("Ð¦ÐµÐ»ÐµÐ²Ð°Ñ Ð´Ð»Ð¸Ð½Ð° Ð½ÑƒÐ»ÐµÐ²Ð°Ñ Ð¸Ð»Ð¸ Ñƒ Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð½ÑƒÐ»ÐµÐ²Ð°Ñ Ð´Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ")

    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð¼ÐµÑÑ‚Ð°: Ð¾Ñ†ÐµÐ½Ð¸Ð¼ Ñ€Ð°Ð·Ð¼ÐµÑ€ Ñ„Ð¸Ð½Ð°Ð»Ð° Ð¸ Ñ€ÐµÐ·ÐµÑ€Ð² Ð¿Ð¾Ð´ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ ÐºÐ»Ð¸Ð¿Ñ‹
    estimated_out = estimate_required_bytes(effective_target)
    if estimated_out > MAX_OUTPUT_BYTES:
        raise RuntimeError(
            f"ÐžÑ†ÐµÐ½Ð¾Ñ‡Ð½Ñ‹Ð¹ Ñ€Ð°Ð·Ð¼ÐµÑ€ Ð¸Ñ‚Ð¾Ð³Ð¾Ð²Ð¾Ð³Ð¾ Ñ„Ð°Ð¹Ð»Ð° Ð¿Ñ€ÐµÐ²Ñ‹ÑˆÐ°ÐµÑ‚ Ð»Ð¸Ð¼Ð¸Ñ‚ 100 Ð“Ð‘ (â‰ˆ{estimated_out/1024**3:.1f} Ð“Ð‘)."
        )

    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    free_out = shutil.disk_usage(str(OUTPUT_DIR)).free
    if free_out < min(estimated_out, MAX_OUTPUT_BYTES):
        raise RuntimeError(
            f"ÐÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¼ÐµÑÑ‚Ð° Ð² Ð¿Ð°Ð¿ÐºÐµ Ð²Ñ‹Ð²Ð¾Ð´Ð°: Ð½ÑƒÐ¶Ð½Ð¾ â‰ˆ{estimated_out/1024**3:.1f} Ð“Ð‘, Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ â‰ˆ{free_out/1024**3:.1f} Ð“Ð‘."
        )

    per_file_alloc = allocate_equalish(effective_target, selected_paths, durations)
    resolved_algo_key, algo_meta = resolve_clip_algorithm(clip_algo_key)

    per_file_clips: Dict[Path, List[Tuple[int, int]]] = {}
    for f in selected_paths:
        alloc = per_file_alloc.get(f, 0)
        if alloc <= 0:
            continue
        clips = plan_for_file(f, alloc, big_parts, small_per_big, algo_key=resolved_algo_key)
        per_file_clips[f] = clips

    sequence = algo_meta["builder"](per_file_clips)
    if not sequence:
        raise RuntimeError("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ ÑÐ¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¿Ð¾ÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ ÐºÐ»Ð¸Ð¿Ð¾Ð²")
    print(f"[CLIP-SEQ] ÐÐ»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼: {algo_meta['title']} ({resolved_algo_key})")

    tmp_parent = pick_temp_dir(TEMP_DIRS, min_free_bytes=max(5 * 1024**3, estimated_out * 2))
    tmp_root = Path(tempfile.mkdtemp(prefix="pmv_", dir=str(tmp_parent)))
    clips_paths: List[Path] = []

    # ÐšÑÑˆ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ñ… ÐºÐ°Ð´Ñ€Ð¾Ð² Ð´Ð»Ñ Ð¿Ñ€Ð¸Ð²ÑÐ·ÐºÐ¸ ÑÑ‚Ð°Ñ€Ñ‚Ð¾Ð² ÐºÐ»Ð¸Ð¿Ð¾Ð²
    keyframe_cache: Dict[Path, Dict[str, Any]] = {}
    KEYFRAME_INITIAL_WINDOW = 10.0
    KEYFRAME_MAX_WINDOW = 300.0
    KEYFRAME_LOOKAHEAD = 0.25

    def _cache_entry(src: Path) -> Dict[str, Any]:
        return keyframe_cache.setdefault(src, {"times": [], "full_scan": False})

    def _insert_keyframes(entry: Dict[str, Any], values: List[float]) -> None:
        if not values:
            return
        times: List[float] = entry["times"]
        for val in values:
            rounded = round(val, 6)
            idx = bisect_left(times, rounded)
            if idx >= len(times) or abs(times[idx] - rounded) > 1e-6:
                times.insert(idx, rounded)

    def _find_prev(entry: Dict[str, Any], t: float) -> Optional[float]:
        times: List[float] = entry["times"]
        if not times:
            return None
        idx = bisect_right(times, t)
        if idx:
            return times[idx - 1]
        return times[0]

    def _probe_keyframes(src: Path, start: Optional[float], end: Optional[float]) -> List[float]:
        cmd = [
            FFPROBE_BIN,
            "-v", "error",
            "-select_streams", "v:0",
            "-skip_frame", "nokey",
            "-show_entries", "frame=pkt_pts_time",
            "-of", "default=nokey=1:noprint_wrappers=1",
        ]
        if start is not None or end is not None:
            interval_start = 0.0 if start is None else max(0.0, start)
            interval_end = interval_start + 0.05
            if end is not None:
                interval_end = max(interval_end, end)
            cmd.extend(["-read_intervals", f"{interval_start:.3f}%{interval_end:.3f}"])
        cmd.append(str(src))
        try:
            out = subprocess.check_output(cmd, text=True)
        except Exception:
            return []
        found: List[float] = []
        for line in out.strip().splitlines():
            try:
                found.append(float(line.strip()))
            except Exception:
                continue
        return sorted(found)

    def get_prev_keyframe_time(src: Path, t: float) -> float:
        entry = _cache_entry(src)
        cached = _find_prev(entry, t)
        if cached is not None:
            return cached

        window = KEYFRAME_INITIAL_WINDOW
        while window <= KEYFRAME_MAX_WINDOW:
            window_start = max(0.0, t - window)
            window_end = max(t + KEYFRAME_LOOKAHEAD, window_start + 0.05)
            new_vals = _probe_keyframes(src, window_start, window_end)
            _insert_keyframes(entry, new_vals)
            cached = _find_prev(entry, t)
            if cached is not None or window_start <= 0:
                break
            window *= 2

        if cached is not None:
            return cached

        if not entry.get("full_scan"):
            full_vals = _probe_keyframes(src, None, None)
            _insert_keyframes(entry, full_vals)
            entry["full_scan"] = True
            cached = _find_prev(entry, t)
            if cached is not None:
                return cached

        return t

    try:
        total = len(sequence)
        for idx, (src, start, dur) in enumerate(sequence, 1):
            ext = ".ts" if USE_TS_CONCAT else ".mp4"
            out = tmp_root / f"clip_{idx:03d}{ext}"
            start_f = float(start)
            if SNAP_TO_KEYFRAMES:
                start_f = get_prev_keyframe_time(src, start_f)
            print(f"[{idx}/{total}] {src.name}: start={start_f:.3f}, dur={dur}")
            t0 = time.time()
            try:
                extract_clip(src, start_f, dur, out)
                print(f"  -> clip ok ({time.time() - t0:.1f}s)")
                clips_paths.append(out)
            except Exception as e:
                print(f"[ERROR] ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ð¸ ÐºÐ»Ð¸Ð¿Ð° Ð¸Ð· {src}: {e}")
                try:
                    sid = db_get_source_id_by_path(src)
                    if sid is not None:
                        db_mark_source_problem(sid, f"extract_error={e}")
                except Exception:
                    pass
                continue

        if not clips_paths:
            raise RuntimeError("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¸Ð·Ð²Ð»ÐµÑ‡ÑŒ Ð½Ð¸ Ð¾Ð´Ð½Ð¾Ð³Ð¾ ÐºÐ»Ð¸Ð¿Ð° â€” Ð²ÑÐµ Ð¿Ð¾Ð¿Ñ‹Ñ‚ÐºÐ¸ Ð·Ð°ÐºÐ¾Ð½Ñ‡Ð¸Ð»Ð¸ÑÑŒ Ð¾ÑˆÐ¸Ð±ÐºÐ°Ð¼Ð¸.")

        out_path = make_output_name(
            selected_files=selected_paths,
            target_seconds=target_seconds,
            big_parts=big_parts,
            small_per_big=small_per_big,
            run_seed=run_seed,
            algo_tag=algo_meta.get("short"),
        )
        concat_via_list(clips_paths, out_path)
        if out_path.with_suffix(".mp4").exists():
            out_path = out_path.with_suffix(".mp4")
        return out_path
    finally:
        shutil.rmtree(tmp_root, ignore_errors=True)


def autocreate_make_one_pairs(
    target_seconds: int,
    max_sources: int,
    min_sources: int,
    excluded_ids: set[int],
    big_parts: int = 5,
    small_per_big: int = 5,
    strategy: str = "max_group",
    clip_algo_key: Optional[str] = None,
) -> Optional[Tuple[Path, List[int], Tuple[str, str]]]:
    """
    Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ñ‚ Ð¾Ð´Ð½Ð¾ PMV Ð¸Ð· ÐŸÐÐ : 1 Ð½Ð¾Ð²Ñ‹Ð¹ + 1 ÑÑ‚Ð°Ñ€Ñ‹Ð¹ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸Ðº, Ð¿Ð¾Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ð¾.
    Ð“Ñ€ÑƒÐ¿Ð¿Ñ‹ Ð¿Ð¾ (codec,res). Ð‘ÐµÑ€Ñ‘Ð¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐºÐ»ÑŽÑ‡Ð¸, Ð³Ð´Ðµ ÐµÑÑ‚ÑŒ Ð¸ Ð½Ð¾Ð²Ñ‹Ðµ, Ð¸ ÑÑ‚Ð°Ñ€Ñ‹Ðµ.
    """
    new_groups = db_get_unused_sources_grouped()
    old_groups = db_get_used_sources_grouped()
    if not new_groups or not old_groups:
        return None

    # ÐºÐ»ÑŽÑ‡Ð¸ Ð¿ÐµÑ€ÐµÑÐµÑ‡ÐµÐ½Ð¸Ñ
    common_keys = []
    for k in new_groups.keys():
        if k in old_groups:
            # Ñ„Ð¸Ð»ÑŒÑ‚Ñ€ÑƒÐµÐ¼ excluded
            new_rows = [r for r in new_groups[k] if int(r["id"]) not in excluded_ids]
            old_rows = [r for r in old_groups[k] if int(r["id"]) not in excluded_ids]
            if new_rows and old_rows:
                common_keys.append((k, new_rows, old_rows))
    if not common_keys:
        return None

    # Ð²Ñ‹Ð±Ñ€Ð°Ñ‚ÑŒ ÐºÐ»ÑŽÑ‡ Ð¿Ð¾ ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸Ð¸
    if strategy == "weighted_random":
        total = sum(min(len(nr), len(orows)) for _, nr, orows in common_keys)
        rnd = random.randint(1, max(1, total))
        acc = 0
        key, new_rows, old_rows = common_keys[0]
        for k, nr, orows in common_keys:
            acc += min(len(nr), len(orows))
            if rnd <= acc:
                key, new_rows, old_rows = k, nr, orows
                break
    elif strategy == "random":
        key, new_rows, old_rows = random.choice(common_keys)
    else:  # max_group Ð¿Ð¾ â€œÐ¼Ð¸Ð½Ð¸Ð¼ÑƒÐ¼Ñƒ Ð¿Ð°Ñ€Ñ‹â€
        key, new_rows, old_rows = max(common_keys, key=lambda t: min(len(t[1]), len(t[2])))

    # ÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð¿Ð°Ñ€ Ð¼Ð¾Ð¶ÐµÐ¼ Ð²Ð·ÑÑ‚ÑŒ
    max_pairs = min(len(new_rows), len(old_rows), max_sources // 2)
    need_pairs = max(1, (min_sources + 1) // 2)
    if max_pairs < need_pairs:
        return None

    # Ð´Ð¸Ð²ÐµÑ€ÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ñ Ð¿Ð¾ Ð¿Ð°Ð¿ÐºÐ°Ð¼ Ð´Ð»Ñ Ð½Ð¾Ð²Ñ‹Ñ… Ð¸ ÑÑ‚Ð°Ñ€Ñ‹Ñ… Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾
    def pick_diverse(rows: List[sqlite3.Row], count: int) -> List[sqlite3.Row]:
        dir_map: Dict[Path, List[sqlite3.Row]] = {}
        for r in rows:
            d = Path(r["video_path"]).resolve().parent
            dir_map.setdefault(d, []).append(r)
        for lst in dir_map.values():
            random.shuffle(lst)
        chosen: List[sqlite3.Row] = []
        taken: Dict[Path, int] = {d: 0 for d in dir_map}
        progressed = True
        while len(chosen) < count and progressed:
            progressed = False
            for d, lst in list(dir_map.items()):
                if taken[d] >= PER_DIR_MAX_FIRST_PASS:
                    continue
                if lst:
                    chosen.append(lst.pop())
                    taken[d] += 1
                    progressed = True
                    if len(chosen) >= count:
                        break
        if len(chosen) < count:
            leftovers: List[sqlite3.Row] = []
            for lst in dir_map.values():
                leftovers.extend(lst)
            random.shuffle(leftovers)
            for r in leftovers:
                chosen.append(r)
                if len(chosen) >= count:
                    break
        return chosen

    pick_n = max_pairs
    new_pick = pick_diverse(new_rows, pick_n)
    old_pick = pick_diverse(old_rows, pick_n)

    # Ñ‡ÐµÑ€ÐµÐ´ÑƒÐµÐ¼: Ð½Ð¾Ð²Ñ‹Ð¹, ÑÑ‚Ð°Ñ€Ñ‹Ð¹
    chosen_rows: List[sqlite3.Row] = []
    for nr, orow in zip(new_pick, old_pick):
        chosen_rows.append(nr)
        chosen_rows.append(orow)
    # ÑƒÑ€ÐµÐ·Ð°ÐµÐ¼ Ð´Ð¾ Ð»Ð¸Ð¼Ð¸Ñ‚Ð°
    chosen_rows = chosen_rows[: max_sources]

    paths = [Path(r["video_path"]) for r in chosen_rows]
    source_ids = [int(r["id"]) for r in chosen_rows]

    out_path = make_pmv_from_files(paths, target_seconds, big_parts, small_per_big, clip_algo_key=clip_algo_key)
    out_path, move_comment = move_output_to_network_storage(out_path)
    pmv_tag = Path(out_path).name

    db_insert_compilation(out_path, source_ids, comments=move_comment)
    db_update_sources_pmv_list(source_ids, pmv_tag)
    excluded_ids.update(source_ids)

    return out_path, source_ids, key


def autocreate_pmv_batch(
    total_videos: int,
    minutes_each: int,
    max_sources: int,
    min_sources: int,
) -> str:
    """
    Ð”ÐµÐ»Ð°ÐµÑ‚ Ð´Ð¾ total_videos PMV:
    - ÑÐ½Ð°Ñ‡Ð°Ð»Ð° Ð¸Ð· ÐÐžÐ’Ð«Ð¥ (Ð½ÐµÑƒÑ‡Ð°ÑÑ‚Ð²Ð¾Ð²Ð°Ð²ÑˆÐ¸Ñ…), Ð¿Ð¾Ñ‚Ð¾Ð¼ Ð¸Ð· Ð¡Ð¢ÐÐ Ð«Ð¥,
    - Ð¿Ñ€Ð¸ ÑÑ‚Ð¾Ð¼:
        new_count  = ceil(total_videos / 2)
        old_count  = floor(total_videos / 2)
    Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ð¹ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚.
    """
    target_seconds = max(60, minutes_each * 60)

    # ÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð½ÑƒÐ¶Ð½Ð¾ Ð¿Ð¾Ð¿Ñ‹Ñ‚Ð°Ñ‚ÑŒÑÑ ÑÐ´ÐµÐ»Ð°Ñ‚ÑŒ
    new_target = (total_videos + 1) // 2   # Ð¾ÐºÑ€ÑƒÐ³Ð»ÐµÐ½Ð¸Ðµ Ð²Ð²ÐµÑ€Ñ…
    old_target = total_videos // 2         # Ð¾ÐºÑ€ÑƒÐ³Ð»ÐµÐ½Ð¸Ðµ Ð²Ð½Ð¸Ð·

    created_new = 0
    created_old = 0

    excluded_new: set[int] = set()
    excluded_old: set[int] = set()

    log_lines: List[str] = []
    algo_picker = ClipAlgorithmPicker(total_videos)

    # -------- ÐÐ¾Ð²Ñ‹Ðµ (ÐºÐ°Ðº pmvnew) --------
    for i in range(new_target):
        algo_key = algo_picker.current()
        try:
            res = autocreate_make_one_pairs(
                target_seconds=target_seconds,
                max_sources=max_sources,
                min_sources=min_sources,
                excluded_ids=excluded_new,
                strategy=CURRENT_STRATEGY,
                clip_algo_key=algo_key,
            )
        except Exception as e:
            log_lines.append(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ð¸ Ð½Ð¾Ð²Ð¾Ð³Ð¾ PMV #{i+1}: {e}")
            break

        if not res:
            # Ð¤ÐžÐ›Ð‘Ð•Ðš: Ð¿Ñ€Ð¾Ð±ÑƒÐµÐ¼ ÑÐ¾Ð±Ñ€Ð°Ñ‚ÑŒ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¸Ð· Ð½Ð¾Ð²Ñ‹Ñ…, ÐµÑÐ»Ð¸ Ð¿Ð°Ñ€ Ð½Ðµ Ð½Ð°Ð±Ñ€Ð°Ð»Ð¾ÑÑŒ
            try:
                res = fallback_new_only_make_one(
                    target_seconds=target_seconds,
                    max_sources=max_sources,
                    min_sources=min_sources,
                    excluded_ids=excluded_new,
                    strategy=CURRENT_STRATEGY,
                    clip_algo_key=algo_key,
                )
            except Exception as e:
                log_lines.append(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° (fallback new-only) Ð¿Ñ€Ð¸ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ð¸ Ð½Ð¾Ð²Ð¾Ð³Ð¾ PMV #{i+1}: {e}")
                break

            if not res:
                if i == 0:
                    log_lines.append("âš ï¸ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ ÑÐ¾Ð·Ð´Ð°Ñ‚ÑŒ Ð½Ð¸ Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ð½Ð¾Ð²Ð¾Ð³Ð¾ PMV â€” Ð¼Ð°Ð»Ð¾ Ð½ÐµÐ¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð².")
                else:
                    log_lines.append("âš ï¸ Ð˜ÑÑ‡ÐµÑ€Ð¿Ð°Ð½ Ð¿ÑƒÐ» Ð½ÐµÐ¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² Ð´Ð»Ñ Ð½Ð¾Ð²Ñ‹Ñ… PMV.")
                break

        out_path, src_ids, (codec, reso) = res
        algo_picker.commit()
        _, algo_meta = resolve_clip_algorithm(algo_key)
        created_new += 1
        log_lines.append(
            f"âœ… ÐÐ¾Ð²Ð¾Ðµ PMV #{created_new}: {out_path.name} "
            f"(Ð³Ñ€ÑƒÐ¿Ð¿Ð° {codec} {reso}, Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð²: {len(src_ids)}, Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼: {algo_meta['short']})"
        )

    # -------- Ð¡Ñ‚Ð°Ñ€Ñ‹Ðµ (ÑƒÐ¶Ðµ ÑƒÑ‡Ð°ÑÑ‚Ð²Ð¾Ð²Ð°Ð²ÑˆÐ¸Ðµ) --------
    for i in range(old_target):
        algo_key = algo_picker.current()
        try:
            res = autocreate_make_one_pairs(
                target_seconds=target_seconds,
                max_sources=max_sources,
                min_sources=min_sources,
                excluded_ids=excluded_old,
                strategy=CURRENT_STRATEGY,
                clip_algo_key=algo_key,
            )
        except Exception as e:
            log_lines.append(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ð¸ PMV Ð¸Ð· ÑÑ‚Ð°Ñ€Ñ‹Ñ… Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² #{i+1}: {e}")
            break

        if not res:
            if i == 0:
                log_lines.append("âš ï¸ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ ÑÐ¾Ð·Ð´Ð°Ñ‚ÑŒ Ð½Ð¸ Ð¾Ð´Ð½Ð¾Ð³Ð¾ PMV Ð¸Ð· ÑÑ‚Ð°Ñ€Ñ‹Ñ… Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð².")
            else:
                log_lines.append("âš ï¸ Ð˜ÑÑ‡ÐµÑ€Ð¿Ð°Ð½ Ð¿ÑƒÐ» ÑÑ‚Ð°Ñ€Ñ‹Ñ… Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² Ð´Ð»Ñ PMV.")
            break

        out_path, src_ids, (codec, reso) = res
        algo_picker.commit()
        _, algo_meta = resolve_clip_algorithm(algo_key)
        created_old += 1
        log_lines.append(
            f"âœ… PMV Ð¸Ð· ÑÑ‚Ð°Ñ€Ñ‹Ñ… Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² #{created_old}: {out_path.name} "
            f"(Ð³Ñ€ÑƒÐ¿Ð¿Ð° {codec} {reso}, Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð²: {len(src_ids)}, Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼: {algo_meta['short']})"
        )

    created_total = created_new + created_old

    header = (
        f"ðŸ ÐÐ²Ñ‚Ð¾ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾.\n"
        f"Ð—Ð°Ð¿Ñ€Ð¾ÑˆÐµÐ½Ð¾ Ð²Ð¸Ð´ÐµÐ¾: {total_videos}\n"
        f"Ð¤Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸ ÑÐ¾Ð·Ð´Ð°Ð½Ð¾: {created_total} "
        f"(Ð½Ð¾Ð²Ñ‹Ñ…: {created_new}, Ð¸Ð· ÑÑ‚Ð°Ñ€Ñ‹Ñ…: {created_old})."
    )

    if not log_lines:
        return header
    return header + "\n\n" + "\n".join(log_lines)


# =========================
# Ð¢Ð•Ð›Ð•Ð“Ð ÐÐœ-Ð‘ÐžÐ¢
# =========================

user_sessions: Dict[int, Dict] = {}


def check_access(update: Update) -> bool:
    uid = update.effective_user.id if update.effective_user else 0
    return uid == ALLOWED_USER_ID


async def unauthorized(update: Update) -> None:
    await update.effective_chat.send_message("â›” Ð£ Ð²Ð°Ñ Ð½ÐµÑ‚ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð° Ðº ÑÑ‚Ð¾Ð¼Ñƒ Ð±Ð¾Ñ‚Ñƒ.")



async def cmd_start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not check_access(update):
        return await unauthorized(update)

    text = (
        f"ðŸ‘‹ ÐŸÑ€Ð¸Ð²ÐµÑ‚! PMV-Ð±Ð¾Ñ‚ {BUILD_NAME}.\n\n"
        "Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ðµ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹:\n"
        "/addfolder <Ð¿ÑƒÑ‚ÑŒ> â€“ Ð´Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð¿Ð°Ð¿ÐºÑƒ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸\n"
        "/folders â€“ Ð¿Ð¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ Ð¿Ð°Ð¿ÐºÐ¸ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸\n"
        "/scan â€“ Ð¿Ñ€Ð¾ÑÐºÐ°Ð½Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¿Ð°Ð¿ÐºÐ¸ Ð¸ Ð¾Ð±Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ ÑÐ¿Ð¸ÑÐ¾Ðº Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð²\n"
        "/scanignore â€“ Ð´Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð¿Ð¾Ð´Ð¿Ð°Ð¿ÐºÑƒ Ð² ÑÐ¿Ð¸ÑÐ¾Ðº Ð¸ÑÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ð¹ ÑÐºÐ°Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ\n\n"
        "/pmvnew â€“ ÑÐ¾Ð·Ð´Ð°Ñ‚ÑŒ Ð½Ð¾Ð²Ð¾Ðµ PMV Ð¸Ð· ÐµÑ‰Ñ‘ ÐÐ• Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð²\n"
        "/pmvold â€“ ÑÐ¾Ð·Ð´Ð°Ñ‚ÑŒ PMV Ð¸Ð· Ð›Ð®Ð‘Ð«Ð¥ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² (Ð²ÐºÐ»ÑŽÑ‡Ð°Ñ ÑƒÐ¶Ðµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ)\n"
        "/autocreate â€“ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ ÑÐ¾Ð·Ð´Ð°Ñ‚ÑŒ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ PMV Ð¿Ð¾ Ð·Ð°Ð´Ð°Ð½Ð½Ñ‹Ð¼ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð°Ð¼\n"
        "/newcompmusic â€“ ÑÐ¾Ð±Ñ€Ð°Ñ‚ÑŒ PMV Ð¿Ð¾Ð´ Ð¼ÑƒÐ·Ñ‹ÐºÑƒ Ð¸Ð· music_projects\n"
        "/musicprep â€“ Ð¿Ñ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ñ‚Ñ€ÐµÐº Ð¸Ð· Ð¿Ð°Ð¿ÐºÐ¸ Music Ð¸ ÑÐ¾Ð·Ð´Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¾ÐµÐºÑ‚\n"
        "/videofx â€“ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÑŒ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð³Ð»Ð¸Ñ‚Ñ‡ÐµÐ¹ Ð¸ Ð¿ÐµÑ€ÐµÑ…Ð¾Ð´Ð¾Ð² Ð¼ÐµÐ¶Ð´Ñƒ ÐºÐ»Ð¸Ð¿Ð°Ð¼Ð¸\n"
        "/musicprepcheck â€“ ÑÐ¾Ð·Ð´Ð°Ñ‚ÑŒ MP3 ÑÐ¾ Ñ‰ÐµÐ»Ñ‡ÐºÐ°Ð¼Ð¸ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ð¾Ð²\n"
        "/ratepmv â€“ Ð¾Ñ†ÐµÐ½Ð¸Ñ‚ÑŒ Ð³Ð¾Ñ‚Ð¾Ð²Ñ‹Ðµ PMV Ð¸ Ð¿Ñ€Ð¸ Ð¶ÐµÐ»Ð°Ð½Ð¸Ð¸ Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð²Ð¸Ð´ÐµÐ¾ Ð²Ð½ÑƒÑ‚Ñ€Ð¸\n"
        "/rategrp â€“ Ð¾Ñ‚Ð¼ÐµÑ‚Ð¸Ñ‚ÑŒ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¸ Ñ†Ð²ÐµÑ‚Ð°Ð¼Ð¸ Ð²Ð½ÑƒÑ‚Ñ€Ð¸ Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð½Ð¾Ð¹ Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹\n"
        "/compmv â€” ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð¹ Ðº PMV\n"
        "/comvid â€” ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð¹ Ðº Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÑƒ\n"
        "/lookcom â€” Ð¿Ñ€Ð¾ÑÐ¼Ð¾Ñ‚Ñ€ Ð²ÑÐµÑ… ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸ÐµÐ² Ñ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸ÑÐ¼Ð¸.\n"
        "/badfiles â€” ÑÐ¿Ð¸ÑÐ¾Ðº Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð½Ñ‹Ñ… Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð²\n"
        "/strategy [Ð¸Ð¼Ñ] â€” Ð¿Ð¾ÑÐ¼Ð¾Ñ‚Ñ€ÐµÑ‚ÑŒ/ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸ÑŽ Ð²Ñ‹Ð±Ð¾Ñ€Ð° Ð³Ñ€ÑƒÐ¿Ð¿ (max_group, weighted_random, random)\n"
        "/move2oculus â€” ÑÐºÐ¾Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð½ÐµÐ´Ð¾ÑÑ‚Ð°ÑŽÑ‰Ð¸Ðµ Ñ„Ð°Ð¹Ð»Ñ‹ Ð¸Ð· y:\\output Ð½Ð° Oculus Ñ‡ÐµÑ€ÐµÐ· ADB\n\n"
        "Ð•ÑÐ»Ð¸ adb Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½, Ð¿Ð¾ÑÑ‚Ð°Ð²ÑŒ Platform Tools Ð² C:\\platform-tools Ð¸ Ð²Ñ‹Ð¿Ð¾Ð»Ð½Ð¸ Ð² PowerShell:\n"
        "$env:Path += ';C:\\platform-tools'\n"
        "setx Path $env:Path\n"
    )
    await update.message.reply_text(text, reply_markup=build_main_reply_keyboard())

async def cmd_lookcom(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð¸ Ðº ÐºÐ¾Ð¼Ð¿Ð¸Ð»ÑÑ†Ð¸ÑÐ¼ Ð¸ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ°Ð¼.
    """
    if not check_access(update):
        return await unauthorized(update)

    comp_rows = db_get_compilations_with_comments()
    src_rows = db_get_sources_with_comments()

    if not comp_rows and not src_rows:
        return await update.message.reply_text("ÐŸÐ¾ÐºÐ° Ð½ÐµÑ‚ Ð½Ð¸ Ð¾Ð´Ð½Ð¾Ð³Ð¾ ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ñ.")

    parts: List[str] = []

    if comp_rows:
        parts.append("ðŸ“€ ÐšÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð¸ Ðº ÐºÐ¾Ð¼Ð¿Ð¸Ð»ÑÑ†Ð¸ÑÐ¼:")
        for r in comp_rows:
            name = Path(r["video_path"]).name
            parts.append(f"- {name} (Ð´Ð°Ñ‚Ð°: {r['pmv_date']}): {r['comments']}")

    if src_rows:
        if parts:
            parts.append("")  # Ð¿ÑƒÑÑ‚Ð°Ñ ÑÑ‚Ñ€Ð¾ÐºÐ°-Ñ€Ð°Ð·Ð´ÐµÐ»Ð¸Ñ‚ÐµÐ»ÑŒ
        parts.append("ðŸŽž ÐšÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð¸ Ðº Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ°Ð¼:")
        for r in src_rows:
            parts.append(f"- {r['video_name']} (id={r['id']}): {r['comments']}")

    text = "\n".join(parts)
    if len(text) <= 4000:
        await update.message.reply_text(text)
        return

    chunk_size = 3800
    for i in range(0, len(text), chunk_size):
        await update.message.reply_text(text[i:i + chunk_size])



async def cmd_compmv(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    Ð”Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð¹ Ðº ÐºÐ¾Ð¼Ð¿Ð¸Ð»ÑÑ†Ð¸Ð¸ (PMV).
    /compmv -> ÑÐ¿Ð¸ÑÐ¾Ðº PMV -> Ð½Ð¾Ð¼ÐµÑ€ -> Ñ‚ÐµÐºÑÑ‚ ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ñ.
    """
    if not check_access(update):
        return await unauthorized(update)

    rows = db_get_all_compilations()
    if not rows:
        return await update.message.reply_text("ÐŸÐ¾ÐºÐ° Ð½ÐµÑ‚ Ð½Ð¸ Ð¾Ð´Ð½Ð¾Ð¹ ÐºÐ¾Ð¼Ð¿Ð¸Ð»ÑÑ†Ð¸Ð¸.")

    lines = ["ðŸŽ¬ ÐšÐ¾Ð¼Ð¿Ð¸Ð»ÑÑ†Ð¸Ð¸:"]
    for idx, r in enumerate(rows, 1):
        name = Path(r["video_path"]).name
        date_str = r["pmv_date"]
        lines.append(f"{idx}. {name} (Ð´Ð°Ñ‚Ð°: {date_str}, id={r['id']})")

    lines.append("")
    lines.append("ÐŸÑ€Ð¸ÑˆÐ»Ð¸Ñ‚Ðµ Ð½Ð¾Ð¼ÐµÑ€ PMV, Ðº ÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ð¼Ñƒ Ñ…Ð¾Ñ‚Ð¸Ñ‚Ðµ Ð´Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð¹ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€: 2).")

    user_sessions[update.effective_user.id] = {
        "state": "compmv_choose",
        "pmv_rows": rows,
    }

    await update.message.reply_text("\n".join(lines))


async def cmd_addfolder(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not check_access(update):
        return await unauthorized(update)

    args = context.args
    if not args:
        return await update.message.reply_text("Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ: /addfolder C:\\path\\to\\folder")

    folder = " ".join(args).strip().strip('"')
    p = Path(folder)
    if not p.exists() or not p.is_dir():
        return await update.message.reply_text(f"ÐŸÐ°Ð¿ÐºÐ° Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°: {p}")

    db_add_upload_folder(str(p))
    await update.message.reply_text(f"âœ… ÐŸÐ°Ð¿ÐºÐ° Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð°: {p}")


async def cmd_folders(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not check_access(update):
        return await unauthorized(update)

    rows = db_get_upload_folders(include_ignored=True)
    if not rows:
        return await update.message.reply_text("ÐŸÐ°Ð¿Ð¾Ðº Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð¿Ð¾ÐºÐ° Ð½ÐµÑ‚. Ð”Ð¾Ð±Ð°Ð²ÑŒÑ‚Ðµ Ñ‡ÐµÑ€ÐµÐ· /addfolder")

    active = [r for r in rows if not r["ignored"]]
    ignored = [r for r in rows if r["ignored"]]
    lines = ["ðŸ“‚ ÐŸÐ°Ð¿ÐºÐ¸ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸:"]
    if not active:
        lines.append("ÐÐµÑ‚ Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ñ… Ð¿Ð°Ð¿Ð¾Ðº Ð´Ð»Ñ ÑÐºÐ°Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ.")
    else:
        for r in active:
            lines.append(f"{r['id']}. {r['folder_path']} (Ñ {r['date_added']})")
    if ignored:
        lines.append("")
        lines.append("ðŸš« Ð˜Ð³Ð½Ð¾Ñ€Ð¸Ñ€ÑƒÐµÐ¼Ñ‹Ðµ Ð¿Ð¾Ð´Ð¿Ð°Ð¿ÐºÐ¸ (/scanignore):")
        for r in ignored:
            lines.append(f"{r['id']}. {r['folder_path']} (Ñ {r['date_added']})")
    await update.message.reply_text("\n".join(lines))


async def cmd_scan(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not check_access(update):
        return await unauthorized(update)

    rows = db_get_upload_folders()
    if not rows:
        return await update.message.reply_text("ÐÐµÑ‚ Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ñ… Ð¿Ð°Ð¿Ð¾Ðº. Ð”Ð¾Ð±Ð°Ð²ÑŒÑ‚Ðµ ÐµÑ‘ Ñ‡ÐµÑ€ÐµÐ· /addfolder")
    ignored_rows = db_get_scan_ignored_folders()

    await update.message.reply_text("ÐÐ°Ñ‡Ð¸Ð½Ð°ÑŽ Ð¿ÐµÑ€ÐµÑÐºÐ°Ð½Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ ÐºÐ°Ñ‚Ð°Ð»Ð¾Ð³Ð¸... ÑÑ‚Ð¾ Ð¼Ð¾Ð¶ÐµÑ‚ Ð·Ð°Ð½ÑÑ‚ÑŒ Ð²Ñ€ÐµÐ¼Ñ.")

    env = ScanEnvironment(
        default_exts=DEFAULT_EXTS,
        normalize_path_str=_normalize_path_str,
        normalize_path_prefix=_normalize_path_prefix,
        is_path_under_prefixes=_is_path_under_prefixes,
        combine_comments=combine_comments,
        merge_pmv_lists=merge_pmv_lists,
        video_info_sort=video_info_sort,
        db_get_sources_full=db_get_sources_full,
        db_update_source_fields=db_update_source_fields,
        db_insert_source=db_insert_source,
        db_delete_sources_by_ids=db_delete_sources_by_ids,
        db_path=DB_PATH,
        backup_dir=SCRIPT_DIR / "old",
    )

    lines, _stats = run_scan(rows, ignored_rows, env)
    symlink_notes = sync_nas_symlinks()
    if symlink_notes:
        lines.append("")
        lines.extend(symlink_notes)
    await update.message.reply_text("\n".join(lines))

async def cmd_scanignore(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not check_access(update):
        return await unauthorized(update)

    user_id = update.effective_user.id
    user_sessions[user_id] = {
        "state": "scanignore_wait_path",
    }
    lines = [
        "ÐŸÑ€Ð¸ÑˆÐ»Ð¸Ñ‚Ðµ Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ Ð¿ÑƒÑ‚ÑŒ Ð¿Ð°Ð¿ÐºÐ¸, ÐºÐ¾Ñ‚Ð¾Ñ€ÑƒÑŽ Ð½ÑƒÐ¶Ð½Ð¾ Ð¸ÑÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒ Ð¸Ð· /scan.",
        "ÐœÐ¾Ð¶Ð½Ð¾ ÑƒÐºÐ°Ð·Ñ‹Ð²Ð°Ñ‚ÑŒ Ð¿Ð¾Ð´Ð¿Ð°Ð¿ÐºÐ¸ ÑƒÐ¶Ðµ Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð½Ñ‹Ñ… ÐºÐ°Ñ‚Ð°Ð»Ð¾Ð³Ð¾Ð² (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€ X:\\tor\\tmp).",
        "Ð§Ñ‚Ð¾Ð±Ñ‹ Ð¾Ñ‚Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ, Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ /start Ð¸Ð»Ð¸ Ð´Ñ€ÑƒÐ³ÑƒÑŽ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñƒ.",
    ]
    await update.message.reply_text("\n".join(lines))

async def cmd_comvid(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    Ð”Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð¹ Ðº Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÑƒ.
    /comvid -> ÑÐ¿Ð¸ÑÐ¾Ðº Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² -> Ð½Ð¾Ð¼ÐµÑ€ -> Ñ‚ÐµÐºÑÑ‚ ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ñ.
    """
    if not check_access(update):
        return await unauthorized(update)

    rows = db_get_all_sources()
    if not rows:
        return await update.message.reply_text("Ð’ Ð±Ð°Ð·Ðµ Ð½ÐµÑ‚ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð².")

    lines = ["ðŸŽ¥ Ð˜ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¸:"]
    # Ñ‡Ñ‚Ð¾Ð±Ñ‹ ÑÐ¿Ð¸ÑÐ¾Ðº Ð½Ðµ Ð±Ñ‹Ð» ÑÐ¾Ð²ÑÐµÐ¼ Ð±ÐµÐ·ÑƒÐ¼Ð½Ñ‹Ð¼, Ð¼Ð¾Ð¶Ð½Ð¾ Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ñ‚ÑŒ, Ð½Ð¾ Ð¿Ð¾ Ð¢Ð— Ð²Ñ‹Ð²Ð¾Ð´Ð¸Ð¼ Ð²ÑÐµ
    for idx, r in enumerate(rows, 1):
        name = r["video_name"]
        lines.append(f"{idx}. {name} (id={r['id']})")

    lines.append("")
    lines.append("ÐŸÑ€Ð¸ÑˆÐ»Ð¸Ñ‚Ðµ Ð½Ð¾Ð¼ÐµÑ€ Ð²Ð¸Ð´ÐµÐ¾, Ðº ÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ð¼Ñƒ Ñ…Ð¾Ñ‚Ð¸Ñ‚Ðµ Ð´Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð¹ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€: 5).")

    user_sessions[update.effective_user.id] = {
        "state": "comvid_choose",
        "src_rows": rows,
    }

    await update.message.reply_text("\n".join(lines))

async def cmd_autocreate(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¸Ñ… PMV Ð¿Ð¾Ð´Ñ€ÑÐ´.

    Ð¨Ð°Ð³Ð¸:
    1) Ð¡Ð¿Ñ€Ð¾ÑÐ¸Ñ‚ÑŒ, ÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð²Ð¸Ð´ÐµÐ¾ ÑÐ¾Ð·Ð´Ð°Ñ‚ÑŒ.
    2) Ð¡Ð¿Ñ€Ð¾ÑÐ¸Ñ‚ÑŒ Ð´Ð»Ð¸Ð½Ñƒ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ (Ð² Ð¼Ð¸Ð½ÑƒÑ‚Ð°Ñ…).
    3) Ð¡Ð¿Ñ€Ð¾ÑÐ¸Ñ‚ÑŒ Ð¼Ð°ÐºÑÐ¸Ð¼ÑƒÐ¼ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² Ð½Ð° Ð¾Ð´Ð½Ð¾ PMV.
    4) Ð¡Ð¿Ñ€Ð¾ÑÐ¸Ñ‚ÑŒ Ð¼Ð¸Ð½Ð¸Ð¼ÑƒÐ¼ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² Ð½Ð° Ð¾Ð´Ð½Ð¾ PMV.
    5) Ð—Ð°Ñ‚ÐµÐ¼ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸:
       - ÑÐ½Ð°Ñ‡Ð°Ð»Ð° Ð´ÐµÐ»Ð°ÐµÑ‚ Ð½ÑƒÐ¶Ð½Ð¾Ðµ Ñ‡Ð¸ÑÐ»Ð¾ PMV Ð¸Ð· ÐÐžÐ’Ð«Ð¥ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² (ÐºÐ°Ðº pmvnew),
       - Ð·Ð°Ñ‚ÐµÐ¼ Ð¸Ð· Ð¡Ð¢ÐÐ Ð«Ð¥ (ÑƒÐ¶Ðµ ÑƒÑ‡Ð°ÑÑ‚Ð²Ð¾Ð²Ð°Ð²ÑˆÐ¸Ñ… Ð² ÐºÐ¾Ð¼Ð¿Ð¸Ð»ÑÑ†Ð¸ÑÑ…),
       ÑÐ¾Ð±Ð»ÑŽÐ´Ð°Ñ Ð¿Ñ€Ð¾Ð¿Ð¾Ñ€Ñ†Ð¸ÑŽ: Ð¿Ð¾Ð»Ð¾Ð²Ð¸Ð½Ð° Ð¸Ð· Ð½Ð¾Ð²Ñ‹Ñ…, Ð¿Ð¾Ð»Ð¾Ð²Ð¸Ð½Ð° Ð¸Ð· ÑÑ‚Ð°Ñ€Ñ‹Ñ…
       (Ð¿Ñ€Ð¸ Ð½ÐµÑ‡Ñ‘Ñ‚Ð½Ð¾Ð¼ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ðµ â€” +1 Ðº Ð½Ð¾Ð²Ñ‹Ð¼).
    """
    if not check_access(update):
        return await unauthorized(update)

    user_id = update.effective_user.id

    user_sessions[user_id] = {
        "state": "autocreate_ask_count",
    }

    await update.message.reply_text(
        "ðŸš€ ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ðµ PMV.\n\n"
        "Ð¡ÐºÐ¾Ð»ÑŒÐºÐ¾ Ð²Ð¸Ð´ÐµÐ¾ ÑÐ¾Ð·Ð´Ð°Ñ‚ÑŒ? Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ñ†ÐµÐ»Ð¾Ðµ Ñ‡Ð¸ÑÐ»Ð¾ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€: 4)."
    )

def db_get_used_sources_grouped() -> Dict[Tuple[str, str], List[sqlite3.Row]]:
    """
    Ð‘ÐµÑ€Ñ‘Ñ‚ Ð¢ÐžÐ›Ð¬ÐšÐž ÑƒÐ¶Ðµ ÑƒÑ‡Ð°ÑÑ‚Ð²Ð¾Ð²Ð°Ð²ÑˆÐ¸Ðµ Ð² ÐºÐ¾Ð¼Ð¿Ð¸Ð»ÑÑ†Ð¸ÑÑ… Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¸ (pmv_list Ð½Ðµ Ð¿ÑƒÑÑ‚Ð¾Ð¹)
    Ð¸ Ð³Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€ÑƒÐµÑ‚ Ð¿Ð¾ (codec, resolution).
    Ð­Ñ‚Ð¾ Ð¿ÑƒÐ» Â«ÑÑ‚Ð°Ñ€Ñ‹Ñ…Â» Ð²Ð¸Ð´ÐµÐ¾ Ð´Ð»Ñ autocreate.
    """
    conn = get_conn()
    cur = conn.cursor()
    cur.execute(
        """
        SELECT * FROM sources
        WHERE pmv_list IS NOT NULL AND pmv_list != ''
        """
    )
    rows = cur.fetchall()
    conn.close()

    groups: Dict[Tuple[str, str], List[sqlite3.Row]] = {}
    for r in rows:
        codec = r["codec"] or "?"
        resolution = r["resolution"] or "??x??"
        key = (codec, resolution)
        groups.setdefault(key, []).append(r)
    return groups


def fallback_new_only_make_one(
    target_seconds: int,
    max_sources: int,
    min_sources: int,
    excluded_ids: set[int],
    big_parts: int = 5,
    small_per_big: int = 5,
    strategy: str = "max_group",
    clip_algo_key: Optional[str] = None,
) -> Optional[Tuple[Path, List[int], Tuple[str, str]]]:
    """Ð ÐµÐ·ÐµÑ€Ð²: ÑÐ¾Ð·Ð´Ð°Ñ‚ÑŒ PMV Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¸Ð· ÐÐžÐ’Ð«Ð¥ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² (Ð±ÐµÐ· Ð¿Ð°Ñ€),
    Ñ Ð´Ð¸Ð²ÐµÑ€ÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸ÐµÐ¹ Ð¿Ð¾ Ð¿Ð°Ð¿ÐºÐ°Ð¼ Ð¸ ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸ÐµÐ¹ Ð²Ñ‹Ð±Ð¾Ñ€Ð° Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹."""
    groups = db_get_unused_sources_grouped()
    if not groups:
        return None

    # Ñ„Ð¸Ð»ÑŒÑ‚Ñ€ excluded
    filtered: List[Tuple[Tuple[str, str], List[sqlite3.Row]]] = []
    for key, rows in groups.items():
        rem = [r for r in rows if int(r["id"]) not in excluded_ids]
        if rem:
            filtered.append((key, rem))
    if not filtered:
        return None

    # Ð²Ñ‹Ð±Ð¾Ñ€ Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹ Ð¿Ð¾ ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸Ð¸
    if strategy == "weighted_random":
        total = sum(len(rows) for _, rows in filtered)
        rnd = random.randint(1, max(1, total))
        acc = 0
        key, rows = filtered[0]
        for k, rws in filtered:
            acc += len(rws)
            if rnd <= acc:
                key, rows = k, rws
                break
    elif strategy == "random":
        key, rows = random.choice(filtered)
    else:
        key, rows = max(filtered, key=lambda kv: len(kv[1]))

    use_count = min(len(rows), max_sources)
    if use_count < 1 or len(rows) < max(1, min_sources):
        # best-effort: ÐµÑÐ»Ð¸ Ð½Ðµ Ð´Ð¾Ñ‚ÑÐ³Ð¸Ð²Ð°ÐµÐ¼ Ð´Ð¾ Ð¼Ð¸Ð½Ð¸Ð¼ÑƒÐ¼Ð° â€” Ð±ÐµÑ€Ñ‘Ð¼ ÑÐºÐ¾Ð»ÑŒÐºÐ¾ ÐµÑÑ‚ÑŒ
        use_count = min(len(rows), max_sources)
        if use_count < 1:
            return None

    # Ð´Ð¸Ð²ÐµÑ€ÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ñ Ð¿Ð¾ Ð¿Ð°Ð¿ÐºÐ°Ð¼
    dir_map: Dict[Path, List[sqlite3.Row]] = {}
    for r in rows:
        d = Path(r["video_path"]).resolve().parent
        dir_map.setdefault(d, []).append(r)
    for lst in dir_map.values():
        random.shuffle(lst)

    chosen_rows: List[sqlite3.Row] = []
    taken: Dict[Path, int] = {d: 0 for d in dir_map}
    progressed = True
    while len(chosen_rows) < use_count and progressed:
        progressed = False
        for d, lst in list(dir_map.items()):
            if taken[d] >= PER_DIR_MAX_FIRST_PASS:
                continue
            if lst:
                chosen_rows.append(lst.pop())
                taken[d] += 1
                progressed = True
                if len(chosen_rows) >= use_count:
                    break
    if len(chosen_rows) < use_count:
        leftovers: List[sqlite3.Row] = []
        for lst in dir_map.values():
            leftovers.extend(lst)
        random.shuffle(leftovers)
        for r in leftovers:
            chosen_rows.append(r)
            if len(chosen_rows) >= use_count:
                break

    paths = [Path(r["video_path"]) for r in chosen_rows]
    source_ids = [int(r["id"]) for r in chosen_rows]

    out_path = make_pmv_from_files(paths, target_seconds, big_parts, small_per_big, clip_algo_key=clip_algo_key)
    out_path, move_comment = move_output_to_network_storage(out_path)
    pmv_tag = Path(out_path).name
    db_insert_compilation(out_path, source_ids, comments=move_comment)
    db_update_sources_pmv_list(source_ids, pmv_tag)
    excluded_ids.update(source_ids)
    return out_path, source_ids, key



async def cmd_pmvnew(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not check_access(update):
        return await unauthorized(update)

    groups = db_get_unused_sources_grouped()
    if not groups:
        return await update.message.reply_text("ÐÐµÑ‚ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² Ð±ÐµÐ· PMV. Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð²Ð¾ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚ÐµÑÑŒ /scan.")

    group_entries = [
        SourceGroupEntry(key=key, rows=list(rows), unused_count=len(rows))
        for key, rows in groups.items()
    ]
    group_entries = sort_source_group_entries(group_entries)
    group_list: List[Tuple[Tuple[str, str], List[sqlite3.Row]]] = [
        (entry.key, entry.rows) for entry in group_entries
    ]

    lines = format_source_group_lines(
        group_entries, "ÐÐ°Ð¹Ð´ÐµÐ½Ñ‹ Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² (codec, resolution):"
    )
    lines.append("")
    lines.append("ÐžÑ‚Ð²ÐµÑ‚ÑŒÑ‚Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸ÐµÐ¼ Ñ Ð½Ð¾Ð¼ÐµÑ€Ð¾Ð¼ Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹, ÐºÐ¾Ñ‚Ð¾Ñ€ÑƒÑŽ Ð±ÑƒÐ´ÐµÐ¼ Ð¾Ð±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°Ñ‚ÑŒ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€: 1).")

    user_sessions[update.effective_user.id] = {
        "state": "choose_group",
        "groups": group_list,
    }

    await update.message.reply_text("\n".join(lines))

async def cmd_pmvold(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    ÐšÐ°Ðº pmvnew, Ð½Ð¾ Ð±ÐµÑ€Ñ‘Ñ‚ Ð’Ð¡Ð• Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¸, Ð° Ð½Ðµ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ñ‚Ðµ, Ñƒ ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ñ… pmv_list Ð¿ÑƒÑÑ‚Ð¾Ð¹.
    """
    if not check_access(update):
        return await unauthorized(update)

    groups = db_get_all_sources_grouped()
    if not groups:
        return await update.message.reply_text("Ð’ Ð±Ð°Ð·Ðµ Ð½ÐµÑ‚ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð². Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð²Ð¾ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚ÐµÑÑŒ /scan.")

    unused_groups = db_get_unused_sources_grouped()
    group_entries = [
        SourceGroupEntry(
            key=key,
            rows=list(rows),
            unused_count=len(unused_groups.get(key, [])),
        )
        for key, rows in groups.items()
    ]
    group_entries = sort_source_group_entries(group_entries)
    group_list: List[Tuple[Tuple[str, str], List[sqlite3.Row]]] = [
        (entry.key, entry.rows) for entry in group_entries
    ]

    lines = format_source_group_lines(
        group_entries,
        "ÐÐ°Ð¹Ð´ÐµÐ½Ñ‹ Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² (codec, resolution) â€” Ð’ÐšÐ›Ð®Ð§ÐÐ¯ ÑƒÐ¶Ðµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ:",
    )
    lines.append("")
    lines.append("ÐžÑ‚Ð²ÐµÑ‚ÑŒÑ‚Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸ÐµÐ¼ Ñ Ð½Ð¾Ð¼ÐµÑ€Ð¾Ð¼ Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹, ÐºÐ¾Ñ‚Ð¾Ñ€ÑƒÑŽ Ð±ÑƒÐ´ÐµÐ¼ Ð¾Ð±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°Ñ‚ÑŒ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€: 1).")

    user_sessions[update.effective_user.id] = {
        "state": "choose_group",
        "groups": group_list,
    }

    await update.message.reply_text("\n".join(lines))



async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not check_access(update):
        return await unauthorized(update)

    user_id = update.effective_user.id
    text = (update.message.text or "").strip()

    # Ð›Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ…ÐµÐ»Ð¿ÐµÑ€, Ñ€ÐµÐ¶ÐµÑ‚ Ð´Ð»Ð¸Ð½Ð½Ñ‹Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Ð½Ð° Ñ‡Ð°ÑÑ‚Ð¸
    async def reply_long(msg: str, chunk_size: int = 4000):
        if len(msg) <= chunk_size:
            await update.message.reply_text(msg)
            return
        for i in range(0, len(msg), chunk_size):
            await update.message.reply_text(msg[i:i + chunk_size])

    lowered_text = text.lower()
    if lowered_text in {"musicprep", "/musicprep"}:
        return await cmd_musicprep(update, context)
    if lowered_text in {"newcompmusic", "/newcompmusic"}:
        return await cmd_newcompmusic(update, context)
    if lowered_text in {"scan", "/scan"}:
        return await cmd_scan(update, context)
    if lowered_text in {"rategrp", "/rategrp"}:
        return await cmd_rategrp(update, context)
    if lowered_text in {"reports", "/reports", "Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ñ‹", "Ð¾Ñ‚Ñ‡ÐµÑ‚Ñ‹"}:
        return await cmd_reports(update, context)
    if lowered_text in {"flagpmv", "/flagpmv", "find", "/find", "Ð½Ð°Ð¹Ñ‚Ð¸"}:
        return await cmd_find(update, context)
    if lowered_text in {"createrandompmv", "/createrandompmv"}:
        return await cmd_randompmv(update, context)

    sess = user_sessions.get(user_id)
    if not sess:
        return await reply_long(
            "Ð¯ Ð²Ð°Ñ Ð½Ðµ Ð¿Ð¾Ð½ÑÐ». Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ /pmvnew Ð´Ð»Ñ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ PMV Ð¸Ð»Ð¸ /scan Ð´Ð»Ñ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð²."
        )

    state = sess.get("state")

    if state == "scanignore_wait_path":
        candidate = text.strip().strip('"')
        if not candidate:
            return await reply_long("ÐŸÑ€Ð¸ÑˆÐ»Ð¸Ñ‚Ðµ Ð¿ÑƒÑ‚ÑŒ Ðº Ð¿Ð°Ð¿ÐºÐµ, Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€ X:\\\\tor\\\\tmp.")
        try:
            raw_path = Path(candidate)
            if not raw_path.is_absolute():
                raw_path = (SCRIPT_DIR / raw_path).resolve(strict=False)
            else:
                raw_path = raw_path.resolve(strict=False)
        except Exception as exc:
            return await reply_long(f"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ñ€Ð°Ð·Ð¾Ð±Ñ€Ð°Ñ‚ÑŒ Ð¿ÑƒÑ‚ÑŒ: {exc}")

        db_add_scan_ignore(str(raw_path))
        user_sessions.pop(user_id, None)

        note = ""
        if not raw_path.exists():
            note = "\nâš ï¸ ÐŸÐ°Ð¿ÐºÐ° Ð¿Ð¾ÐºÐ° Ð½Ðµ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚, Ð½Ð¾ Ð±ÑƒÐ´ÐµÑ‚ Ð¸Ð³Ð½Ð¾Ñ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒÑÑ, ÐºÐ¾Ð³Ð´Ð° Ð¿Ð¾ÑÐ²Ð¸Ñ‚ÑÑ."
        return await reply_long(f"Ð“Ð¾Ñ‚Ð¾Ð²Ð¾. {raw_path} Ð±Ð¾Ð»ÑŒÑˆÐµ Ð½Ðµ ÑÐºÐ°Ð½Ð¸Ñ€ÑƒÐµÑ‚ÑÑ.{note}")

    if state in {
        "musicprep_wait_track",
        "musicprep_wait_seconds",
        "musicprep_wait_mode",
        "musicprep_wait_sensitivity",
        "newcompmusic_wait_project",
        "newcompmusic_wait_group",
        "newcompmusic_choose_duration",
        "newcompmusic_choose_groupmode",
        "newcompmusic_choose_color",
        "newcompmusic_wait_sources",
        "newcompmusic_wait_algo",
        "musicprepcheck_wait_project",
        "musicprep_ask_sensitivity",
    }:
        return await reply_long("Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ ÐºÐ½Ð¾Ð¿ÐºÐ¸ Ð¿Ð¾Ð´ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸ÐµÐ¼ Ð¸Ð»Ð¸ Ð·Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ðµ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñƒ Ð·Ð°Ð½Ð¾Ð²Ð¾.")

    if state == "randompmv_wait_count":
        sess = sess or {}
        try:
            total_runs = int(text)
        except ValueError:
            return await reply_long("ÐÑƒÐ¶Ð½Ð¾ ÑƒÐºÐ°Ð·Ð°Ñ‚ÑŒ Ñ†ÐµÐ»Ð¾Ðµ Ñ‡Ð¸ÑÐ»Ð¾ Ð¾Ñ‚ 1 Ð´Ð¾ 30.")
        if total_runs < RANDOMPMV_MIN_BATCH:
            return await reply_long("ÐÑƒÐ¶Ð½Ð¾ ÑƒÐºÐ°Ð·Ð°Ñ‚ÑŒ Ð¿Ð¾Ð»Ð¾Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ðµ Ñ‡Ð¸ÑÐ»Ð¾.")
        total_runs = min(total_runs, RANDOMPMV_MAX_BATCH)
        sess["randompmv_total_runs"] = total_runs
        sess["state"] = "randompmv_wait_newcount"
        user_sessions[user_id] = sess
        await update.message.reply_text(
            "Ð¡ÐºÐ¾Ð»ÑŒÐºÐ¾ Ð½Ð¾Ð²Ñ‹Ñ… Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð´Ð¾Ð»Ð¶Ð½Ð¾ Ð±Ñ‹Ñ‚ÑŒ Ð² PMV?",
            reply_markup=build_randompmv_newcount_keyboard(),
        )
        return

    if state == "randompmv_wait_newcount":
        sess = sess or {}
        try:
            min_new = int(text)
        except ValueError:
            return await reply_long("Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ñ†ÐµÐ»Ð¾Ðµ Ñ‡Ð¸ÑÐ»Ð¾ Ð½Ð¾Ð²Ñ‹Ñ… Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² (0 Ð´Ð¾Ð¿ÑƒÑÐºÐ°ÐµÑ‚ÑÑ).")
        if min_new < 0:
            return await reply_long("Ð§Ð¸ÑÐ»Ð¾ Ð½Ð¾Ð²Ñ‹Ñ… Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² Ð½Ðµ Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ Ð¾Ñ‚Ñ€Ð¸Ñ†Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¼.")
        total_runs = int(sess.get("randompmv_total_runs") or 0)
        if total_runs <= 0:
            user_sessions.pop(user_id, None)
            return await reply_long("Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð²Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¹ Ñ‡ÐµÑ€ÐµÐ· CreateRandomPMV.")
        user_sessions.pop(user_id, None)
        await update.message.reply_text(
            f"Ð—Ð°Ð¿ÑƒÑÐºÐ°ÑŽ {total_runs} Random PMV (Ð½Ð¾Ð²Ñ‹Ñ… â‰¥ {min_new})..."
        )
        return await run_randompmv_batch(reply_long, user_id, total_runs, min_new)


    if state in {"find_wait_term", "find_wait_choice"}:
        term = text.strip()
        if not term:
            return await reply_long("ÐŸÑ€Ð¸ÑˆÐ»Ð¸Ñ‚Ðµ Ñ‡Ð°ÑÑ‚ÑŒ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ñ Ñ„Ð°Ð¹Ð»Ð°, Ð¿Ñ€Ð¸Ð¼ÐµÑ€: 20251207 Ð¸Ð»Ð¸ 0734.")
        matches = _search_find_matches(term)
        sess["find_matches"] = matches
        if not matches:
            sess["state"] = "find_wait_term"
            return await reply_long("ÐÐµ Ð½Ð°ÑˆÐ»Ð° PMV Ð¿Ð¾ ÑÑ‚Ð¾Ð¼Ñƒ Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ñƒ. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð´Ñ€ÑƒÐ³ÑƒÑŽ Ñ‡Ð°ÑÑ‚ÑŒ Ð¸Ð¼ÐµÐ½Ð¸.")
        sess["state"] = "find_wait_choice"
        pmv_count = sum(1 for m in matches if m.get("type") == "pmv")
        src_count = sum(1 for m in matches if m.get("type") == "source")
        lines = ["ÐÐ°ÑˆÐ»Ð¸ÑÑŒ ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ñ. Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð½ÑƒÐ¶Ð½Ñ‹Ð¹ Ñ„Ð°Ð¹Ð» ÐºÐ½Ð¾Ð¿ÐºÐ¾Ð¹ Ð½Ð¸Ð¶Ðµ."]
        lines.append(f"PMV: {pmv_count} Â· Ð˜ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¸: {src_count}")
        for idx, match in enumerate(matches, 1):
            if match.get("type") == "pmv":
                lines.append(f"{idx}. PMV Â· {match.get('stem')}")
            else:
                color = extract_color_emoji(match.get("comments"))
                prefix = f"{color} " if color else ""
                lines.append(f"{idx}. {prefix}{match.get('video_name')}")
        await update.message.reply_text(
            "\n".join(lines),
            reply_markup=build_find_keyboard(matches),
        )
        return

    # =========================
    # NEWCOMPMUSIC: Ð²Ñ‹Ð±Ð¾Ñ€ Ð¼ÑƒÐ·Ñ‹ÐºÐ°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°
    # =========================
    if state == "newcompmusic_choose_project":
        if not text.isdigit():
            return await reply_long("ÐÑƒÐ¶Ð½Ð¾ Ð¿Ñ€Ð¸ÑÐ»Ð°Ñ‚ÑŒ Ð½Ð¾Ð¼ÐµÑ€ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð° (Ñ†ÐµÐ»Ð¾Ðµ Ñ‡Ð¸ÑÐ»Ð¾).")
        idx = int(text)
        projects: List[Dict[str, Any]] = sess.get("music_projects") or []
        if not (1 <= idx <= len(projects)):
            return await reply_long("ÐÐµÑ‚ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð° Ñ Ñ‚Ð°ÐºÐ¸Ð¼ Ð½Ð¾Ð¼ÐµÑ€Ð¾Ð¼. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ ÑÐ½Ð¾Ð²Ð°.")
        chosen = projects[idx - 1]
        manifest_data = chosen.get("manifest_data")
        if not manifest_data and chosen.get("manifest_path") and chosen["manifest_path"].exists():
            try:
                manifest_data = json.loads(chosen["manifest_path"].read_text(encoding="utf-8"))
                chosen["manifest_data"] = manifest_data
            except Exception as exc:
                return await reply_long(f"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ñ€Ð¾Ñ‡Ð¸Ñ‚Ð°Ñ‚ÑŒ manifest.json: {exc}")
        parsed_segments = parse_manifest_segments(manifest_data or {})
        total_duration = chosen.get("duration")
        if total_duration is None and parsed_segments:
            total_duration = parsed_segments[-1].end
        seg_count = len(parsed_segments)
        minutes = (total_duration or 0.0) / 60.0 if total_duration else None

        groups = get_source_groups_prefer_unused()
        if not groups:
            return await reply_long("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð½Ð°Ð¹Ñ‚Ð¸ Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð². Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð¿Ñ€Ð¾ÑÐºÐ°Ð½Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ /scan.")

        sess["state"] = "newcompmusic_choose_orientation"
        sess["music_selected"] = {
            "slug": chosen["slug"],
            "name": chosen["name"],
            "duration": total_duration,
            "segments": seg_count,
            "manifest": manifest_data,
            "audio_path": str(chosen.get("audio_path")) if chosen.get("audio_path") else None,
            "parsed_segments": parsed_segments,
        }
        lines = [
            f"Ð’Ñ‹Ð±Ñ€Ð°Ð½ Ð¿Ñ€Ð¾ÐµÐºÑ‚: {chosen['name']} (slug: {chosen['slug']}).",
            f"Ð¡Ð¼ÐµÐ½ ÐºÐ»Ð¸Ð¿Ð¾Ð²: {seg_count}",
        ]
        if minutes:
            lines.append(f"ÐŸÑ€Ð¾Ð´Ð¾Ð»Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ â‰ˆ {minutes:.1f} Ð¼Ð¸Ð½ÑƒÑ‚.")
        group_entries = [
            SourceGroupEntry(key=key, rows=list(rows), unused_count=unused_count)
            for key, rows, unused_count in groups
        ]
        sorted_entries, orientation_map = sort_group_entries_with_orientation(group_entries)
        sess["music_group_orientations"] = orientation_map
        sess["music_groups_all"] = [
            (entry.key, entry.rows, entry.unused_count) for entry in sorted_entries
        ]
        sess["music_groups"] = []
        sess["music_orientation_preference"] = None
        lines.append("")
        lines.append("Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¾Ñ€Ð¸ÐµÐ½Ñ‚Ð°Ñ†Ð¸ÑŽ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð²: VR, HOR Ð¸Ð»Ð¸ VER.")
        lines.append("ÐŸÑ€Ð¸ÑˆÐ»Ð¸Ñ‚Ðµ Ð¾Ð´Ð½Ð¾ Ð¸Ð· ÑÑ‚Ð¸Ñ… Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ð¹ Ð¸Ð»Ð¸ Ð½Ð°Ð¶Ð¼Ð¸Ñ‚Ðµ ÐºÐ½Ð¾Ð¿ÐºÑƒ Ð½Ð¸Ð¶Ðµ.")
        return await reply_long(
            "\n".join(lines),
            reply_markup=build_newcomp_orientation_keyboard(),
        )

    if state == "newcompmusic_choose_orientation":
        choice = text.strip().upper()
        if choice == "BACK":
            return await reply_long("Ð’Ñ‹Ð±Ð¾Ñ€ ÑÐ±Ñ€Ð¾ÑˆÐµÐ½. Ð£ÐºÐ°Ð¶Ð¸Ñ‚Ðµ Ð¾Ñ€Ð¸ÐµÐ½Ñ‚Ð°Ñ†Ð¸ÑŽ: VR, HOR Ð¸Ð»Ð¸ VER.")
        if choice not in NEWCOMPMUSIC_ORIENTATION_CHOICES:
            return await reply_long("Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ VR, HOR Ð¸Ð»Ð¸ VER.")
        all_groups = sess.get("music_groups_all") or []
        if not all_groups:
            return await reply_long("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð½Ð°Ð¹Ñ‚Ð¸ Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹. Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ðµ /newcompmusic Ð·Ð°Ð½Ð¾Ð²Ð¾.")
        orientation_map = sess.get("music_group_orientations") or {}
        filtered = filter_groups_by_orientation(all_groups, orientation_map, choice)
        if not filtered:
            return await reply_long("ÐÐµÑ‚ Ð³Ñ€ÑƒÐ¿Ð¿ Ñ Ñ‚Ð°ÐºÐ¾Ð¹ Ð¾Ñ€Ð¸ÐµÐ½Ñ‚Ð°Ñ†Ð¸ÐµÐ¹. Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð´Ñ€ÑƒÐ³Ð¾Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼.")
        sess["music_orientation_preference"] = choice
        sess["music_groups"] = filtered
        sess["state"] = "newcompmusic_choose_group"
        group_entries = [
            SourceGroupEntry(key=key, rows=list(rows), unused_count=unused)
            for key, rows, unused in filtered
        ]
        orientation_map = sess.get("music_group_orientations") or {}

        lines = _build_group_selection_lines(
            sess, group_entries, choice, prompt_kind="text"
        )
        return await reply_long("\n".join(lines))

    if state == "newcompmusic_choose_group":
        if not text.isdigit():
            return await reply_long("ÐÑƒÐ¶Ð½Ð¾ Ð¿Ñ€Ð¸ÑÐ»Ð°Ñ‚ÑŒ Ð½Ð¾Ð¼ÐµÑ€ Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹.")
        idx = int(text)
        groups: List[Tuple[Tuple[str, str], List[sqlite3.Row], int]] = sess.get("music_groups") or []
        if not (1 <= idx <= len(groups)):
            return await reply_long("ÐÐµÑ‚ Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹ Ñ Ñ‚Ð°ÐºÐ¸Ð¼ Ð½Ð¾Ð¼ÐµÑ€Ð¾Ð¼.")
        key, rows, unused_count = groups[idx - 1]
        if not rows:
            return await reply_long("Ð’ Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð½Ð¾Ð¹ Ð³Ñ€ÑƒÐ¿Ð¿Ðµ Ð½ÐµÑ‚ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð². Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð´Ñ€ÑƒÐ³ÑƒÑŽ.")

        orientation_label = (sess.get("music_group_orientations") or {}).get(key)
        if not orientation_label:
            orientation_label = _resolution_orientation(key[1] or "")[0]
        sess["music_group_choice"] = {
            "key": key,
            "count": len(rows),
            "orientation": orientation_label,
            "total_count": len(rows),
            "unused_count": unused_count,
            "group_number": idx,
        }
        sess["music_group_rows"] = list(rows)
        sess["music_folder_only_new"] = False
        sess.pop("music_color_rows", None)
        sess["state"] = "newcompmusic_choose_groupmode"
        summary = [
            f"Ð“Ñ€ÑƒÐ¿Ð¿Ð° {idx} Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð°: {key[0]} {key[1]} (Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð²: {len(rows)}).",
            "ÐšÐ°Ðº Ð±ÑƒÐ´ÐµÐ¼ Ð³Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¸?",
        ]
        await reply_long("\n".join(summary))
        return await update.message.reply_text(
            "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚:",
            reply_markup=build_newcomp_groupmode_keyboard(),
        )

    if state == "newcompmusic_wait_folder":
        options: List[Dict[str, Any]] = sess.get("music_folder_options") or []
        if not text.isdigit():
            return await reply_long("Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¿Ð¾Ð´Ð¿Ð°Ð¿ÐºÑƒ ÐºÐ½Ð¾Ð¿ÐºÐ°Ð¼Ð¸ Ð¿Ð¾Ð´ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸ÐµÐ¼ Ð¸Ð»Ð¸ Ð¿Ñ€Ð¸ÑˆÐ»Ð¸Ñ‚Ðµ ÐµÑ‘ Ð½Ð¾Ð¼ÐµÑ€.")
        idx = int(text)
        if not (1 <= idx <= len(options)):
            return await reply_long("ÐÐµÑ‚ Ð¿Ð°Ð¿ÐºÐ¸ Ñ Ñ‚Ð°ÐºÐ¸Ð¼ Ð½Ð¾Ð¼ÐµÑ€Ð¾Ð¼. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ ÑÐ½Ð¾Ð²Ð°.")
        token = options[idx - 1]["token"]
        try:
            count, label = apply_newcomp_folder_choice(sess, token, next_state="newcompmusic_ask_sources")
        except ValueError as exc:
            return await reply_long(str(exc))
        project_info = sess.get("music_selected") or {}
        codec, res = sess.get("music_group_choice", {}).get("key") or ("?", "?")
        lines = [
            f"ÐŸÐ°Ð¿ÐºÐ° Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð°: {label} (Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð²: {count}).",
            f"Ð“Ñ€ÑƒÐ¿Ð¿Ð°: {codec} {res}.",
            "Ð¡ÐºÐ¾Ð»ÑŒÐºÐ¾ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² Ð·Ð°Ð´ÐµÐ¹ÑÑ‚Ð²Ð¾Ð²Ð°Ñ‚ÑŒ? ÐŸÑ€Ð¸ÑˆÐ»Ð¸Ñ‚Ðµ Ñ†ÐµÐ»Ð¾Ðµ Ñ‡Ð¸ÑÐ»Ð¾ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€: 6).",
        ]
        return await reply_long("\n".join(lines))

    if state == "newcompmusic_ask_sources":
        try:
            sources_count = int(text)
            if sources_count <= 0:
                raise ValueError
        except ValueError:
            return await reply_long("ÐÑƒÐ¶Ð½Ð¾ ÑƒÐºÐ°Ð·Ð°Ñ‚ÑŒ Ð¿Ð¾Ð»Ð¾Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ðµ Ñ‡Ð¸ÑÐ»Ð¾ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð².")
        available = int((sess.get("music_group_choice") or {}).get("count") or 0)
        info_line = None
        if available and sources_count > available:
            sources_count = available
            info_line = _source_limit_message(sess, available)

        sess["music_sources"] = sources_count
        sess["state"] = "newcompmusic_ask_algo"

        algo_parts = [
            f"{key} ({meta['title']})"
            for key, meta in CLIP_SEQUENCE_ALGORITHMS.items()
        ]
        base_line = f"ÐžÐº, Ð²Ð¾Ð·ÑŒÐ¼Ñ‘Ð¼ {sources_count} Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð²."
        if info_line:
            base_line = f"{info_line}\n{base_line}"
        msg = (
            f"ÃÂ“Ã‘Â€Ã‘ÂƒÃÂ¿ÃÂ¿ÃÂ° {key[0]} {key[1]} ÃÂ²Ã‘Â‹ÃÂ±Ã‘Â€ÃÂ°ÃÂ½ÃÂ°. "
            "ÃÂÃÂ¾ÃÂ²Ã‘Â‹Ã‘Â… ÃÂ¸Ã‘ÂÃ‘Â…ÃÂ¾ÃÂ´ÃÂ½ÃÂ¸ÃÂºÃÂ¾ÃÂ² ÃÂ½ÃÂµÃ‘Â‚, ÃÂ²Ã‘Â‹ÃÂ±ÃÂµÃ‘Â€ÃÂ¸Ã‘Â‚ÃÂµ Ã‘Â†ÃÂ²ÃÂµÃ‘Â‚ ÃÂ´ÃÂ»Ã‘Â ÃÂ¿ÃÂµÃ‘Â€ÃÂµÃÂ¾Ã‘Â†ÃÂµÃÂ½ÃÂºÃÂ¸:"
        )
        await update.message.reply_text(
            msg, reply_markup=build_rategrp_rerate_keyboard(available)
        )
        return
        sess["rategrp_queue"] = queue
        sess["rategrp_total"] = len(queue)
        sess["rategrp_processed"] = 0
        sess["rategrp_queue_origin"] = "unrated"
        sess["state"] = "rategrp_rate_source"

        async def send_rategrp(msg: str, markup: Optional[InlineKeyboardMarkup] = None) -> None:
            await update.message.reply_text(msg, reply_markup=markup)

        await send_rategrp(f"Ð“Ñ€ÑƒÐ¿Ð¿Ð° {key[0]} {key[1]} Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð°. ÐÐµÐ¾Ñ†ÐµÐ½Ñ‘Ð½Ð½Ñ‹Ñ… Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð²: {len(queue)}.")
        return await rategrp_send_next_prompt(sess, send_rategrp)

    if state == "rategrp_choose_rerate_color":
        color_key = normalize_rategrp_color_input(text)

        async def send_rategrp(msg: str, markup: Optional[InlineKeyboardMarkup] = None) -> None:
            await update.message.reply_text(msg, reply_markup=markup)

        if not color_key:
            rows = sess.get("rategrp_rerate_rows") or []
            available = _rategrp_available_colors(rows)
            if available:
                await send_rategrp(
                    "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ñ†Ð²ÐµÑ‚ Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ ÐºÐ½Ð¾Ð¿Ð¾Ðº Ð½Ð¸Ð¶Ðµ.",
                    build_rategrp_rerate_keyboard(available),
                )
            else:
                await reply_long("ÐÐµÑ‚ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² Ð´Ð»Ñ Ð¿ÐµÑ€ÐµÐ¾Ñ†ÐµÐ½ÐºÐ¸. Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð´Ñ€ÑƒÐ³ÑƒÑŽ Ð³Ñ€ÑƒÐ¿Ð¿Ñƒ.")
            return
        if await _rategrp_start_rerate(sess, color_key, send_rategrp):
            return
        return

    if state == "rategrp_rate_source":
        color_key = normalize_rategrp_color_input(text)
        if not color_key:
            return await reply_long(f"Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ ÐºÐ½Ð¾Ð¿ÐºÐ¸ {RATEGRP_COLOR_PROMPT} Ð¸Ð»Ð¸ Ð¿Ñ€Ð¸ÑˆÐ»Ð¸Ñ‚Ðµ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ Ñ†Ð²ÐµÑ‚Ð°.")

        async def send_rategrp(msg: str, markup: Optional[InlineKeyboardMarkup] = None) -> None:
            await update.message.reply_text(msg, reply_markup=markup)

        return await rategrp_apply_rating(sess, color_key, send_rategrp)
    # ====== MUSICPREP: Ð²Ñ‹Ð±Ð¾Ñ€ Ñ‚Ñ€ÐµÐºÐ° Ð¸ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð² ======
    if state == "musicprep_choose_file":
        if not text.isdigit():
            return await reply_long("ÐÑƒÐ¶Ð½Ð¾ Ð¿Ñ€Ð¸ÑÐ»Ð°Ñ‚ÑŒ Ð½Ð¾Ð¼ÐµÑ€ Ñ‚Ñ€ÐµÐºÐ°.")
        files = sess.get("music_files") or []
        idx = int(text)
        if not (1 <= idx <= len(files)):
            return await reply_long("ÐÐµÑ‚ Ñ‚Ñ€ÐµÐºÐ° Ñ Ñ‚Ð°ÐºÐ¸Ð¼ Ð½Ð¾Ð¼ÐµÑ€Ð¾Ð¼.")
        sess["musicprep_file"] = files[idx - 1]
        sess["state"] = "musicprep_ask_name"
        return await reply_long("Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð¸Ð¼Ñ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð° (Ð¸Ð»Ð¸ Ð¾ÑÑ‚Ð°Ð²ÑŒÑ‚Ðµ Ð¿ÑƒÑÑ‚Ñ‹Ð¼).")

    if state == "musicprep_ask_name":
        sess["musicprep_name"] = text.strip() or None
        sess["state"] = "musicprep_ask_segment"
        mod = load_music_generator_module()
        default_seg = getattr(mod, "DEFAULT_TARGET_SEGMENT", 1.0)
        return await reply_long(
            f"Ð£ÐºÐ°Ð¶Ð¸Ñ‚Ðµ Ð¼Ð¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½ÑƒÑŽ Ð´Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ð° Ð² ÑÐµÐºÑƒÐ½Ð´Ð°Ñ… "
            f"(Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ {default_seg})."
        )

    if state == "musicprep_ask_segment":
        mod = load_music_generator_module()
        default_seg = getattr(mod, "DEFAULT_TARGET_SEGMENT", 1.0)
        try:
            segment_len = float(text)
            if segment_len < 0:
                raise ValueError
        except ValueError:
            segment_len = default_seg
        sess["musicprep_segment"] = segment_len
        sess["state"] = "musicprep_ask_mode"
        modes = getattr(mod, "SEGMENT_MODES", ("beat",))
        return await reply_long(
            "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼ ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸ Ð¿Ð¾ Ð¼ÑƒÐ·Ñ‹ÐºÐµ "
            f"(Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹: {', '.join(modes)})."
        )

    if state == "musicprep_ask_mode":
        mod = load_music_generator_module()
        modes = getattr(mod, "SEGMENT_MODES", ("beat",))
        mode = text.strip().lower() or getattr(mod, "DEFAULT_SEGMENT_MODE", modes[0])
        if mode not in modes:
            return await reply_long("ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼. ÐŸÐ¾Ð²Ñ‚Ð¾Ñ€Ð¸Ñ‚Ðµ Ð²Ð²Ð¾Ð´.")
        sess["musicprep_selected_mode"] = mode
        options = get_musicprep_sensitivity_options(mode)
        if options:
            sess["musicprep_sensitivity_options"] = options
            sess["state"] = "musicprep_ask_sensitivity"
            lines = [
                f"ÐÐ»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼ {mode} Ð²Ñ‹Ð±Ñ€Ð°Ð½.",
                "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ñ‡ÑƒÐ²ÑÑ‚Ð²Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°:",
            ]
            for idx, opt in enumerate(options, 1):
                lines.append(f"{idx}. {opt['label']} â€” {opt['description']}")
            lines.append("ÐŸÑ€Ð¸ÑˆÐ»Ð¸Ñ‚Ðµ Ð½Ð¾Ð¼ÐµÑ€ Ð¸Ð»Ð¸ ÐºÐ»ÑŽÑ‡ÐµÐ²Ð¾Ðµ ÑÐ»Ð¾Ð²Ð¾.")
            return await reply_long("\n".join(lines))

        async def send(msg: str) -> None:
            await reply_long(msg)

        return await finalize_musicprep_project(send, sess, user_id, mode)

    if state == "musicprep_ask_sensitivity":
        options: List[Dict[str, Any]] = sess.get("musicprep_sensitivity_options") or []
        mode = sess.get("musicprep_selected_mode") or "beat"
        if not options:
            sess["state"] = "musicprep_ask_mode"
            return await reply_long("ÐŸÐ¾Ð²Ñ‚Ð¾Ñ€Ð¸Ñ‚Ðµ Ð²Ñ‹Ð±Ð¾Ñ€ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ð° ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸.")

        choice = text.strip().lower()
        selected: Optional[Dict[str, Any]] = None
        if choice.isdigit():
            idx = int(choice) - 1
            if 0 <= idx < len(options):
                selected = options[idx]
        if not selected:
            for opt in options:
                if choice in {opt["key"].lower(), opt["label"].lower()}:
                    selected = opt
                    break
        if not selected:
            return await reply_long("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ñ‚ÑŒ Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚. ÐŸÑ€Ð¸ÑˆÐ»Ð¸Ñ‚Ðµ Ð½Ð¾Ð¼ÐµÑ€ Ð¸Ð· ÑÐ¿Ð¸ÑÐºÐ°.")

        analysis_kwargs = selected.get("analysis_kwargs") or {}

        async def send(msg: str) -> None:
            await reply_long(msg)

        return await finalize_musicprep_project(send, sess, user_id, mode, analysis_kwargs)

    # ====== MUSICPREP: Ð²Ñ‹Ð±Ð¾Ñ€ Ñ‚Ñ€ÐµÐºÐ° Ð¸ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð² ======
    if state == "musicprep_choose_file":
        if not text.isdigit():
            return await reply_long("ÐÑƒÐ¶Ð½Ð¾ Ð¿Ñ€Ð¸ÑÐ»Ð°Ñ‚ÑŒ Ð½Ð¾Ð¼ÐµÑ€ Ñ‚Ñ€ÐµÐºÐ°.")
        files = sess.get("music_files") or []
        idx = int(text)
        if not (1 <= idx <= len(files)):
            return await reply_long("ÐÐµÑ‚ Ñ‚Ñ€ÐµÐºÐ° Ñ Ñ‚Ð°ÐºÐ¸Ð¼ Ð½Ð¾Ð¼ÐµÑ€Ð¾Ð¼.")
        sess["musicprep_file"] = files[idx - 1]
        sess["state"] = "musicprep_ask_name"
        return await reply_long("Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð¸Ð¼Ñ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð° (Ð¸Ð»Ð¸ Ð¾ÑÑ‚Ð°Ð²ÑŒÑ‚Ðµ Ð¿ÑƒÑÑ‚Ñ‹Ð¼).")

    if state == "musicprep_ask_name":
        sess["musicprep_name"] = text.strip() or None
        sess["state"] = "musicprep_ask_segment"
        mod = load_music_generator_module()
        default_seg = getattr(mod, "DEFAULT_TARGET_SEGMENT", 1.0)
        return await reply_long(
            f"Ð£ÐºÐ°Ð¶Ð¸Ñ‚Ðµ Ð¼Ð¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½ÑƒÑŽ Ð´Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ð° Ð² ÑÐµÐºÑƒÐ½Ð´Ð°Ñ… "
            f"(Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ {default_seg})."
        )

    if state == "musicprep_ask_segment":
        mod = load_music_generator_module()
        default_seg = getattr(mod, "DEFAULT_TARGET_SEGMENT", 1.0)
        try:
            segment_len = float(text)
            if segment_len < 0:
                raise ValueError
        except ValueError:
            segment_len = default_seg
        sess["musicprep_segment"] = segment_len
        sess["state"] = "musicprep_ask_mode"
        modes = getattr(mod, "SEGMENT_MODES", ("beat",))
        return await reply_long(
            "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼ ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸ Ð¿Ð¾ Ð¼ÑƒÐ·Ñ‹ÐºÐµ "
            f"(Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹: {', '.join(modes)})."
        )

    if state == "musicprep_ask_mode":
        mod = load_music_generator_module()
        modes = getattr(mod, "SEGMENT_MODES", ("beat",))
        mode = text.strip().lower() or getattr(mod, "DEFAULT_SEGMENT_MODE", modes[0])
        if mode not in modes:
            return await reply_long("ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼. ÐŸÐ¾Ð²Ñ‚Ð¾Ñ€Ð¸Ñ‚Ðµ Ð²Ð²Ð¾Ð´.")
        sess["musicprep_selected_mode"] = mode
        options = get_musicprep_sensitivity_options(mode)
        if options:
            sess["musicprep_sensitivity_options"] = options
            sess["state"] = "musicprep_ask_sensitivity"
            lines = [
                f"ÐÐ»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼ {mode} Ð²Ñ‹Ð±Ñ€Ð°Ð½.",
                "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ñ‡ÑƒÐ²ÑÑ‚Ð²Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°:",
            ]
            for idx, opt in enumerate(options, 1):
                lines.append(f"{idx}. {opt['label']} â€” {opt['description']}")
            lines.append("ÐŸÑ€Ð¸ÑˆÐ»Ð¸Ñ‚Ðµ Ð½Ð¾Ð¼ÐµÑ€ Ð¸Ð»Ð¸ ÐºÐ»ÑŽÑ‡ÐµÐ²Ð¾Ðµ ÑÐ»Ð¾Ð²Ð¾.")
            return await reply_long("\n".join(lines))

        async def send(msg: str) -> None:
            await reply_long(msg)

        return await finalize_musicprep_project(send, sess, user_id, mode)

    # =========================
    # AUTOCREATE: Ð´Ð¸Ð°Ð»Ð¾Ð³
    # =========================

    # Ð¨Ð°Ð³ 1: ÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð²Ð¸Ð´ÐµÐ¾ ÑÐ¾Ð·Ð´Ð°Ñ‚ÑŒ
    if state == "autocreate_ask_count":
        try:
            count = int(text)
            if count <= 0:
                raise ValueError
        except ValueError:
            return await reply_long("ÐÑƒÐ¶Ð½Ð¾ Ð¿Ð¾Ð»Ð¾Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ðµ Ñ†ÐµÐ»Ð¾Ðµ Ñ‡Ð¸ÑÐ»Ð¾ â€” ÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð²Ð¸Ð´ÐµÐ¾ ÑÐ¾Ð·Ð´Ð°Ñ‚ÑŒ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€: 4).")

        sess["autocreate_total_videos"] = count
        sess["state"] = "autocreate_ask_length"

        return await reply_long(
            f"ÐžÐº, ÑÐ¾Ð·Ð´Ð°Ñ‘Ð¼ Ð´Ð¾ {count} Ð²Ð¸Ð´ÐµÐ¾.\n"
            "Ð¢ÐµÐ¿ÐµÑ€ÑŒ Ð²Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð´Ð»Ð¸Ð½Ñƒ ÐšÐÐ–Ð”ÐžÐ“Ðž Ð²Ð¸Ð´ÐµÐ¾ Ð² Ð¼Ð¸Ð½ÑƒÑ‚Ð°Ñ… (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€: 15)."
        )

    # Ð¨Ð°Ð³ 2: Ð´Ð»Ð¸Ð½Ð° ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ Ð²Ð¸Ð´ÐµÐ¾
    if state == "autocreate_ask_length":
        try:
            minutes = int(text)
            if minutes <= 0:
                raise ValueError
        except ValueError:
            minutes = DEFAULT_TARGET_MINUTES

        sess["autocreate_minutes"] = minutes
        sess["state"] = "autocreate_ask_max_sources"

        return await reply_long(
            f"Ð–ÐµÐ»Ð°ÐµÐ¼Ð°Ñ Ð´Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ PMV Ð¾ÐºÐ¾Ð»Ð¾ {minutes} Ð¼Ð¸Ð½ÑƒÑ‚.\n"
            "Ð¢ÐµÐ¿ÐµÑ€ÑŒ Ð²Ð²ÐµÐ´Ð¸Ñ‚Ðµ ÐœÐÐšÐ¡Ð˜ÐœÐÐ›Ð¬ÐÐžÐ• ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² Ð½Ð° Ð¾Ð´Ð½Ð¾ Ð²Ð¸Ð´ÐµÐ¾ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€: 10)."
        )

    if state == "autocreate_ask_max_sources":
        try:
            max_sources = int(text)
            if max_sources <= 0:
                raise ValueError
        except ValueError:
            max_sources = 10

        min_sources = max_sources
        total_videos = sess.get("autocreate_total_videos", 1)
        minutes = sess.get("autocreate_minutes", DEFAULT_TARGET_MINUTES)

        user_sessions.pop(user_id, None)

        await reply_long(
            f"Ð—Ð°Ð¿ÑƒÑÐºÐ°ÑŽ Ð¿Ð°ÐºÐµÑ‚Ð½ÑƒÑŽ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸ÑŽ Ð¸Ð· {total_videos} PMV.\n"
            f"Ð”Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾: ~{minutes} Ð¼Ð¸Ð½ÑƒÑ‚.\n"
            f"Ð˜ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² Ð½Ð° Ð¾Ð´Ð½Ð¾ Ð²Ð¸Ð´ÐµÐ¾: Ð¼Ð¸Ð½Ð¸Ð¼ÑƒÐ¼ {min_sources}, Ð¼Ð°ÐºÑÐ¸Ð¼ÑƒÐ¼ {max_sources}.\n"
            "ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÑŽ ÑÐ¾Ð±Ñ€Ð°Ñ‚ÑŒ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾ Ñ€Ð°Ð·Ð½Ð¾Ð¾Ð±Ñ€Ð°Ð·Ð½Ñ‹Ðµ (ÐºÐ°Ðº Ð¿Ð¾ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¼ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ°Ð¼) Ñ€Ð¾Ð»Ð¸ÐºÐ¸, "
            "Ð½Ð°ÑÐºÐ¾Ð»ÑŒÐºÐ¾ ÑÑ‚Ð¾ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑÑ. ÐÑƒ Ñ‡Ñ‚Ð¾, Ð¿Ð¾ÐµÑ…Ð°Ð»Ð¸..."
        )

        try:
            report = autocreate_pmv_batch(
                total_videos=total_videos,
                minutes_each=minutes,
                max_sources=max_sources,
                min_sources=min_sources,
            )
        except Exception as e:
            return await reply_long(f"ÐžÐ¹, Ð¿Ñ€Ð¾Ð¸Ð·Ð¾ÑˆÐ»Ð° Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð²Ð¾ Ð²Ñ€ÐµÐ¼Ñ Ð¿Ð°ÐºÐµÑ‚Ð½Ð¾Ð¹ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ PMV: {e}")

        return await reply_long(report)

    # =========================
    # Ð”ÐÐ›Ð¬Ð¨Ð• â€” Ð’Ð¡Ð¯ Ð¡Ð¢ÐÐ ÐÐ¯ Ð›ÐžÐ“Ð˜ÐšÐ
    # =========================

    # ====== Ð¨Ð°Ð³ 1: Ð²Ñ‹Ð±Ð¾Ñ€ Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹ ======
    if state == "choose_group":
        if not text.isdigit():
            return await reply_long("ÐÑƒÐ¶Ð½Ð¾ Ð¿Ñ€Ð¾ÑÑ‚Ð¾ Ñ‡Ð¸ÑÐ»Ð¾ â€” Ð½Ð¾Ð¼ÐµÑ€ Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹.")
        idx = int(text)
        groups: List[Tuple[Tuple[str, str], List[sqlite3.Row]]] = sess["groups"]
        if not (1 <= idx <= len(groups)):
            return await reply_long("ÐÐµÐ²ÐµÑ€Ð½Ñ‹Ð¹ Ð½Ð¾Ð¼ÐµÑ€ Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹.")
        key, rows = groups[idx - 1]
        codec, res = key

        sess["state"] = "choose_files"
        sess["current_group"] = key
        sess["current_rows"] = rows

        lines = [f"Ð’Ñ‹Ð±Ñ€Ð°Ð½Ð° Ð³Ñ€ÑƒÐ¿Ð¿Ð°: {codec} {res}. Ð¤Ð°Ð¹Ð»Ñ‹:"]
        for i, r in enumerate(rows, 1):
            lines.append(f"{i}. {Path(r['video_path']).name} (id={r['id']})")
        lines.append("")
        lines.append("ÐžÑ‚Ð²ÐµÑ‚ÑŒÑ‚Ðµ: 'all' Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð²Ð·ÑÑ‚ÑŒ Ð²ÑÐµ, Ð»Ð¸Ð±Ð¾ Ð½Ð¾Ð¼ÐµÑ€Ð° Ñ„Ð°Ð¹Ð»Ð¾Ð² Ñ‡ÐµÑ€ÐµÐ· Ð¿Ñ€Ð¾Ð±ÐµÐ» (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€: 1 3 5).")
        return await reply_long("\n".join(lines))

    # ====== Ð¨Ð°Ð³ 2: Ð²Ñ‹Ð±Ð¾Ñ€ Ñ„Ð°Ð¹Ð»Ð¾Ð² ======
    if state == "choose_files":
        rows: List[sqlite3.Row] = sess["current_rows"]

        if text.lower() in {"all", "Ð²ÑÐµ"}:
            selected_rows = rows
        else:
            parts = text.replace(",", " ").split()
            idxs = []
            for p in parts:
                if not p.isdigit():
                    continue
                v = int(p)
                if 1 <= v <= len(rows):
                    idxs.append(v - 1)
            if not idxs:
                return await reply_long(
                    "ÐÐµ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ð»Ð¾ÑÑŒ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ñ‚ÑŒ Ð½Ð¾Ð¼ÐµÑ€Ð°. ÐÐ°Ð¿Ð¸ÑˆÐ¸Ñ‚Ðµ 'all' Ð¸Ð»Ð¸ Ð½Ð¾Ð¼ÐµÑ€Ð° Ñ„Ð°Ð¹Ð»Ð¾Ð² Ñ‡ÐµÑ€ÐµÐ· Ð¿Ñ€Ð¾Ð±ÐµÐ»."
                )
            selected_rows = [rows[i] for i in idxs]

        if not selected_rows:
            return await reply_long("ÐŸÑƒÑÑ‚Ð¾Ð¹ Ð²Ñ‹Ð±Ð¾Ñ€. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ ÐµÑ‰Ñ‘ Ñ€Ð°Ð·.")

        sess["state"] = "choose_length"
        sess["selected_rows"] = selected_rows

        names = ", ".join(Path(r["video_path"]).name for r in selected_rows)
        msg = (
            f"Ð’Ñ‹Ð±Ñ€Ð°Ð½Ð¾ Ñ„Ð°Ð¹Ð»Ð¾Ð²: {len(selected_rows)}.\n"
            f"Ð˜Ð¼ÐµÐ½Ð°: {names}\n\n"
            "Ð¢ÐµÐ¿ÐµÑ€ÑŒ Ð²Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð¶ÐµÐ»Ð°ÐµÐ¼ÑƒÑŽ Ð´Ð»Ð¸Ð½Ñƒ Ð¸Ñ‚Ð¾Ð³Ð¾Ð²Ð¾Ð³Ð¾ PMV Ð² ÐœÐ˜ÐÐ£Ð¢ÐÐ¥ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€: 15)."
        )
        return await reply_long(msg)

    # ====== Ð¨Ð°Ð³ 3: Ð²Ñ‹Ð±Ð¾Ñ€ Ð´Ð»Ð¸Ð½Ñ‹ ======
    if state == "choose_length":
        try:
            minutes = int(text)
            if minutes <= 0:
                raise ValueError
        except ValueError:
            minutes = DEFAULT_TARGET_MINUTES

        sess["target_minutes"] = minutes
        sess["state"] = "choose_big_parts"

        return await reply_long(
            f"ÐžÐº, Ñ†ÐµÐ»ÐµÐ²Ð°Ñ Ð´Ð»Ð¸Ð½Ð° ~{minutes} Ð¼Ð¸Ð½ÑƒÑ‚.\n"
            "Ð¡ÐºÐ¾Ð»ÑŒÐºÐ¾ Ð‘ÐžÐ›Ð¬Ð¨Ð˜Ð¥ Ñ‡Ð°ÑÑ‚ÐµÐ¹ Ð½Ð° ÐºÐ°Ð¶Ð´Ñ‹Ð¹ Ñ„Ð°Ð¹Ð» (big_parts)? (Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ 5)"
        )

    # ====== Ð¨Ð°Ð³ 4: Ð²Ñ‹Ð±Ð¾Ñ€ big_parts ======
    if state == "choose_big_parts":
        try:
            big_parts = int(text)
            if big_parts <= 0:
                raise ValueError
        except ValueError:
            big_parts = 5

        sess["big_parts"] = big_parts
        sess["state"] = "choose_small_parts"

        return await reply_long(
            f"big_parts = {big_parts}\n"
            "Ð¡ÐºÐ¾Ð»ÑŒÐºÐ¾ ÐœÐÐ›Ð•ÐÐ¬ÐšÐ˜Ð¥ ÐºÐ»Ð¸Ð¿Ð¾Ð² Ð² ÐºÐ°Ð¶Ð´Ð¾Ð¹ Ð±Ð¾Ð»ÑŒÑˆÐ¾Ð¹ Ñ‡Ð°ÑÑ‚Ð¸ (small_per_big)? (Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ 5)"
        )

    # ====== Ð¨Ð°Ð³ 5: Ð²Ñ‹Ð±Ð¾Ñ€ small_per_big Ð¸ Ð·Ð°Ð¿ÑƒÑÐº Ð½Ð°Ñ€ÐµÐ·ÐºÐ¸ ======
    if state == "choose_small_parts":
        try:
            small_per_big = int(text)
            if small_per_big <= 0:
                raise ValueError
        except ValueError:
            small_per_big = 5

        minutes = sess["target_minutes"]
        selected_rows: List[sqlite3.Row] = sess["selected_rows"]
        big_parts = sess["big_parts"]

        target_seconds = minutes * 60

        await reply_long(
            f"ÐžÐº, Ð´ÐµÐ»Ð°ÐµÐ¼ PMV ~{minutes} Ð¼Ð¸Ð½ÑƒÑ‚.\n"
            f"big_parts = {big_parts}, small_per_big = {small_per_big}, Ñ„Ð°Ð¹Ð»Ð¾Ð²: {len(selected_rows)}.\n"
            "ÐÐ°Ñ‡Ð¸Ð½Ð°ÑŽ Ð½Ð°Ñ€ÐµÐ·ÐºÑƒ, Ð¿Ð¾Ð´Ð¾Ð¶Ð´Ð¸Ñ‚Ðµ..."
        )

        paths = [Path(r["video_path"]) for r in selected_rows]
        source_ids = [int(r["id"]) for r in selected_rows]

        user_sessions.pop(user_id, None)

        manual_algo_key = random.choice(list(CLIP_SEQUENCE_ALGORITHMS.keys()))
        manual_algo_key, manual_algo_meta = resolve_clip_algorithm(manual_algo_key)

        move_comment = ""
        try:
            out_path = make_pmv_from_files(
                paths,
                target_seconds,
                big_parts,
                small_per_big,
                clip_algo_key=manual_algo_key,
            )
            out_path, move_comment = move_output_to_network_storage(out_path)
        except Exception as e:
            return await reply_long(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ð¸ PMV: {e}")

        pmv_tag = Path(out_path).name
        db_insert_compilation(out_path, source_ids, comments=move_comment)
        db_update_sources_pmv_list(source_ids, pmv_tag)

        return await reply_long(
            f"âœ… Ð“Ð¾Ñ‚Ð¾Ð²Ð¾!\nÐ¤Ð°Ð¹Ð»: {out_path}\n"
            f"ÐÐ»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼ ÐºÐ»Ð¸Ð¿Ð¾Ð²: {manual_algo_meta['title']} ({manual_algo_meta['short']}).\n"
            f"PMV Ð·Ð°Ð¿Ð¸ÑÐ°Ð½ Ð² Ð±Ð°Ð·Ñƒ, Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¸ Ð¿Ð¾Ð¼ÐµÑ‡ÐµÐ½Ñ‹ ÐºÐ°Ðº Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ."
        )

def apply_pmv_rating(
    row_obj: Union[sqlite3.Row, Dict[str, Any]],
    rating: int,
) -> Tuple[Dict[str, Any], str]:
    """
    ÐŸÐ¾Ð¼ÐµÑ‡Ð°ÐµÑ‚ PMV Ð¾Ñ†ÐµÐ½ÐºÐ¾Ð¹ Ð¸ Ð¿Ñ€Ð¸ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¿ÐµÑ€ÐµÐ½Ð¾ÑÐ¸Ñ‚ Ñ„Ð°Ð¹Ð» Ð² Ð¿Ð°Ð¿ÐºÑƒ rating_<Ð¾Ñ†ÐµÐ½ÐºÐ°>.
    Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð¾Ð±Ð½Ð¾Ð²Ð»Ñ‘Ð½Ð½ÑƒÑŽ Ð·Ð°Ð¿Ð¸ÑÑŒ Ð¸ Ð¸Ð¼Ñ Ñ„Ð°Ð¹Ð»Ð° Ð´Ð»Ñ Ð»Ð¾Ð³Ð¾Ð²/Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð².
    """
    row = dict(row_obj)
    pmv_id = int(row["id"])
    old_path = Path(row["video_path"])
    pmv_name = old_path.name

    db_append_compilation_comment(pmv_id, f"pmv_rating={rating}")

    try:
        rating_dir = NETWORK_OUTPUT_ROOT / f"rating_{rating}"
        rating_dir.mkdir(parents=True, exist_ok=True)

        new_path = rating_dir / old_path.name
        if old_path.resolve() != new_path.resolve():
            shutil.move(str(old_path), str(new_path))

            conn = get_conn()
            cur = conn.cursor()
            cur.execute(
                "UPDATE compilations SET video_path = ? WHERE id = ?",
                (str(new_path.resolve()), pmv_id),
            )
            conn.commit()
            conn.close()

            row["video_path"] = str(new_path.resolve())
    except Exception as e:
        db_append_compilation_comment(pmv_id, f"move_error={e}")

    return row, pmv_name


def apply_pmv_rating_pairs(
    pmv_rows: List[sqlite3.Row],
    pairs: Iterable[Tuple[int, int]],
) -> Tuple[List[str], List[str]]:
    """
    ÐŸÑ€Ð¸Ð¼ÐµÐ½ÑÐµÑ‚ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð¿Ð°Ñ€ (Ð½Ð¾Ð¼ÐµÑ€, Ð¾Ñ†ÐµÐ½ÐºÐ°) Ðº ÑÐ¿Ð¸ÑÐºÑƒ PMV.
    Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð´Ð²Ð° ÑÐ¿Ð¸ÑÐºÐ° ÑÑ‚Ñ€Ð¾Ðº: ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð½Ñ‹Ðµ Ð¸ Ð¾ÑˆÐ¸Ð±ÐºÐ¸.
    """
    success_lines: List[str] = []
    error_lines: List[str] = []
    total = len(pmv_rows)

    for idx_val, rating_val in pairs:
        if rating_val < 1 or rating_val > 5:
            error_lines.append(f"PMV â„–{idx_val}: Ð¾Ñ†ÐµÐ½ÐºÐ° Ð´Ð¾Ð»Ð¶Ð½Ð° Ð±Ñ‹Ñ‚ÑŒ 1-5.")
            continue
        if not (1 <= idx_val <= total):
            error_lines.append(f"PMV â„–{idx_val}: Ñ‚Ð°ÐºÐ¾Ð³Ð¾ Ð½Ð¾Ð¼ÐµÑ€Ð° Ð½ÐµÑ‚ (Ð²ÑÐµÐ³Ð¾ {total}).")
            continue

        try:
            _, pmv_name = apply_pmv_rating(pmv_rows[idx_val - 1], rating_val)
        except Exception as exc:
            error_lines.append(f"PMV â„–{idx_val}: Ð¾ÑˆÐ¸Ð±ÐºÐ° {exc}.")
            continue

        success_lines.append(f"{pmv_name} â†’ {rating_val}/5")

    return success_lines, error_lines


async def process_ratepmv_choice(
    sess: Dict[str, Any],
    idx: int,
    rating: int,
    reply_long: Callable[[str], Awaitable[None]],
) -> Optional[bool]:
    if rating < 1 or rating > 5:
        return await reply_long("ÐžÑ†ÐµÐ½ÐºÐ° Ð´Ð¾Ð»Ð¶Ð½Ð° Ð±Ñ‹Ñ‚ÑŒ Ð¾Ñ‚ 1 Ð´Ð¾ 5.")

    pmv_rows: List[sqlite3.Row] = sess.get("pmv_rows") or []
    if not pmv_rows:
        return await reply_long("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð½Ð°Ð¹Ñ‚Ð¸ ÑÐ¿Ð¸ÑÐ¾Ðº PMV Ð´Ð»Ñ Ð¾Ñ†ÐµÐ½ÐºÐ¸.")
    if not (1 <= idx <= len(pmv_rows)):
        return await reply_long("ÐÐµÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ñ‹Ð¹ Ð½Ð¾Ð¼ÐµÑ€ PMV.")

    row_obj = pmv_rows[idx - 1]
    row, pmv_name = apply_pmv_rating(row_obj, rating)

    sess["state"] = "ratepmv_confirm_sources"
    sess["chosen_pmv"] = row
    sess["pmv_rating"] = rating

    await reply_long(
        f"Ð’Ñ‹ Ð²Ñ‹Ð±Ñ€Ð°Ð»Ð¸ PMV â„–{idx}: {pmv_name}\n"
        f"ÐžÑ†ÐµÐ½ÐºÐ° Ð·Ð°Ñ„Ð¸ÐºÑÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð°: {rating}/5.\n"
        f"Ð¤Ð°Ð¹Ð» Ð¿ÐµÑ€ÐµÐ½ÐµÑÑ‘Ð½ Ð² rating_{rating}.\n\n"
        "ÐÐ°Ð¿Ð¸ÑˆÐ¸Ñ‚Ðµ, Ð±ÑƒÐ´ÐµÑ‚Ðµ Ð»Ð¸ Ð¾Ñ†ÐµÐ½Ð¸Ð²Ð°Ñ‚ÑŒ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¸ (Ð´Ð°/Ð½ÐµÑ‚)."
    )
    return True

# ====== RATEPMV: Ð²Ñ‹Ð±Ð¾Ñ€ PMV Ð¸ Ð¾Ð±Ñ‰ÐµÐ¹ Ð¾Ñ†ÐµÐ½ÐºÐ¸ ======
    if state == "ratepmv_choose_pmv":
        tokens = text.replace(",", " ").split()
        digits = [t for t in tokens if t.isdigit()]
        if len(digits) < 2:
            return await reply_long(
                "Ð£ÐºÐ°Ð¶Ð¸ Ñ…Ð¾Ñ‚Ñ Ð±Ñ‹ Ð¾Ð´Ð½Ñƒ Ð¿Ð°Ñ€Ñƒ `<Ð½Ð¾Ð¼ÐµÑ€> <Ð¾Ñ†ÐµÐ½ÐºÐ° 1-5>` (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€: `2 5` Ð¸Ð»Ð¸ `1 5 2 4`)."
            )

        numbers = [int(t) for t in digits]
        if len(numbers) == 2:
            idx, rating = numbers
            return await process_ratepmv_choice(sess, idx, rating, reply_long)

        if len(numbers) % 2 != 0:
            return await reply_long(
                "Ð’ Ð¿Ð°ÐºÐµÑ‚Ð½Ð¾Ð¼ Ñ€ÐµÐ¶Ð¸Ð¼Ðµ Ð½ÑƒÐ¶Ð½Ð¾ Ñ‡Ñ‘Ñ‚Ð½Ð¾Ðµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ñ‡Ð¸ÑÐµÐ» â€” Ð½Ð¾Ð¼ÐµÑ€ PMV Ð¸ Ð¾Ñ†ÐµÐ½ÐºÐ° 1-5."
            )

        pmv_rows: List[sqlite3.Row] = sess.get("pmv_rows") or []
        if not pmv_rows:
            return await reply_long("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð½Ð°Ð¹Ñ‚Ð¸ ÑÐ¿Ð¸ÑÐ¾Ðº PMV Ð´Ð»Ñ Ð¾Ñ†ÐµÐ½ÐºÐ¸.")

        await reply_long("ÐŸÑ€Ð¸Ð½ÑÐ» Ð¿Ð°ÐºÐµÑ‚, Ð²Ñ‹ÑÑ‚Ð°Ð²Ð»ÑÑŽ Ð¾Ñ†ÐµÐ½ÐºÐ¸...")

        rating_pairs = [
            (numbers[i], numbers[i + 1]) for i in range(0, len(numbers), 2)
        ]
        success_lines, error_lines = apply_pmv_rating_pairs(pmv_rows, rating_pairs)

        if not success_lines:
            msg = "ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ Ð½Ð¸ Ð¾Ð´Ð½Ñƒ Ð¿Ð°Ñ€Ñƒ. ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒ Ð½Ð¾Ð¼ÐµÑ€Ð° Ð¸ Ð¾Ñ†ÐµÐ½ÐºÐ¸."
            if error_lines:
                msg += "\n" + "\n".join(error_lines)
            return await reply_long(msg)

        user_sessions.pop(user_id, None)

        lines = [
            f"âœ… ÐŸÐ°ÐºÐµÑ‚Ð½Ð°Ñ Ð¾Ñ†ÐµÐ½ÐºÐ° Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð°, Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¾ PMV: {len(success_lines)}.",
            "Ð£ÑÐ¿ÐµÑˆÐ½Ð¾ Ð¾Ñ‚Ð¼ÐµÑ‡ÐµÐ½Ñ‹:",
        ]
        lines.extend(f"- {entry}" for entry in success_lines)
        if error_lines:
            lines.append("")
            lines.append("âš ï¸ ÐŸÑ€Ð¾Ð¿ÑƒÑ‰ÐµÐ½Ñ‹:")
            lines.extend(f"- {entry}" for entry in error_lines)
        lines.append("")
        lines.append("ÐžÑ†ÐµÐ½ÐºÐ¸ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¾Ð² Ð² Ð¿Ð°ÐºÐµÑ‚Ð½Ð¾Ð¼ Ñ€ÐµÐ¶Ð¸Ð¼Ðµ Ð½Ðµ ÑÑ‚Ð°Ð²ÑÑ‚ÑÑ â€” Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÑŒ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ð¹ PMV Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾, ÐµÑÐ»Ð¸ Ð½ÑƒÐ¶Ð½Ð¾.")
        return await reply_long("\n".join(lines))

    # ====== RATEPMV: ÑÐ¿Ñ€Ð¾ÑÐ¸Ñ‚ÑŒ, Ð¾Ñ†ÐµÐ½Ð¸Ð²Ð°Ñ‚ÑŒ Ð»Ð¸ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¸ ======
    if state == "ratepmv_confirm_sources":
        answer = text.lower()
        if answer not in {"Ð´Ð°", "Ð´", "yes", "y", "Ð½ÐµÑ‚", "Ð½Ðµ", "no", "n"}:
            return await reply_long("ÐžÑ‚Ð²ÐµÑ‚ÑŒÑ‚Ðµ 'Ð´Ð°' Ð¸Ð»Ð¸ 'Ð½ÐµÑ‚'.")

        if answer in {"Ð½ÐµÑ‚", "Ð½Ðµ", "no", "n"}:
            user_sessions.pop(user_id, None)
            return await reply_long("âœ… ÐžÑ†ÐµÐ½ÐºÐ° PMV ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð°.")

        chosen_pmv: sqlite3.Row | dict = sess["chosen_pmv"]
        pmv_id = int(chosen_pmv["id"])
        source_ids_str = chosen_pmv["source_ids"] or ""
        src_ids = [int(x) for x in source_ids_str.split(",") if x.strip().isdigit()]

        if not src_ids:
            user_sessions.pop(user_id, None)
            return await reply_long(
                "Ð’ ÑÑ‚Ð¾Ð¹ ÐºÐ¾Ð¼Ð¿Ð¸Ð»ÑÑ†Ð¸Ð¸ Ð½Ðµ Ð½Ð°ÑˆÐ»Ð¾ÑÑŒ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² (source_ids Ð¿ÑƒÑÑ‚Ñ‹Ðµ)."
            )

        conn = get_conn()
        cur = conn.cursor()
        q_marks = ",".join("?" for _ in src_ids)
        cur.execute(f"SELECT * FROM sources WHERE id IN ({q_marks})", src_ids)
        src_rows = cur.fetchall()
        conn.close()

        if not src_rows:
            user_sessions.pop(user_id, None)
            return await reply_long(
                "ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð½Ð°Ð¹Ñ‚Ð¸ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¸ Ð² Ð±Ð°Ð·Ðµ. ÐžÑ†ÐµÐ½ÐºÐ° PMV ÑƒÐ¶Ðµ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð°."
            )

        src_map = {r["id"]: r for r in src_rows}
        ordered_sources = [src_map[sid] for sid in src_ids if sid in src_map]

        # ðŸ”¥ ÐÐžÐ’ÐžÐ•: Ð²Ñ‹ÐºÐ¸Ð´Ñ‹Ð²Ð°ÐµÐ¼ Ñ‚Ðµ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¸, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ ÑƒÐ¶Ðµ Ð¾Ñ†ÐµÐ½ÐµÐ½Ñ‹ Ð´Ð»Ñ Ð­Ð¢ÐžÐ“Ðž PMV
        unrated_sources = []
        already_rated = 0
        marker = f"pmv#{pmv_id}_rating="
        for r in ordered_sources:
            comments = (r["comments"] or "")
            if marker in comments:
                already_rated += 1
            else:
                unrated_sources.append(r)

        if not unrated_sources:
            user_sessions.pop(user_id, None)
            return await reply_long(
                "Ð’ÑÐµ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¸ Ð² ÑÑ‚Ð¾Ð¹ ÐºÐ¾Ð¼Ð¿Ð¸Ð»ÑÑ†Ð¸Ð¸ ÑƒÐ¶Ðµ Ð¸Ð¼ÐµÑŽÑ‚ Ð¾Ñ†ÐµÐ½ÐºÐ¸ Ð´Ð»Ñ ÑÑ‚Ð¾Ð³Ð¾ PMV. âœ…"
            )

        sess["state"] = "ratepmv_sources_scores"
        sess["sources_rows"] = unrated_sources

        lines = []
        if already_rated:
            lines.append(f"Ð§Ð°ÑÑ‚ÑŒ Ð²Ð¸Ð´ÐµÐ¾ ÑƒÐ¶Ðµ Ð¾Ñ†ÐµÐ½ÐµÐ½Ð° Ð´Ð»Ñ ÑÑ‚Ð¾Ð³Ð¾ PMV: Ð¿Ñ€Ð¾Ð¿ÑƒÑ‰ÐµÐ½Ð¾ {already_rated} ÑˆÑ‚.")
        lines.append("ÐžÑ†ÐµÐ½Ð¸Ð¼ Ð¾ÑÑ‚Ð°Ð²ÑˆÐ¸ÐµÑÑ Ð²Ð¸Ð´ÐµÐ¾ Ð² ÑÑ‚Ð¾Ð¹ ÐºÐ¾Ð¼Ð¿Ð¸Ð»ÑÑ†Ð¸Ð¸:")
        for i, r in enumerate(unrated_sources, 1):
            lines.append(f"{i}. {r['video_name']} (id={r['id']})")
        lines.append("")
        lines.append(
            "ÐŸÑ€Ð¸ÑˆÐ»Ð¸Ñ‚Ðµ Ð¾Ñ†ÐµÐ½ÐºÐ¸ Ñ‡ÐµÑ€ÐµÐ· Ð¿Ñ€Ð¾Ð±ÐµÐ», Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€: `5 3 4 1 5`.\n"
            "ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¾Ñ†ÐµÐ½Ð¾Ðº Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ Ð¼ÐµÐ½ÑŒÑˆÐµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð° Ð²Ð¸Ð´ÐµÐ¾ â€” "
            "Ð»Ð¸ÑˆÐ½Ð¸Ðµ Ð²Ð¸Ð´ÐµÐ¾ Ð¾ÑÑ‚Ð°Ð½ÑƒÑ‚ÑÑ Ð±ÐµÐ· Ð¾Ñ†ÐµÐ½ÐºÐ¸."
        )
        return await reply_long("\n".join(lines))

    # ====== RATEPMV: Ð¿Ñ€Ð¸Ñ‘Ð¼ Ð¾Ñ†ÐµÐ½Ð¾Ðº Ð¿Ð¾ ÐºÐ°Ð¶Ð´Ð¾Ð¼Ñƒ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÑƒ ======
    if state == "ratepmv_sources_scores":
        parts = text.replace(",", " ").split()
        ratings: List[int] = []
        for p in parts:
            if not p.isdigit():
                continue
            v = int(p)
            if 1 <= v <= 5:
                ratings.append(v)

        if not ratings:
            return await reply_long(
                "ÐÐµ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ð»Ð¾ÑÑŒ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ñ‚ÑŒ Ð½Ð¸ Ð¾Ð´Ð½Ð¾Ð¹ Ð¾Ñ†ÐµÐ½ÐºÐ¸ Ð¾Ñ‚ 1 Ð´Ð¾ 5. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ ÐµÑ‰Ñ‘ Ñ€Ð°Ð·."
            )

        sources_rows: List[sqlite3.Row] = sess["sources_rows"]
        chosen_pmv: sqlite3.Row | dict = sess["chosen_pmv"]
        pmv_id = int(chosen_pmv["id"])

        for src_row, rate in zip(sources_rows, ratings):
            sid = int(src_row["id"])
            db_append_source_comment(sid, f"pmv#{pmv_id}_rating={rate}")

        user_sessions.pop(user_id, None)
        return await reply_long(
            f"âœ… ÐžÑ†ÐµÐ½ÐºÐ¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ñ‹.\n"
            f"Ð’Ð¸Ð´ÐµÐ¾ Ð¾Ñ†ÐµÐ½ÐµÐ½Ð¾: {len(ratings)} Ð¸Ð· {len(sources_rows)} (Ð² ÑÑ‚Ð¾Ð¹ ÑÐµÑÑÐ¸Ð¸)."
        )

    # ====== COMPMV: Ð²Ñ‹Ð±Ð¾Ñ€ PMV ======
    if state == "compmv_choose":
        if not text.isdigit():
            return await reply_long("ÐÑƒÐ¶Ð½Ð¾ Ð¿Ñ€Ð¾ÑÑ‚Ð¾ Ñ‡Ð¸ÑÐ»Ð¾ â€” Ð½Ð¾Ð¼ÐµÑ€ PMV.")

        idx = int(text)
        pmv_rows: List[sqlite3.Row] = sess["pmv_rows"]
        if not (1 <= idx <= len(pmv_rows)):
            return await reply_long("ÐÐµÐ²ÐµÑ€Ð½Ñ‹Ð¹ Ð½Ð¾Ð¼ÐµÑ€ PMV.")

        row = pmv_rows[idx - 1]
        pmv_id = int(row["id"])
        pmv_name = Path(row["video_path"]).name
        

        sess["state"] = "compmv_enter_comment"
        sess["chosen_pmv_id"] = pmv_id

        return await reply_long(
            f"Ð’Ñ‹ Ð²Ñ‹Ð±Ñ€Ð°Ð»Ð¸ PMV: {pmv_name} (id={pmv_id}).\n"
            "Ð¢ÐµÐ¿ÐµÑ€ÑŒ Ð¿Ñ€Ð¸ÑˆÐ»Ð¸Ñ‚Ðµ Ñ‚ÐµÐºÑÑ‚ ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ñ."
        )

    # ====== COMPMV: Ð²Ð²Ð¾Ð´ ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ñ ======
    if state == "compmv_enter_comment":
        pmv_id = sess.get("chosen_pmv_id")
        comment_text = text.strip()
        if not comment_text:
            return await reply_long("ÐšÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð¹ Ð¿ÑƒÑÑ‚Ð¾Ð¹. ÐŸÑ€Ð¸ÑˆÐ»Ð¸Ñ‚Ðµ Ð½ÐµÐ¿ÑƒÑÑ‚Ð¾Ð¹ Ñ‚ÐµÐºÑÑ‚.")

        db_append_compilation_comment(pmv_id, comment_text)

        user_sessions.pop(user_id, None)
        return await reply_long("âœ… ÐšÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð¹ Ðº ÐºÐ¾Ð¼Ð¿Ð¸Ð»ÑÑ†Ð¸Ð¸ ÑÐ¾Ñ…Ñ€Ð°Ð½Ñ‘Ð½.")

    # ====== COMVID: Ð²Ñ‹Ð±Ð¾Ñ€ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ° ======
    if state == "comvid_choose":
        if not text.isdigit():
            return await reply_long("ÐÑƒÐ¶Ð½Ð¾ Ð¿Ñ€Ð¾ÑÑ‚Ð¾ Ñ‡Ð¸ÑÐ»Ð¾ â€” Ð½Ð¾Ð¼ÐµÑ€ Ð²Ð¸Ð´ÐµÐ¾.")

        idx = int(text)
        src_rows: List[sqlite3.Row] = sess["src_rows"]
        if not (1 <= idx <= len(src_rows)):
            return await reply_long("ÐÐµÐ²ÐµÑ€Ð½Ñ‹Ð¹ Ð½Ð¾Ð¼ÐµÑ€ Ð²Ð¸Ð´ÐµÐ¾.")

        row = src_rows[idx - 1]
        src_id = int(row["id"])
        src_name = row["video_name"]

        sess["state"] = "comvid_enter_comment"
        sess["chosen_src_id"] = src_id

        return await reply_long(
            f"Ð’Ñ‹ Ð²Ñ‹Ð±Ñ€Ð°Ð»Ð¸ Ð²Ð¸Ð´ÐµÐ¾: {src_name} (id={src_id}).\n"
            "Ð¢ÐµÐ¿ÐµÑ€ÑŒ Ð¿Ñ€Ð¸ÑˆÐ»Ð¸Ñ‚Ðµ Ñ‚ÐµÐºÑÑ‚ ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ñ."
        )

    # ====== COMVID: Ð²Ð²Ð¾Ð´ ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ñ ======
    if state == "comvid_enter_comment":
        src_id = sess.get("chosen_src_id")
        comment_text = text.strip()
        if not comment_text:
            return await reply_long("ÐšÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð¹ Ð¿ÑƒÑÑ‚Ð¾Ð¹. ÐŸÑ€Ð¸ÑˆÐ»Ð¸Ñ‚Ðµ Ð½ÐµÐ¿ÑƒÑÑ‚Ð¾Ð¹ Ñ‚ÐµÐºÑÑ‚.")

        db_append_source_comment(src_id, comment_text)

        user_sessions.pop(user_id, None)
        return await reply_long("âœ… ÐšÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð¹ Ðº Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÑƒ ÑÐ¾Ñ…Ñ€Ð°Ð½Ñ‘Ð½.")

    # Ð•ÑÐ»Ð¸ Ñ‡Ñ‚Ð¾-Ñ‚Ð¾ Ð¿Ð¾ÑˆÐ»Ð¾ Ð½Ðµ Ñ‚Ð°Ðº
    await reply_long("Ð§Ñ‚Ð¾-Ñ‚Ð¾ Ð¿Ð¾ÑˆÐ»Ð¾ Ð½Ðµ Ñ‚Ð°Ðº Ñ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸ÐµÐ¼ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð°. Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ðµ /pmvnew Ð¸Ð»Ð¸ /autocreate Ð·Ð°Ð½Ð¾Ð²Ð¾.")
    user_sessions.pop(user_id, None)


async def handle_callback(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    query = update.callback_query
    if not check_access(update):
        await query.answer("ÐÐµÑ‚ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð°", show_alert=True)
        return await unauthorized(update)

    user_id = query.from_user.id if query.from_user else 0
    data = (query.data or "").strip()
    sess = user_sessions.get(user_id)

    if not sess:
        await query.answer("Ð¡ÐµÑÑÐ¸Ñ ÑƒÑÑ‚Ð°Ñ€ÐµÐ»Ð°", show_alert=True)
        return

    if data.startswith("report_group:"):
        if sess.get("state") != "reports_wait_choice":
            await query.answer("Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð¾Ñ‚ÐºÑ€Ð¾Ð¹Ñ‚Ðµ Ð¼ÐµÐ½ÑŽ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð¾Ð².", show_alert=True)
            return
        color_key = data.split(":", 1)[1]
        report_env = ReportEnvironment(
            db_get_groups=db_get_all_sources_grouped,
            color_choices=RATEGRP_COLOR_CHOICES,
        )
        text = build_color_group_report(report_env, color_key)
        await query.answer("Ð“Ð¾Ñ‚Ð¾Ð²Ð¾")
        await query.message.reply_text(text)
        return

    if data.startswith("randompmv_count:"):
        if not sess or sess.get("state") != "randompmv_wait_count":
            return await query.answer("ÐÐµÑ‚ Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾Ð¹ ÑÐµÑÑÐ¸Ð¸ CreateRandomPMV", show_alert=True)
        try:
            total_runs = int(data.split(":", 1)[1])
        except ValueError:
            return await query.answer("ÐÐµ Ð¿Ð¾Ð½ÑÐ» Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð½Ð¾Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ", show_alert=True)
        total_runs = max(RANDOMPMV_MIN_BATCH, min(total_runs, RANDOMPMV_MAX_BATCH))
        sess["randompmv_total_runs"] = total_runs
        sess["state"] = "randompmv_wait_newcount"
        user_sessions[user_id] = sess
        await query.answer("ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð·Ð°Ð¿ÑƒÑÐºÐ¾Ð² ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¾")
        await query.message.reply_text(
            "Ð¡ÐºÐ¾Ð»ÑŒÐºÐ¾ Ð½Ð¾Ð²Ñ‹Ñ… Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð²ÐºÐ»ÑŽÑ‡Ð°Ñ‚ÑŒ Ð² ÐºÐ°Ð¶Ð´Ñ‹Ð¹ PMV?",
            reply_markup=build_randompmv_newcount_keyboard(),
        )
        return

    if data.startswith("randompmv_newcount:"):
        if not sess or sess.get("state") != "randompmv_wait_newcount":
            return await query.answer("Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð²Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ PMV", show_alert=True)
        try:
            min_new = int(data.split(":", 1)[1])
        except ValueError:
            return await query.answer("ÐÐµ Ð¿Ð¾Ð½ÑÐ» Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð½Ð¾Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ", show_alert=True)
        if min_new < 0:
            return await query.answer("Ð§Ð¸ÑÐ»Ð¾ Ð½Ðµ Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ Ð¾Ñ‚Ñ€Ð¸Ñ†Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¼", show_alert=True)
        total_runs = int(sess.get("randompmv_total_runs") or 0)
        if total_runs <= 0:
            user_sessions.pop(user_id, None)
            return await query.answer("Ð¡ÐµÑÑÐ¸Ñ CreateRandomPMV ÑÐ±Ñ€Ð¾ÑˆÐµÐ½Ð°", show_alert=True)

        async def send_from_query(message: str) -> None:
            await query.message.reply_text(message)

        user_sessions.pop(user_id, None)
        await query.answer(f"Ð—Ð°Ð¿ÑƒÑÐºÐ°ÑŽ {total_runs} Random PMV")
        await query.message.reply_text(
            f"Ð—Ð°Ð¿ÑƒÑÐºÐ°ÑŽ {total_runs} Random PMV (Ð½Ð¾Ð²Ñ‹Ñ… â‰¥ {min_new})..."
        )
        return await run_randompmv_batch(send_from_query, user_id, total_runs, min_new)

    if data.startswith("find_pick:"):
        if not sess.get("find_mode"):
            return await query.answer("Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð·Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ðµ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñƒ Â«ÐÐ°Ð¹Ñ‚Ð¸Â».", show_alert=True)
        try:
            idx = int(data.split(":", 1)[1])
        except ValueError:
            return await query.answer("ÐÐµ Ð¿Ð¾Ð½ÑÐ» Ð½Ð¾Ð¼ÐµÑ€", show_alert=True)
        matches: List[Dict[str, Any]] = sess.get("find_matches") or []
        if not (0 <= idx < len(matches)):
            return await query.answer("ÐÐµÑ‚ Ñ‚Ð°ÐºÐ¾Ð³Ð¾ PMV Ð² ÑÐ¿Ð¸ÑÐºÐµ", show_alert=True)

        async def send_find(message: str, markup: Optional[InlineKeyboardMarkup] = None) -> None:
            await query.message.reply_text(message, reply_markup=markup)

        await query.answer("ÐžÑ‚ÐºÑ€Ñ‹Ð²Ð°ÑŽ PMV")
        await query.message.edit_reply_markup(None)
        entry = matches[idx]
        if entry.get("type") == "pmv":
            return await _start_find_pmv_queue(sess, entry, send_find)
        if entry.get("type") == "source":
            rows = db_get_sources_by_ids([entry["id"]])
            if not rows:
                return await query.message.reply_text("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð½Ð°Ð¹Ñ‚Ð¸ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸Ðº Ð² Ð±Ð°Ð·Ðµ.")
            return await _start_find_single_source(sess, rows[0], send_find)
        return await query.message.reply_text("ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ Ñ‚Ð¸Ð¿ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð°.")

    if data == "find_retry":
        if not sess.get("find_mode"):
            return await query.answer("Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð·Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ðµ Â«ÐÐ°Ð¹Ñ‚Ð¸Â».", show_alert=True)
        sess["state"] = "find_wait_term"
        sess["find_matches"] = []
        await query.answer("Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð´Ñ€ÑƒÐ³Ð¾Ð¹ Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚ Ð¸Ð¼ÐµÐ½Ð¸")
        return await query.message.reply_text(
            "ÐŸÑ€Ð¸ÑˆÐ»Ð¸Ñ‚Ðµ Ð½Ð¾Ð²Ñ‹Ð¹ Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚ Ð¸Ð¼ÐµÐ½Ð¸ PMV. ÐÐ°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, Ð´Ð°Ñ‚Ñƒ 20251207 Ð¸Ð»Ð¸ Ð²Ñ€ÐµÐ¼Ñ 0734."
        )

    if data.startswith("ratepmv_select:"):
        if sess.get("state") != "ratepmv_choose_pmv":
            return await query.answer("Ð¡ÐµÐ¹Ñ‡Ð°Ñ Ð½Ðµ Ð¶Ð´Ñƒ Ð²Ñ‹Ð±Ð¾Ñ€ PMV", show_alert=True)
        try:
            idx = int(data.split(":", 1)[1])
        except ValueError:
            return await query.answer("ÐÐµ Ð¿Ð¾Ð½ÑÐ» Ð½Ð¾Ð¼ÐµÑ€", show_alert=True)
        pmv_rows: List[sqlite3.Row] = sess.get("pmv_rows") or []
        if not (1 <= idx <= len(pmv_rows)):
            return await query.answer("ÐÐµÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ñ‹Ð¹ Ð½Ð¾Ð¼ÐµÑ€ PMV", show_alert=True)
        row = pmv_rows[idx - 1]
        name = Path(row["video_path"]).name
        sess["state"] = "ratepmv_wait_rating"
        sess["ratepmv_selected_idx"] = idx
        await query.answer("PMV Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð¾")
        await query.message.reply_text(
            f"PMV â„–{idx}: {name}\nÐ’Ñ‹Ð±ÐµÑ€Ð¸ Ð¾Ñ†ÐµÐ½ÐºÑƒ 1-5:",
            reply_markup=build_ratepmv_score_keyboard(),
        )
        return

    if data.startswith("ratepmv_rate:"):
        if sess.get("state") != "ratepmv_wait_rating":
            return await query.answer("Ð¡ÐµÐ¹Ñ‡Ð°Ñ Ð½Ðµ Ð¶Ð´Ñƒ Ð¾Ñ†ÐµÐ½ÐºÑƒ", show_alert=True)
        try:
            rating = int(data.split(":", 1)[1])
        except ValueError:
            return await query.answer("ÐÐµ Ð¿Ð¾Ð½ÑÐ» Ð¾Ñ†ÐµÐ½ÐºÑƒ", show_alert=True)
        idx = int(sess.get("ratepmv_selected_idx") or 0)
        if idx <= 0:
            return await query.answer("ÐÐµÑ‚ Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð½Ð¾Ð³Ð¾ PMV", show_alert=True)

        async def send_from_query(message: str) -> None:
            await query.message.reply_text(message)

        await query.answer(f"ÐžÑ†ÐµÐ½ÐºÐ°: {rating}")
        await process_ratepmv_choice(sess, idx, rating, send_from_query)
        sess.pop("ratepmv_selected_idx", None)
        return

    if data.startswith("ratepmv_bulk:"):
        if sess.get("state") not in {"ratepmv_choose_pmv", "ratepmv_wait_rating"}:
            return await query.answer("ÐŸÐ°ÐºÐµÑ‚Ð½Ð°Ñ Ð¾Ñ†ÐµÐ½ÐºÐ° ÑÐµÐ¹Ñ‡Ð°Ñ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°", show_alert=True)
        try:
            rating = int(data.split(":", 1)[1])
        except ValueError:
            return await query.answer("ÐÐµ Ð¿Ð¾Ð½ÑÐ» Ð¾Ñ†ÐµÐ½ÐºÑƒ", show_alert=True)
        if rating < 1 or rating > 5:
            return await query.answer("ÐžÑ†ÐµÐ½ÐºÐ° Ð´Ð¾Ð»Ð¶Ð½Ð° Ð±Ñ‹Ñ‚ÑŒ 1-5", show_alert=True)

        pmv_rows: List[sqlite3.Row] = sess.get("pmv_rows") or []
        if not pmv_rows:
            return await query.answer("ÐÐµÑ‚ ÑÐ¿Ð¸ÑÐºÐ° PMV", show_alert=True)

        await query.answer("ÐŸÑ€Ð¸Ð¼ÐµÐ½ÑÑŽ Ð¿Ð°ÐºÐµÑ‚Ð½ÑƒÑŽ Ð¾Ñ†ÐµÐ½ÐºÑƒâ€¦")

        pairs = [(idx + 1, rating) for idx in range(len(pmv_rows))]
        success_lines, error_lines = apply_pmv_rating_pairs(pmv_rows, pairs)

        if not success_lines:
            msg = "ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ñ€Ð¸Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ Ð¿Ð°ÐºÐµÑ‚Ð½ÑƒÑŽ Ð¾Ñ†ÐµÐ½ÐºÑƒ."
            if error_lines:
                msg += "\n" + "\n".join(error_lines)
            return await query.message.reply_text(msg)

        user_sessions.pop(user_id, None)

        lines = [
            f"âœ… Ð’ÑÐµ Ð¿Ð¾ÐºÐ°Ð·Ð°Ð½Ð½Ñ‹Ðµ PMV Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ð»Ð¸ Ð¾Ñ†ÐµÐ½ÐºÑƒ {rating}/5: {len(success_lines)} ÑˆÑ‚.",
            "Ð£ÑÐ¿ÐµÑˆÐ½Ð¾ Ð¾Ñ‚Ð¼ÐµÑ‡ÐµÐ½Ñ‹:",
        ]
        lines.extend(f"- {entry}" for entry in success_lines)
        if error_lines:
            lines.append("")
            lines.append("âš ï¸ ÐŸÑ€Ð¾Ð¿ÑƒÑ‰ÐµÐ½Ñ‹:")
            lines.extend(f"- {entry}" for entry in error_lines)
        lines.append("")
        lines.append("ÐžÑ†ÐµÐ½ÐºÐ¸ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¾Ð² Ð½Ðµ ÑÑ‚Ð°Ð²Ð¸Ð»Ð¸ÑÑŒ. Ð•ÑÐ»Ð¸ Ð½ÑƒÐ¶Ð½Ð¾ â€” Ð²Ñ‹Ð±ÐµÑ€Ð¸ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ð¹ PMV Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾.")
        await query.message.reply_text("\n".join(lines))
        return

    if data == "rategrp_from_pmv":
        if sess.get("state") != "rategrp_choose_orientation":
            return await query.answer("Ð­Ñ‚Ð° Ð¾Ð¿Ñ†Ð¸Ñ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð° Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð² Ð½Ð°Ñ‡Ð°Ð»Ðµ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹ rategrp.", show_alert=True)

        async def send_rategrp(msg: str, markup: Optional[InlineKeyboardMarkup] = None) -> None:
            await query.message.reply_text(msg, reply_markup=markup)

        success = await _start_rategrp_from_pmv(sess, send_rategrp)
        if success:
            await query.answer("ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÑŽ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¸ Ð¸Ð· PMV")
        else:
            await query.answer("ÐÐµÑ‚ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ÑÑ‰Ð¸Ñ… Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð²", show_alert=True)
        return

    if data.startswith("musicprep_show:"):
        mode = data.split(":", 1)[1]
        show_used = mode == "used"
        sess["state"] = "musicprep_wait_track"
        text, keyboard = build_musicprep_track_keyboard(sess, show_used=show_used)
        try:
            await query.edit_message_text(text, reply_markup=keyboard)
        except Exception:
            await query.message.reply_text(text, reply_markup=keyboard)
        return await query.answer()

    if data.startswith("musicprep_track:"):
        tracks = sess.get("music_tracks") or {}
        token = data.split(":", 1)[1]
        info = tracks.get(token)
        if not info:
            return await query.answer("Ð¢Ñ€ÐµÐº Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½", show_alert=True)
        path = Path(info["path"])
        _, title = extract_track_title_components(path)
        prefix = slugify_token(title or path.stem)
        sess["musicprep_file"] = str(path)
        sess["musicprep_project_prefix"] = prefix
        sess.pop("musicprep_project_partial", None)
        sess["state"] = "musicprep_wait_seconds"
        await query.answer("Ð¢Ñ€ÐµÐº Ð²Ñ‹Ð±Ñ€Ð°Ð½")
        await query.message.reply_text(
            f"Ð¢Ñ€ÐµÐº Ð²Ñ‹Ð±Ñ€Ð°Ð½: {path.name}\n"
            f"ÐŸÑ€ÐµÑ„Ð¸ÐºÑ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°: {prefix}\n"
            "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¼Ð¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½ÑƒÑŽ Ð´Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ð°:",
            reply_markup=build_musicprep_seconds_keyboard(),
        )
        return

    if data.startswith("musicprep_seconds:"):
        if sess.get("state") not in {"musicprep_wait_seconds", "musicprep_wait_mode"}:
            return await query.answer("Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð²Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ñ‚Ñ€ÐµÐº", show_alert=True)
        try:
            seconds = int(data.split(":", 1)[1])
        except ValueError:
            return await query.answer("ÐÐµÐ²ÐµÑ€Ð½Ð¾Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ", show_alert=True)
        prefix = sess.get("musicprep_project_prefix") or "project"
        partial = f"{prefix}_{seconds}"
        sess["musicprep_segment"] = float(seconds)
        sess["musicprep_project_partial"] = partial
        sess["state"] = "musicprep_wait_mode"
        await query.answer(f"{seconds} ÑÐµÐº.")
        if seconds == 0:
            length_line = "Ð”Ð»Ð¸Ð½Ð° ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ð°: Ð°Ð²Ñ‚Ð¾ (Ð¼Ð¸Ð½Ð¸Ð¼ÑƒÐ¼ Ð½Ðµ Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½)."
        else:
            length_line = f"Ð”Ð»Ð¸Ð½Ð° ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ð°: {seconds} ÑÐµÐº."
        await query.message.reply_text(
            f"{length_line}\n"
            f"Ð˜Ð¼Ñ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð° ÑÑ‚Ð°Ð½ÐµÑ‚: {partial}_<algo>\n"
            "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼ ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸:",
            reply_markup=build_musicprep_mode_keyboard(),
        )
        return

    if data.startswith("musicprep_mode:"):
        if sess.get("state") != "musicprep_wait_mode":
            return await query.answer("Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð²Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ñ‹", show_alert=True)

        mode = data.split(":", 1)[1]
        if mode not in {"beat", "onset", "uniform"}:
            return await query.answer("ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼", show_alert=True)

        sess["musicprep_selected_mode"] = mode
        options = get_musicprep_sensitivity_options(mode)
        if options:
            sess["musicprep_sensitivity_options"] = options
            sess["state"] = "musicprep_wait_sensitivity"
            await query.answer("ÐÐ»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼ Ð²Ñ‹Ð±Ñ€Ð°Ð½")
            await query.message.reply_text(
                "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ñ‡ÑƒÐ²ÑÑ‚Ð²Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°:",
                reply_markup=build_musicprep_sensitivity_keyboard(mode),
            )
            return

        await query.answer("Ð—Ð°Ð¿ÑƒÑÐºÐ°ÑŽ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸ÑŽâ€¦")

        async def send(msg: str) -> None:
            await query.message.reply_text(msg)

        return await finalize_musicprep_project(send, sess, user_id, mode)

    if data.startswith("musicprep_sens:"):
        if sess.get("state") != "musicprep_wait_sensitivity":
            return await query.answer("Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð²Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼", show_alert=True)
        parts = data.split(":", 2)
        if len(parts) != 3:
            return await query.answer("ÐÐµÐ²ÐµÑ€Ð½Ñ‹Ð¹ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€", show_alert=True)
        _, mode, key = parts
        options = get_musicprep_sensitivity_options(mode)
        selected = next((opt for opt in options if opt["key"] == key), None)
        if not selected:
            return await query.answer("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ñ‚ÑŒ Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚", show_alert=True)
        sess["state"] = None
        await query.answer("Ð§ÑƒÐ²ÑÑ‚Ð²Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð°")

        async def send(msg: str) -> None:
            await query.message.reply_text(msg)

        return await finalize_musicprep_project(
            send, sess, user_id, mode, selected.get("analysis_kwargs") or {}
        )

    if data.startswith("musicprepcheck_project:"):
        if sess.get("state") != "musicprepcheck_wait_project":
            return await query.answer("Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð·Ð°Ð¿ÑƒÑÑ‚Ð¸ /musicprepcheck", show_alert=True)
        slug = data.split(":", 1)[1]
        projects_map: Dict[str, Dict[str, Any]] = sess.get("musicprepcheck_projects") or {}
        project = projects_map.get(slug)
        if not project:
            return await query.answer("ÐŸÑ€Ð¾ÐµÐºÑ‚ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½", show_alert=True)
        await query.answer("Ð“Ð¾Ñ‚Ð¾Ð²Ð»ÑŽ Ñ‰ÐµÐ»Ñ‡ÐºÐ¸â€¦")
        try:
            output_path = generate_musicprep_click_preview(project)
        except Exception as exc:
            return await query.message.reply_text(f"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ ÑÐ¾Ð·Ð´Ð°Ñ‚ÑŒ MP3 ÑÐ¾ Ñ‰ÐµÐ»Ñ‡ÐºÐ°Ð¼Ð¸: {exc}")

        caption = f"Ð©ÐµÐ»Ñ‡ÐºÐ¸ Ð´Ð»Ñ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð° {project.get('name') or slug}"
        try:
            with output_path.open("rb") as fh:
                await context.bot.send_document(
                    chat_id=update.effective_chat.id,
                    document=fh,
                    filename=output_path.name,
                    caption=caption,
                )
        except Exception:
            await query.message.reply_text(f"Ð¤Ð°Ð¹Ð» ÑÐ¾Ñ…Ñ€Ð°Ð½Ñ‘Ð½: {output_path}")
        else:
            await query.message.reply_text(f"Ð“Ð¾Ñ‚Ð¾Ð²Ð¾. Ð¤Ð°Ð¹Ð»: {output_path}")
        return

    if data.startswith("newcomp_show:"):
        mode = data.split(":", 1)[1]
        show_used = mode == "used"
        if show_used and not sess.get("music_projects_duration_filter"):
            async def send_duration(text: str, markup: Optional[InlineKeyboardMarkup] = None) -> None:
                try:
                    await query.edit_message_text(text, reply_markup=markup)
                except Exception:
                    await query.message.reply_text(text, reply_markup=markup)

            await prompt_newcomp_duration(sess, send_duration)
            await query.answer()
            return
        sess["state"] = "newcompmusic_wait_project"
        text, keyboard = build_newcomp_project_keyboard(sess, show_used=show_used)
        try:
            await query.edit_message_text(text, reply_markup=keyboard)
        except Exception:
            await query.message.reply_text(text, reply_markup=keyboard)
        return await query.answer()

    if data == "newcomp_bucket_menu":
        async def send_duration(text: str, markup: Optional[InlineKeyboardMarkup] = None) -> None:
            try:
                await query.edit_message_text(text, reply_markup=markup)
            except Exception:
                await query.message.reply_text(text, reply_markup=markup)

        await prompt_newcomp_duration(sess, send_duration)
        return await query.answer()

    if data.startswith("newcomp_bucket:"):
        bucket = data.split(":", 1)[1]
        valid_keys = {key for key, _, _, _ in NEWCOMPMUSIC_DURATION_BUCKETS}
        if bucket not in valid_keys:
            return await query.answer("ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð°Ñ Ð´Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ", show_alert=True)
        sess["music_projects_duration_filter"] = bucket
        sess["state"] = "newcompmusic_wait_project"
        text, keyboard = build_newcomp_project_keyboard(sess, show_used=True)
        try:
            await query.edit_message_text(text, reply_markup=keyboard)
        except Exception:
            await query.message.reply_text(text, reply_markup=keyboard)
        return await query.answer("Ð¤Ð¸Ð»ÑŒÑ‚Ñ€ Ð¾Ð±Ð½Ð¾Ð²Ð»Ñ‘Ð½")

    if data.startswith("newcomp_project:"):
        projects_map: Dict[str, Dict[str, Any]] = sess.get("music_projects_map") or {}
        token = data.split(":", 1)[1]
        chosen = projects_map.get(token)
        if not chosen:
            return await query.answer("ÐŸÑ€Ð¾ÐµÐºÑ‚ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½", show_alert=True)

        manifest_data = chosen.get("manifest_data")
        manifest_path = chosen.get("manifest_path")
        if not manifest_data and manifest_path and Path(manifest_path).exists():
            try:
                manifest_data = json.loads(Path(manifest_path).read_text(encoding="utf-8"))
                chosen["manifest_data"] = manifest_data
            except Exception as exc:
                return await query.answer(f"ÐžÑˆÐ¸Ð±ÐºÐ° manifest.json: {exc}", show_alert=True)

        parsed_segments = parse_manifest_segments(manifest_data or {})
        total_duration = chosen.get("duration")
        if total_duration is None and parsed_segments:
            total_duration = parsed_segments[-1].end
        seg_count = len(parsed_segments)
        minutes = (total_duration / 60.0) if total_duration else None

        groups = get_source_groups_prefer_unused()
        if not groups:
            return await query.answer("ÐÐµÑ‚ Ð³Ñ€ÑƒÐ¿Ð¿ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð². Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° /scan.", show_alert=True)

        sess["state"] = "newcompmusic_choose_orientation"
        sess["music_selected"] = {
            "slug": chosen.get("slug"),
            "name": chosen.get("name"),
            "duration": total_duration,
            "segments": seg_count,
            "manifest": manifest_data,
            "audio_path": str(chosen.get("audio_path")) if chosen.get("audio_path") else None,
            "parsed_segments": parsed_segments,
        }
        group_entries = [
            SourceGroupEntry(key=key, rows=list(rows), unused_count=unused_count)
            for key, rows, unused_count in groups
        ]
        sorted_entries, orientation_map = sort_group_entries_with_orientation(group_entries)
        sess["music_group_orientations"] = orientation_map
        sess["music_groups_all"] = [
            (entry.key, entry.rows, entry.unused_count) for entry in sorted_entries
        ]
        sess["music_groups"] = []
        sess["music_orientation_preference"] = None

        lines = [
            f"Ð’Ñ‹Ð±Ñ€Ð°Ð½ Ð¿Ñ€Ð¾ÐµÐºÑ‚: {chosen['name']} (slug: {chosen['slug']}).",
            f"Ð¡Ð¼ÐµÐ½ ÐºÐ»Ð¸Ð¿Ð¾Ð²: {seg_count}",
        ]
        if minutes:
            lines.append(f"ÐŸÑ€Ð¾Ð´Ð¾Ð»Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ â‰ˆ {minutes:.1f} Ð¼Ð¸Ð½ÑƒÑ‚.")
        lines.append("")
        lines.append("Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¾Ñ€Ð¸ÐµÐ½Ñ‚Ð°Ñ†Ð¸ÑŽ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð²: VR, HOR Ð¸Ð»Ð¸ VER.")

        await query.answer("ÐŸÑ€Ð¾ÐµÐºÑ‚ Ð²Ñ‹Ð±Ñ€Ð°Ð½")
        await query.message.reply_text(
            "\n".join(lines),
            reply_markup=build_newcomp_orientation_keyboard(),
        )
        return

    if data.startswith("newcomp_orient:"):
        if sess.get("state") != "newcompmusic_choose_orientation":
            return await query.answer("Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð²Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¿Ñ€Ð¾ÐµÐºÑ‚", show_alert=True)
        target = data.split(":", 1)[1].upper()
        if target not in NEWCOMPMUSIC_ORIENTATION_CHOICES:
            return await query.answer("ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼", show_alert=True)
        all_groups = sess.get("music_groups_all") or []
        if not all_groups:
            return await query.answer("Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð³Ñ€ÑƒÐ¿Ð¿ Ð¿ÑƒÑÑ‚. Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ðµ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñƒ Ð·Ð°Ð½Ð¾Ð²Ð¾.", show_alert=True)
        orientation_map = sess.get("music_group_orientations") or {}
        filtered = filter_groups_by_orientation(all_groups, orientation_map, target)
        if not filtered:
            return await query.answer("ÐÐµÑ‚ Ð³Ñ€ÑƒÐ¿Ð¿ Ð² ÑÑ‚Ð¾Ð¹ Ð¾Ñ€Ð¸ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸.", show_alert=True)
        sess["music_orientation_preference"] = target
        sess["music_groups"] = filtered
        sess["state"] = "newcompmusic_wait_group"
        group_entries = [
            SourceGroupEntry(key=key, rows=list(rows), unused_count=unused)
            for key, rows, unused in filtered
        ]
        msg_lines = _build_group_selection_lines(
            sess, group_entries, target, prompt_kind="inline"
        )
        await query.answer("ÐžÑ€Ð¸ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ñ Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð°")
        await query.message.reply_text(
            "\n".join(msg_lines),
            reply_markup=build_numeric_keyboard("newcomp_group", len(filtered)),
        )
        return

    if data.startswith("rategrp_orient:"):
        if sess.get("state") != "rategrp_choose_orientation":
            return await query.answer("Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð·Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ðµ /rategrp", show_alert=True)
        target = data.split(":", 1)[1].upper()
        if target not in NEWCOMPMUSIC_ORIENTATION_CHOICES:
            return await query.answer("ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼", show_alert=True)
        all_groups = sess.get("rategrp_groups_all") or []
        if not all_groups:
            return await query.answer("ÐÐµÑ‚ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ñ… Ð³Ñ€ÑƒÐ¿Ð¿. Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ðµ /rategrp Ð·Ð°Ð½Ð¾Ð²Ð¾.", show_alert=True)
        orientation_map = sess.get("rategrp_group_orientations") or {}
        filtered = filter_groups_by_orientation(all_groups, orientation_map, target)
        if not filtered:
            return await query.answer("ÐÐµÑ‚ Ð³Ñ€ÑƒÐ¿Ð¿ Ð² ÑÑ‚Ð¾Ð¹ Ð¾Ñ€Ð¸ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸.", show_alert=True)
        sess["rategrp_orientation_preference"] = target
        sess["rategrp_groups"] = filtered
        sess["state"] = "rategrp_choose_group"
        group_entries = [
            SourceGroupEntry(key=key, rows=list(rows), unused_count=unused)
            for key, rows, unused in filtered
        ]
        msg_lines = format_rategrp_group_prompt(sess, group_entries, target, prompt_kind="inline")
        await query.answer("ÐžÑ€Ð¸ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ñ Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð°")
        await query.message.reply_text(
            "\n".join(msg_lines),
            reply_markup=build_numeric_keyboard("rategrp_group", len(filtered)),
        )
        return

    if data.startswith("rategrp_group:"):
        if sess.get("state") != "rategrp_choose_group":
            return await query.answer("Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð²Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¾Ñ€Ð¸ÐµÐ½Ñ‚Ð°Ñ†Ð¸ÑŽ", show_alert=True)
        try:
            idx = int(data.split(":", 1)[1])
        except ValueError:
            return await query.answer("ÐÐµÐ²ÐµÑ€Ð½Ñ‹Ð¹ Ð½Ð¾Ð¼ÐµÑ€ Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹", show_alert=True)
        groups = sess.get("rategrp_groups") or []
        if not (1 <= idx <= len(groups)):
            return await query.answer("ÐÐµÑ‚ Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹ Ñ Ñ‚Ð°ÐºÐ¸Ð¼ Ð½Ð¾Ð¼ÐµÑ€Ð¾Ð¼", show_alert=True)
        key, rows, _ = groups[idx - 1]
        rows = [dict(row) for row in rows]
        orientation_label = (sess.get("rategrp_group_orientations") or {}).get(key)
        if not orientation_label:
            orientation_label = _resolution_orientation(key[1] or "")[0]
        sess["rategrp_group_choice"] = {
            "key": key,
            "label": f"{key[0]} {key[1]}",
            "orientation": orientation_label,
        }
        sess["rategrp_rerate_rows"] = rows
        queue = _prepare_rategrp_queue(rows)
        if not queue:
            available = _rategrp_available_colors(rows)
            if not available:
                return await query.answer("Ð’ ÑÑ‚Ð¾Ð¹ Ð³Ñ€ÑƒÐ¿Ð¿Ðµ Ð½ÐµÑ‚ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð².", show_alert=True)
            sess["state"] = "rategrp_choose_rerate_color"
            await query.answer("Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ñ†Ð²ÐµÑ‚ Ð´Ð»Ñ Ð¿ÐµÑ€ÐµÐ¾Ñ†ÐµÐ½ÐºÐ¸")

            async def send_rategrp(msg: str, markup: Optional[InlineKeyboardMarkup] = None) -> None:
                await query.message.reply_text(msg, reply_markup=markup)

            await send_rategrp(
                f"Ð“Ñ€ÑƒÐ¿Ð¿Ð° {key[0]} {key[1]} Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð°. ÐÐ¾Ð²Ñ‹Ñ… Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² Ð½ÐµÑ‚, Ð²Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ñ†Ð²ÐµÑ‚ Ð´Ð»Ñ Ð¿ÐµÑ€ÐµÐ¾Ñ†ÐµÐ½ÐºÐ¸:",
                build_rategrp_rerate_keyboard(available),
            )
            return
        sess["rategrp_queue"] = queue
        sess["rategrp_total"] = len(queue)
        sess["rategrp_processed"] = 0
        sess["rategrp_queue_origin"] = "unrated"
        sess["state"] = "rategrp_rate_source"

        async def send_rategrp(msg: str, markup: Optional[InlineKeyboardMarkup] = None) -> None:
            await query.message.reply_text(msg, reply_markup=markup)

        await query.answer("Ð“Ñ€ÑƒÐ¿Ð¿Ð° Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð°")
        await send_rategrp(f"Ð“Ñ€ÑƒÐ¿Ð¿Ð° {key[0]} {key[1]} Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð°. ÐÐµÐ¾Ñ†ÐµÐ½Ñ‘Ð½Ð½Ñ‹Ñ… Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð²: {len(queue)}.")
        return await rategrp_send_next_prompt(sess, send_rategrp)

    if data.startswith("rategrp_color:"):
        if sess.get("state") != "rategrp_rate_source":
            return await query.answer("Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð²Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð³Ñ€ÑƒÐ¿Ð¿Ñƒ", show_alert=True)
        color_key = data.split(":", 1)[1]
        choice = RATEGRP_COLOR_CHOICES.get(color_key)
        if not choice:
            return await query.answer("ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ Ñ†Ð²ÐµÑ‚", show_alert=True)

        async def send_rategrp(msg: str, markup: Optional[InlineKeyboardMarkup] = None) -> None:
            await query.message.reply_text(msg, reply_markup=markup)

        await query.answer(f"ÐžÑ‚Ð¼ÐµÑ‡ÐµÐ½Ð¾ {choice['emoji']}")
        return await rategrp_apply_rating(sess, color_key, send_rategrp)

    if data.startswith("rategrp_rerate_color:"):
        if sess.get("state") != "rategrp_choose_rerate_color":
            return await query.answer("Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð²Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð³Ñ€ÑƒÐ¿Ð¿Ñƒ", show_alert=True)
        color_key = data.split(":", 1)[1]

        async def send_rategrp(msg: str, markup: Optional[InlineKeyboardMarkup] = None) -> None:
            await query.message.reply_text(msg, reply_markup=markup)

        success = await _rategrp_start_rerate(sess, color_key, send_rategrp)
        if success:
            await query.answer("Ð—Ð°Ð¿ÑƒÑÐºÐ°ÑŽ Ð¿ÐµÑ€ÐµÐ¾Ñ†ÐµÐ½ÐºÑƒ")
        else:
            await query.answer("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð½Ð°Ñ‡Ð°Ñ‚ÑŒ Ð¿ÐµÑ€ÐµÐ¾Ñ†ÐµÐ½ÐºÑƒ", show_alert=True)
        return

    if data == "rategrp_rerate_back":
        if sess.get("state") != "rategrp_choose_rerate_color":
            return await query.answer("Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð²Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð³Ñ€ÑƒÐ¿Ð¿Ñƒ", show_alert=True)
        sess["state"] = "rategrp_choose_group"
        groups = sess.get("rategrp_groups") or []
        orientation = sess.get("rategrp_orientation_preference") or "?"
        group_entries = [
            SourceGroupEntry(key=key, rows=list(rows), unused_count=unused) for key, rows, unused in groups
        ]
        lines = format_rategrp_group_prompt(sess, group_entries, orientation, prompt_kind="inline")
        keyboard = build_numeric_keyboard("rategrp_group", len(groups)) if groups else None
        await query.message.reply_text("\n".join(lines), reply_markup=keyboard)
        return await query.answer("Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð´Ñ€ÑƒÐ³ÑƒÑŽ Ð³Ñ€ÑƒÐ¿Ð¿Ñƒ")

    if data.startswith("newcomp_group:"):
        if sess.get("state") != "newcompmusic_wait_group":
            return await query.answer("Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð²Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¿Ñ€Ð¾ÐµÐºÑ‚", show_alert=True)
        try:
            idx = int(data.split(":", 1)[1])
        except ValueError:
            return await query.answer("ÐÐµÐ²ÐµÑ€Ð½Ñ‹Ð¹ Ð½Ð¾Ð¼ÐµÑ€ Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹", show_alert=True)
        groups: List[Tuple[Tuple[str, str], List[sqlite3.Row], int]] = sess.get("music_groups") or []
        if not (1 <= idx <= len(groups)):
            return await query.answer("ÐÐµÑ‚ Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹ Ñ Ñ‚Ð°ÐºÐ¸Ð¼ Ð½Ð¾Ð¼ÐµÑ€Ð¾Ð¼", show_alert=True)
        key, rows, unused_count = groups[idx - 1]
        if not rows:
            return await query.answer("Ð“Ñ€ÑƒÐ¿Ð¿Ð° Ð¿ÑƒÑÑ‚Ð°Ñ", show_alert=True)

        orientation_label = (sess.get("music_group_orientations") or {}).get(key)
        if not orientation_label:
            orientation_label = _resolution_orientation(key[1] or "")[0]
        sess["music_group_choice"] = {
            "key": key,
            "count": len(rows),
            "orientation": orientation_label,
            "total_count": len(rows),
            "unused_count": unused_count,
            "group_number": idx,
        }
        sess["music_group_rows"] = list(rows)
        sess["music_folder_only_new"] = False
        sess.pop("music_color_rows", None)
        sess["state"] = "newcompmusic_choose_groupmode"

        await query.answer("Ð“Ñ€ÑƒÐ¿Ð¿Ð° Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð°")
        await query.message.reply_text(
            "Ð“Ñ€ÑƒÐ¿Ð¿Ð° Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð°. ÐšÐ°Ðº Ð±ÑƒÐ´ÐµÐ¼ Ð³Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¸?",
            reply_markup=build_newcomp_groupmode_keyboard(),
        )
        return

    if data.startswith("newcomp_folder:"):
        if sess.get("state") != "newcompmusic_wait_folder":
            return await query.answer("Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð²Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð³Ñ€ÑƒÐ¿Ð¿Ñƒ", show_alert=True)
        token = data.split(":", 1)[1]
        try:
            count, label = apply_newcomp_folder_choice(
                sess, token, next_state="newcompmusic_wait_sources"
            )
        except ValueError as exc:
            return await query.answer(str(exc), show_alert=True)

        choice = sess.get("music_group_choice") or {}
        codec, res = choice.get("key") or ("?", "?")
        project_info = sess.get("music_selected") or {}
        segs = project_info.get("segments")
        duration = project_info.get("duration")
        duration_minutes = (duration / 60.0) if duration else None

        msg_lines = [
            f"ÐŸÐ°Ð¿ÐºÐ° Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð°: {label} (Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð²: {count}).",
            f"Ð“Ñ€ÑƒÐ¿Ð¿Ð°: {codec} {res}.",
        ]
        if duration_minutes:
            msg_lines.append(f"ÐŸÑ€Ð¾Ð´Ð¾Ð»Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð° â‰ˆ {duration_minutes:.1f} Ð¼Ð¸Ð½ÑƒÑ‚.")
        if segs is not None:
            msg_lines.append(f"Ð¡Ð¼ÐµÐ½ ÐºÐ»Ð¸Ð¿Ð¾Ð²: {segs}.")
        msg_lines.append("Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ, ÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² Ð·Ð°Ð´ÐµÐ¹ÑÑ‚Ð²Ð¾Ð²Ð°Ñ‚ÑŒ:")

        await query.answer("ÐŸÐ°Ð¿ÐºÐ° Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð°")
        await query.message.reply_text(
            "\n".join(msg_lines),
            reply_markup=build_newcomp_sources_keyboard(),
        )
        return

    if data == "newcomp_folder_back":
        if sess.get("state") != "newcompmusic_wait_folder":
            return await query.answer("Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð²Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð³Ñ€ÑƒÐ¿Ð¿Ñƒ", show_alert=True)
        groups = sess.get("music_groups") or []
        if not groups:
            return await query.answer("ÐÐµÑ‚ ÑÐ¿Ð¸ÑÐºÐ° Ð³Ñ€ÑƒÐ¿Ð¿. Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ðµ Ð·Ð°Ð½Ð¾Ð²Ð¾.", show_alert=True)
        sess["state"] = "newcompmusic_wait_group"
        sess.pop("music_group_choice", None)
        sess.pop("music_group_rows", None)
        sess.pop("music_color_rows", None)
        sess["music_folder_only_new"] = False
        orientation_label = sess.get("music_orientation_preference") or "?"
        group_entries = [
            SourceGroupEntry(key=key, rows=list(rows), unused_count=unused)
            for key, rows, unused in groups
        ]
        msg_lines = _build_group_selection_lines(
            sess, group_entries, orientation_label, prompt_kind="inline"
        )
        await query.answer("Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð´Ñ€ÑƒÐ³ÑƒÑŽ Ð³Ñ€ÑƒÐ¿Ð¿Ñƒ")
        await query.message.reply_text(
            "\n".join(msg_lines),
            reply_markup=build_numeric_keyboard("newcomp_group", len(groups)),
        )
        return

    if data.startswith("newcomp_groupmode:"):
        if sess.get("state") != "newcompmusic_choose_groupmode":
            return await query.answer("Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð²Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð³Ñ€ÑƒÐ¿Ð¿Ñƒ", show_alert=True)
        mode = data.split(":", 1)[1]
        rows = sess.get("music_group_rows") or []
        if not rows:
            return await query.answer("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ð³Ñ€ÑƒÐ¿Ð¿Ñƒ.", show_alert=True)
        if mode == "folders":
            available = _count_rows_for_folder_mode(rows, False)
            if available == 0:
                return await query.answer("Ð’ Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð½Ð¾Ð¹ Ð³Ñ€ÑƒÐ¿Ð¿Ðµ Ð½ÐµÑ‚ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð².", show_alert=True)
            sess["music_color_rows"] = None
            sess["music_color_choice"] = None
            sess["music_color_autotag"] = None
            group_choice = sess.get("music_group_choice") or {}
            total = group_choice.get("total_count")
            if total:
                group_choice["count"] = total
            sess["music_group_choice"] = group_choice
            sess["music_folder_only_new"] = False
            sess["state"] = "newcompmusic_wait_folder"
            msg_text, keyboard = compose_newcomp_folder_prompt(sess)
            await query.answer("ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÑŽ Ð¿Ð°Ð¿ÐºÐ¸")
            await query.message.reply_text(msg_text, reply_markup=keyboard)
            return
        if mode == "colors":
            counts, unrated = _compute_rategrp_color_counts(rows)
            total_colored = sum(counts.values())
            if total_colored == 0:
                return await query.answer("Ð’ ÑÑ‚Ð¾Ð¹ Ð³Ñ€ÑƒÐ¿Ð¿Ðµ Ð½ÐµÑ‚ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² Ñ Ð¾Ñ†ÐµÐ½ÐºÐ°Ð¼Ð¸.", show_alert=True)
            green_emoji = RATEGRP_COLOR_CHOICES["green"]["emoji"]
            yellow_emoji = RATEGRP_COLOR_CHOICES["yellow"]["emoji"]
            red_emoji = RATEGRP_COLOR_CHOICES["red"]["emoji"]
            combo_counts = {
                "green_new": len(_filter_green_new_rows(rows)),
                "green_yellow": len(
                    _filter_rows_by_color(rows, {green_emoji, yellow_emoji}, include_unrated=False)
                ),
                "green_yellow_red": len(
                    _filter_rows_by_color(
                        rows,
                        {green_emoji, yellow_emoji, red_emoji},
                        include_unrated=False,
                    )
                ),
            }
            sess["state"] = "newcompmusic_choose_color"
            await query.answer("Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ñ†Ð²ÐµÑ‚")
            await query.message.reply_text(
                "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ñ†Ð²ÐµÑ‚ Ð¾Ñ†ÐµÐ½ÐºÐ¸:",
                reply_markup=build_newcomp_color_keyboard(counts, unrated, combo_counts),
            )
            return
        return await query.answer("ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼", show_alert=True)

    if data == "newcomp_color_back":
        if sess.get("state") != "newcompmusic_choose_color":
            return await query.answer("Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð²Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ñ€ÐµÐ¶Ð¸Ð¼", show_alert=True)
        sess["state"] = "newcompmusic_choose_groupmode"
        sess.pop("music_color_rows", None)
        sess.pop("music_color_choice", None)
        sess.pop("music_color_autotag", None)
        group_choice = sess.get("music_group_choice") or {}
        total = group_choice.get("total_count")
        if total:
            group_choice["count"] = total
        sess["music_group_choice"] = group_choice
        await query.answer("Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÑŽ Ð²Ñ‹Ð±Ð¾Ñ€")
        await query.message.reply_text(
            "ÐšÐ°Ðº Ð±ÑƒÐ´ÐµÐ¼ Ð³Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¸?",
            reply_markup=build_newcomp_groupmode_keyboard(),
        )
        return

    if data.startswith("newcomp_color:"):
        if sess.get("state") != "newcompmusic_choose_color":
            return await query.answer("Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð²Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ñ€ÐµÐ¶Ð¸Ð¼", show_alert=True)
        color_key = data.split(":", 1)[1]
        rows = sess.get("music_group_rows") or []
        choice = RATEGRP_COLOR_CHOICES.get(color_key)
        include_unrated = False
        allowed: Set[str] = set()
        if choice:
            emoji = choice["emoji"]
            allowed = {emoji}
            filtered = _filter_rows_by_color(rows, allowed, include_unrated=False)
        elif color_key == "green_new":
            allowed = {RATEGRP_COLOR_CHOICES["green"]["emoji"]}
            filtered = _filter_green_new_rows(rows)
            include_unrated = True
        elif color_key == "green_yellow":
            allowed = {
                RATEGRP_COLOR_CHOICES["green"]["emoji"],
                RATEGRP_COLOR_CHOICES["yellow"]["emoji"],
            }
            filtered = _filter_rows_by_color(rows, allowed, include_unrated=False)
        elif color_key == "green_yellow_red":
            allowed = {
                RATEGRP_COLOR_CHOICES["green"]["emoji"],
                RATEGRP_COLOR_CHOICES["yellow"]["emoji"],
                RATEGRP_COLOR_CHOICES["red"]["emoji"],
            }
            filtered = _filter_rows_by_color(rows, allowed, include_unrated=False)
        else:
            return await query.answer("ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ Ñ†Ð²ÐµÑ‚", show_alert=True)
        emoji_label = (
            choice["emoji"]
            if choice
            else {
                "green_new": f"{RATEGRP_COLOR_CHOICES['green']['emoji']}+ðŸ†•",
                "green_yellow": f"{RATEGRP_COLOR_CHOICES['green']['emoji']}+{RATEGRP_COLOR_CHOICES['yellow']['emoji']}",
                "green_yellow_red": f"{RATEGRP_COLOR_CHOICES['green']['emoji']}+{RATEGRP_COLOR_CHOICES['yellow']['emoji']}+{RATEGRP_COLOR_CHOICES['red']['emoji']}",
            }.get(color_key, "?")
        )
        if not filtered:
            return await query.answer("ÐÐµÑ‚ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² Ñ Ñ‚Ð°ÐºÐ¾Ð¹ Ð¾Ñ†ÐµÐ½ÐºÐ¾Ð¹.", show_alert=True)
        sess["music_color_rows"] = filtered
        sess["music_color_choice"] = emoji_label
        autotag = None
        if include_unrated:
            autotag_emoji = RATEGRP_COLOR_CHOICES["green"]["emoji"]
            autotag_ids: List[int] = []
            for row in filtered:
                if _rategrp_row_color(row) is None:
                    try:
                        autotag_ids.append(int(row["id"]))
                    except Exception:
                        continue
            if autotag_ids:
                autotag = {"emoji": autotag_emoji, "ids": autotag_ids}
        else:
            autotag = None
        sess["music_color_autotag"] = autotag
        group_choice = sess.get("music_group_choice") or {}
        group_choice["count"] = len(filtered)
        sess["music_group_choice"] = group_choice
        sess["state"] = "newcompmusic_wait_sources"
        codec, res = group_choice.get("key") or ("?", "?")
        msg_lines = [
            f"Ð’Ñ‹Ð±Ñ€Ð°Ð½ Ñ†Ð²ÐµÑ‚ {emoji_label}: {len(filtered)} Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð².",
            f"Ð“Ñ€ÑƒÐ¿Ð¿Ð°: {codec} {res}.",
            "Ð¡ÐºÐ¾Ð»ÑŒÐºÐ¾ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² Ð·Ð°Ð´ÐµÐ¹ÑÑ‚Ð²Ð¾Ð²Ð°Ñ‚ÑŒ? ÐŸÑ€Ð¸ÑˆÐ»Ð¸Ñ‚Ðµ Ñ‡Ð¸ÑÐ»Ð¾ Ð¸Ð»Ð¸ Ð²Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð½Ð° ÐºÐ»Ð°Ð²Ð¸Ð°Ñ‚ÑƒÑ€Ðµ.",
        ]
        await query.answer("Ð¦Ð²ÐµÑ‚ Ð²Ñ‹Ð±Ñ€Ð°Ð½")
        await query.message.reply_text(
            "\n".join(msg_lines),
            reply_markup=build_newcomp_sources_keyboard(),
        )
        return

    if data.startswith("newcomp_folder_mode:"):
        if sess.get("state") != "newcompmusic_wait_folder":
            return await query.answer("Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð²Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð³Ñ€ÑƒÐ¿Ð¿Ñƒ", show_alert=True)
        mode = data.split(":", 1)[1]
        target_unused_only = mode == "new"
        current = bool(sess.get("music_folder_only_new"))
        if target_unused_only == current:
            return await query.answer("Ð­Ñ‚Ð¾Ñ‚ Ñ€ÐµÐ¶Ð¸Ð¼ ÑƒÐ¶Ðµ Ð°ÐºÑ‚Ð¸Ð²ÐµÐ½.")
        rows = sess.get("music_group_rows") or []
        if not rows:
            return await query.answer("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¸ Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹.", show_alert=True)
        total_count = _count_rows_for_folder_mode(rows, target_unused_only)
        if target_unused_only and total_count == 0:
            return await query.answer("ÐÐ¾Ð²Ñ‹Ñ… Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² Ð² ÑÑ‚Ð¾Ð¹ Ð³Ñ€ÑƒÐ¿Ð¿Ðµ Ð½ÐµÑ‚.", show_alert=True)
        sess["music_folder_only_new"] = target_unused_only
        msg_text, keyboard = compose_newcomp_folder_prompt(sess)
        notice = "ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÑŽ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½Ð¾Ð²Ñ‹Ðµ." if target_unused_only else "Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÑŽ Ð²ÑÐµ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¸."
        await query.answer(notice)
        await query.message.reply_text(msg_text, reply_markup=keyboard)
        return

    if data.startswith("newcomp_sources:"):
        if sess.get("state") != "newcompmusic_wait_sources":
            return await query.answer("Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð²Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð³Ñ€ÑƒÐ¿Ð¿Ñƒ", show_alert=True)
        try:
            count = int(data.split(":", 1)[1])
        except ValueError:
            return await query.answer("ÐÐµÐ²ÐµÑ€Ð½Ð¾Ðµ Ñ‡Ð¸ÑÐ»Ð¾", show_alert=True)
        available = int((sess.get("music_group_choice") or {}).get("count") or 0)
        info_line = None
        if available and count > available:
            count = available
            info_line = _source_limit_message(sess, available)
        sess["music_sources"] = count
        sess["state"] = "newcompmusic_wait_algo"

        await query.answer("ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð¾" if not info_line else "Ð‘ÐµÑ€Ñ‘Ð¼ Ð¼Ð°ÐºÑÐ¸Ð¼ÑƒÐ¼")
        algo_desc = ", ".join(f"{meta['short']} ({meta['title']})" for meta in CLIP_SEQUENCE_ALGORITHMS.values())
        msg_lines = []
        if info_line:
            msg_lines.append(info_line)
        msg_lines.append(f"ÐžÐº, Ð²Ð¾Ð·ÑŒÐ¼Ñ‘Ð¼ {count} Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð².")
        msg_lines.append(
            f"Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¼ÐµÑ‚Ð¾Ð´ Ñ€Ð°Ð½Ð´Ð¾Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸ ÐºÐ»Ð¸Ð¿Ð¾Ð²: {algo_desc}",
        )
        await query.message.reply_text(
            "\n".join(msg_lines),
            reply_markup=build_newcomp_algo_keyboard(),
        )
        return

    if data.startswith("newcomp_algo:"):
        if sess.get("state") != "newcompmusic_wait_algo":
            return await query.answer("Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð²Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð²", show_alert=True)
        short = data.split(":", 1)[1]
        resolved_key = normalize_clip_algo_choice(short)
        if not resolved_key:
            return await query.answer("ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼", show_alert=True)

        async def send_from_query(message: str) -> None:
            await query.message.reply_text(message)

        await query.answer("Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñâ€¦")
        return await run_newcompmusic_generation(send_from_query, sess, resolved_key, user_id)

    await query.answer("ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð°Ñ ÐºÐ½Ð¾Ð¿ÐºÐ°", show_alert=True)


async def cmd_badfiles(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not check_access(update):
        return await unauthorized(update)

    rows = db_get_problem_sources()
    if not rows:
        return await update.message.reply_text("ÐŸÑ€Ð¾Ð±Ð»ÐµÐ¼Ð½Ñ‹Ðµ Ñ„Ð°Ð¹Ð»Ñ‹ Ð½Ðµ Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ñ‹.")

    lines = ["âš ï¸ ÐŸÑ€Ð¾Ð±Ð»ÐµÐ¼Ð½Ñ‹Ðµ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¸:"]
    for r in rows:
        lines.append(f"- id={r['id']}: {r['video_name']} â€” {r['video_path']}")
    await update.message.reply_text("\n".join(lines))


async def cmd_strategy(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not check_access(update):
        return await unauthorized(update)

    global CURRENT_STRATEGY

    args = context.args
    if not args:
        return await update.message.reply_text(
            "Ð¢ÐµÐºÑƒÑ‰Ð°Ñ ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸Ñ: " + CURRENT_STRATEGY + "\nÐ”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ðµ: " + ", ".join(ALLOWED_STRATEGIES)
        )

    name = args[0].strip().lower()
    if name not in ALLOWED_STRATEGIES:
        return await update.message.reply_text(
            "ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð°Ñ ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸Ñ. Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ðµ: " + ", ".join(ALLOWED_STRATEGIES)
        )

    CURRENT_STRATEGY = name
    return await update.message.reply_text(f"ÐžÐº, ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸Ñ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð°: {CURRENT_STRATEGY}")


async def cmd_videofx(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not check_access(update):
        return await unauthorized(update)

    global GLITCH_EFFECTS_PER_VIDEO, TRANSITION_EFFECTS_PER_VIDEO

    args = context.args
    if not args:
        return await update.message.reply_text(
            "Ð¢ÐµÐºÑƒÑ‰Ð¸Ðµ Ð²Ð¸Ð·ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ðµ ÑÑ„Ñ„ÐµÐºÑ‚Ñ‹:\n"
            f"- Ð³Ð»Ð¸Ñ‚Ñ‡-Ð²ÑÑ‚Ð°Ð²Ð¾Ðº: {GLITCH_EFFECTS_PER_VIDEO}\n"
            f"- Ð¿ÐµÑ€ÐµÑ…Ð¾Ð´Ð¾Ð²: {TRANSITION_EFFECTS_PER_VIDEO}\n\n"
            "Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ /videofx <Ð³Ð»Ð¸Ñ‚Ñ‡ÐµÐ¹> <Ð¿ÐµÑ€ÐµÑ…Ð¾Ð´Ð¾Ð²>, Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€ /videofx 6 3."
        )

    try:
        glitches = max(0, int(args[0]))
        transitions = max(
            0, int(args[1]) if len(args) > 1 else TRANSITION_EFFECTS_PER_VIDEO
        )
    except ValueError:
        return await update.message.reply_text(
            "ÐÑƒÐ¶Ð½Ð¾ ÑƒÐºÐ°Ð·Ð°Ñ‚ÑŒ Ñ†ÐµÐ»Ñ‹Ðµ Ñ‡Ð¸ÑÐ»Ð°: /videofx <Ð³Ð»Ð¸Ñ‚Ñ‡ÐµÐ¹> <Ð¿ÐµÑ€ÐµÑ…Ð¾Ð´Ð¾Ð²>"
        )

    GLITCH_EFFECTS_PER_VIDEO = glitches
    TRANSITION_EFFECTS_PER_VIDEO = transitions
    return await update.message.reply_text(
        f"Ð“Ð¾Ñ‚Ð¾Ð²Ð¾. Ð“Ð»Ð¸Ñ‚Ñ‡ÐµÐ¹: {GLITCH_EFFECTS_PER_VIDEO}, Ð¿ÐµÑ€ÐµÑ…Ð¾Ð´Ð¾Ð²: {TRANSITION_EFFECTS_PER_VIDEO}."
    )



async def cmd_ratepmv(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not check_access(update):
        return await unauthorized(update)

    rows = db_get_all_compilations()
    if not rows:
        return await update.message.reply_text("ÐŸÐ¾Ñ…Ð¾Ð¶Ðµ, Ð¿Ð¾ÐºÐ° Ð½ÐµÑ‚ Ð³Ð¾Ñ‚Ð¾Ð²Ñ‹Ñ… PMV Ð¸ Ð¾Ñ†ÐµÐ½Ð¸Ð²Ð°Ñ‚ÑŒ Ð½ÐµÑ‡ÐµÐ³Ð¾.")

    unrated = []
    for r in rows:
        comments = (r["comments"] or "").lower()
        if "pmv_rating=" not in comments:
            unrated.append(r)

    if not unrated:
        return await update.message.reply_text("Ð’ÑÐµ PMV ÑƒÐ¶Ðµ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ð»Ð¸ Ð¾Ñ†ÐµÐ½ÐºÐ¸! ðŸ”¥")

    unrated_sorted = sorted(
        unrated,
        key=lambda row: ((row["pmv_date"] or ""), int(row["id"] or 0)),
    )
    display_rows = unrated_sorted[:10]
    remaining = max(0, len(unrated_sorted) - len(display_rows))

    lines = [f"Ð‘ÐµÐ· Ð¾Ñ†ÐµÐ½ÐºÐ¸ Ð¾ÑÑ‚Ð°Ð»Ð¾ÑÑŒ PMV: {len(unrated_sorted)}."]
    if remaining > 0:
        lines.append(f"ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÑŽ 10 ÑÐ°Ð¼Ñ‹Ñ… ÑÑ‚Ð°Ñ€Ñ‹Ñ…, ÐµÑ‰Ñ‘ Ð¶Ð´ÑƒÑ‚ ÑÐ²Ð¾ÐµÐ¹ Ð¾Ñ‡ÐµÑ€ÐµÐ´Ð¸: {remaining}.")
    lines.append("")
    for idx, r in enumerate(display_rows, 1):
        name = Path(r["video_path"]).name
        date_str = r["pmv_date"]
        lines.append(f"{idx}. {name} (Ð´Ð°Ñ‚Ð°: {date_str}, id={r['id']})")

    lines.append("")
    lines.append("ÐœÐ¾Ð¶ÐµÑˆÑŒ Ð²Ñ‹Ð±Ñ€Ð°Ñ‚ÑŒ PMV ÐºÐ½Ð¾Ð¿ÐºÐ¾Ð¹ Ð¸Ð»Ð¸ Ð¿Ñ€Ð¸ÑÐ»Ð°Ñ‚ÑŒ Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼ `<Ð½Ð¾Ð¼ÐµÑ€> <Ð¾Ñ†ÐµÐ½ÐºÐ° 1-5>` (Ð¿Ñ€Ð¸Ð¼ÐµÑ€: `2 5`).")
    lines.append("Ð”Ð»Ñ Ð¿Ð°ÐºÐµÑ‚Ð½Ð¾Ð¹ Ð¾Ñ†ÐµÐ½ÐºÐ¸ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÑŒ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð¿Ð°Ñ€ Ð¿Ð¾Ð´Ñ€ÑÐ´: `<1 5 2 4 3 5>` Ð¸Ð»Ð¸ Ð½Ð°Ð¶Ð¼Ð¸ ÐºÐ½Ð¾Ð¿ÐºÑƒ `-> Ð²ÑÐµÐ¼` ÑÐ¾ ÑÐ½Ð¸Ð·Ñƒ ÐºÐ»Ð°Ð²Ð¸Ð°Ñ‚ÑƒÑ€Ñ‹.")

    user_sessions[update.effective_user.id] = {
        "state": "ratepmv_choose_pmv",
        "pmv_rows": display_rows,
    }

    await update.message.reply_text(
        "\n".join(lines),
        reply_markup=build_ratepmv_pmv_keyboard(display_rows),
    )




def get_source_groups_prefer_unused() -> List[Tuple[Tuple[str, str], List[sqlite3.Row], int]]:
    unused = db_get_unused_sources_grouped()
    all_groups = db_get_all_sources_grouped()
    all_keys = set(all_groups.keys()) | set(unused.keys())
    entries: List[SourceGroupEntry] = []

    for key in all_keys:
        rows_all = all_groups.get(key) or []
        if len(rows_all) <= 5:
            continue
        unused_count = len(unused.get(key) or [])
        entries.append(SourceGroupEntry(key=key, rows=list(rows_all), unused_count=unused_count))

    sorted_entries = sort_source_group_entries(entries)
    return [(entry.key, entry.rows, entry.unused_count) for entry in sorted_entries]


async def cmd_newcompmusic(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not check_access(update):
        return await unauthorized(update)

    projects = load_music_projects()
    if not projects:
        return await update.message.reply_text(
            "ÐŸÐ°Ð¿ÐºÐ° music_projects Ð¿ÑƒÑÑ‚Ð°. Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° ÑÐ¾Ð·Ð´Ð°Ð¹Ñ‚Ðµ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ñ‹ Ñ‡ÐµÑ€ÐµÐ· music_guided_generator.py."
        )

    project_map: Dict[str, Dict[str, Any]] = {}
    unused_tokens: List[str] = []
    used_tokens: List[str] = []
    for idx, proj in enumerate(projects, 1):
        token = f"mp{idx}"
        project_map[token] = proj
        if proj.get("usage_count"):
            used_tokens.append(token)
        else:
            unused_tokens.append(token)

    session_payload = {
        "state": "newcompmusic_wait_project",
        "music_projects_map": project_map,
        "music_projects_unused": unused_tokens,
        "music_projects_used": used_tokens,
        "music_projects": projects,
        "music_projects_duration_filter": None,
    }
    user_sessions[update.effective_user.id] = session_payload

    show_used = not unused_tokens and bool(used_tokens)
    if show_used and not session_payload.get("music_projects_duration_filter"):
        async def send_duration(text: str, markup: Optional[InlineKeyboardMarkup] = None) -> None:
            await update.message.reply_text(text, reply_markup=markup)

        await prompt_newcomp_duration(session_payload, send_duration)
        return

    text, keyboard = build_newcomp_project_keyboard(session_payload, show_used=show_used)
    await update.message.reply_text(text, reply_markup=keyboard)


async def cmd_randompmv(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not check_access(update):
        return await unauthorized(update)

    user_sessions[update.effective_user.id] = {
        "state": "randompmv_wait_count",
    }
    msg = (
        "CreateRandomPMV: Ð²Ñ‹Ð±ÐµÑ€Ð¸, ÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð¾Ð² ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ (5â€“30), "
        "Ð° Ð·Ð°Ñ‚ÐµÐ¼ Ð·Ð°Ð´Ð°Ð¹ Ð¼Ð¸Ð½Ð¸Ð¼ÑƒÐ¼ Ð½Ð¾Ð²Ñ‹Ñ… Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¾Ð² (0â€“60) Ð´Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ PMV. "
        "Ð‘Ð¾Ñ‚ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð¿Ð¾Ð´Ð±ÐµÑ€Ñ‘Ñ‚ Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹ Ð¸ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ñ‹ Ð¿Ð¾Ð´ ÑÑ‚Ð¸ Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ñ."
    )
    await update.message.reply_text(msg, reply_markup=build_randompmv_count_keyboard())


async def cmd_rategrp(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not check_access(update):
        return await unauthorized(update)

    groups = get_source_groups_prefer_unused()
    if not groups:
        return await update.message.reply_text("ÐÐµÑ‚ Ð³Ñ€ÑƒÐ¿Ð¿ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð². Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð¿Ñ€Ð¾ÑÐºÐ°Ð½Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ /scan.")

    group_entries = [
        SourceGroupEntry(key=key, rows=list(rows), unused_count=unused_count)
        for key, rows, unused_count in groups
    ]
    sorted_entries, orientation_map = sort_group_entries_with_orientation(group_entries)

    session_payload = {
        "state": "rategrp_choose_orientation",
        "rategrp_group_orientations": orientation_map,
        "rategrp_groups_all": [
            (entry.key, entry.rows, entry.unused_count) for entry in sorted_entries
        ],
        "rategrp_groups": [],
        "rategrp_orientation_preference": None,
    }
    user_sessions[update.effective_user.id] = session_payload

    lines = [
        "ÐšÐ¾Ð¼Ð°Ð½Ð´Ð° rategrp: Ð¾Ñ†ÐµÐ½ÐºÐ° Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð² Ñ†Ð²ÐµÑ‚Ð°Ð¼Ð¸.",
        "Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð²Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¾Ñ€Ð¸ÐµÐ½Ñ‚Ð°Ñ†Ð¸ÑŽ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð²: VR, HOR Ð¸Ð»Ð¸ VER,",
        "Ð¸Ð»Ð¸ Ð½Ð°Ð¶Ð¼Ð¸Ñ‚Ðµ Â«Ð˜Ð— PMVÂ», Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ ÑÐ»ÑƒÑ‡Ð°Ð¹Ð½Ñ‹Ðµ Ð½ÐµÐ¾Ñ†ÐµÐ½Ñ‘Ð½Ð½Ñ‹Ðµ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¸ Ð¸Ð· ÑÐ²ÐµÐ¶Ð¸Ñ… PMV.",
    ]
    await update.message.reply_text(
        "\n".join(lines),
        reply_markup=build_rategrp_orientation_keyboard(),
    )


async def cmd_reports(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not check_access(update):
        return await unauthorized(update)

    user_sessions[update.effective_user.id] = {
        "state": "reports_wait_choice",
    }
    await update.message.reply_text(
        "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚ Ð¿Ð¾ Ñ†Ð²ÐµÑ‚Ñƒ Ð¸ Ð³Ñ€ÑƒÐ¿Ð¿Ð°Ð¼.",
        reply_markup=build_reports_keyboard(),
    )


async def cmd_find(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not check_access(update):
        return await unauthorized(update)
    user_id = update.effective_user.id
    user_sessions[user_id] = {
        "state": "find_wait_term",
        "find_mode": True,
        "find_matches": [],
    }
    await update.message.reply_text(
        "ÐŸÑ€Ð¸ÑˆÐ»Ð¸Ñ‚Ðµ Ñ‡Ð°ÑÑ‚ÑŒ Ð¸Ð¼ÐµÐ½Ð¸ Ñ„Ð°Ð¹Ð»Ð°, Ð´Ð°Ñ‚Ñ‹ Ð¸Ð»Ð¸ Ð¾Ñ‚Ð¼ÐµÑ‚ÐºÐ¸ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸. "
        "Ð¯ Ð½Ð°Ð¹Ð´Ñƒ ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ñ ÑÑ€ÐµÐ´Ð¸ Ð³Ð¾Ñ‚Ð¾Ð²Ñ‹Ñ… PMV Ð¸ ÑÑ€ÐµÐ´Ð¸ Ð¸ÑÑ…Ð¾Ð´Ð½Ð¸ÐºÐ¾Ð².",
    )


async def cmd_musicprep(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not check_access(update):
        return await unauthorized(update)

    files = list_music_input_files()
    if not files:
        return await update.message.reply_text(
            f"ÐŸÐ°Ð¿ÐºÐ° {MUSIC_INPUT_DIR} Ð¿ÑƒÑÑ‚Ð°. Ð”Ð¾Ð±Ð°Ð²ÑŒÑ‚Ðµ Ñ‚ÑƒÐ´Ð° MP3/FLAC/M4A Ð¸ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð¸Ñ‚Ðµ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñƒ."
        )

    usage_map = collect_music_track_usage()
    track_map: Dict[str, Dict[str, Any]] = {}
    unused_tokens: List[str] = []
    used_tokens: List[str] = []

    for idx, path in enumerate(sorted(files, key=lambda p: p.name.lower()), 1):
        token = f"mt{idx}"
        norm = _normalize_path_str(path)
        count = usage_map.get(norm, 0)
        track_map[token] = {
            "path": str(path),
            "usage": count,
        }
        if count:
            used_tokens.append(token)
        else:
            unused_tokens.append(token)

    session_payload = {
        "state": "musicprep_wait_track",
        "music_tracks": track_map,
        "music_tracks_unused": unused_tokens,
        "music_tracks_used": used_tokens,
    }
    user_sessions[update.effective_user.id] = session_payload

    show_used = not unused_tokens and bool(used_tokens)
    text, keyboard = build_musicprep_track_keyboard(session_payload, show_used=show_used)
    await update.message.reply_text(text, reply_markup=keyboard)


async def cmd_musicprepcheck(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not check_access(update):
        return await unauthorized(update)

    projects = load_music_projects()
    if not projects:
        return await update.message.reply_text(
            "ÐŸÐ°Ð¿ÐºÐ° music_projects Ð¿ÑƒÑÑ‚Ð°. Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° ÑÐ¾Ð·Ð´Ð°Ð¹Ñ‚Ðµ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ñ‹ Ñ‡ÐµÑ€ÐµÐ· music_guided_generator.py."
        )

    project_map: Dict[str, Dict[str, Any]] = {}
    for proj in projects:
        slug = proj.get("slug") or sanitize_filename(proj.get("name") or "project")
        project_map[slug] = proj
    keyboard = build_musicprepcheck_keyboard(projects)
    user_sessions[update.effective_user.id] = {
        "state": "musicprepcheck_wait_project",
        "musicprepcheck_projects": project_map,
    }

    await update.message.reply_text(
        "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¿Ñ€Ð¾ÐµÐºÑ‚, Ð¸ Ñ ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÑŽ MP3 ÑÐ¾ Ñ‰ÐµÐ»Ñ‡ÐºÐ°Ð¼Ð¸ Ð¿Ð¾ ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ð°Ð¼ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°.",
        reply_markup=keyboard,
    )


async def cmd_move2oculus(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not check_access(update):
        return await unauthorized(update)

    script_path = SCRIPT_DIR / "move2oculus.py"
    if not script_path.exists():
        return await update.message.reply_text("move2oculus.py Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½ Ñ€ÑÐ´Ð¾Ð¼ ÑÐ¾ ÑÐºÑ€Ð¸Ð¿Ñ‚Ð¾Ð¼.")

    await update.message.reply_text("Ð—Ð°Ð¿ÑƒÑÐºÐ°ÑŽ ÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð¸Ð·Ð°Ñ†Ð¸ÑŽ Ñ Oculus. ÐŸÐ¾Ð´Ð¾Ð¶Ð´Ð¸Ñ‚Ðµ, ÑÑ‚Ð¾ Ð¼Ð¾Ð¶ÐµÑ‚ Ð·Ð°Ð½ÑÑ‚ÑŒ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð¼Ð¸Ð½ÑƒÑ‚...")

    process = await asyncio.create_subprocess_exec(
        sys.executable,
        str(script_path),
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.PIPE,
    )

    stdout_lines: List[str] = []
    stderr_lines: List[str] = []
    chunk_size = 3500
    output_queue: asyncio.Queue[Tuple[str, str]] = asyncio.Queue()

    async def send_chunks(msg: str) -> None:
        if not msg:
            return
        for i in range(0, len(msg), chunk_size):
            await update.message.reply_text(msg[i : i + chunk_size])

    async def read_stream(stream, label: str, collector: List[str]) -> None:
        while True:
            line = await stream.readline()
            if not line:
                break
            text = line.decode(errors="ignore").rstrip()
            if not text:
                continue
            collector.append(text)
            await output_queue.put((label, text))

    async def pump_output() -> None:
        while True:
            label, text = await output_queue.get()
            prefix = "STDOUT" if label == "stdout" else "STDERR"
            await send_chunks(f"{prefix}: {text}")
            output_queue.task_done()

    stdout_task = asyncio.create_task(read_stream(process.stdout, "stdout", stdout_lines))
    stderr_task = asyncio.create_task(read_stream(process.stderr, "stderr", stderr_lines))
    pump_task = asyncio.create_task(pump_output())

    await process.wait()
    await stdout_task
    await stderr_task
    await output_queue.join()
    pump_task.cancel()
    with contextlib.suppress(asyncio.CancelledError):
        await pump_task

    returncode = process.returncode or 0
    if returncode == 0:
        header = "âœ… Ð¡Ð¸Ð½Ñ…Ñ€Ð¾Ð½Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð°."
    else:
        header = f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° (ÐºÐ¾Ð´ {returncode})."

    tail_stdout = "\n".join(stdout_lines[-20:])
    tail_stderr = "\n".join(stderr_lines[-20:])
    parts = [header]
    if tail_stdout:
        parts.append("ÐŸÐ¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ:\n" + tail_stdout)
    if tail_stderr:
        parts.append("STDERR (Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ ÑÑ‚Ñ€Ð¾ÐºÐ¸):\n" + tail_stderr)
    await send_chunks("\n\n".join(parts))


# =========================
# MAIN
# =========================

def main() -> None:
    print(f"Ð—Ð°Ð¿ÑƒÑÐº PMV Telegram Bot {BUILD_NAME}")
    init_db()
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    app = ApplicationBuilder().token(TELEGRAM_BOT_TOKEN).build()

    # Command handlers
    app.add_handler(CommandHandler("start", cmd_start))
    app.add_handler(CommandHandler("addfolder", cmd_addfolder))
    app.add_handler(CommandHandler("folders", cmd_folders))
    app.add_handler(CommandHandler("scan", cmd_scan))
    app.add_handler(CommandHandler("scanignore", cmd_scanignore))
    app.add_handler(CommandHandler("pmvnew", cmd_pmvnew))
    app.add_handler(CommandHandler("ratepmv", cmd_ratepmv))
    app.add_handler(CommandHandler("badfiles", cmd_badfiles))
    app.add_handler(CommandHandler("strategy", cmd_strategy))
    app.add_handler(CommandHandler("videofx", cmd_videofx))
    app.add_handler(CommandHandler("pmvold", cmd_pmvold))
    app.add_handler(CommandHandler("compmv", cmd_compmv))
    app.add_handler(CommandHandler("comvid", cmd_comvid))
    app.add_handler(CommandHandler("lookcom", cmd_lookcom))
    app.add_handler(CommandHandler("autocreate", cmd_autocreate))
    app.add_handler(CommandHandler("newcompmusic", cmd_newcompmusic))
    app.add_handler(CommandHandler("createrandompmv", cmd_randompmv))
    app.add_handler(CommandHandler("rategrp", cmd_rategrp))
    app.add_handler(CommandHandler("reports", cmd_reports))
    app.add_handler(CommandHandler("find", cmd_find))
    app.add_handler(CommandHandler("musicprep", cmd_musicprep))
    app.add_handler(CommandHandler("musicprepcheck", cmd_musicprepcheck))
    app.add_handler(CommandHandler("move2oculus", cmd_move2oculus))
    app.add_handler(CallbackQueryHandler(handle_callback))

    # Text handler
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))


    app.run_polling()


if __name__ == "__main__":
    main()
