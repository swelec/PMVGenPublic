#!/usr/bin/env python3
# coding: utf-8

import contextlib
import os
import json
import re
import sqlite3
import subprocess
import tempfile
import time
import shutil
import random
import unicodedata
import shlex
from pathlib import Path
from datetime import datetime, date
from dataclasses import dataclass
from typing import Any, Callable, Dict, Iterable, List, Tuple, Optional, Union, Awaitable, Set
from collections import defaultdict
import math
import wave
from array import array

from shutil import which

import zipfile
import urllib.request
import importlib.util
import asyncio
import sys
import types
from bisect import bisect_left, bisect_right
import heapq

try:
    import private_settings  # type: ignore
except ModuleNotFoundError:
    private_settings = types.SimpleNamespace()

_PRIVATE_SETTING_SENTINEL = object()


def _get_private_setting(name: str, default: Any = None) -> Any:
    value = getattr(private_settings, name, _PRIVATE_SETTING_SENTINEL)
    if value is not _PRIVATE_SETTING_SENTINEL:
        return value
    value = os.environ.get(name, _PRIVATE_SETTING_SENTINEL)
    if value is not _PRIVATE_SETTING_SENTINEL:
        return value
    return default


def _coerce_int(value: Any, default: int) -> int:
    try:
        return int(value)
    except (TypeError, ValueError):
        return default

def _coerce_bool(value: Any, default: bool) -> bool:
    """
    ????????? ???????? ???????? ? bool, ??????????? ?????? ???? true/false, 1/0 ? ?.?.
    """
    if value in (_PRIVATE_SETTING_SENTINEL, None):
        return default
    if isinstance(value, bool):
        return value
    if isinstance(value, (int, float)):
        return bool(value)
    text = str(value).strip().lower()
    if text in {"1", "true", "yes", "on", "y"}:
        return True
    if text in {"0", "false", "no", "off", "n"}:
        return False
    return default


from telegram import (
    Update,
    InlineKeyboardButton,
    InlineKeyboardMarkup,
    KeyboardButton,
    ReplyKeyboardMarkup,
)
from telegram.ext import (
    ApplicationBuilder,
    CommandHandler,
    CallbackQueryHandler,
    MessageHandler,
    ContextTypes,
    filters,
)

from scan import ScanEnvironment, run_scan
from reports import ReportEnvironment, build_color_group_report

# =========================
# –ì–õ–û–ë–ê–õ–¨–ù–´–ï –ù–ê–°–¢–†–û–ô–ö–ò
# =========================

BUILD_NAME = "build3444"

SCRIPT_DIR = Path(__file__).resolve().parent

FFMPEG_ZIP_URL = "https://www.gyan.dev/ffmpeg/builds/ffmpeg-release-essentials.zip"


def _ensure_ffmpeg_binaries() -> None:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –µ—Å—Ç—å –ª–∏ ffmpeg.exe –∏ ffprobe.exe —Ä—è–¥–æ–º —Å–æ —Å–∫—Ä–∏–ø—Ç–æ–º.
    –ï—Å–ª–∏ –Ω–µ—Ç ‚Äî —Å–∫–∞—á–∏–≤–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω—é—é —Å–±–æ—Ä–∫—É FFmpeg (release-essentials),
    –≤—ã—Ç–∞—Å–∫–∏–≤–∞–µ—Ç –±–∏–Ω–∞—Ä–Ω–∏–∫–∏ –∏ –∫–ª–∞–¥—ë—Ç –≤ SCRIPT_DIR.
    """
    ffmpeg_path = SCRIPT_DIR / "ffmpeg.exe"
    ffprobe_path = SCRIPT_DIR / "ffprobe.exe"

    if ffmpeg_path.exists() and ffprobe_path.exists():
        # –£–∂–µ –µ—Å—Ç—å ‚Äî –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º
        return

    print("[FFMPEG] ffmpeg.exe –∏–ª–∏ ffprobe.exe –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –°–∫–∞—á–∏–≤–∞—é FFmpeg...")

    import tempfile
    import shutil

    try:
        with tempfile.TemporaryDirectory() as tmpdir:
            tmpdir = Path(tmpdir)
            zip_path = tmpdir / "ffmpeg.zip"

            # –°–∫–∞—á–∏–≤–∞–µ–º –∞—Ä—Ö–∏–≤
            print(f"[FFMPEG] –°–∫–∞—á–∏–≤–∞–Ω–∏–µ {FFMPEG_ZIP_URL} ...")
            urllib.request.urlretrieve(FFMPEG_ZIP_URL, zip_path)

            # –†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º
            print("[FFMPEG] –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∞—Ä—Ö–∏–≤–∞...")
            with zipfile.ZipFile(zip_path, "r") as zf:
                members = zf.namelist()

                # –ò—â–µ–º ffmpeg.exe –∏ ffprobe.exe –≤–Ω—É—Ç—Ä–∏ –∞—Ä—Ö–∏–≤–∞
                ffmpeg_member = None
                ffprobe_member = None

                for m in members:
                    lower = m.lower()
                    if lower.endswith("bin/ffmpeg.exe"):
                        ffmpeg_member = m
                    elif lower.endswith("bin/ffprobe.exe"):
                        ffprobe_member = m

                if not ffmpeg_member or not ffprobe_member:
                    raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ ffmpeg.exe –∏–ª–∏ ffprobe.exe –≤ –∞—Ä—Ö–∏–≤–µ FFmpeg")

                # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É
                zf.extract(ffmpeg_member, tmpdir)
                zf.extract(ffprobe_member, tmpdir)

                # –ö–æ–ø–∏—Ä—É–µ–º —Ä—è–¥–æ–º —Å–æ —Å–∫—Ä–∏–ø—Ç–æ–º
                extracted_ffmpeg = tmpdir / ffmpeg_member
                extracted_ffprobe = tmpdir / ffprobe_member

                shutil.copy2(extracted_ffmpeg, ffmpeg_path)
                shutil.copy2(extracted_ffprobe, ffprobe_path)

            print("[FFMPEG] ffmpeg.exe –∏ ffprobe.exe —Å–∫–∞—á–∞–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã —Ä—è–¥–æ–º —Å–æ —Å–∫—Ä–∏–ø—Ç–æ–º.")
    except Exception as e:
        raise RuntimeError(
            f"–ù–µ —É–¥–∞–ª–æ—Å—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–∫–∞—á–∞—Ç—å –∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å FFmpeg: {e}\n"
            f"–ü–æ–ø—Ä–æ–±—É–π —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å FFmpeg –≤—Ä—É—á–Ω—É—é –∏–ª–∏ —á–µ—Ä–µ–∑ winget."
        )



def _locate_bin(name: str) -> str:
    """
    –ò—â–µ–º –±–∏–Ω–∞—Ä–Ω–∏–∫ –≤ —Ç–∞–∫–æ–º –ø–æ—Ä—è–¥–∫–µ:
    1) –í –ø–∞–ø–∫–µ —Å–æ —Å–∫—Ä–∏–ø—Ç–æ–º (SCRIPT_DIR/ffmpeg.exe –∏ —Ç.–ø.)
    2) –î–ª—è ffmpeg/ffprobe ‚Äî –ø—ã—Ç–∞–µ–º—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–∫–∞—á–∞—Ç—å
    3) –í —Å–∏—Å—Ç–µ–º–Ω–æ–º PATH (which)
    """
    exe_name = name + ".exe" if os.name == "nt" else name

    # 1. –õ–æ–∫–∞–ª—å–Ω–æ, —Ä—è–¥–æ–º —Å–æ —Å–∫—Ä–∏–ø—Ç–æ–º
    local_path = SCRIPT_DIR / exe_name
    if local_path.exists():
        return str(local_path)

    # 2. –î–ª—è ffmpeg/ffprobe ‚Äî –∞–≤—Ç–æ–¥–æ–∫–∞—á–∫–∞
    if name in ("ffmpeg", "ffprobe"):
        _ensure_ffmpeg_binaries()
        if local_path.exists():
            return str(local_path)

    # 3. –í PATH
    found = which(name)
    if found:
        return found

    raise FileNotFoundError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –±–∏–Ω–∞—Ä–Ω–∏–∫ '{name}'. "
                            f"–ü–æ–ø—Ä–æ–±—É–π —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –µ–≥–æ –≤ PATH –∏–ª–∏ –ø–æ–ª–æ–∂–∏—Ç—å {exe_name} —Ä—è–¥–æ–º —Å–æ —Å–∫—Ä–∏–ø—Ç–æ–º.")

DB_PATH = SCRIPT_DIR / "pmv_bot.db"
OUTPUT_DIR = SCRIPT_DIR / "output"
_network_output_root_value = _get_private_setting("NETWORK_OUTPUT_ROOT")
_enable_network_copy_value = _get_private_setting("ENABLE_NETWORK_COPY")
ENABLE_NETWORK_COPY = _coerce_bool(_enable_network_copy_value, False)
NETWORK_OUTPUT_ROOT = (
    Path(str(_network_output_root_value))
    if _network_output_root_value
    else OUTPUT_DIR
)
MEDIA_PLAYER_EXECUTABLE = Path(r"C:\Program Files (x86)\K-Lite Codec Pack\MPC-HC64\mpc-hc64.exe")
TEMP_DIRS = [
    SCRIPT_DIR / "tmp",
    OUTPUT_DIR,
]
MUSIC_PROJECTS_DIR = SCRIPT_DIR / "music_projects"
MUSIC_INPUT_DIR = SCRIPT_DIR / "Music"

_music_generator_module = None
MUSIC_INPUT_DIR = SCRIPT_DIR / "Music"

DEFAULT_EXTS = {".mp4", ".mov", ".mkv", ".m4v"}

# –ì–õ–û–ë–ê–õ–¨–ù–´–ï –ü–£–¢–ò –ö FFMPEG/FFPROBE
FFMPEG_BIN = _locate_bin("ffmpeg")
FFPROBE_BIN = _locate_bin("ffprobe")

LOGS_DIR = SCRIPT_DIR / "logs"
RANDOMPMV_LOG_PATH = LOGS_DIR / "randompmv_history.jsonl"
CODEX_FEEDBACK_LOG_PATH = LOGS_DIR / "codex_feedback.jsonl"


# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞—Ä–µ–∑–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
DEFAULT_TARGET_MINUTES = 30       # –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤–≤–µ–¥—ë—Ç —á—É—à—å ‚Äî –ø–æ–¥—Å—Ç—Ä–∞—Ö—É–µ–º—Å—è
PER_FILE_MIN_SECONDS = 300        # 5 –º–∏–Ω—É—Ç (–º–∏–Ω–∏–º—É–º, –ù–û —Ç–µ–ø–µ—Ä—å –Ω–µ –ª–æ–º–∞–µ—Ç —Ç–∞—Ä–≥–µ—Ç)
PER_FILE_MAX_SECONDS = 600        # 10 –º–∏–Ω—É—Ç
RANDOM_SEED = 42
USE_TS_CONCAT = True              # –∫–∞–∫ –∏ —Ä–∞–Ω—å—à–µ
MAX_OUTPUT_BYTES = 100 * 1024**3  # –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ —Ä–∞–∑–º–µ—Ä –∏—Ç–æ–≥–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞ (~100 –ì–ë)
SNAP_TO_KEYFRAMES = True          # –ø–æ–¥—Å—Ç—Ä–∞–∏–≤–∞—Ç—å —Å—Ç–∞—Ä—Ç –∫–ª–∏–ø–æ–≤ –∫ –ø—Ä–µ–¥—ã–¥—É—â–µ–º—É –∫–ª—é—á–µ–≤–æ–º—É –∫–∞–¥—Ä—É
PER_DIR_MAX_FIRST_PASS = 1        # –Ω–∞ –ø–µ—Ä–≤–æ–º –ø—Ä–æ—Ö–æ–¥–µ –±—Ä–∞—Ç—å –Ω–µ –±–æ–ª–µ–µ N –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ –∏–∑ –ø–∞–ø–∫–∏
MIN_SMALL_CLIP_SECONDS = 3        # –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –º–∞–ª–µ–Ω—å–∫–æ–≥–æ –∫–ª–∏–ø–∞ (—Å–µ–∫)
ALLOWED_STRATEGIES = ["max_group", "weighted_random", "random"]
CURRENT_STRATEGY = "max_group"
GLITCH_EFFECTS_PER_VIDEO = 0      # —Å–∫–æ–ª—å–∫–æ –≥–ª–∏—Ç—á-–≤—Å—Ç–∞–≤–æ–∫ –¥–µ–ª–∞—Ç—å –Ω–∞ –≤–∏–¥–µ–æ
TRANSITION_EFFECTS_PER_VIDEO = 0  # —Å–∫–æ–ª—å–∫–æ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ –¥–æ–±–∞–≤–ª—è—Ç—å –º–µ–∂–¥—É –∫–ª–∏–ø–∞–º–∏
FX_GLITCH_DURATION = 0.25         # –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≥–ª–∏—Ç—á-–≤—Å—Ç–∞–≤–∫–∏ (—Å–µ–∫)
FX_TRANSITION_DURATION = 0.35     # –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–µ—Ä–µ—Ö–æ–¥–∞ (—Å–µ–∫)
XFADE_TRANSITIONS = [
    "fade",
    "fadeblack",
    "fadewhite",
    "wipeleft",
    "wiperight",
    "wipeup",
    "wipedown",
    "smoothleft",
    "smoothright",
    "circleopen",
    "circleclose",
]
POI_POINTS_PER_MIN_RANGE = (1, 3)
POI_SPREAD_SECONDS = 2.0
POI_ANALYSIS_RESET = 1.0
POI_MAX_POINTS = 120
RATEGRP_PMV_MAX_QUEUE = 250
CLIP_HEAD_GUARD_SECONDS = 60
CLIP_TAIL_GUARD_SECONDS = 60
NAS_SSH_HOST = _get_private_setting("NAS_SSH_HOST", "")
NAS_SSH_PORT = _coerce_int(_get_private_setting("NAS_SSH_PORT", 22), 22)
NAS_SSH_USER = _get_private_setting("NAS_SSH_USER", "")
NAS_SSH_PASSWORD = _get_private_setting("NAS_SSH_PASSWORD", "")
NAS_SHARE_PREFIX = _get_private_setting("NAS_SHARE_PREFIX", "")
NAS_SHARE_ROOT = _get_private_setting("NAS_SHARE_ROOT", "")
NAS_SIM_REMOTE_ROOT = _get_private_setting("NAS_SIM_REMOTE_ROOT", "")
NAS_SYMLINK_COLOR_FOLDERS = {
    "green": "green",
    "yellow": "yellow",
    "red": "red",
    "pink": "pink",
    "blue": "blue",
    "favorite": "favorite",
    "inspect": "inspect",
    "delete": "delete",
}
NAS_SSH_TIMEOUT = _coerce_int(_get_private_setting("NAS_SSH_TIMEOUT", 30), 30)
NEWCOMPMUSIC_DURATION_BUCKETS = [
    ("short", "1‚Äì4 –º–∏–Ω", 0, 4 * 60 + 59),
    ("medium", "5‚Äì8 –º–∏–Ω", 5 * 60, 8 * 60 + 59),
    ("long", "9+ –º–∏–Ω", 9 * 60, None),
]
NEWCOMPMUSIC_DURATION_LABELS = {key: label for key, label, _, _ in NEWCOMPMUSIC_DURATION_BUCKETS}

RANDOMPMV_COUNT_OPTIONS = [5, 10, 15, 20, 25, 30]
RANDOMPMV_MIN_BATCH = 1
RANDOMPMV_MAX_BATCH = 30
RANDOMPMV_SOURCES_PER_MINUTE = 5.0  # –±–∞–∑–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, –æ—Å—Ç–∞–≤–ª–µ–Ω–æ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
RANDOMPMV_MIN_SOURCES_PER_MINUTE = 2.0
RANDOMPMV_MAX_SOURCES_PER_MINUTE = 5.0
RANDOMPMV_FULL_RATIO_MINUTES = 10.0
RANDOMPMV_NEW_SOURCE_CHOICES = [0, 5, 10, 15, 20, 30, 40, 50, 60]
BADCLIP_MAX_MATCHES = 10
AUTO_MUSICPREP_SEGMENT_RANGE = (0.8, 1.4)

# =========================
# Telegram –¥–æ—Å—Ç—É–ø
# =========================
# –í–ü–ò–®–ò –°–í–û–ò –ó–ù–ê–ß–ï–ù–ò–Ø:
TELEGRAM_BOT_TOKEN = _get_private_setting("TELEGRAM_BOT_TOKEN", "")
_allowed_user_id_value = _get_private_setting("ALLOWED_USER_ID")
ALLOWED_USER_ID = _coerce_int(_allowed_user_id_value, 0)  # —Ç–≤–æ–π Telegram user id (—Ü–µ–ª–æ–µ —á–∏—Å–ª–æ)

if not TELEGRAM_BOT_TOKEN:
    raise RuntimeError("–ù–µ –∑–∞–¥–∞–Ω TELEGRAM_BOT_TOKEN")
if not ALLOWED_USER_ID:
    raise RuntimeError("–ù–µ –∑–∞–¥–∞–Ω ALLOWED_USER_ID")

# =========================
# –ë–ê–ó–ê –î–ê–ù–ù–´–• (SQLite)
# =========================

def get_conn() -> sqlite3.Connection:
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    return conn


def init_db() -> None:
    conn = get_conn()
    cur = conn.cursor()

    # –¢–∞–±–ª–∏—Ü–∞ –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS sources (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            video_path TEXT NOT NULL UNIQUE,
            video_name TEXT NOT NULL,
            size_bytes INTEGER NOT NULL,
            codec TEXT,
            resolution TEXT,
            pmv_list TEXT DEFAULT '',
            comments TEXT DEFAULT '',
            date_added TEXT NOT NULL
        )
        """
    )

    # –¢–∞–±–ª–∏—Ü–∞ –∫–æ–º–ø–∏–ª—è—Ü–∏–π
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS compilations (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            video_path TEXT NOT NULL,
            pmv_date TEXT NOT NULL,
            source_ids TEXT NOT NULL,
            comments TEXT DEFAULT ''
        )
        """
    )

    # –¢–∞–±–ª–∏—Ü–∞ –∫–Ω–æ–ø–æ–∫ (—Ç–µ–≥–∏)
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS buttons (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            short_name TEXT NOT NULL UNIQUE,
            description TEXT NOT NULL
        )
        """
    )

    # –¢–∞–±–ª–∏—Ü–∞ –ø–∞–ø–æ–∫ –∑–∞–≥—Ä—É–∑–∫–∏
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS upload_folders (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            folder_path TEXT NOT NULL UNIQUE,
            date_added TEXT NOT NULL,
            ignored INTEGER NOT NULL DEFAULT 0
        )
        """
    )
    cur.execute("PRAGMA table_info(upload_folders)")
    upload_cols = [row[1] for row in cur.fetchall()]
    if "ignored" not in upload_cols:
        cur.execute(
            "ALTER TABLE upload_folders ADD COLUMN ignored INTEGER NOT NULL DEFAULT 0"
        )

    # –¢–∞–±–ª–∏—Ü–∞ —Å —Ä–∞–Ω–¥–æ–º–Ω—ã–º–∏ –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –¥–ª—è PMV
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS random_names (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            adjective TEXT NOT NULL,
            noun TEXT NOT NULL,
            verb TEXT NOT NULL,
            number INTEGER NOT NULL
        )
        """
    )

    # –ó–∞–ø–æ–ª–Ω—è–µ–º random_names, –µ—Å–ª–∏ –ø—É—Å—Ç–æ (10 —Å—Ç—Ä–æ–∫)
    cur.execute("SELECT COUNT(*) AS cnt FROM random_names")
    cnt = cur.fetchone()["cnt"]
    if cnt == 0:
        rows = [
            ("—Ç–∏—Ö–∏–π", "–æ–∫–µ–∞–Ω", "–¥—Ä–µ–π—Ñ—É–µ—Ç", 1),
            ("—è—Ä–∫–∏–π", "–≤–µ—Ç–µ—Ä", "–ø–æ—ë—Ç", 7),
            ("–±—ã—Å—Ç—Ä—ã–π", "–ø—É–ª—å—Å", "–∑–∞–º–∏—Ä–∞–µ—Ç", 3),
            ("–Ω–æ—á–Ω–æ–π", "–≥–æ—Ä–æ–¥", "–¥—ã—à–∏—Ç", 9),
            ("–º–µ–¥–ª–µ–Ω–Ω—ã–π", "–æ–≥–æ–Ω—å", "—Ç–∞–Ω—Ü—É–µ—Ç", 5),
            ("–∑–æ–ª–æ—Ç–æ–π", "–∑–∞–∫–∞—Ç", "—Ç–∞–µ—Ç", 2),
            ("–ª—ë–≥–∫–∏–π", "–¥—ã–º", "—Å–∫–æ–ª—å–∑–∏—Ç", 8),
            ("–≥–ª—É–±–æ–∫–∏–π", "—Ä–∏—Ç–º", "–∫–∞—á–∞–µ—Ç", 4),
            ("—Å—É–º—Ä–∞—á–Ω—ã–π", "—Å–≤–µ—Ç", "–º–∞–Ω–∏—Ç", 6),
            ("–Ω–µ–∂–Ω—ã–π", "—à—Ç–æ—Ä–º", "—à–µ–ø—á–µ—Ç", 10),
        ]
        cur.executemany(
            "INSERT INTO random_names (adjective, noun, verb, number) VALUES (?, ?, ?, ?)",
            rows,
        )

    conn.commit()
    conn.close()

def db_get_all_compilations() -> List[sqlite3.Row]:
    conn = get_conn()
    cur = conn.cursor()
    # —Å–≤–µ–∂–∏–µ —Å–≤–µ—Ä—Ö—É
    cur.execute(
        """
        SELECT id, video_path, pmv_date, source_ids, comments
        FROM compilations
        ORDER BY pmv_date DESC, id DESC
        """
    )
    rows = cur.fetchall()
    conn.close()
    return rows


def db_append_compilation_comment(comp_id: int, new_piece: str) -> None:
    conn = get_conn()
    cur = conn.cursor()
    cur.execute("SELECT comments FROM compilations WHERE id = ?", (comp_id,))
    row = cur.fetchone()
    if not row:
        conn.close()
        return
    current = (row["comments"] or "").strip()
    if not current:
        updated = new_piece
    else:
        updated = current + " | " + new_piece
    cur.execute("UPDATE compilations SET comments = ? WHERE id = ?", (updated, comp_id))
    conn.commit()
    conn.close()


def db_append_source_comment(source_id: int, new_piece: str) -> None:
    conn = get_conn()
    cur = conn.cursor()
    cur.execute("SELECT comments FROM sources WHERE id = ?", (source_id,))
    row = cur.fetchone()
    if not row:
        conn.close()
        return
    current = (row["comments"] or "").strip()
    if not current:
        updated = new_piece
    else:
        updated = current + " | " + new_piece
    cur.execute("UPDATE sources SET comments = ? WHERE id = ?", (updated, source_id))
    conn.commit()
    conn.close()


def combine_comments(*pieces: Optional[str]) -> str:
    parts = [p.strip() for p in pieces if p and p.strip()]
    return " | ".join(parts)


def _append_jsonl(path: Path, payload: Dict[str, Any]) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    with path.open("a", encoding="utf-8") as fh:
        json.dump(payload, fh, ensure_ascii=False)
        fh.write("\n")


def log_randompmv_event(event: Dict[str, Any]) -> None:
    payload = dict(event)
    payload.setdefault("timestamp", datetime.now().isoformat(timespec="seconds"))
    _append_jsonl(RANDOMPMV_LOG_PATH, payload)


def _randompmv_compute_target_sources(duration_minutes: float) -> Tuple[int, float]:
    minutes = max(1.0, float(duration_minutes))
    if minutes >= RANDOMPMV_FULL_RATIO_MINUTES:
        per_minute = RANDOMPMV_MAX_SOURCES_PER_MINUTE
    else:
        span = max(1.0, RANDOMPMV_FULL_RATIO_MINUTES - 1.0)
        progress = max(0.0, min(1.0, (minutes - 1.0) / span))
        per_minute = RANDOMPMV_MIN_SOURCES_PER_MINUTE + (
            (RANDOMPMV_MAX_SOURCES_PER_MINUTE - RANDOMPMV_MIN_SOURCES_PER_MINUTE) * progress
        )
    per_minute = max(
        RANDOMPMV_MIN_SOURCES_PER_MINUTE,
        min(per_minute, RANDOMPMV_MAX_SOURCES_PER_MINUTE),
    )
    return max(1, math.ceil(minutes * per_minute)), per_minute


def log_codex_feedback(thought: str, assumption: str, actions: Optional[str] = None, meta: Optional[Dict[str, Any]] = None) -> None:
    entry: Dict[str, Any] = {
        "timestamp": datetime.now().isoformat(timespec="seconds"),
        "thought": thought,
        "assumption": assumption,
    }
    if actions:
        entry["actions"] = actions
    if meta:
        entry["meta"] = meta
    _append_jsonl(CODEX_FEEDBACK_LOG_PATH, entry)


def parse_source_id_list(field: str) -> List[int]:
    result: List[int] = []
    if not field:
        return result
    for token in field.replace(";", ",").split(","):
        token = token.strip()
        if token.isdigit():
            result.append(int(token))
    return result


def merge_pmv_lists(*values: Optional[str]) -> str:
    """
    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Å–ø–∏—Å–∫–∏ PMV-—É—á–∞—Å—Ç–∏–π –±–µ–∑ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤, —Å–æ—Ö—Ä–∞–Ω—è—è –ø–æ—Ä—è–¥–æ–∫ –ø–æ—è–≤–ª–µ–Ω–∏—è.
    """
    merged: List[str] = []
    seen: Set[str] = set()
    for value in values:
        if not value:
            continue
        for piece in value.split(","):
            cleaned = piece.strip()
            if cleaned and cleaned not in seen:
                seen.add(cleaned)
                merged.append(cleaned)
    return ", ".join(merged)


def db_add_upload_folder(folder_path: str, ignored: bool = False) -> None:
    conn = get_conn()
    cur = conn.cursor()
    cur.execute(
        """
        INSERT INTO upload_folders (folder_path, date_added, ignored)
        VALUES (?, ?, ?)
        ON CONFLICT(folder_path) DO UPDATE SET ignored = excluded.ignored
        """,
        (folder_path, date.today().isoformat(), int(ignored)),
    )
    conn.commit()
    conn.close()


def db_add_scan_ignore(folder_path: str) -> None:
    db_add_upload_folder(folder_path, ignored=True)


def db_get_upload_folders(include_ignored: bool = False) -> List[sqlite3.Row]:
    conn = get_conn()
    cur = conn.cursor()
    if include_ignored:
        cur.execute("SELECT * FROM upload_folders ORDER BY id")
    else:
        cur.execute("SELECT * FROM upload_folders WHERE ignored = 0 ORDER BY id")
    rows = cur.fetchall()
    conn.close()
    return rows


def db_get_scan_ignored_folders() -> List[sqlite3.Row]:
    conn = get_conn()
    cur = conn.cursor()
    cur.execute("SELECT * FROM upload_folders WHERE ignored = 1 ORDER BY id")
    rows = cur.fetchall()
    conn.close()
    return rows


def db_insert_source(
    video_path: Path,
    codec: str,
    resolution: str,
    size_bytes: Optional[int] = None,
    video_name: Optional[str] = None,
) -> Optional[int]:
    p = video_path.resolve()
    size_bytes = size_bytes if size_bytes is not None else p.stat().st_size
    video_name = video_name or p.name
    conn = get_conn()
    cur = conn.cursor()
    try:
        cur.execute(
            """
            INSERT INTO sources (video_path, video_name, size_bytes, codec, resolution, date_added)
            VALUES (?, ?, ?, ?, ?, ?)
            """,
            (
                str(p),
                video_name,
                size_bytes,
                codec,
                resolution,
                date.today().isoformat(),
            ),
        )
        conn.commit()
        return int(cur.lastrowid)
    except sqlite3.IntegrityError:
        return None
    finally:
        conn.close()


def db_get_unused_sources_grouped() -> Dict[Tuple[str, str], List[sqlite3.Row]]:
    conn = get_conn()
    cur = conn.cursor()
    cur.execute(
        """
        SELECT * FROM sources
        WHERE pmv_list IS NULL OR pmv_list = ''
        """
    )
    rows = cur.fetchall()
    conn.close()

    groups: Dict[Tuple[str, str], List[sqlite3.Row]] = {}
    for r in rows:
        codec = r["codec"] or "?"
        resolution = r["resolution"] or "??x??"
        key = (codec, resolution)
        groups.setdefault(key, []).append(r)
    return groups


def db_search_sources_by_term(term: str, limit: int = 50) -> List[sqlite3.Row]:
    conn = get_conn()
    cur = conn.cursor()
    pattern = f"%{term.lower()}%"
    cur.execute(
        """
        SELECT *
        FROM sources
        WHERE lower(video_name) LIKE ? OR lower(video_path) LIKE ?
        ORDER BY date_added DESC, id DESC
        LIMIT ?
        """,
        (pattern, pattern, int(limit)),
    )
    rows = cur.fetchall()
    conn.close()
    return rows

def db_get_all_sources_grouped() -> Dict[Tuple[str, str], List[sqlite3.Row]]:
    """
    –ë–µ—Ä—ë—Ç –í–°–ï –∏—Å—Ö–æ–¥–Ω–∏–∫–∏ (–∏ —É–∂–µ —É—á–∞—Å—Ç–≤–æ–≤–∞–≤—à–∏–µ, –∏ –Ω–µ—Ç)
    –∏ –≥—Ä—É–ø–ø–∏—Ä—É–µ—Ç –ø–æ (codec, resolution).
    """
    conn = get_conn()
    cur = conn.cursor()
    cur.execute("SELECT * FROM sources")
    rows = cur.fetchall()
    conn.close()

    groups: Dict[Tuple[str, str], List[sqlite3.Row]] = {}
    for r in rows:
        codec = r["codec"] or "?"
        resolution = r["resolution"] or "??x??"
        key = (codec, resolution)
        groups.setdefault(key, []).append(r)
    return groups


def load_music_projects() -> List[Dict[str, Any]]:
    projects: List[Dict[str, Any]] = []
    if not MUSIC_PROJECTS_DIR.exists():
        return projects

    usage_map = collect_music_project_usage()

    for entry in MUSIC_PROJECTS_DIR.iterdir():
        if not entry.is_dir():
            continue
        manifest_path = entry / "manifest.json"
        audio_path = entry / "audio.mp3"
        usage_info = usage_map.get(entry.name, {"count": 0, "last_date": None})
        try:
            manifest_data: Dict[str, Any] = {}
            segments_count = 0
            total_duration = None
            if manifest_path.exists():
                manifest_data = json.loads(manifest_path.read_text(encoding="utf-8"))
                segments = (manifest_data.get("analysis") or {}).get("segments") or []
                segments_count = len(segments)
                if segments:
                    total_duration = float(segments[-1].get("end", 0.0) or 0.0)
            projects.append(
                {
                    "slug": entry.name,
                    "name": manifest_data.get("name") or entry.name,
                    "dir": entry,
                    "manifest_path": manifest_path,
                    "audio_path": audio_path if audio_path.exists() else None,
                    "segments_count": segments_count,
                    "duration": total_duration,
                    "manifest_data": manifest_data or None,
                    "usage_count": usage_info.get("count", 0),
                    "last_used": usage_info.get("last_date"),
                }
            )
        except Exception as exc:
            projects.append(
                {
                    "slug": entry.name,
                    "name": f"{entry.name} (–æ—à–∏–±–∫–∞ –º–∞–Ω–∏—Ñ–µ—Å—Ç–∞: {exc})",
                    "dir": entry,
                    "manifest_path": manifest_path,
                    "audio_path": audio_path if audio_path.exists() else None,
                    "segments_count": 0,
                    "duration": None,
                    "manifest_data": None,
                    "usage_count": usage_info.get("count", 0),
                    "last_used": usage_info.get("last_date"),
                }
            )

    projects.sort(key=lambda p: (p.get("usage_count", 0), p["name"].lower()))
    return projects


def collect_music_project_usage() -> Dict[str, Dict[str, Any]]:
    usage: Dict[str, Dict[str, Any]] = {}
    conn = get_conn()
    cur = conn.cursor()
    cur.execute("SELECT pmv_date, comments FROM compilations WHERE comments LIKE '%music_project=%'")
    rows = cur.fetchall()
    conn.close()

    for row in rows:
        comments = row["comments"] or ""
        date_str = row["pmv_date"]
        try:
            pmv_date = datetime.strptime(date_str, "%Y-%m-%d").date()
        except Exception:
            pmv_date = None
        for match in re.findall(r"music_project=([\w\-]+)", comments):
            info = usage.setdefault(match, {"count": 0, "last_date": None})
            info["count"] += 1
            if pmv_date and (info["last_date"] is None or pmv_date > info["last_date"]):
                info["last_date"] = pmv_date
    return usage


def _normalize_path_str(path_like: Union[str, Path]) -> str:
    if isinstance(path_like, Path):
        raw = path_like
    else:
        raw = Path(str(path_like))
    try:
        return str(raw.resolve(strict=False)).lower()
    except Exception:
        return str(raw).lower()


def _normalize_path_prefix(path_like: Union[str, Path]) -> str:
    normalized = _normalize_path_str(path_like)
    normalized = normalized.replace("\\", "/").rstrip("/")
    return normalized


def _is_path_under_prefixes(
    target_path: Union[str, Path], prefixes: Iterable[str]
) -> bool:
    target = _normalize_path_prefix(target_path)
    for prefix in prefixes:
        if not prefix:
            continue
        check = prefix.rstrip("/")
        if target == check or target.startswith(check + "/"):
            return True
    return False


def collect_music_track_usage() -> Dict[str, int]:
    usage: Dict[str, int] = {}
    if not MUSIC_PROJECTS_DIR.exists():
        return usage

    input_by_name: Dict[str, str] = {
        p.name.lower(): _normalize_path_str(p) for p in list_music_input_files()
    }

    for entry in MUSIC_PROJECTS_DIR.iterdir():
        if not entry.is_dir():
            continue
        manifest_path = entry / "manifest.json"
        if not manifest_path.exists():
            continue
        try:
            data = json.loads(manifest_path.read_text(encoding="utf-8"))
        except Exception:
            continue
        source_file = data.get("source_file") or data.get("original_audio")
        if not source_file:
            audio_path = data.get("audio_path")
            if audio_path:
                # Backward compatibility: older manifests did not store source_file.
                candidate = input_by_name.get(Path(audio_path).name.lower())
                if candidate:
                    source_file = candidate
        if not source_file:
            continue
        norm = _normalize_path_str(source_file)
        if not norm:
            continue
        usage[norm] = usage.get(norm, 0) + 1
    return usage


TRACK_SPLIT_RE = re.compile(r"\s*[-‚Äì‚Äî]\s*")
SLUG_TOKEN_RE = re.compile(r"[^a-z0-9]+")


def truncate_button_label(text: str, max_len: int = 30) -> str:
    text = text.strip()
    if len(text) <= max_len:
        return text
    return text[: max_len - 1] + "‚Ä¶"


def truncate_label_keep_suffix(text: str, max_len: int = 30) -> str:
    text = text.strip()
    if len(text) <= max_len:
        return text
    return "‚Ä¶" + text[-(max_len - 1):]


def extract_track_title_components(path: Path) -> Tuple[str, str]:
    stem = path.stem.strip()
    normalized = stem.replace("‚Äî", "-").replace("‚Äì", "-")
    parts = [p.strip() for p in normalized.split("-", 1)]
    if len(parts) == 2:
        artist, title = parts
    else:
        artist, title = "", stem
    return artist, title or stem


def slugify_token(value: str) -> str:
    if not value:
        return "project"
    normalized = unicodedata.normalize("NFKD", value).encode("ascii", "ignore").decode("ascii")
    slug = SLUG_TOKEN_RE.sub("_", normalized.lower()).strip("_")
    return slug or "project"


def build_main_reply_keyboard() -> ReplyKeyboardMarkup:
    """
    –ü–æ—Å—Ç–æ—è–Ω–Ω–æ–µ –º–µ–Ω—é —Å–Ω–∏–∑—É —Å –æ—Å–Ω–æ–≤–Ω—ã–º–∏ –∫–æ–º–∞–Ω–¥–∞–º–∏.
    """
    rows = [
        [KeyboardButton("musicprep"), KeyboardButton("newcompmusic")],
        [KeyboardButton("rategrp"), KeyboardButton("–ù–∞–π—Ç–∏")],
        [KeyboardButton("CreateRandomPMV"), KeyboardButton("–û—Ç—á—ë—Ç—ã")],
        [KeyboardButton("scan")],
    ]
    return ReplyKeyboardMarkup(rows, resize_keyboard=True, one_time_keyboard=False)


def build_reports_keyboard() -> InlineKeyboardMarkup:
    rows = [
        [InlineKeyboardButton("üü¢ + –ì—Ä—É–ø–ø—ã", callback_data="report_group:green")],
        [InlineKeyboardButton("üü° + –ì—Ä—É–ø–ø—ã", callback_data="report_group:yellow")],
        [InlineKeyboardButton("üî¥ + –ì—Ä—É–ø–ø—ã", callback_data="report_group:red")],
        [InlineKeyboardButton("ü©∑ + –ì—Ä—É–ø–ø—ã", callback_data="report_group:pink")],
    ]
    return InlineKeyboardMarkup(rows)


def build_newcomp_duration_keyboard() -> InlineKeyboardMarkup:
    rows = [
        [InlineKeyboardButton(label, callback_data=f"newcomp_bucket:{key}")]
        for key, label, _, _ in NEWCOMPMUSIC_DURATION_BUCKETS
    ]
    rows.append([InlineKeyboardButton("‚Ü©Ô∏è –ù–æ–≤—ã–µ –ø—Ä–æ–µ–∫—Ç—ã", callback_data="newcomp_show:unused")])
    return InlineKeyboardMarkup(rows)


def project_duration_seconds(project: Dict[str, Any]) -> Optional[int]:
    duration = project.get("duration")
    if duration is not None:
        try:
            return max(0, int(float(duration)))
        except Exception:
            pass
    manifest = project.get("manifest_data") or {}
    manifest_dur = manifest.get("duration")
    if manifest_dur:
        try:
            return max(0, int(float(manifest_dur)))
        except Exception:
            pass
    segments = project.get("parsed_segments") or []
    if segments:
        try:
            return max(0, int(float(segments[-1].end)))
        except Exception:
            pass
    return None


def project_matches_duration(project: Optional[Dict[str, Any]], bucket_key: Optional[str]) -> bool:
    if not bucket_key:
        return True
    if not project:
        return False
    seconds = project_duration_seconds(project)
    if seconds is None:
        return bucket_key == "long"
    for key, _, min_sec, max_sec in NEWCOMPMUSIC_DURATION_BUCKETS:
        if key != bucket_key:
            continue
        if max_sec is None:
            return seconds >= min_sec
        return min_sec <= seconds <= max_sec
    return True


def filter_project_tokens_by_duration(
    session: Dict[str, Any],
    tokens: List[str],
    bucket_key: Optional[str],
) -> List[str]:
    if not bucket_key:
        return tokens
    project_map: Dict[str, Dict[str, Any]] = session.get("music_projects_map") or {}
    filtered: List[str] = []
    for token in tokens:
        project = project_map.get(token)
        if project_matches_duration(project, bucket_key):
            filtered.append(token)
    return filtered


def build_musicprep_track_keyboard(
    session: Dict[str, Any],
    show_used: bool,
) -> Tuple[str, InlineKeyboardMarkup]:
    track_map: Dict[str, Dict[str, Any]] = session.get("music_tracks") or {}
    tokens = session.get("music_tracks_used" if show_used else "music_tracks_unused") or []
    def sort_key(token: str) -> Tuple[int, str]:
        info = track_map.get(token) or {}
        count = int(info.get("usage") or 0)
        path = Path(info.get("path") or "")
        _, title = extract_track_title_components(path)
        return (count, title.lower())
    tokens = sorted(tokens, key=sort_key)
    rows: List[List[InlineKeyboardButton]] = []
    for token in tokens:
        info = track_map.get(token)
        if not info:
            continue
        path = Path(info["path"])
        _, title = extract_track_title_components(path)
        count = int(info.get("usage") or 0)
        base_label = f"{count} ¬∑ {title}"
        label = truncate_button_label(base_label)
        rows.append([InlineKeyboardButton(label or "?", callback_data=f"musicprep_track:{token}")])

    toggle_target = "unused" if show_used else "used"
    toggle_label = "–ü–æ–∫–∞–∑–∞—Ç—å –Ω–æ–≤—ã–µ" if show_used else "–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ"
    rows.append([InlineKeyboardButton(toggle_label, callback_data=f"musicprep_show:{toggle_target}")])

    if not tokens:
        text = (
            "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö —Ç—Ä–µ–∫–æ–≤ –ø–æ–∫–∞ –Ω–µ—Ç." if show_used else "–ù–æ–≤—ã—Ö —Ç—Ä–µ–∫–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ."
        )
    else:
        text = "üéµ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ —Ç—Ä–µ–∫–∏:" if show_used else "üéµ –î–æ—Å—Ç—É–ø–Ω—ã–µ —Ç—Ä–µ–∫–∏ (–Ω–æ–≤—ã–µ):"
    return text, InlineKeyboardMarkup(rows)


def build_musicprep_seconds_keyboard() -> InlineKeyboardMarkup:
    zero_row = [InlineKeyboardButton("0", callback_data="musicprep_seconds:0")]
    first_row = [InlineKeyboardButton(str(i), callback_data=f"musicprep_seconds:{i}") for i in range(1, 6)]
    second_row = [InlineKeyboardButton(str(i), callback_data=f"musicprep_seconds:{i}") for i in range(6, 11)]
    third_row = [InlineKeyboardButton(str(i), callback_data=f"musicprep_seconds:{i}") for i in range(11, 15)]
    fourth_row = [InlineKeyboardButton("15", callback_data="musicprep_seconds:15")]
    return InlineKeyboardMarkup([zero_row, first_row, second_row, third_row, fourth_row])


def build_musicprep_mode_keyboard() -> InlineKeyboardMarkup:
    row = [
        InlineKeyboardButton("beat", callback_data="musicprep_mode:beat"),
        InlineKeyboardButton("onset", callback_data="musicprep_mode:onset"),
        InlineKeyboardButton("uniform", callback_data="musicprep_mode:uniform"),
    ]
    return InlineKeyboardMarkup([row])


MUSICPREP_SENSITIVITY_PRESETS: Dict[str, List[Dict[str, Any]]] = {
    "beat": [
        {
            "key": "soft",
            "label": "–ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–π (–ª–æ–≤–∏—Ç—å —Ö—ç—Ç—ã)",
            "description": "–î–æ–±–∞–≤–ª—è–µ—Ç —Å–µ–≥–º–µ–Ω—Ç—ã –Ω–∞ —Ç–∏—Ö–∏—Ö –¥–æ–ª—è—Ö.",
            "analysis_kwargs": {"beat_tightness": 0.6, "sensitivity_scale": 1.4},
        },
        {
            "key": "default",
            "label": "–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π",
            "description": "–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∂–∏–º.",
            "analysis_kwargs": {},
        },
        {
            "key": "tight",
            "label": "–¢–æ–ª—å–∫–æ —Å–∏–ª—å–Ω—ã–µ –¥–æ–ª–∏",
            "description": "–ü—Ä–æ–ø—É—Å–∫–∞–µ—Ç —Å–ª–∞–±—ã–µ —É–¥–∞—Ä—ã –∏ —Ç–∏—à–∏–Ω—É.",
            "analysis_kwargs": {"beat_tightness": 2.0, "sensitivity_scale": 0.85},
        },
    ],
    "onset": [
        {
            "key": "soft",
            "label": "–ë–æ–ª—å—à–µ –≤—Å–ø–ª–µ—Å–∫–æ–≤",
            "description": "–ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–π –∫ —Ö–∞–π-—Ö—ç—Ç–∞–º.",
            "analysis_kwargs": {"onset_delta": 0.02, "sensitivity_scale": 1.5},
        },
        {
            "key": "default",
            "label": "–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π",
            "description": "–†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã.",
            "analysis_kwargs": {},
        },
        {
            "key": "tight",
            "label": "–¢–æ–ª—å–∫–æ –≥—Ä–æ–º–∫–∏–µ –ø–∏–∫–∏",
            "description": "–§–æ–∫—É—Å –Ω–∞ –º–æ—â–Ω—ã—Ö —É–¥–∞—Ä–∞—Ö.",
            "analysis_kwargs": {"onset_delta": 0.12, "sensitivity_scale": 0.8},
        },
    ],
}


def get_musicprep_sensitivity_options(mode: str) -> List[Dict[str, Any]]:
    return MUSICPREP_SENSITIVITY_PRESETS.get(mode, [])


def build_musicprep_sensitivity_keyboard(mode: str) -> InlineKeyboardMarkup:
    options = get_musicprep_sensitivity_options(mode)
    rows: List[List[InlineKeyboardButton]] = []
    for opt in options:
        rows.append(
            [
                InlineKeyboardButton(
                    opt["label"], callback_data=f"musicprep_sens:{mode}:{opt['key']}"
                )
            ]
        )
    if not rows:
        rows = [[InlineKeyboardButton("–°—Ç–∞–Ω–¥–∞—Ä—Ç", callback_data="musicprep_sens:auto:default")]]
    return InlineKeyboardMarkup(rows)


async def finalize_musicprep_project(
    send_func: Callable[[str], Awaitable[None]],
    sess: Dict[str, Any],
    user_id: int,
    mode: str,
    analysis_kwargs: Optional[Dict[str, Any]] = None,
) -> None:
    file_str = sess.get("musicprep_file")
    if not file_str:
        return await send_func("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—ã–π —Ç—Ä–µ–∫.")

    file_path = Path(file_str)
    mod = load_music_generator_module()

    segment_len = sess.get("musicprep_segment")
    if segment_len is None:
        segment_len = getattr(mod, "DEFAULT_TARGET_SEGMENT", 1.0)

    project_partial = sess.get("musicprep_project_partial")
    if project_partial:
        project_name = f"{project_partial}_{mode}"
    else:
        project_name = sess.get("musicprep_name")

    try:
        manifest = mod.create_music_project(
            mp3_path=file_path,
            name=project_name,
            target_segment=float(segment_len),
            segment_mode=mode,
            analysis_kwargs=analysis_kwargs or {},
        )
    except Exception as exc:
        user_sessions.pop(user_id, None)
        return await send_func(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –º—É–∑—ã–∫–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞: {exc}")

    user_sessions.pop(user_id, None)
    await send_func(
        "‚úÖ –ú—É–∑—ã–∫–∞–ª—å–Ω—ã–π –ø—Ä–æ–µ–∫—Ç —Å–æ–∑–¥–∞–Ω.\n"
        f"–ò–º—è: {manifest.name}\n"
        f"Slug: {manifest.slug}\n"
        f"–§–∞–π–ª: {manifest.audio_path}\n"
        f"–°–µ–≥–º–µ–Ω—Ç–æ–≤: {len(manifest.analysis.segments)}\n"
        f"–†–µ–∂–∏–º: {manifest.analysis.mode}"
    )



def _random_musicprep_segment_length(default_value: float) -> float:
    low, high = AUTO_MUSICPREP_SEGMENT_RANGE
    try:
        low_val = float(low)
    except Exception:
        low_val = max(0.5, default_value * 0.7)
    try:
        high_val = float(high)
    except Exception:
        high_val = max(low_val + 0.1, default_value * 1.3)
    if high_val <= low_val:
        high_val = max(low_val + 0.1, default_value if default_value > 0 else 1.0)
    return round(random.uniform(low_val, high_val), 2)


def _auto_musicprep_project_name(mp3_path: Path) -> str:
    base = re.sub(r"\s+", " ", mp3_path.stem.strip()) or "Music Project"
    if len(base) > 64:
        base = base[:64].rstrip()
    suffix = datetime.now().strftime("%Y%m%d_%H%M%S")
    rand = random.randint(100, 999)
    return f"{base} {suffix}_{rand}"


def auto_create_random_music_project(
    used_music_paths: Optional[Set[str]] = None,
) -> Dict[str, Any]:
    music_files = list_music_input_files()
    if not music_files:
        raise RuntimeError("Music folder is empty. Add MP3/FLAC/WAV tracks before running.")

    normalized_used = {p for p in (used_music_paths or set())}
    available = [p for p in music_files if _normalize_path_str(p) not in normalized_used]
    if not available:
        available = music_files
    mp3_path = random.choice(available)

    mod = load_music_generator_module()
    default_segment = getattr(mod, "DEFAULT_TARGET_SEGMENT", 1.0)
    modes = getattr(mod, "SEGMENT_MODES", ("beat",))
    segment_len = _random_musicprep_segment_length(float(default_segment or 1.0))
    mode = random.choice(list(modes) or ["beat"])
    analysis_kwargs = {}
    options = get_musicprep_sensitivity_options(mode)
    if options:
        selected = random.choice(options)
        analysis_kwargs = dict(selected.get("analysis_kwargs") or {})

    project_name = _auto_musicprep_project_name(mp3_path)
    manifest = mod.create_music_project(
        mp3_path=mp3_path,
        name=project_name,
        target_segment=segment_len,
        segment_mode=mode,
        analysis_kwargs=analysis_kwargs,
    )
    manifest_data = manifest.to_dict()
    analysis_obj = getattr(manifest, "analysis", None)
    segments = list(getattr(analysis_obj, "segments", []) or [])
    segments_count = len(segments)
    duration = None
    if segments:
        try:
            duration = float(segments[-1].end)
        except Exception:
            duration = None

    audio_path = Path(manifest.audio_path)
    project_dir = audio_path.parent
    manifest_path = project_dir / "manifest.json"
    info = {
        "slug": manifest.slug,
        "name": manifest.name,
        "dir": project_dir,
        "manifest_path": manifest_path,
        "audio_path": audio_path if audio_path.exists() else None,
        "segments_count": segments_count,
        "duration": duration,
        "manifest_data": manifest_data,
        "usage_count": 0,
        "last_used": None,
    }
    if used_music_paths is not None:
        used_music_paths.add(_normalize_path_str(mp3_path))
    return info

def build_musicprepcheck_keyboard(projects: List[Dict[str, Any]]) -> InlineKeyboardMarkup:
    buttons: List[List[InlineKeyboardButton]] = []
    sorted_projects = sorted(
        projects,
        key=lambda proj: proj.get("manifest_data", {}).get("created_at")
        or proj.get("created_at")
        or "",
        reverse=True,
    )
    rows: List[List[InlineKeyboardButton]] = []
    for proj in sorted_projects:
        slug = proj.get("slug") or sanitize_filename(proj.get("name") or "project")
        name = proj.get("name") or proj.get("slug")
        segs = proj.get("segments_count") or 0
        label = truncate_label_keep_suffix(f"{name} ({segs} —Å–µ–≥)")
        rows.append(
            [InlineKeyboardButton(label or slug or "?", callback_data=f"musicprepcheck_project:{slug}")]
        )
    return InlineKeyboardMarkup(rows or [[InlineKeyboardButton("–ù–µ—Ç –ø—Ä–æ–µ–∫—Ç–æ–≤", callback_data="noop")]])


def build_newcomp_project_keyboard(session: Dict[str, Any], show_used: bool) -> Tuple[str, InlineKeyboardMarkup]:
    projects_map: Dict[str, Dict[str, Any]] = session.get("music_projects_map") or {}
    tokens = session.get("music_projects_used" if show_used else "music_projects_unused") or []
    duration_filter = session.get("music_projects_duration_filter") if show_used else None
    if show_used:
        tokens = filter_project_tokens_by_duration(session, tokens, duration_filter)
    rows: List[List[InlineKeyboardButton]] = []

    for token in tokens:
        proj = projects_map.get(token)
        if not proj:
            continue
        label = truncate_button_label(proj["name"])
        usage = proj.get("usage_count") or 0
        if show_used and usage:
            label = truncate_button_label(f"{label} ({usage})")
        rows.append([InlineKeyboardButton(label or token, callback_data=f"newcomp_project:{token}")])

    toggle_target = "unused" if show_used else "used"
    toggle_label = "–ü–æ–∫–∞–∑–∞—Ç—å –Ω–æ–≤—ã–µ" if show_used else "–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ"
    if show_used:
        rows.append([InlineKeyboardButton("–ò–∑–º–µ–Ω–∏—Ç—å –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å", callback_data="newcomp_bucket_menu")])
    rows.append([InlineKeyboardButton(toggle_label, callback_data=f"newcomp_show:{toggle_target}")])

    if not tokens:
        if show_used:
            label = NEWCOMPMUSIC_DURATION_LABELS.get(duration_filter or "", "–ª—é–±–æ–π –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
            text = f"–ò—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤ ({label}) –ø–æ–∫–∞ –Ω–µ—Ç."
        else:
            text = "–ù–æ–≤—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ."
    else:
        if show_used:
            label = NEWCOMPMUSIC_DURATION_LABELS.get(duration_filter or "", "–ª—é–±–æ–π –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
            text = f"üéµ –ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –ø—Ä–æ–µ–∫—Ç—ã ({label}):"
        else:
            text = "üéµ –î–æ—Å—Ç—É–ø–Ω—ã–µ –Ω–æ–≤—ã–µ –ø—Ä–æ–µ–∫—Ç—ã:"
    return text, InlineKeyboardMarkup(rows)


async def prompt_newcomp_duration(
    session: Dict[str, Any],
    send_fn: Callable[[str, Optional[InlineKeyboardMarkup]], Awaitable[Any]],
) -> None:
    session["state"] = "newcompmusic_choose_duration"
    await send_fn("–í—ã–±–µ—Ä–∏—Ç–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤:", build_newcomp_duration_keyboard())


def build_numeric_keyboard(prefix: str, total: int, per_row: int = 5) -> InlineKeyboardMarkup:
    rows: List[List[InlineKeyboardButton]] = []
    row: List[InlineKeyboardButton] = []
    for i in range(1, total + 1):
        row.append(InlineKeyboardButton(str(i), callback_data=f"{prefix}:{i}"))
        if len(row) >= per_row:
            rows.append(row)
            row = []
    if row:
        rows.append(row)
    return InlineKeyboardMarkup(rows or [[InlineKeyboardButton("1", callback_data=f"{prefix}:1")]])


NEWCOMPMUSIC_SOURCE_CHOICES = [5, 10, 20, 30, 50, 60, 80, 100]
NEWCOMPMUSIC_ORIENTATION_CHOICES = ("VR", "HOR", "VER")
RATEGRP_COLOR_CHOICES: Dict[str, Dict[str, str]] = {
    "green": {"emoji": "üü¢", "label": "–∑–µ–ª—ë–Ω–∞—è"},
    "yellow": {"emoji": "üü°", "label": "–∂—ë–ª—Ç–∞—è"},
    "red": {"emoji": "üî¥", "label": "–∫—Ä–∞—Å–Ω–∞—è"},
    "pink": {"emoji": "ü©∑", "label": "—Ä–æ–∑–æ–≤–∞—è"},
    "blue": {"emoji": "üîµ", "label": "—Å–∏–Ω—è—è"},
    "favorite": {"emoji": "‚≠ê", "label": "–∏–∑–±—Ä–∞–Ω–Ω–æ–µ"},
    "inspect": {"emoji": "üëÅ", "label": "–ø—Ä–∏—Å–º–æ—Ç—Ä–µ—Ç—å—Å—è"},
    "delete": {"emoji": "‚ùå", "label": "—É–¥–∞–ª–∏—Ç—å"},
}
RATEGRP_COLOR_EMOJIS = tuple(choice["emoji"] for choice in RATEGRP_COLOR_CHOICES.values())
RATEGRP_COLOR_PROMPT = " / ".join(choice["emoji"] for choice in RATEGRP_COLOR_CHOICES.values())

# –î–æ–±–∞–≤–ª—è–µ–º –≤ NAS_SYMLINK_COLOR_FOLDERS –∞–ª–∏–∞—Å—ã –ø–æ —ç–º–æ–¥–∑–∏, —á—Ç–æ–±—ã –Ω–µ –∑–∞–≤–∏—Å–µ—Ç—å
# –æ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∫–ª—é—á–µ–π —Ü–≤–µ—Ç–æ–≤.
for _color_key, _color_info in RATEGRP_COLOR_CHOICES.items():
    _emoji = _color_info["emoji"]
    _folder = NAS_SYMLINK_COLOR_FOLDERS.get(_color_key)
    if _folder and _emoji not in NAS_SYMLINK_COLOR_FOLDERS:
        NAS_SYMLINK_COLOR_FOLDERS[_emoji] = _folder


def extract_color_emoji(text: Optional[str]) -> Optional[str]:
    if not text:
        return None
    for emoji in RATEGRP_COLOR_EMOJIS:
        if emoji in text:
            return emoji
    return None


def db_set_source_color(source_id: int, emoji: str) -> Optional[str]:
    conn = get_conn()
    cur = conn.cursor()
    cur.execute("SELECT comments FROM sources WHERE id = ?", (source_id,))
    row = cur.fetchone()
    if not row:
        conn.close()
        return None
    current = (row["comments"] or "").strip()
    parts = [part.strip() for part in current.split("|") if part.strip()]
    parts = [
        part
        for part in parts
        if not any(color_emoji in part for color_emoji in RATEGRP_COLOR_EMOJIS)
    ]
    parts.append(f"color={emoji}")
    updated = " | ".join(parts)
    cur.execute("UPDATE sources SET comments = ? WHERE id = ?", (updated, source_id))
    conn.commit()
    conn.close()
    return updated


def build_newcomp_sources_keyboard() -> InlineKeyboardMarkup:
    rows: List[List[InlineKeyboardButton]] = []
    row: List[InlineKeyboardButton] = []
    for count in NEWCOMPMUSIC_SOURCE_CHOICES:
        row.append(InlineKeyboardButton(str(count), callback_data=f"newcomp_sources:{count}"))
        if len(row) == 4:
            rows.append(row)
            row = []
    if row:
        rows.append(row)
    return InlineKeyboardMarkup(rows)


def build_newcomp_orientation_keyboard() -> InlineKeyboardMarkup:
    buttons = [
        InlineKeyboardButton(label, callback_data=f"newcomp_orient:{label}")
        for label in NEWCOMPMUSIC_ORIENTATION_CHOICES
    ]
    return InlineKeyboardMarkup([buttons])


def build_rategrp_orientation_keyboard() -> InlineKeyboardMarkup:
    buttons = [
        InlineKeyboardButton(label, callback_data=f"rategrp_orient:{label}")
        for label in NEWCOMPMUSIC_ORIENTATION_CHOICES
    ]
    extra = [InlineKeyboardButton("–ò–ó PMV", callback_data="rategrp_from_pmv")]
    return InlineKeyboardMarkup([buttons, extra])


def build_rategrp_color_keyboard() -> InlineKeyboardMarkup:
    rows: List[List[InlineKeyboardButton]] = []
    row: List[InlineKeyboardButton] = []
    for idx, (key, choice) in enumerate(RATEGRP_COLOR_CHOICES.items(), 1):
        row.append(InlineKeyboardButton(choice["emoji"], callback_data=f"rategrp_color:{key}"))
        if len(row) == 4:
            rows.append(row)
            row = []
    if row:
        rows.append(row)
    return InlineKeyboardMarkup(rows)


def build_rategrp_rerate_keyboard(
    available: List[Tuple[str, str, int]]
) -> InlineKeyboardMarkup:
    rows: List[List[InlineKeyboardButton]] = []
    for color_key, emoji, count in available:
        label = f"{emoji} ({count})"
        rows.append([InlineKeyboardButton(label, callback_data=f"rategrp_rerate_color:{color_key}")])
    rows.append([InlineKeyboardButton("‚Ü©Ô∏è –ù–∞–∑–∞–¥", callback_data="rategrp_rerate_back")])
    return InlineKeyboardMarkup(rows)


def build_newcomp_groupmode_keyboard() -> InlineKeyboardMarkup:
    return InlineKeyboardMarkup(
        [
            [InlineKeyboardButton("üìÅ –ü–æ –ø–∞–ø–∫–∞–º", callback_data="newcomp_groupmode:folders")],
            [InlineKeyboardButton("üé® –ü–æ –æ—Ü–µ–Ω–∫–∞–º", callback_data="newcomp_groupmode:colors")],
        ]
    )


def build_newcomp_color_keyboard(
    color_counts: Dict[str, int],
    unrated_count: int,
    combo_counts: Optional[Dict[str, int]] = None,
) -> InlineKeyboardMarkup:
    rows: List[List[InlineKeyboardButton]] = []
    single_row: List[InlineKeyboardButton] = []
    for key, info in RATEGRP_COLOR_CHOICES.items():
        emoji = info["emoji"]
        count = color_counts.get(emoji, 0)
        single_row.append(
            InlineKeyboardButton(f"{emoji} ({count})", callback_data=f"newcomp_color:{key}")
        )
    if single_row:
        rows.append(single_row)
    combo_counts = combo_counts or {}
    green = RATEGRP_COLOR_CHOICES["green"]["emoji"]
    yellow = RATEGRP_COLOR_CHOICES["yellow"]["emoji"]
    red = RATEGRP_COLOR_CHOICES["red"]["emoji"]
    green_new_total = combo_counts.get(
        "green_new", color_counts.get(green, 0) + unrated_count
    )
    green_yellow_total = combo_counts.get(
        "green_yellow", color_counts.get(green, 0) + color_counts.get(yellow, 0)
    )
    green_yellow_red_total = combo_counts.get(
        "green_yellow_red",
        color_counts.get(green, 0)
        + color_counts.get(yellow, 0)
        + color_counts.get(red, 0),
    )
    combo_row: List[InlineKeyboardButton] = []
    combo_row.append(
        InlineKeyboardButton(
            f"{green}+üÜï ({green_new_total})",
            callback_data="newcomp_color:green_new",
        )
    )
    combo_row.append(
        InlineKeyboardButton(
            f"{green}+{yellow} ({green_yellow_total})",
            callback_data="newcomp_color:green_yellow",
        )
    )
    combo_row.append(
        InlineKeyboardButton(
            f"{green}+{yellow}+{red} ({green_yellow_red_total})",
            callback_data="newcomp_color:green_yellow_red",
        )
    )
    rows.append(combo_row)
    rows.append([InlineKeyboardButton("‚¨Ö –ù–∞–∑–∞–¥", callback_data="newcomp_color_back")])
    return InlineKeyboardMarkup(rows)


def build_newcomp_algo_keyboard() -> InlineKeyboardMarkup:
    row = [
        InlineKeyboardButton("CAR", callback_data="newcomp_algo:car"),
        InlineKeyboardButton("WAV", callback_data="newcomp_algo:wav"),
        InlineKeyboardButton("BST", callback_data="newcomp_algo:bst"),
        InlineKeyboardButton("POI", callback_data="newcomp_algo:poi"),
        InlineKeyboardButton("LAY", callback_data="newcomp_algo:strata"),
    ]
    return InlineKeyboardMarkup([row])


def build_randompmv_count_keyboard() -> InlineKeyboardMarkup:
    buttons: List[List[InlineKeyboardButton]] = []
    row: List[InlineKeyboardButton] = []
    for idx, value in enumerate(RANDOMPMV_COUNT_OPTIONS, 1):
        row.append(InlineKeyboardButton(str(value), callback_data=f"randompmv_count:{value}"))
        if idx % 3 == 0:
            buttons.append(row)
            row = []
    if row:
        buttons.append(row)
    return InlineKeyboardMarkup(buttons)


def build_randompmv_orientation_keyboard() -> InlineKeyboardMarkup:
    buttons = [
        InlineKeyboardButton(label, callback_data=f"randompmv_orient:{label}")
        for label in NEWCOMPMUSIC_ORIENTATION_CHOICES
    ]
    buttons.append(InlineKeyboardButton("–í–°–ï", callback_data="randompmv_orient:ALL"))
    return InlineKeyboardMarkup([buttons])


def build_randompmv_newcount_keyboard() -> InlineKeyboardMarkup:
    buttons: List[List[InlineKeyboardButton]] = []
    row: List[InlineKeyboardButton] = []
    for idx, value in enumerate(RANDOMPMV_NEW_SOURCE_CHOICES, 1):
        row.append(InlineKeyboardButton(str(value), callback_data=f"randompmv_newcount:{value}"))
        if idx % 4 == 0:
            buttons.append(row)
            row = []
    if row:
        buttons.append(row)
    return InlineKeyboardMarkup(buttons)


def build_newcomp_folder_keyboard(
    options: List[Dict[str, Any]],
    unused_only: bool = False,
) -> InlineKeyboardMarkup:
    buttons: List[List[InlineKeyboardButton]] = []
    row: List[InlineKeyboardButton] = []
    for opt in options:
        label = truncate_button_label(f"{opt['label']} ({opt['count']})", 28)
        row.append(
            InlineKeyboardButton(label or "?", callback_data=f"newcomp_folder:{opt['token']}")
        )
        if len(row) >= 2:
            buttons.append(row)
            row = []
    if row:
        buttons.append(row)
    controls: List[List[InlineKeyboardButton]] = []
    if not buttons:
        controls.append([InlineKeyboardButton("–í—Å–µ –ø–∞–ø–∫–∏", callback_data="newcomp_folder:all")])
    else:
        controls.extend(buttons)
    toggle_label = "–í—Å–µ –∏—Å—Ö–æ–¥–Ω–∏–∫–∏" if unused_only else "üÜï –¢–æ–ª—å–∫–æ –Ω–æ–≤–æ–µ"
    toggle_target = "all" if unused_only else "new"
    controls.append([InlineKeyboardButton(toggle_label, callback_data=f"newcomp_folder_mode:{toggle_target}")])
    controls.append([InlineKeyboardButton("–ù–∞–∑–∞–¥ –∫ –≥—Ä—É–ø–ø–∞–º", callback_data="newcomp_folder_back")])
    return InlineKeyboardMarkup(controls)


def build_ratepmv_pmv_keyboard(rows: List[sqlite3.Row]) -> InlineKeyboardMarkup:
    buttons: List[List[InlineKeyboardButton]] = []
    for idx, row in enumerate(rows, 1):
        path = Path(row["video_path"])
        label = truncate_button_label(f"{idx}. {path.stem}", max_len=35)
        if not label:
            label = f"#{idx}"
        buttons.append([InlineKeyboardButton(label, callback_data=f"ratepmv_select:{idx}")])
    if not buttons:
        return InlineKeyboardMarkup([[InlineKeyboardButton("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö PMV", callback_data="noop")]])

    bulk_row = [
        InlineKeyboardButton(f"{score} -> –≤—Å–µ–º", callback_data=f"ratepmv_bulk:{score}")
        for score in range(1, 6)
    ]
    buttons.append(bulk_row)
    return InlineKeyboardMarkup(buttons)


def build_ratepmv_score_keyboard() -> InlineKeyboardMarkup:
    row = [
        InlineKeyboardButton(str(score), callback_data=f"ratepmv_rate:{score}")
        for score in range(1, 6)
    ]
    return InlineKeyboardMarkup([row])


async def run_newcompmusic_generation(
    send_fn: Callable[[str], Awaitable[None]],
    sess: Dict[str, Any],
    resolved_key: str,
    user_id: int,
) -> None:
    resolved_key, algo_meta = resolve_clip_algorithm(resolved_key)
    selected = sess.get("music_selected") or {}
    parsed_segments: List[MusicSegment] = selected.get("parsed_segments") or []
    if not parsed_segments:
        return await send_fn("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Å–µ–≥–º–µ–Ω—Ç—ã –≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ.")

    audio_path_str = selected.get("audio_path")
    if not audio_path_str:
        return await send_fn("–í –ø—Ä–æ–µ–∫—Ç–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç audio.mp3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–∞–ø–∫—É music_projects.")

    sources_count = int(sess.get("music_sources") or 0)
    if sources_count <= 0:
        return await send_fn("–ù–µ —É–∫–∞–∑–∞–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤.")

    await send_fn("–ó–∞–ø—É—Å–∫–∞—é –º—É–∑—ã–∫–∞–ª—å–Ω—É—é –∫–æ–º–ø–∏–ª—è—Ü–∏—é. –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç...")

    move_comment = ""
    try:
        preferred_group = None
        if sess.get("music_group_choice"):
            preferred_group = tuple(sess["music_group_choice"]["key"])
        group_choice = sess.get("music_group_choice") or {}
        preferred_folder = group_choice.get("folder_path")
        orientation_label = (group_choice.get("orientation") or "HOR").upper()
        color_rows = sess.get("music_color_rows")
        group_number = group_choice.get("group_number")
        min_new_required = max(0, int(sess.get("music_min_new_sources") or 0))
        if color_rows:
            source_rows = pick_specific_source_rows(
                list(color_rows),
                sources_count,
                min_new_required=min_new_required,
            )
        else:
            source_rows = choose_random_source_rows(
                sources_count,
                group_strategy=CURRENT_STRATEGY,
                preferred_group=preferred_group,
                preferred_folder=preferred_folder,
            )
        out_path, source_ids, (resolved_key, algo_meta) = make_music_synced_pmv(
            selected.get("name") or selected.get("slug") or "music",
            parsed_segments,
            Path(audio_path_str),
            source_rows,
            resolved_key,
            orientation=orientation_label,
            group_number=group_number,
        )
        out_path, move_comment = move_output_to_network_storage(out_path)
    except Exception as exc:
        user_sessions.pop(user_id, None)
        await send_fn(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {exc}")
        if sess.get("_raise_on_newcomp_error"):
            raise
        return

    pmv_tag = Path(out_path).name
    comments = combine_comments(f"music_project={selected.get('slug')}", move_comment)
    db_insert_compilation(
        out_path,
        source_ids,
        comments=comments,
    )
    db_update_sources_pmv_list(source_ids, pmv_tag)
    autotag = sess.get("music_color_autotag")
    if autotag:
        emoji = autotag.get("emoji")
        autotag_ids = set(int(i) for i in autotag.get("ids") or [])
        if emoji and autotag_ids:
            for sid in source_ids:
                if sid in autotag_ids:
                    db_append_source_comment(sid, f"color={emoji}")

    user_sessions.pop(user_id, None)

    duration = selected.get("duration")
    minutes = (duration / 60.0) if duration else None
    msg_lines = [
        "‚úÖ –ú—É–∑—ã–∫–∞–ª—å–Ω–∞—è –∫–æ–º–ø–∏–ª—è—Ü–∏—è –≥–æ—Ç–æ–≤–∞!",
        f"–§–∞–π–ª: {out_path}",
        f"–ü—Ä–æ–µ–∫—Ç: {selected.get('name')} (slug: {selected.get('slug')}).",
        f"–ê–ª–≥–æ—Ä–∏—Ç–º –∫–ª–∏–ø–æ–≤: {algo_meta['title']} ({resolved_key}/{algo_meta.get('short')}).",
        f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤: {len(source_ids)}.",
        f"–°–µ–≥–º–µ–Ω—Ç–æ–≤ –ø–æ –º–∞–Ω–∏—Ñ–µ—Å—Ç—É: {len(parsed_segments)}.",
    ]
    if minutes:
        msg_lines.append(f"–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø—Ä–æ–µ–∫—Ç–∞ ‚âà {minutes:.1f} –º–∏–Ω.")
    await send_fn("\n".join(msg_lines))


def _project_slug_key(project: Dict[str, Any]) -> str:
    slug = (project.get("slug") or project.get("name") or f"project-{id(project)}").strip()
    return slug.lower()


def _prepare_randompmv_session(
    used_group_keys: Optional[Set[Tuple[str, str]]] = None,
    min_new_sources: int = 0,
    forced_projects: Optional[List[Dict[str, Any]]] = None,
    orientation_preference: Optional[str] = None,
) -> Tuple[Dict[str, Any], str, Dict[str, Any]]:
    raw_projects: List[Dict[str, Any]] = []
    if forced_projects:
        raw_projects.extend(forced_projects)
    raw_projects.extend(load_music_projects())

    if not raw_projects:
        raise RuntimeError("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø—Ä–æ–µ–∫—Ç–æ–≤ –≤ music_projects.")

    seen_slugs: Set[str] = set()
    deduped: List[Dict[str, Any]] = []
    for proj in raw_projects:
        key = _project_slug_key(proj)
        if key in seen_slugs:
            continue
        seen_slugs.add(key)
        deduped.append(proj)

    forced_slugs = {_project_slug_key(p) for p in (forced_projects or [])}
    forced_list: List[Dict[str, Any]] = []
    unused_projects: List[Dict[str, Any]] = []
    other_projects: List[Dict[str, Any]] = []
    for proj in deduped:
        slug_key = _project_slug_key(proj)
        usage = int(proj.get("usage_count") or 0)
        if slug_key in forced_slugs:
            forced_list.append(proj)
        elif usage <= 0:
            unused_projects.append(proj)
        else:
            other_projects.append(proj)

    project_candidates = forced_list + unused_projects + other_projects

    groups_raw = get_source_groups_prefer_unused()
    if not groups_raw:
        raise RuntimeError("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –≥—Ä—É–ø–ø –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤. –í—ã–ø–æ–ª–Ω–∏—Ç–µ /scan.")
    group_entries = [
        SourceGroupEntry(key=key, rows=list(rows), unused_count=unused)
        for key, rows, unused in groups_raw
    ]
    sorted_entries, orientation_map = sort_group_entries_with_orientation(group_entries)
    prepared_groups = [(entry.key, list(entry.rows), entry.unused_count) for entry in sorted_entries]

    fallback_result: Optional[Tuple[Dict[str, Any], str, Dict[str, Any]]] = None
    last_error: Optional[Exception] = None

    for project in project_candidates:
        try:
            strict_result = _prepare_randompmv_from_project(
                project,
                used_group_keys,
                prepared_groups,
                orientation_map,
                require_target=True,
                min_new_sources=min_new_sources,
                orientation_preference=orientation_preference,
            )
        except Exception as exc:
            last_error = exc
            continue

        if strict_result:
            return strict_result

        if fallback_result is not None:
            continue

        try:
            fallback_result = _prepare_randompmv_from_project(
                project,
                used_group_keys,
                prepared_groups,
                orientation_map,
                require_target=False,
                min_new_sources=min_new_sources,
                orientation_preference=orientation_preference,
            )
        except Exception as exc:
            last_error = exc
            continue

    if fallback_result:
        return fallback_result
    if last_error:
        raise last_error
    raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–æ–±—Ä–∞—Ç—å –≥—Ä—É–ø–ø—É —Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤.")


def _prepare_randompmv_from_project(
    project: Dict[str, Any],
    used_group_keys: Optional[Set[Tuple[str, str]]],
    prepared_groups: List[Tuple[Tuple[str, str], List[sqlite3.Row], int]],
    orientation_map: Dict[Tuple[str, str], str],
    require_target: bool,
    min_new_sources: int = 0,
    orientation_preference: Optional[str] = None,
) -> Optional[Tuple[Dict[str, Any], str, Dict[str, Any]]]:
    manifest_data = project.get("manifest_data")
    manifest_path = project.get("manifest_path")
    if not manifest_data and manifest_path and Path(manifest_path).exists():
        manifest_data = json.loads(Path(manifest_path).read_text(encoding="utf-8"))
        project["manifest_data"] = manifest_data
    parsed_segments = parse_manifest_segments(manifest_data or {})
    if not parsed_segments:
        raise RuntimeError(f"–î–ª—è –ø—Ä–æ–µ–∫—Ç–∞ {project.get('name')} –Ω–µ –Ω–∞—à–ª–æ—Å—å –≤–∞–ª–∏–¥–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤.")

    audio_path = project.get("audio_path")
    audio_path_path = Path(audio_path) if audio_path else None
    if not audio_path_path or not audio_path_path.exists():
        raise RuntimeError(f"–£ –ø—Ä–æ–µ–∫—Ç–∞ {project.get('name')} –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç audio.mp3.")

    duration_seconds = float(project.get("duration") or 0.0)
    if duration_seconds <= 0 and parsed_segments:
        duration_seconds = float(parsed_segments[-1].end)
    duration_minutes = max(duration_seconds / 60.0, 1.0)
    target_sources, target_ratio = _randompmv_compute_target_sources(duration_minutes)
    required_total_sources = max(target_sources, max(0, min_new_sources))

    orientation_choice = (orientation_preference or "").upper()
    if orientation_choice in NEWCOMPMUSIC_ORIENTATION_CHOICES:
        orientation_cycle = [orientation_choice]
    else:
        orientation_cycle = list(NEWCOMPMUSIC_ORIENTATION_CHOICES)
        random.shuffle(orientation_cycle)

    def pick_group(
        forbid_used: bool,
        require_target_count: bool,
    ) -> Optional[Tuple[Tuple[str, str], List[sqlite3.Row], int, List[sqlite3.Row], str]]:
        for orient in orientation_cycle:
            filtered = filter_groups_by_orientation(prepared_groups, orientation_map, orient)
            if not filtered:
                continue
            shuffled = filtered[:]
            random.shuffle(shuffled)
            for key, rows, unused in shuffled:
                if forbid_used and used_group_keys and key in used_group_keys:
                    continue
                color_rows = list(rows)
                if not color_rows:
                    continue
                new_available = sum(1 for row in color_rows if _is_unused_source_row(row))
                if min_new_sources > 0 and new_available < min_new_sources:
                    continue
                if require_target_count:
                    if len(color_rows) < required_total_sources:
                        continue
                else:
                    if len(color_rows) < max(min_new_sources, 1):
                        continue
                return (key, list(rows), unused, list(color_rows), orient)
        return None

    search_plan = [(True, True), (False, True)]
    if not require_target:
        search_plan.extend([(True, False), (False, False)])

    chosen: Optional[
        Tuple[Tuple[str, str], List[sqlite3.Row], int, List[sqlite3.Row], str]
    ] = None
    for forbid_used, need_target in search_plan:
        candidate = pick_group(forbid_used, need_target)
        if candidate:
            chosen = candidate
            break

    if not chosen:
        if require_target:
            return None
        raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–æ–±—Ä–∞—Ç—å –≥—Ä—É–ø–ø—É —Å –∏—Å—Ö–æ–¥–Ω–∏–∫–∞–º–∏.")

    key, rows, unused_count, color_rows, chosen_orientation = chosen
    if not color_rows:
        raise RuntimeError("–í—ã–±—Ä–∞–Ω–Ω–∞—è –≥—Ä—É–ø–ø–∞ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤.")
    group_idx = next(
        (idx for idx, (group_key, _, _) in enumerate(prepared_groups, 1) if group_key == key),
        None,
    )
    orientation_label = (orientation_map.get(key) or _resolution_orientation(key[1] or "")[0]).upper()
    color_label = "–í–°–ï"

    new_sources_available = sum(1 for row in color_rows if _is_unused_source_row(row))
    if min_new_sources > 0 and new_sources_available < min_new_sources:
        raise RuntimeError("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –Ω–æ–≤—ã—Ö –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ –¥–ª—è —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è.")

    total_required = max(target_sources, min_new_sources)
    sources_count = min(len(color_rows), total_required)
    if sources_count <= 0:
        raise RuntimeError("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.")

    autotag = None

    algo_key = random.choice(list(CLIP_SEQUENCE_ALGORITHMS.keys()))

    music_selected = {
        "slug": project.get("slug"),
        "name": project.get("name"),
        "duration": project.get("duration"),
        "segments": len(parsed_segments),
        "manifest": manifest_data,
        "audio_path": str(audio_path_path),
        "parsed_segments": parsed_segments,
    }
    group_choice = {
        "key": key,
        "count": len(color_rows),
        "orientation": orientation_label,
        "total_count": len(rows),
        "unused_count": unused_count,
        "group_number": group_idx,
    }
    session = {
        "state": "newcompmusic_wait_algo",
        "music_selected": music_selected,
        "music_group_choice": group_choice,
        "music_group_rows": list(rows),
        "music_groups_all": prepared_groups,
        "music_group_orientations": orientation_map,
        "music_orientation_preference": chosen_orientation,
        "music_color_rows": list(color_rows),
        "music_color_choice": color_label,
        "music_color_autotag": autotag,
        "music_sources": sources_count,
        "music_folder_only_new": False,
        "_raise_on_newcomp_error": True,
        "music_min_new_sources": max(0, min_new_sources),
    }
    meta = {
        "project": project.get("name") or project.get("slug"),
        "orientation": chosen_orientation or orientation_label,
        "group": f"{key[0]} {key[1]}",
        "group_key": [key[0], key[1]],
        "sources": sources_count,
        "color": color_label,
        "algo_key": algo_key,
        "duration_minutes": duration_minutes,
        "target_sources": target_sources,
        "target_ratio": target_ratio,
        "available_color_sources": len(color_rows),
        "limited_sources": len(color_rows) < target_sources,
        "min_new_sources": max(0, min_new_sources),
        "new_sources_available": new_sources_available,
    }
    return session, algo_key, meta


async def run_randompmv_batch(
    send_fn: Callable[[str], Awaitable[None]],
    user_id: int,
    total_runs: int,
    min_new_sources: int = 0,
    orientation_preference: Optional[str] = None,
) -> None:
    total = max(RANDOMPMV_MIN_BATCH, min(int(total_runs), RANDOMPMV_MAX_BATCH))
    created = 0
    used_groups: Set[Tuple[str, str]] = set()
    used_music_paths: Set[str] = set()
    auto_musicprep_disabled = False
    for idx in range(1, total + 1):
        forced_projects: Optional[List[Dict[str, Any]]] = None
        if not auto_musicprep_disabled:
            try:
                forced_project = auto_create_random_music_project(used_music_paths)
            except Exception as auto_exc:
                auto_musicprep_disabled = True
                await send_fn(
                    f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –Ω–æ–≤—ã–π music project: {auto_exc}. "
                    "–ü–æ–ø—Ä–æ–±—É—é –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —É–∂–µ –≥–æ—Ç–æ–≤—ã–µ –ø—Ä–æ–µ–∫—Ç—ã."
                )
            else:
                forced_projects = [forced_project]

        try:
            session, algo_key, meta = _prepare_randompmv_session(
                used_groups,
                min_new_sources=min_new_sources,
                forced_projects=forced_projects,
                orientation_preference=orientation_preference,
            )
        except Exception as exc:
            log_randompmv_event(
                {
                    "run_index": idx,
                    "total_runs": total,
                    "status": "prepare_error",
                    "error": str(exc),
                }
            )
            await send_fn(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å Random PMV #{idx}: {exc}")
            break

        algo_meta = CLIP_SEQUENCE_ALGORITHMS.get(algo_key, {})
        base_event = {
            "run_index": idx,
            "total_runs": total,
            **meta,
        }
        log_randompmv_event({**base_event, "status": "start"})

        source_line = f"{meta['sources']} –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤."
        if meta.get("target_sources") and meta["sources"] < meta["target_sources"]:
            source_line += f" (–Ω—É–∂–Ω–æ ‚âà {meta['target_sources']})"
        if min_new_sources > 0:
            source_line += f", –Ω–æ–≤—ã—Ö ‚â• {min_new_sources}"
        await send_fn(
            f"‚ñ∂Ô∏è Random PMV #{idx}/{total}: –ø—Ä–æ–µ–∫—Ç {meta['project']}, "
            f"{meta['orientation']} / {meta['group']}, {source_line} ({meta['color']}), "
            f"–∞–ª–≥–æ—Ä–∏—Ç–º {algo_meta.get('short', algo_key)}."
        )
        try:
            user_sessions[user_id] = session
            await run_newcompmusic_generation(send_fn, session, algo_key, user_id)
        except Exception as exc:
            log_randompmv_event({**base_event, "status": "generation_error", "error": str(exc)})
            break
        else:
            created += 1
            log_randompmv_event({**base_event, "status": "success"})
            group_key = session.get("music_group_choice", {}).get("key")
            if group_key:
                used_groups.add(tuple(group_key))

    user_sessions.pop(user_id, None)
    if created:
        await send_fn(f"‚úÖ Random PMV –∑–∞–≤–µ—Ä—à—ë–Ω. –°–æ–∑–¥–∞–Ω–æ {created} –∏–∑ {total}.")
    else:
        await send_fn("‚ö†Ô∏è Random PMV –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å.")


def load_music_generator_module():
    global _music_generator_module
    if _music_generator_module is not None:
        return _music_generator_module
    module_path = SCRIPT_DIR / "music_guided_generator.py"
    if not module_path.exists():
        raise RuntimeError("music_guided_generator.py –Ω–µ –Ω–∞–π–¥–µ–Ω —Ä—è–¥–æ–º —Å–æ —Å–∫—Ä–∏–ø—Ç–æ–º.")
    spec = importlib.util.spec_from_file_location("music_guided_generator", module_path)
    if spec is None or spec.loader is None:
        raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å music_guided_generator.py")
    module = types.ModuleType("music_guided_generator")
    module.__file__ = str(module_path)
    sys.modules["music_guided_generator"] = module
    spec.loader.exec_module(module)
    _music_generator_module = module
    return module


def list_music_input_files() -> List[Path]:
    MUSIC_INPUT_DIR.mkdir(parents=True, exist_ok=True)
    files = []
    for path in sorted(MUSIC_INPUT_DIR.iterdir(), key=lambda p: p.name.lower()):
        if path.is_file() and path.suffix.lower() in {".mp3", ".wav", ".flac", ".m4a"}:
            files.append(path)
    return files


RESOLUTION_RE = re.compile(r"(\d+)\s*[x—ÖX–•]\s*(\d+)")
ORIENTATION_ORDER = {"VR": 0, "HOR": 1, "VER": 2}


@dataclass
class SourceGroupEntry:
    key: Tuple[str, str]
    rows: List[sqlite3.Row]
    unused_count: int = 0


def _resolution_pixels(res: str) -> int:
    if not res:
        return 0
    match = RESOLUTION_RE.search(res)
    if not match:
        return 0
    try:
        width = int(match.group(1))
        height = int(match.group(2))
        return width * height
    except ValueError:
        return 0


def _resolution_orientation(res: str) -> Tuple[str, int]:
    """
    –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞:
    VR (~2:1), –≥–æ—Ä–∏–∑–æ–Ω—Ç, –≤–µ—Ä—Ç–∏–∫–∞–ª—å.
    """
    match = RESOLUTION_RE.search(res or "")
    if not match:
        return "HOR", ORIENTATION_ORDER["HOR"]
    try:
        width = int(match.group(1))
        height = int(match.group(2))
    except ValueError:
        return "HOR", ORIENTATION_ORDER["HOR"]
    if width <= 0 or height <= 0:
        return "HOR", ORIENTATION_ORDER["HOR"]
    if width >= height:
        ratio = width / height if height else float("inf")
        if ratio >= 1.8:
            return "VR", ORIENTATION_ORDER["VR"]
        return "HOR", ORIENTATION_ORDER["HOR"]
    else:
        return "VER", ORIENTATION_ORDER["VER"]


def _friendly_folder_label(folder: Path, roots: Optional[List[Path]] = None) -> str:
    roots = roots or []
    try:
        folder_resolved = folder.resolve(strict=False)
    except Exception:
        folder_resolved = folder
    for root in roots:
        try:
            root_resolved = root.resolve(strict=False)
        except Exception:
            root_resolved = root
        try:
            rel = folder_resolved.relative_to(root_resolved)
            rel_str = str(rel).replace("\\", "/")
            base = root_resolved.name or str(root_resolved)
            if not rel_str:
                return base
            return f"{base}/{rel_str}"
        except ValueError:
            continue
    label = folder_resolved.name or str(folder_resolved)
    return label.replace("\\", "/")


def _is_unused_source_row(row: sqlite3.Row) -> bool:
    try:
        pmv_list = row["pmv_list"]
    except Exception:
        pmv_list = None
    return not (pmv_list or "").strip()


def compute_group_folder_options(
    rows: List[sqlite3.Row],
    unused_only: bool = False,
) -> Tuple[List[Dict[str, Any]], Dict[str, Dict[str, Any]]]:
    folder_map: Dict[str, Dict[str, Any]] = {}
    for row in rows:
        if unused_only and not _is_unused_source_row(row):
            continue
        try:
            parent = Path(row["video_path"]).resolve(strict=False).parent
        except Exception:
            parent = Path(row["video_path"]).parent
        folder_key = _normalize_path_prefix(parent)
        info = folder_map.setdefault(
            folder_key,
            {"rows": [], "count": 0, "path": parent},
        )
        info["rows"].append(row)
        info["count"] += 1

    sorted_folders = sorted(
        folder_map.items(),
        key=lambda item: (-item[1]["count"], item[0]),
    )
    roots = [Path(r["folder_path"]) for r in db_get_upload_folders(include_ignored=True)]

    options: List[Dict[str, Any]] = []
    token_map: Dict[str, Dict[str, Any]] = {}
    for idx, (folder_key, info) in enumerate(sorted_folders, 1):
        token = f"folder{idx}"
        label = _friendly_folder_label(Path(info["path"]), roots)
        option = {
            "token": token,
            "label": label,
            "count": info["count"],
            "path": str(Path(info["path"])),
        }
        options.append(option)
        token_map[token] = {
            **info,
            "label": label,
            "path": option["path"],
        }

    total_rows = [row for row in rows if (not unused_only or _is_unused_source_row(row))]
    token_map["all"] = {
        "rows": total_rows,
        "count": len(total_rows),
        "path": None,
        "label": "–í—Å–µ –ø–∞–ø–∫–∏",
    }
    options.insert(
        0,
        {
            "token": "all",
            "label": "–í—Å–µ –ø–∞–ø–∫–∏",
            "count": len(total_rows),
            "path": None,
        },
    )
    return options, token_map


def filter_groups_by_orientation(
    groups: List[Tuple[Tuple[str, str], List[sqlite3.Row], int]],
    orientation_map: Dict[Tuple[str, str], str],
    target: str,
) -> List[Tuple[Tuple[str, str], List[sqlite3.Row], int]]:
    normalized = (target or "").upper()
    if normalized not in NEWCOMPMUSIC_ORIENTATION_CHOICES:
        return []
    filtered: List[Tuple[Tuple[str, str], List[sqlite3.Row], int]] = []
    for key, rows, unused in groups:
        label = (orientation_map.get(key) or "").upper()
        if not label:
            label = _resolution_orientation(key[1] or "")[0]
        if label.upper() == normalized:
            filtered.append((key, rows, unused))
    return filtered


def _build_group_selection_lines(
    sess: Dict[str, Any],
    group_entries: List[SourceGroupEntry],
    orientation: str,
    prompt_kind: str = "text",
) -> List[str]:
    orientation_map = sess.get("music_group_orientations") or {}

    def orientation_prefix(entry: SourceGroupEntry) -> str:
        return orientation_map.get(entry.key, "")

    project_info = sess.get("music_selected") or {}
    lines: List[str] = []
    if project_info.get("name"):
        lines.append(f"–ü—Ä–æ–µ–∫—Ç: {project_info.get('name')} (slug: {project_info.get('slug')}).")
    segs = project_info.get("segments")
    if segs is not None:
        lines.append(f"–°–º–µ–Ω –∫–ª–∏–ø–æ–≤: {segs}")
    duration = project_info.get("duration")
    if duration:
        lines.append(f"–ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å ‚âà {(duration / 60.0):.1f} –º–∏–Ω—É—Ç.")
    lines.append(f"–û—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è: {orientation}.")
    lines.append("")
    lines.extend(
        format_source_group_lines(
            group_entries,
            "–í—ã–±–µ—Ä–∏—Ç–µ –≥—Ä—É–ø–ø—É –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ (codec + —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ):",
            prefix_func=orientation_prefix,
        )
    )
    lines.append("")
    if prompt_kind == "inline":
        lines.append("–ù–∞–∂–º–∏—Ç–µ –Ω–æ–º–µ—Ä –≥—Ä—É–ø–ø—ã –Ω–∞ –∫–ª–∞–≤–∏–∞—Ç—É—Ä–µ –Ω–∏–∂–µ.")
    else:
        lines.append("–ü—Ä–∏—à–ª–∏—Ç–µ –Ω–æ–º–µ—Ä –≥—Ä—É–ø–ø—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä: 3).")
    return lines


def format_folder_selection_message(
    codec: str,
    resolution: str,
    project_info: Dict[str, Any],
    options: List[Dict[str, Any]],
    max_listed: int = 20,
    unused_only: bool = False,
) -> str:
    project_name = project_info.get("name") or project_info.get("slug") or ""
    lines = [
        f"–ì—Ä—É–ø–ø–∞ –≤—ã–±—Ä–∞–Ω–∞: {codec} {resolution} (–∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤: {options[0]['count']}).",
    ]
    if project_name:
        lines.append(f"–ü—Ä–æ–µ–∫—Ç: {project_name}.")
    if unused_only:
        lines.append("–§–∏–ª—å—Ç—Ä –≤–∫–ª—é—á–µ–Ω: —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ –∏—Å—Ö–æ–¥–Ω–∏–∫–∏.")
    lines.append("–¢–µ–ø–µ—Ä—å –≤—ã–±–µ—Ä–∏—Ç–µ –ø–æ–¥–ø–∞–ø–∫—É (–∏–ª–∏ ¬´–í—Å–µ –ø–∞–ø–∫–∏¬ª):")
    listed = 0
    for idx, opt in enumerate(options, 1):
        if listed >= max_listed:
            break
        label = opt["label"]
        lines.append(f"{idx}. {label} ({opt['count']})")
        listed += 1
    remaining = len(options) - listed
    if remaining > 0:
        lines.append(f"... –∏ –µ—â—ë {remaining} –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫–∏ –Ω–∏–∂–µ.")
    return "\n".join(lines)


def compose_newcomp_folder_prompt(
    sess: Dict[str, Any],
) -> Tuple[str, InlineKeyboardMarkup]:
    rows = sess.get("music_group_rows") or []
    options, folder_map = compute_group_folder_options(
        rows,
        unused_only=sess.get("music_folder_only_new", False),
    )
    sess["music_folder_options"] = options
    sess["music_folder_map"] = folder_map
    codec, res = sess.get("music_group_choice", {}).get("key") or ("?", "?")
    project_info = sess.get("music_selected") or {}
    msg_text = format_folder_selection_message(
        codec,
        res,
        project_info,
        options,
        unused_only=sess.get("music_folder_only_new", False),
    )
    msg_text += "\n\n–ï—Å–ª–∏ –Ω—É–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å –¥—Ä—É–≥—É—é –≥—Ä—É–ø–ø—É, –Ω–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É ¬´–ù–∞–∑–∞–¥ –∫ –≥—Ä—É–ø–ø–∞–º¬ª –Ω–∏–∂–µ."
    keyboard = build_newcomp_folder_keyboard(
        options, unused_only=sess.get("music_folder_only_new", False)
    )
    return msg_text, keyboard


def _rategrp_row_has_color(row: sqlite3.Row) -> bool:
    comments = ""
    try:
        comments = row["comments"] or ""
    except Exception:
        comments = ""
    return any(emoji in comments for emoji in RATEGRP_COLOR_EMOJIS)


def _rategrp_row_color(row: sqlite3.Row) -> Optional[str]:
    comments = ""
    try:
        comments = row["comments"] or ""
    except Exception:
        comments = ""
    for info in RATEGRP_COLOR_CHOICES.values():
        if info["emoji"] in comments:
            return info["emoji"]
    return None


def _rategrp_balanced_shuffle(rows: List[sqlite3.Row]) -> List[sqlite3.Row]:
    pool = list(rows)
    if len(pool) <= 1:
        return pool

    def pick_index(length: int, zone: str) -> int:
        if length <= 1:
            return 0
        third = max(1, length // 3)
        if zone == "front":
            return random.randint(0, max(0, third - 1))
        if zone == "back":
            start = max(0, length - third)
            return random.randint(start, length - 1)
        mid_start = max(0, (length // 2) - (third // 2))
        mid_end = min(length - 1, mid_start + third - 1)
        return random.randint(mid_start, max(mid_start, mid_end))

    pattern = ["front", "back", "middle"]
    idx = 0
    result: List[sqlite3.Row] = []
    while pool:
        zone = pattern[idx % len(pattern)]
        pick = pick_index(len(pool), zone)
        result.append(pool.pop(pick))
        idx += 1
    return result


def _rategrp_rows_to_queue(rows: List[sqlite3.Row], shuffle: bool = True) -> List[Dict[str, Any]]:
    shuffled_rows = _rategrp_balanced_shuffle(rows) if shuffle else rows
    queue: List[Dict[str, Any]] = []
    for row in shuffled_rows:
        try:
            sid = int(row["id"])
            path_str = str(row["video_path"])
        except Exception:
            continue
        queue.append({"id": sid, "path": path_str, "name": Path(path_str).name})
    return queue


def _fetch_unrated_pmv_rows(limit: int = RATEGRP_PMV_MAX_QUEUE) -> List[sqlite3.Row]:
    rows = db_get_used_sources_list()
    if not rows:
        return []
    usage = collect_source_usage_stats()
    scored: List[Tuple[int, float, sqlite3.Row]] = []
    for row in rows:
        if _rategrp_row_has_color(row):
            continue
        try:
            sid = int(row["id"])
        except Exception:
            continue
        info = usage.get(sid) or {}
        last_date = info.get("last_date")
        ordinal = last_date.toordinal() if last_date else 0
        scored.append((ordinal, random.random(), row))
    scored.sort(key=lambda item: (-item[0], item[1]))
    ordered = [item[2] for item in scored]
    if limit > 0:
        ordered = ordered[:limit]
    return ordered


async def _start_rategrp_from_pmv(
    session: Dict[str, Any],
    send_fn: Callable[[str, Optional[InlineKeyboardMarkup]], Awaitable[Any]],
) -> bool:
    rows = _fetch_unrated_pmv_rows()
    if not rows:
        await send_fn("–ù–µ –Ω–∞—à—ë–ª —É—á–∞—Å—Ç–≤–æ–≤–∞–≤—à–∏—Ö –≤ PMV –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ –±–µ–∑ –æ—Ü–µ–Ω–∫–∏.", None)
        return False
    queue = _rategrp_rows_to_queue(rows, shuffle=True)
    session["rategrp_queue"] = queue
    session["rategrp_total"] = len(queue)
    session["rategrp_processed"] = 0
    session["rategrp_queue_origin"] = "pmv"
    session["state"] = "rategrp_rate_source"

    await send_fn(
        f"–ò–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö PMV –Ω–∞–π–¥–µ–Ω–æ {len(queue)} –Ω–µ–æ—Ü–µ–Ω—ë–Ω–Ω—ã—Ö –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤. –û—Ü–µ–Ω–∏–º –∏—Ö!",
        None,
    )
    await rategrp_send_next_prompt(session, send_fn)
    return True


def _search_find_matches(term: str, limit: int = BADCLIP_MAX_MATCHES) -> List[Dict[str, Any]]:
    normalized = term.strip().lower()
    if not normalized:
        return []
    rows = db_get_all_compilations()
    today = datetime.now().strftime("%Y-%m-%d")
    pmv_primary: List[Dict[str, Any]] = []
    pmv_secondary: List[Dict[str, Any]] = []
    for row in rows:
        path = Path(row["video_path"])
        haystack = f"{path.name.lower()} {str(path).lower()}"
        if normalized not in haystack:
            continue
        entry = {
            "type": "pmv",
            "id": int(row["id"]),
            "video_path": str(path),
            "pmv_date": row["pmv_date"],
            "source_ids": row["source_ids"],
            "stem": path.stem,
        }
        container = (
            pmv_primary
            if (today in str(path.parent) or (row["pmv_date"] or "").startswith(today))
            else pmv_secondary
        )
        container.append(entry)

    source_rows = db_search_sources_by_term(normalized, limit * 2)
    source_entries: List[Dict[str, Any]] = []
    for row in source_rows:
        try:
            resolved = str(Path(row["video_path"]))
        except Exception:
            resolved = str(row["video_path"])
        source_entries.append(
            {
                "type": "source",
                "id": int(row["id"]),
                "video_path": resolved,
                "video_name": row["video_name"],
                "codec": row["codec"],
                "resolution": row["resolution"],
                "comments": row["comments"],
            }
        )

    combined = pmv_primary + pmv_secondary + source_entries
    results: List[Dict[str, Any]] = []
    seen_keys: Set[Tuple[str, int]] = set()
    for entry in combined:
        key = (entry["type"], entry["id"])
        if key in seen_keys:
            continue
        seen_keys.add(key)
        results.append(entry)
        if len(results) >= limit:
            break
    return results


def build_find_keyboard(matches: List[Dict[str, Any]]) -> InlineKeyboardMarkup:
    rows: List[List[InlineKeyboardButton]] = []
    for idx, entry in enumerate(matches, 1):
        if entry.get("type") == "pmv":
            label = truncate_label_keep_suffix(f"PMV ¬∑ {entry.get('stem')}", 48)
        else:
            color = extract_color_emoji(entry.get("comments"))
            prefix = f"{color} " if color else ""
            label = truncate_label_keep_suffix(f"{prefix}{entry.get('video_name')}", 48)
        rows.append([InlineKeyboardButton(label or str(idx), callback_data=f"find_pick:{idx - 1}")])
    rows.append([InlineKeyboardButton("‚Ü©Ô∏è –ù–æ–≤—ã–π –ø–æ–∏—Å–∫", callback_data="find_retry")])
    return InlineKeyboardMarkup(rows)


async def _start_find_pmv_queue(
    session: Dict[str, Any],
    match: Dict[str, Any],
    send_fn: Callable[[str, Optional[InlineKeyboardMarkup]], Awaitable[Any]],
) -> bool:
    source_ids = parse_source_id_list(match.get("source_ids") or "")
    if not source_ids:
        await send_fn("–£ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ PMV –Ω–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤.", None)
        return False
    rows = db_get_sources_by_ids(source_ids)
    if not rows:
        await send_fn("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏—Å—Ö–æ–¥–Ω–∏–∫–∏ –≤ –±–∞–∑–µ.", None)
        return False
    rows_map = {int(row["id"]): row for row in rows}
    ordered_rows = [rows_map[sid] for sid in source_ids if sid in rows_map]
    queue = _rategrp_rows_to_queue(ordered_rows, shuffle=False)
    if not queue:
        await send_fn("–û—á–µ—Ä–µ–¥—å –ø—É—Å—Ç–∞—è ‚Äî –≤–æ–∑–º–æ–∂–Ω–æ —Ñ–∞–π–ª—ã —É–¥–∞–ª–µ–Ω—ã.", None)
        return False
    session["rategrp_queue"] = queue
    session["rategrp_total"] = len(queue)
    session["rategrp_processed"] = 0
    session["rategrp_queue_origin"] = "find_pmv"
    session["state"] = "rategrp_rate_source"
    session["find_current"] = match
    session["find_mode"] = True
    session["find_rows"] = ordered_rows
    session["rategrp_rerate_rows"] = ordered_rows
    session["rategrp_group_choice"] = {
        "label": truncate_button_label(match.get("stem") or Path(match.get("video_path", "?")).stem),
        "orientation": match.get("pmv_date") or "PMV",
        "key": ("PMV", match.get("stem") or "?"),
        "count": len(queue),
    }
    await send_fn(
        f"PMV ¬´{match.get('stem')}¬ª –≤—ã–±—Ä–∞–Ω–∞. –ò—Å—Ö–æ–¥–Ω–∏–∫–æ–≤: {len(queue)}. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ü–≤–µ—Ç–Ω—ã–µ –∫–Ω–æ–ø–∫–∏ –Ω–∏–∂–µ.",
        None,
    )
    await rategrp_send_next_prompt(session, send_fn)
    return True


async def _start_find_single_source(
    session: Dict[str, Any],
    row: sqlite3.Row,
    send_fn: Callable[[str, Optional[InlineKeyboardMarkup]], Awaitable[Any]],
) -> bool:
    try:
        sid = int(row["id"])
    except Exception:
        await send_fn("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å ID –∏—Å—Ö–æ–¥–Ω–∏–∫–∞.", None)
        return False
    path = str(row["video_path"])
    queue = [{"id": sid, "path": path, "name": Path(path).name}]
    session["rategrp_queue"] = queue
    session["rategrp_total"] = len(queue)
    session["rategrp_processed"] = 0
    session["rategrp_queue_origin"] = "find_single"
    session["state"] = "rategrp_rate_source"
    session["find_mode"] = True
    session["find_single_row"] = row
    session["rategrp_rerate_rows"] = [row]
    session["rategrp_group_choice"] = {
        "label": row["video_name"],
        "orientation": row["codec"] or "SRC",
        "key": ("SRC", row["resolution"] or "?"),
    }
    color = extract_color_emoji(row["comments"])
    prefix = f"{color} " if color else ""
    await send_fn(f"–ò—Å—Ö–æ–¥–Ω–∏–∫ –Ω–∞–π–¥–µ–Ω: {prefix}{row['video_name']}.", None)
    await rategrp_send_next_prompt(session, send_fn)
    return True


def _count_rategrp_unrated(rows: List[sqlite3.Row]) -> int:
    return sum(1 for row in rows if not _rategrp_row_has_color(row))


def _count_rows_for_folder_mode(rows: List[sqlite3.Row], unused_only: bool) -> int:
    if not unused_only:
        return len(rows)
    return sum(1 for row in rows if _is_unused_source_row(row))


def format_rategrp_group_prompt(
    session: Dict[str, Any],
    group_entries: List[SourceGroupEntry],
    orientation: str,
    prompt_kind: str = "text",
) -> List[str]:
    orientation_map = session.get("rategrp_group_orientations") or {}

    def prefix_func(entry: SourceGroupEntry) -> str:
        return orientation_map.get(entry.key, "")

    display_entries: List[SourceGroupEntry] = []
    for entry in group_entries:
        rows = list(entry.rows)
        display_entries.append(
            SourceGroupEntry(
                key=entry.key,
                rows=rows,
                unused_count=_count_rategrp_unrated(rows),
            )
        )

    lines = [
        f"–û—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è: {orientation}.",
        "",
    ]
    lines.extend(
        format_source_group_lines(
            display_entries,
            "–í—ã–±–µ—Ä–∏—Ç–µ –≥—Ä—É–ø–ø—É –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ (üÜï = –±–µ–∑ –æ—Ü–µ–Ω–∫–∏):",
            prefix_func=prefix_func,
        )
    )
    lines.append("")
    if prompt_kind == "inline":
        lines.append("–ù–∞–∂–º–∏—Ç–µ –Ω–æ–º–µ—Ä –≥—Ä—É–ø–ø—ã –Ω–∞ –∫–ª–∞–≤–∏–∞—Ç—É—Ä–µ –Ω–∏–∂–µ.")
    else:
        lines.append("–ü—Ä–∏—à–ª–∏—Ç–µ –Ω–æ–º–µ—Ä –≥—Ä—É–ø–ø—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä: 3).")
    return lines


def _compute_rategrp_color_counts(rows: List[sqlite3.Row]) -> Tuple[Dict[str, int], int]:
    counts = {info["emoji"]: 0 for info in RATEGRP_COLOR_CHOICES.values()}
    unrated = 0
    for row in rows:
        emoji = _rategrp_row_color(row)
        if emoji and emoji in counts:
            counts[emoji] += 1
        else:
            unrated += 1
    return counts, unrated


def _rategrp_available_colors(rows: List[sqlite3.Row]) -> List[Tuple[str, str, int]]:
    counts, _ = _compute_rategrp_color_counts(rows)
    available: List[Tuple[str, str, int]] = []
    for key, info in RATEGRP_COLOR_CHOICES.items():
        emoji = info["emoji"]
        count = counts.get(emoji, 0)
        if count > 0:
            available.append((key, emoji, count))
    return available


def _filter_rows_by_color(
    rows: List[sqlite3.Row],
    allowed: Set[str],
    include_unrated: bool = False,
) -> List[sqlite3.Row]:
    filtered: List[sqlite3.Row] = []
    for row in rows:
        emoji = _rategrp_row_color(row)
        if emoji:
            if emoji in allowed:
                filtered.append(row)
        else:
            if include_unrated:
                filtered.append(row)
    return filtered


def _filter_green_new_rows(rows: List[sqlite3.Row]) -> List[sqlite3.Row]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ –∑–µ–ª—ë–Ω—ã–µ –∏—Å—Ö–æ–¥–Ω–∏–∫–∏ –∏ –ª—é–±—ã–µ –∏—Å—Ö–æ–¥–Ω–∏–∫–∏ –±–µ–∑ PMV-–∏—Å—Ç–æ—Ä–∏–∏."""
    filtered: List[sqlite3.Row] = []
    green_emoji = RATEGRP_COLOR_CHOICES["green"]["emoji"]
    for row in rows:
        emoji = _rategrp_row_color(row)
        if emoji == green_emoji or _is_unused_source_row(row):
            filtered.append(row)
    return filtered


def _prepare_rategrp_queue(rows: List[sqlite3.Row]) -> List[Dict[str, Any]]:
    unrated_rows = [row for row in rows if not _rategrp_row_has_color(row)]
    return _rategrp_rows_to_queue(unrated_rows)


def _rategrp_update_cached_row_color(
    session: Dict[str, Any],
    source_id: int,
    updated_comments: Optional[str],
) -> None:
    if not updated_comments:
        return
    rows = session.get("rategrp_rerate_rows") or []
    for row in rows:
        try:
            row_id = int(row.get("id") if isinstance(row, dict) else row["id"])
        except Exception:
            continue
        if row_id == source_id:
            try:
                row["comments"] = updated_comments  # type: ignore[index]
            except Exception:
                pass
            break


async def rategrp_send_next_prompt(
    session: Dict[str, Any],
    send_fn: Callable[[str, Optional[InlineKeyboardMarkup]], Awaitable[Any]],
    prefix: Optional[str] = None,
) -> None:
    queue: List[Dict[str, Any]] = session.get("rategrp_queue") or []
    total = int(session.get("rategrp_total", len(queue) or 0))
    processed = int(session.get("rategrp_processed", 0))
    if not queue:
        origin = session.get("rategrp_queue_origin")
        session["rategrp_queue_origin"] = None
        if origin == "find_pmv":
            session["state"] = "find_wait_term"
            session["find_matches"] = []
            lines = [prefix] if prefix else []
            lines.append("–ò—Å—Ö–æ–¥–Ω–∏–∫–∏ –∏–∑ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ PMV –∑–∞–∫–æ–Ω—á–∏–ª–∏—Å—å. –ü—Ä–∏—à–ª–∏—Ç–µ —á–∞—Å—Ç—å –∏–º–µ–Ω–∏ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ñ–∞–π–ª–∞.")
            await send_fn("\n".join(line for line in lines if line), None)
        elif origin == "find_single":
            session["state"] = "find_wait_term"
            session["find_matches"] = []
            lines = [prefix] if prefix else []
            lines.append("–ò—Å—Ö–æ–¥–Ω–∏–∫ –æ—Ü–µ–Ω—ë–Ω. –ú–æ–∂–µ—Ç–µ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –ø–æ–∏—Å–∫ –∏–ª–∏ –≤–≤–µ—Å—Ç–∏ –¥—Ä—É–≥—É—é —á–∞—Å—Ç—å –∏–º–µ–Ω–∏.")
            await send_fn("\n".join(line for line in lines if line), None)
        elif origin == "rerate":
            rows = session.get("rategrp_rerate_rows") or []
            available = _rategrp_available_colors(rows)
            if available:
                session["state"] = "rategrp_choose_rerate_color"
                lines = [prefix] if prefix else []
                lines.append("–í—ã–±–µ—Ä–∏—Ç–µ —Ü–≤–µ—Ç, –∫–æ—Ç–æ—Ä—ã–π —Ö–æ—Ç–∏—Ç–µ –ø–µ—Ä–µ–æ—Ü–µ–Ω–∏—Ç—å –µ—â—ë —Ä–∞–∑.")
                await send_fn(
                    "\n".join(line for line in lines if line),
                    build_rategrp_rerate_keyboard(available),
                )
            else:
                session["state"] = "rategrp_choose_group"
                lines = [prefix] if prefix else []
                lines.append("–í —ç—Ç–æ–π –≥—Ä—É–ø–ø–µ –±–æ–ª—å—à–µ –Ω–µ—Ç –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ –¥–ª—è –ø–µ—Ä–µ–æ—Ü–µ–Ω–∫–∏. –í—ã–±–µ—Ä–∏—Ç–µ –¥—Ä—É–≥—É—é –≥—Ä—É–ø–ø—É.")
                await send_fn("\n".join(line for line in lines if line), None)
        else:
            session["state"] = "rategrp_choose_group"
            lines = [prefix] if prefix else []
            lines.append("–í —ç—Ç–æ–π –≥—Ä—É–ø–ø–µ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å –Ω–µ–æ—Ü–µ–Ω—ë–Ω–Ω—ã—Ö –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤. –í—ã–±–µ—Ä–∏—Ç–µ –¥—Ä—É–≥—É—é –≥—Ä—É–ø–ø—É.")
            await send_fn("\n".join(line for line in lines if line), None)
        return
    current = queue[0]
    idx = processed + 1
    group_choice = session.get("rategrp_group_choice") or {}
    codec, res = group_choice.get("key") or ("?", "?")
    group_label = group_choice.get("label") or f"{codec} {res}"
    orientation = group_choice.get("orientation") or session.get("rategrp_orientation_preference") or "?"
    lines = []
    if prefix:
        lines.append(prefix)
    lines.append(f"–ì—Ä—É–ø–ø–∞: {group_label} ({orientation}).")
    if total:
        lines.append(f"–ò—Å—Ö–æ–¥–Ω–∏–∫ {idx}/{max(total, idx)}")
    else:
        lines.append(f"–ò—Å—Ö–æ–¥–Ω–∏–∫ {idx}")
    path = current["path"]
    lines.append("–ü—É—Ç—å:")
    lines.append(f"```\n{path}\n```")
    lines.append(f"–û—Ü–µ–Ω–∏—Ç–µ –∏—Å—Ö–æ–¥–Ω–∏–∫ –∫–Ω–æ–ø–∫–∞–º–∏ –Ω–∏–∂–µ: {RATEGRP_COLOR_PROMPT}")
    await send_fn("\n".join(lines), build_rategrp_color_keyboard())
    launch_media_preview(path)


async def rategrp_apply_rating(
    session: Dict[str, Any],
    color_key: str,
    send_fn: Callable[[str, Optional[InlineKeyboardMarkup]], Awaitable[Any]],
) -> None:
    queue: List[Dict[str, Any]] = session.get("rategrp_queue") or []
    if not queue:
        await send_fn("–û—á–µ—Ä–µ–¥—å –ø—É—Å—Ç–∞—è. –í—ã–±–µ—Ä–∏—Ç–µ –¥—Ä—É–≥—É—é –≥—Ä—É–ø–ø—É.", None)
        return
    choice = RATEGRP_COLOR_CHOICES.get(color_key)
    if not choice:
        await send_fn("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ü–≤–µ—Ç. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫–∏.", None)
        return
    current = queue.pop(0)
    session["rategrp_queue"] = queue
    session["rategrp_processed"] = int(session.get("rategrp_processed", 0)) + 1
    emoji = choice["emoji"]
    try:
        updated_comments = db_set_source_color(current["id"], emoji)
        _rategrp_update_cached_row_color(session, current["id"], updated_comments)
    except Exception as exc:
        await send_fn(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ü–µ–Ω–∫—É: {exc}", None)
        return
    prefix = f"{emoji} –ò—Å—Ö–æ–¥–Ω–∏–∫ {current['name']} –æ—Ç–º–µ—á–µ–Ω ({choice['label']})."
    await rategrp_send_next_prompt(session, send_fn, prefix=prefix)


async def _rategrp_start_rerate(
    session: Dict[str, Any],
    color_key: str,
    send_fn: Callable[[str, Optional[InlineKeyboardMarkup]], Awaitable[Any]],
) -> bool:
    info = RATEGRP_COLOR_CHOICES.get(color_key)
    rows = session.get("rategrp_rerate_rows") or []
    if not info:
        await send_fn("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ü–≤–µ—Ç.", None)
        return False
    if not rows:
        await send_fn("–ù–µ—Ç –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ –¥–ª—è –ø–µ—Ä–µ–æ—Ü–µ–Ω–∫–∏. –í—ã–±–µ—Ä–∏—Ç–µ –¥—Ä—É–≥—É—é –≥—Ä—É–ø–ø—É.", None)
        return False
    emoji = info["emoji"]
    filtered = [row for row in rows if _rategrp_row_color(row) == emoji]
    if not filtered:
        available = _rategrp_available_colors(rows)
        msg = "–ù–µ –Ω–∞—à—ë–ª –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ —ç—Ç–æ–≥–æ —Ü–≤–µ—Ç–∞. –í—ã–±–µ—Ä–∏—Ç–µ –¥—Ä—É–≥–æ–π."
        markup = build_rategrp_rerate_keyboard(available) if available else None
        await send_fn(msg, markup)
        return False
    queue = _rategrp_rows_to_queue(filtered)
    session["rategrp_queue"] = queue
    session["rategrp_total"] = len(queue)
    session["rategrp_processed"] = 0
    session["state"] = "rategrp_rate_source"
    session["rategrp_queue_origin"] = "rerate"
    await send_fn(
        f"–ü–µ—Ä–µ–æ—Ü–µ–Ω–∫–∞ —Ü–≤–µ—Ç–∞ {emoji} ({info['label']}). –ò—Å—Ö–æ–¥–Ω–∏–∫–æ–≤: {len(queue)}.", None
    )
    await rategrp_send_next_prompt(session, send_fn)
    return True


def normalize_rategrp_color_input(text: str) -> Optional[str]:
    lowered = text.strip().lower()
    mapping = {
        "green": "green",
        "–∑–µ–ª": "green",
        "–∑–µ–ª–µ–Ω": "green",
        "–∑–µ–ª–µ–Ω–∞—è": "green",
        "üü¢": "green",
        "yellow": "yellow",
        "–∂—ë–ª—Ç": "yellow",
        "–∂–µ–ª—Ç": "yellow",
        "–∂–µ–ª—Ç–∞—è": "yellow",
        "üü°": "yellow",
        "red": "red",
        "–∫—Ä–∞—Å–Ω": "red",
        "–∫—Ä–∞—Å–Ω–∞—è": "red",
        "üî¥": "red",
        "pink": "pink",
        "—Ä–æ–∑–æ–≤": "pink",
        "—Ä–æ–∑–æ–≤–∞—è": "pink",
        "ü©∑": "pink",
        "blue": "blue",
        "—Å–∏–Ω": "blue",
        "—Å–∏–Ω—è—è": "blue",
        "üîµ": "blue",
        "favorite": "favorite",
        "fav": "favorite",
        "–∑–≤–µ–∑–¥": "favorite",
        "–∏–∑–±—Ä": "favorite",
        "‚≠ê": "favorite",
        "inspect": "inspect",
        "–≥–ª–∞–∑": "inspect",
        "–∏–Ω—Ç–µ—Ä–µ—Å": "inspect",
        "üëÅ": "inspect",
        "delete": "delete",
        "—É–¥–∞–ª": "delete",
        "–∫—Ä–µ—Å—Ç": "delete",
        "‚ùå": "delete",
    }
    for key, target in mapping.items():
        if lowered.startswith(key):
            return target
    return None


def _source_limit_message(sess: Dict[str, Any], available: int) -> str:
    if sess.get("music_color_rows"):
        return f"–î–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Ü–≤–µ—Ç–∞ –¥–æ—Å—Ç—É–ø–Ω–æ —Ç–æ–ª—å–∫–æ {available} –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤. –í–æ–∑—å–º—ë–º –∏—Ö –≤—Å–µ."
    return f"–í –≤—ã–±—Ä–∞–Ω–Ω–æ–π –ø–æ–¥–ø–∞–ø–∫–µ —Ç–æ–ª—å–∫–æ {available} –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤. –í–æ–∑—å–º—ë–º –∏—Ö –≤—Å–µ."


def launch_media_preview(file_path: Union[str, Path]) -> None:
    if not MEDIA_PLAYER_EXECUTABLE.exists():
        return
    try:
        target = Path(file_path)
    except Exception:
        return
    if not target.exists():
        return
    try:
        subprocess.Popen([str(MEDIA_PLAYER_EXECUTABLE), str(target)])
    except Exception:
        pass


def apply_newcomp_folder_choice(
    sess: Dict[str, Any],
    token: str,
    next_state: str,
) -> Tuple[int, str]:
    folder_map: Dict[str, Dict[str, Any]] = sess.get("music_folder_map") or {}
    info = folder_map.get(token)
    if not info:
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ç–∞–∫—É—é –ø–æ–¥–ø–∞–ø–∫—É.")
    rows = list(info.get("rows") or [])
    if not rows:
        raise ValueError("–í –≤—ã–±—Ä–∞–Ω–Ω–æ–π –ø–æ–¥–ø–∞–ø–∫–µ –Ω–µ—Ç –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤.")
    folder_label = info.get("label") or "–í—Å–µ –ø–∞–ø–∫–∏"
    folder_path = info.get("path")
    choice = sess.setdefault("music_group_choice", {})
    choice["count"] = len(rows)
    choice["folder_path"] = folder_path
    choice["folder_label"] = folder_label
    sess["music_folder_choice"] = {
        "token": token,
        "label": folder_label,
        "path": folder_path,
        "count": len(rows),
    }
    sess["state"] = next_state
    return len(rows), folder_label


def _shorten_codec(codec: str) -> str:
    codec = (codec or "").strip().lower()
    if not codec:
        return "??"
    clean = "".join(ch for ch in codec if ch.isalnum())
    if not clean:
        clean = codec
    return clean[:2].ljust(2, "?")


def _format_compact_date(value: Optional[date]) -> str:
    if not value:
        return "------"
    return value.strftime("%d%m%y")


def collect_source_usage_stats() -> Dict[int, Dict[str, Any]]:
    """
    –°—Ç—Ä–æ–∏—Ç –∏–Ω–¥–µ–∫—Å –ø–æ source_id -> {count, last_date} –∏–∑ —Ç–∞–±–ª–∏—Ü—ã compilations.
    """
    usage: Dict[int, Dict[str, Any]] = {}
    conn = get_conn()
    cur = conn.cursor()
    cur.execute("SELECT pmv_date, source_ids FROM compilations")
    rows = cur.fetchall()
    conn.close()

    for row in rows:
        date_str = row["pmv_date"]
        try:
            last_date = datetime.strptime(date_str, "%Y-%m-%d").date()
        except Exception:
            last_date = None
        source_field = row["source_ids"] or ""
        for part in source_field.replace(";", ",").split(","):
            part = part.strip()
            if not part.isdigit():
                continue
            sid = int(part)
            info = usage.setdefault(sid, {"count": 0, "last_date": None})
            info["count"] += 1
            if last_date and (info["last_date"] is None or last_date > info["last_date"]):
                info["last_date"] = last_date
    return usage


def _group_last_used_date(entry: SourceGroupEntry, usage_index: Dict[int, Dict[str, Any]]) -> Optional[date]:
    last: Optional[date] = None
    for row in entry.rows:
        sid = int(row["id"])
        info = usage_index.get(sid)
        if not info:
            continue
        dt = info.get("last_date")
        if dt and (last is None or dt > last):
            last = dt
    return last


def format_source_group_lines(
    entries: List[SourceGroupEntry],
    header: str,
    prefix_func: Optional[Callable[[SourceGroupEntry], str]] = None,
) -> List[str]:
    usage_index = collect_source_usage_stats()
    lines = [header]
    for idx, entry in enumerate(entries, 1):
        codec, res = entry.key
        codec_short = _shorten_codec(codec)
        resolution_label = f"{(res or '??x??')}{codec_short}"
        total = len(entry.rows)
        new_block = f"(üÜï{entry.unused_count})" if entry.unused_count else ""
        count_label = f"{total}{new_block}"
        last_date = _format_compact_date(_group_last_used_date(entry, usage_index))
        prefix = ""
        if prefix_func:
            custom = (prefix_func(entry) or "").strip()
            if custom:
                prefix = f"{custom} "
        lines.append(f"{idx}. {prefix}{resolution_label} - {count_label} {last_date}")
    return lines


def sort_group_entries_with_orientation(
    entries: List[SourceGroupEntry],
) -> Tuple[List[SourceGroupEntry], Dict[Tuple[str, str], str]]:
    orientation_map: Dict[Tuple[str, str], str] = {}
    annotated: List[Tuple[SourceGroupEntry, str, int]] = []
    for entry in entries:
        label, order = _resolution_orientation(entry.key[1] or "")
        orientation_map[entry.key] = label
        annotated.append((entry, label, order))
    annotated.sort(
        key=lambda item: (
            item[2],
            -_resolution_pixels(item[0].key[1] or ""),
            -len(item[0].rows),
            f"{(item[0].key[0] or '').lower()}_{(item[0].key[1] or '').lower()}",
        )
    )
    sorted_entries = [item[0] for item in annotated]
    return sorted_entries, orientation_map


def sort_source_group_entries(entries: List[SourceGroupEntry]) -> List[SourceGroupEntry]:
    return sorted(
        entries,
        key=lambda e: (
            -_resolution_pixels(e.key[1] or ""),
            -len(e.rows),
            f"{(e.key[0] or '').lower()}_{(e.key[1] or '').lower()}",
        ),
    )

def db_get_used_sources_grouped() -> Dict[Tuple[str, str], List[sqlite3.Row]]:
    """
    –ë–µ—Ä—ë—Ç –¢–û–õ–¨–ö–û —É–∂–µ —É—á–∞—Å—Ç–≤–æ–≤–∞–≤—à–∏–µ –≤ –∫–æ–º–ø–∏–ª—è—Ü–∏—è—Ö –∏—Å—Ö–æ–¥–Ω–∏–∫–∏ (pmv_list –Ω–µ –ø—É—Å—Ç–æ–π)
    –∏ –≥—Ä—É–ø–ø–∏—Ä—É–µ—Ç –ø–æ (codec, resolution).
    """
    conn = get_conn()
    cur = conn.cursor()
    cur.execute(
        """
        SELECT * FROM sources
        WHERE pmv_list IS NOT NULL AND pmv_list != ''
        """
    )
    rows = cur.fetchall()
    conn.close()

    groups: Dict[Tuple[str, str], List[sqlite3.Row]] = {}
    for r in rows:
        codec = r["codec"] or "?"
        resolution = r["resolution"] or "??x??"
        key = (codec, resolution)
        groups.setdefault(key, []).append(r)
    return groups


def db_get_used_sources_list() -> List[sqlite3.Row]:
    conn = get_conn()
    cur = conn.cursor()
    cur.execute(
        """
        SELECT * FROM sources
        WHERE pmv_list IS NOT NULL AND pmv_list != ''
        """
    )
    rows = cur.fetchall()
    conn.close()
    return rows



def db_update_sources_pmv_list(source_ids: List[int], pmv_tag: str) -> None:
    if not source_ids:
        return
    conn = get_conn()
    cur = conn.cursor()
    for sid in source_ids:
        cur.execute("SELECT pmv_list FROM sources WHERE id = ?", (sid,))
        row = cur.fetchone()
        if not row:
            continue
        current = (row["pmv_list"] or "").strip()
        if not current:
            new_val = pmv_tag
        else:
            parts = [p.strip() for p in current.split(",") if p.strip()]
            if pmv_tag not in parts:
                parts.append(pmv_tag)
            new_val = ", ".join(parts)
        cur.execute("UPDATE sources SET pmv_list = ? WHERE id = ?", (new_val, sid))
    conn.commit()
    conn.close()


def db_insert_compilation(
    video_path: Path,
    source_ids: List[int],
    comments: str = "",
) -> None:
    conn = get_conn()
    cur = conn.cursor()
    cur.execute(
        """
        INSERT INTO compilations (video_path, pmv_date, source_ids, comments)
        VALUES (?, ?, ?, ?)
        """,
        (
            str(video_path.resolve()),
            date.today().isoformat(),
            ",".join(str(sid) for sid in source_ids),
            comments,
        ),
    )
    conn.commit()
    conn.close()

def db_get_all_sources() -> List[sqlite3.Row]:
    conn = get_conn()
    cur = conn.cursor()
    cur.execute(
        """
        SELECT id, video_name, video_path, comments
        FROM sources
        ORDER BY id
        """
    )
    rows = cur.fetchall()
    conn.close()
    return rows


def db_get_sources_full() -> List[Dict[str, Any]]:
    conn = get_conn()
    cur = conn.cursor()
    cur.execute(
        """
        SELECT id, video_name, video_path, size_bytes, codec, resolution,
               pmv_list, comments, date_added
        FROM sources
        ORDER BY id
        """
    )
    rows = [dict(row) for row in cur.fetchall()]
    conn.close()
    return rows


def db_update_source_fields(source_id: int, **fields: Any) -> None:
    if not fields:
        return
    columns = ", ".join(f"{key} = ?" for key in fields.keys())
    params = list(fields.values())
    params.append(source_id)
    conn = get_conn()
    cur = conn.cursor()
    cur.execute(f"UPDATE sources SET {columns} WHERE id = ?", params)
    conn.commit()
    conn.close()


def db_delete_sources_by_ids(ids: Iterable[int]) -> int:
    ids_list = [int(i) for i in ids]
    if not ids_list:
        return 0
    placeholders = ", ".join("?" for _ in ids_list)
    conn = get_conn()
    cur = conn.cursor()
    cur.execute(f"DELETE FROM sources WHERE id IN ({placeholders})", ids_list)
    deleted = cur.rowcount
    conn.commit()
    conn.close()
    return deleted


def db_get_sources_with_comments() -> List[sqlite3.Row]:
    conn = get_conn()
    cur = conn.cursor()
    cur.execute(
        """
        SELECT id, video_name, video_path, comments
        FROM sources
        WHERE comments IS NOT NULL AND comments != ''
        ORDER BY id
        """
    )
    rows = cur.fetchall()
    conn.close()
    return rows


def db_get_compilations_with_comments() -> List[sqlite3.Row]:
    conn = get_conn()
    cur = conn.cursor()
    cur.execute(
        """
        SELECT id, video_path, pmv_date, comments
        FROM compilations
        WHERE comments IS NOT NULL AND comments != ''
        ORDER BY pmv_date DESC, id DESC
        """
    )
    rows = cur.fetchall()
    conn.close()
    return rows


def db_get_compilation_by_video_path(video_path: Path) -> Optional[sqlite3.Row]:
    conn = get_conn()
    cur = conn.cursor()
    resolved = str(video_path.resolve())
    cur.execute("SELECT * FROM compilations WHERE video_path = ?", (resolved,))
    row = cur.fetchone()
    if not row:
        cur.execute(
            "SELECT * FROM compilations WHERE video_path LIKE ? ORDER BY id DESC LIMIT 1",
            (f"%{video_path.name}",),
        )
        row = cur.fetchone()
    conn.close()
    return row


def _normalize_windows_share_path(path: str) -> str:
    normalized = path.replace("\\", "/")
    while "//" in normalized:
        normalized = normalized.replace("//", "/")
    return normalized.rstrip("/")


def convert_windows_path_to_nas(path: Optional[str]) -> Optional[str]:
    if not path or not NAS_SHARE_PREFIX or not NAS_SHARE_ROOT:
        return None
    normalized = _normalize_windows_share_path(path)
    prefix = _normalize_windows_share_path(NAS_SHARE_PREFIX)
    if not normalized.lower().startswith(prefix.lower()):
        return None
    suffix = normalized[len(prefix):].lstrip("/")
    if not suffix:
        return None
    root = NAS_SHARE_ROOT.rstrip("/")
    return f"{root}/{suffix}"


def collect_symlink_plan() -> Tuple[Dict[str, List[Tuple[int, str, str]]], int]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç {folder: [(source_id, target_path, safe_name), ...]}, –ø—Ä–æ–ø—É—Å–∫–∞—è
    –∏—Å—Ö–æ–¥–Ω–∏–∫–∏ –±–µ–∑ –æ—Ü–µ–Ω–∫–∏ –∏–ª–∏ –±–µ–∑ —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º–æ–≥–æ –ø—É—Ç–∏.
    """
    plan: Dict[str, List[Tuple[int, str, str]]] = defaultdict(list)
    skipped = 0
    conn = get_conn()
    conn.row_factory = sqlite3.Row
    cur = conn.cursor()
    cur.execute("SELECT id, video_path, comments FROM sources")
    for row in cur.fetchall():
        color_key = _rategrp_row_color(row)
        if not color_key:
            continue
        folder = NAS_SYMLINK_COLOR_FOLDERS.get(color_key)
        if not folder:
            continue
        video_path = row["video_path"]
        remote_target = convert_windows_path_to_nas(video_path)
        if not remote_target:
            skipped += 1
            continue
        try:
            source_id = int(row["id"])
        except Exception:
            skipped += 1
            continue
        safe_name = sanitize_filename(Path(video_path).name or f"source_{source_id}")
        plan[folder].append((source_id, remote_target, safe_name))
    conn.close()
    return plan, skipped


def sync_nas_symlinks() -> List[str]:
    if not NAS_SSH_HOST or not NAS_SIM_REMOTE_ROOT:
        return []
    plan, skipped = collect_symlink_plan()
    total_links = sum(len(v) for v in plan.values())
    if total_links == 0:
        if skipped:
            return [f"‚ÑπÔ∏è –°–∏–º–ª–∏–Ω–∫–∏: –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ (–ø—Ä–æ–ø—É—â–µ–Ω–æ {skipped})."]
        return ["‚ÑπÔ∏è –°–∏–º–ª–∏–Ω–∫–∏: –Ω–µ—Ç –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ —Å –æ—Ü–µ–Ω–∫–∞–º–∏ ‚Äî —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –ø—Ä–æ–ø—É—â–µ–Ω–∞."]
    try:
        import paramiko
    except ImportError:
        return [
            "‚ö†Ô∏è –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–∞–∫–µ—Ç paramiko (`pip install paramiko`), —á—Ç–æ–±—ã –æ–±–Ω–æ–≤–ª—è—Ç—å —Å–∏–º–ª–∏–Ω–∫–∏ –Ω–∞ NAS."
        ]

    root = NAS_SIM_REMOTE_ROOT.rstrip("/")
    script_lines = [
        "set -e",
        f"ROOT={shlex.quote(root)}",
        "mkdir -p \"$ROOT\"",
        "if [ -d \"$ROOT\" ]; then find \"$ROOT\" -mindepth 1 -maxdepth 1 -exec rm -rf {} +; fi",
    ]

    for folder, entries in plan.items():
        folder_path = f"{root}/{folder}"
        script_lines.append(f"mkdir -p {shlex.quote(folder_path)}")
        for source_id, target_path, safe_name in entries:
            link_path = f"{folder_path}/{source_id}_{safe_name}"
            script_lines.append(
                f"ln -sf {shlex.quote(target_path)} {shlex.quote(link_path)}"
            )

    script = "\n".join(script_lines) + "\n"

    client = paramiko.SSHClient()
    client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
    messages: List[str] = []
    try:
        client.connect(
            NAS_SSH_HOST,
            port=NAS_SSH_PORT,
            username=NAS_SSH_USER,
            password=NAS_SSH_PASSWORD or None,
            timeout=NAS_SSH_TIMEOUT,
        )
        stdin, stdout, stderr = client.exec_command("bash -s", timeout=NAS_SSH_TIMEOUT)
        stdin.write(script)
        stdin.channel.shutdown_write()
        out = stdout.read().decode("utf-8", errors="ignore").strip()
        err = stderr.read().decode("utf-8", errors="ignore").strip()
        exit_code = stdout.channel.recv_exit_status()
    finally:
        client.close()

    if exit_code != 0:
        return [
            f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ —Å–∏–º–ª–∏–Ω–∫–æ–≤ –Ω–∞ NAS (–∫–æ–¥ {exit_code}).",
            err or out or "–ë–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞.",
        ]

    msg = f"‚úÖ –ù–∞ NAS —Å–æ–∑–¥–∞–Ω–æ {total_links} —Å–∏–º–ª–∏–Ω–∫–æ–≤ –≤ {len(plan)} –ø–∞–ø–∫–∞—Ö."
    if skipped:
        msg += f" –ü—Ä–æ–ø—É—â–µ–Ω–æ –ø—É—Ç–µ–π: {skipped}."
    messages.append(msg)
    if out:
        messages.append(out)
    if err:
        messages.append(err)
    return messages


def db_get_sources_by_ids(ids: Iterable[int]) -> List[sqlite3.Row]:
    ids_list = [int(i) for i in ids if int(i) > 0]
    if not ids_list:
        return []
    placeholders = ",".join("?" for _ in ids_list)
    conn = get_conn()
    cur = conn.cursor()
    cur.execute(f"SELECT * FROM sources WHERE id IN ({placeholders})", ids_list)
    rows = cur.fetchall()
    conn.close()
    return rows


def db_get_random_name() -> str:
    conn = get_conn()
    cur = conn.cursor()
    cur.execute("SELECT id, adjective, noun, verb, number FROM random_names")
    rows = cur.fetchall()
    conn.close()
    if not rows:
        return "PMV_from_files"
    row = random.choice(rows)
    adj = row["adjective"]
    noun = row["noun"]
    verb = row["verb"]
    num = row["number"]
    # –±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤, —á—Ç–æ–±—ã –∏–º—è —Ñ–∞–π–ª–∞ –±—ã–ª–æ –∞–∫–∫—É—Ä–∞—Ç–Ω—ã–º
    return f"{adj}_{noun}_{verb}{num}"


# –î–æ–ø. DB-—Ö–µ–ª–ø–µ—Ä—ã –¥–ª—è –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤

def db_get_source_id_by_path(video_path: Path) -> Optional[int]:
    conn = get_conn()
    cur = conn.cursor()
    cur.execute("SELECT id FROM sources WHERE video_path = ?", (str(video_path.resolve()),))
    row = cur.fetchone()
    conn.close()
    return int(row["id"]) if row else None


def db_mark_source_problem(source_id: int, reason: str) -> None:
    reason = reason.strip()
    if not reason:
        reason = "unknown"
    ts = datetime.now().strftime("%Y-%m-%d")
    db_append_source_comment(source_id, f"problem={reason};date={ts}")


def db_get_problem_sources() -> List[sqlite3.Row]:
    conn = get_conn()
    cur = conn.cursor()
    cur.execute(
        """
        SELECT id, video_name, video_path, comments
        FROM sources
        WHERE comments LIKE '%problem=%'
        ORDER BY id
        """
    )
    rows = cur.fetchall()
    conn.close()
    return rows

# =========================
# FFPROBE / FFMPEG –£–¢–ò–õ–ò–¢–´
# =========================


def ffprobe_available() -> bool:
    try:
        subprocess.check_output([FFPROBE_BIN, "-version"], stderr=subprocess.STDOUT)
        return True
    except Exception:
        return False



def ffmpeg_probe_duration_seconds(path: Path) -> float:
    try:
        out = subprocess.run(
            [FFMPEG_BIN, "-hide_banner", "-i", str(path)],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
        )
        m = re.search(r"Duration:\s*(\d{2}):(\d{2}):(\d{2}\.\d+)", out.stderr or "")
        if not m:
            return 0.0
        hh, mm, ss = m.groups()
        return int(hh) * 3600 + int(mm) * 60 + float(ss)
    except Exception:
        return 0.0


def ffprobe_duration_seconds(path: Path) -> float:
    if not ffprobe_available():
        return ffmpeg_probe_duration_seconds(path)
    try:
        out = subprocess.check_output(
            [
                FFPROBE_BIN,
                "-v", "error",
                "-show_entries", "format=duration",
                "-of", "default=noprint_wrappers=1:nokey=1",
                str(path),
            ],
            text=True,
        ).strip()
        return float(out)
    except Exception:
        return ffmpeg_probe_duration_seconds(path)



def normalize_codec(codec: str) -> str:
    codec = (codec or "").lower()
    if codec in ("avc1", "h264"):
        return "h264"
    if codec in ("hvc1", "hev1", "hevc"):
        return "hevc"
    return codec


def video_info_sort(path: Path) -> Tuple[str, str]:
    if ffprobe_available():
        try:
            out = subprocess.check_output(
                [
                    FFPROBE_BIN,
                    "-v", "error",
                    "-select_streams", "v:0",
                    "-show_entries", "stream=codec_name,width,height",
                    "-of", "default=nw=1:nk=1",
                    str(path),
                ],
                text=True,
            ).strip().splitlines()
            codec = normalize_codec(out[0] if len(out) > 0 else "")
            w = out[1] if len(out) > 1 else ""
            h = out[2] if len(out) > 2 else ""
            wh = f"{w}x{h}" if w and h else ""
            return codec, wh
        except Exception:
            pass

    try:
        pr = subprocess.run(
            [FFMPEG_BIN, "-hide_banner", "-i", str(path)],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
        )
        stderr = pr.stderr or ""
        m = re.search(r"Video:\s*([a-z0-9_]+)", stderr, re.I)
        codec = normalize_codec(m.group(1)) if m else ""
        m2 = re.search(r"(\d{2,5})x(\d{2,5})", stderr)
        wh = f"{m2.group(1)}x{m2.group(2)}" if m2 else ""
        return codec, wh
    except Exception:
        return "", ""



def detect_video_info(path: Path) -> Dict[str, str]:
    info = {"codec_name": "", "width": "", "height": "", "fps": "", "pix_fmt": ""}
    if ffprobe_available():
        try:
            out = subprocess.check_output(
                [
                    FFPROBE_BIN,
                    "-v", "error",
                    "-select_streams", "v:0",
                    "-show_entries", "stream=codec_name,width,height,avg_frame_rate,pix_fmt",
                    "-of", "default=nw=1:nk=1",
                    str(path),
                ],
                text=True,
            ).strip().splitlines()
            vals = (out + [""] * 5)[:5]
            info["codec_name"], info["width"], info["height"], fps, info["pix_fmt"] = vals
            if "/" in fps and fps != "0/0":
                try:
                    a, b = fps.split("/")
                    fps = str(round(float(a) / float(b), 3))
                except Exception:
                    pass
            info["fps"] = fps
            return info
        except Exception:
            pass

    try:
        pr = subprocess.run(
            [FFMPEG_BIN, "-hide_banner", "-i", str(path)],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
        )
        stderr = pr.stderr or ""
        m = re.search(
            r"Video:\s*([a-z0-9_]+)\s*(\([^)]+\))?,\s*([0-9a-z_]+)?\s*,\s*(\d{2,5})x(\d{2,5})",
            stderr,
            re.I,
        )
        if m:
            info["codec_name"] = m.group(1).lower()
            info["pix_fmt"] = (m.group(3) or "").lower()
            info["width"] = m.group(4) or ""
            info["height"] = m.group(5) or ""
        m2 = re.search(r"(\d+(?:\.\d+)?|\d+/\d+)\s*fps", stderr, re.I)
        if m2:
            info["fps"] = m2.group(1)
    except Exception:
        pass
    return info



def pick_temp_dir(candidates: List[Path], min_free_bytes: int = 5 * 1024**3) -> Path:
    for d in candidates:
        try:
            d.mkdir(parents=True, exist_ok=True)
            total, used, free = shutil.disk_usage(str(d))
            if free > min_free_bytes:
                return d
        except Exception:
            continue
    d0 = candidates[0]
    d0.mkdir(parents=True, exist_ok=True)
    return d0


# =========================
# –õ–û–ì–ò–ö–ê –ü–õ–ê–ù–ò–†–û–í–ê–ù–ò–Ø –ö–õ–ò–ü–û–í
# =========================

def allocate_equalish(
    target_sec: int,
    files: List[Path],
    durations: Dict[Path, int],
    per_min: int = PER_FILE_MIN_SECONDS,
    per_max: int = PER_FILE_MAX_SECONDS,
) -> Dict[Path, int]:
    """
    –†–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –º–µ–∂–¥—É —Ñ–∞–π–ª–∞–º–∏.

    –í–ê–ñ–ù–û: —Ç–µ–ø–µ—Ä—å –ù–ï —Ñ–æ—Ä—Å–∏–º per_min, –µ—Å–ª–∏ target —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–π,
    —á—Ç–æ–±—ã –Ω–µ –ø–æ–ª—É—á–∏—Ç—å —Å–∏—Ç—É–∞—Ü–∏—é, –∫–æ–≥–¥–∞ 15 –º–∏–Ω—É—Ç ‚Üí 45 –º–∏–Ω—É—Ç.
    """
    n = len(files)
    if n == 0 or target_sec <= 0:
        return {f: 0 for f in files}

    total_dur = sum(durations.get(f, 0) for f in files)
    if total_dur <= 0:
        return {f: 0 for f in files}

    ideal = max(1, target_sec // n)
    # —Ç–æ–ª—å–∫–æ –≤–µ—Ä—Ö–Ω–∏–π –ø—Ä–µ–¥–µ–ª, –±–µ–∑ –Ω–∏–∂–Ω–µ–≥–æ
    ideal_clamped = min(per_max, ideal)

    alloc: Dict[Path, int] = {}
    for f in files:
        dur = durations.get(f, 0)
        alloc[f] = min(ideal_clamped, dur)

    max_total = min(target_sec, total_dur)
    current = sum(alloc.values())
    leftover = max_total - current
    if leftover <= 0:
        return alloc

    order = sorted(files, key=lambda f: durations.get(f, 0), reverse=True)

    while leftover > 0:
        progressed = False
        for f in order:
            dur = durations.get(f, 0)
            # –≤—Å—ë –µ—â—ë —É—á–∏—Ç—ã–≤–∞–µ–º –ø–µ—Ä-—Ñ–∞–π–ª –º–∞–∫—Å–∏–º—É–º
            if alloc[f] >= min(per_max, dur):
                continue
            alloc[f] += 1
            leftover -= 1
            progressed = True
            if leftover <= 0:
                break
        if not progressed:
            break

    return alloc


def split_into_big_parts(file_len: int, parts: int) -> List[Tuple[int, int]]:
    parts = max(1, parts)
    base = file_len // parts
    rem = file_len - base * parts
    res = []
    cur = 0
    for i in range(parts):
        L = base + (1 if i < rem else 0)
        res.append((cur, L))
        cur += L
    return res


def jittered_partition(total_len: int, count: int, min_each: int = 1) -> List[int]:
    """–î–µ–ª–∏—Ç total_len –Ω–∞ count —á–∞—Å—Ç–µ–π —Å —à—É–º–æ–º, —Å–æ–±–ª—é–¥–∞—è min_each.
    –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã –¥–ª—è randint –¥–∞–∂–µ –ø—Ä–∏ –º–∞–ª—ã—Ö total_len.
    """
    rng = random.Random(RANDOM_SEED)
    total_len = max(0, int(total_len))
    min_each = max(1, int(min_each))

    # —Å–∫–æ–ª—å–∫–æ —á–∞—Å—Ç–µ–π —Ä–µ–∞–ª—å–Ω–æ –º–æ–∂–µ–º —Å–¥–µ–ª–∞—Ç—å, —É—á–∏—Ç—ã–≤–∞—è –º–∏–Ω–∏–º—É–º
    max_count = max(1, total_len // min_each) if total_len > 0 else 1
    count = max(1, min(int(count), max_count))

    base = max(min_each, total_len // count) if count > 0 else total_len
    jitter = max(1, int(base * 0.3))

    lens: List[int] = []
    remain = total_len
    left = count
    for _ in range(count):
        if left == 1:
            x = remain
        else:
            low = max(min_each, base - jitter)
            # –≤–µ—Ä—Ö–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞ —Å —É—á—ë—Ç–æ–º –æ—Å—Ç–∞–≤—à–µ–≥–æ—Å—è –º–∏–Ω–∏–º—É–º–∞ –Ω–∞ —Ö–≤–æ—Å—Ç
            upper_cap = remain - (left - 1) * min_each
            high = max(low, min(base + jitter, upper_cap))
            if high < low:
                x = max(min_each, min(upper_cap, low))
            else:
                x = rng.randint(low, high)
        lens.append(x)
        remain -= x
    left -= 1
    return lens


def _clip_guard_limits(duration: int) -> Tuple[bool, int, int]:
    head = max(0, int(CLIP_HEAD_GUARD_SECONDS))
    tail = max(0, int(CLIP_TAIL_GUARD_SECONDS))
    if duration <= head + tail:
        return False, 0, duration
    guard_start = min(head, duration)
    guard_end = max(guard_start + 1, duration - tail)
    guard_end = min(guard_end, duration)
    return True, guard_start, guard_end



def _plan_for_file_default(
    file_path: Path,
    file_alloc: int,
    big_parts: int,
    small_per_big: int,
) -> List[Tuple[int, int]]:
    dur = int(ffprobe_duration_seconds(file_path))
    if dur <= 0 or file_alloc <= 0:
        return []

    guard_active, guard_start, guard_end = _clip_guard_limits(dur)

    windows = split_into_big_parts(dur, big_parts)
    base = file_alloc // len(windows)
    rem = file_alloc - base * len(windows)

    clips: List[Tuple[int, int]] = []

    for idx, (wstart, wlen) in enumerate(windows):
        if guard_active:
            eff_start = max(wstart, guard_start)
            eff_end = min(wstart + wlen, guard_end)
            wstart_eff = eff_start
            wlen_eff = max(0, eff_end - eff_start)
        else:
            wstart_eff = wstart
            wlen_eff = wlen
        alloc = min(wlen_eff, base + (1 if idx < rem else 0))
        if alloc <= 0:
            continue
        
        spb = min(small_per_big, max(1, alloc // MIN_SMALL_CLIP_SECONDS))
        lengths = jittered_partition(alloc, spb, min_each=MIN_SMALL_CLIP_SECONDS)

        total_clips_len = sum(lengths)
        slack = max(0, wlen_eff - total_clips_len)
        gaps = spb + 1
        base_gap = slack // gaps
        extra = slack - base_gap * gaps
        cur = wstart_eff + base_gap + (1 if extra > 0 else 0)
        extra_left = max(0, extra - 1)
        for L in lengths:
            clips.append((cur, L))
            cur = cur + L + base_gap + (1 if extra_left > 0 else 0)
            if extra_left > 0:
                extra_left -= 1

    clips.sort(key=lambda x: x[0])
    total = sum(d for _, d in clips)
    if total > file_alloc and clips:
        overflow = total - file_alloc
        s, d = clips[-1]
        d2 = max(1, d - overflow)
        clips[-1] = (s, d2)
    return clips


def plan_for_file(
    file_path: Path,
    file_alloc: int,
    big_parts: int,
    small_per_big: int,
    algo_key: str = "default",
) -> List[Tuple[int, int]]:
    if algo_key == "poi":
        clips = plan_for_file_poi(file_path, file_alloc)
        if clips:
            return clips
    return _plan_for_file_default(file_path, file_alloc, big_parts, small_per_big)


def _extract_audio_energy_profile(path: Path) -> List[Tuple[float, float]]:
    cmd = [
        FFMPEG_BIN,
        "-hide_banner",
        "-nostats",
        "-loglevel",
        "error",
        "-i",
        str(path),
        "-af",
        f"astats=metadata=1:reset={POI_ANALYSIS_RESET},ametadata=print:file=-",
        "-f",
        "null",
        "-",
    ]
    try:
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            check=False,
        )
    except Exception:
        return []
    output = (result.stdout or "") + (result.stderr or "")
    samples: List[Tuple[float, float]] = []
    for raw in output.splitlines():
        line = raw.strip()
        if not line or "pts_time" not in line:
            continue
        parts: Dict[str, str] = {}
        for token in line.split("|"):
            if "=" in token:
                key, value = token.split("=", 1)
                parts[key.strip()] = value.strip()
        try:
            timestamp = float(parts.get("pts_time", "0"))
        except ValueError:
            continue
        key_name = parts.get("key") or ""
        if "Peak_level" not in key_name:
            continue
        try:
            db_val = float(parts.get("value", "-120"))
        except ValueError:
            continue
        amplitude = 10 ** (db_val / 20.0)
        if math.isfinite(amplitude):
            samples.append((timestamp, amplitude))
    return samples


def _select_audio_poi_points(
    duration: float,
    samples: List[Tuple[float, float]],
) -> List[Tuple[float, float]]:

    if not samples or duration <= 0:
        return []
    samples.sort(key=lambda x: x[0])
    minutes = max(1, math.ceil(duration / 60.0))
    per_minute: Dict[int, List[Tuple[float, float]]] = {}
    for ts, amp in samples:
        idx = min(minutes - 1, int(ts // 60))
        per_minute.setdefault(idx, []).append((amp, ts))
    points: List[Tuple[float, float]] = []
    for minute in range(minutes):
        candidates = per_minute.get(minute, [])
        if not candidates:
            continue
        low, high = POI_POINTS_PER_MIN_RANGE
        want = random.randint(low, high)
        want = max(1, min(want, len(candidates)))
        top = heapq.nlargest(want, candidates)
        for amp, ts in top:
            points.append((ts, amp))
    if not points:
        top_global = heapq.nlargest(min(len(samples), POI_MAX_POINTS), samples, key=lambda x: x[1])
        points = [(ts, amp) for ts, amp in top_global]
    points.sort(key=lambda x: x[0])
    return points


def plan_for_file_poi(file_path: Path, file_alloc: int) -> List[Tuple[int, int]]:
    duration = float(ffprobe_duration_seconds(file_path))
    if duration <= 0 or file_alloc <= 0:
        return []
    duration_seconds = max(1, int(duration))
    file_alloc = min(int(file_alloc), duration_seconds)
    if file_alloc <= 0:
        return []
    samples = _extract_audio_energy_profile(file_path)
    poi_points = _select_audio_poi_points(duration, samples)
    if not poi_points:
        return []
    max_points = max(1, min(len(poi_points), max(1, file_alloc // MIN_SMALL_CLIP_SECONDS)))
    if len(poi_points) > max_points:
        poi_points = heapq.nlargest(max_points, poi_points, key=lambda x: x[1])
    poi_points.sort(key=lambda x: x[0])
    per_clip_min = min(
        MIN_SMALL_CLIP_SECONDS,
        max(1, file_alloc // len(poi_points)),
    )
    lengths = jittered_partition(file_alloc, len(poi_points), min_each=per_clip_min)
    guard_active, guard_start, guard_end = _clip_guard_limits(duration_seconds)
    clips: List[Tuple[int, int]] = []
    for (ts, _), clip_len in zip(poi_points, lengths):
        jitter = random.uniform(-POI_SPREAD_SECONDS, POI_SPREAD_SECONDS)
        center = ts + jitter
        start = int(max(0, round(center - clip_len / 2)))
        if guard_active:
            safe_window = max(1, guard_end - guard_start)
            clip_len = min(clip_len, safe_window)
            min_start = guard_start
            max_start = max(min_start, guard_end - clip_len)
            start = max(min_start, min(start, max_start))
        else:
            max_start = max(0, duration_seconds - clip_len)
            if start > max_start:
                start = max_start
        clips.append((start, clip_len))
    clips.sort(key=lambda x: x[0])
    return clips


ClipQueue = Dict[Path, List[Tuple[int, int]]]
ClipSequence = List[Tuple[Path, int, int]]


def _clone_clip_queue(per_file: ClipQueue) -> ClipQueue:
    return {path: clips[:] for path, clips in per_file.items() if clips}


def _sequence_carousel(per_file: ClipQueue) -> ClipSequence:
    queues = _clone_clip_queue(per_file)
    out: ClipSequence = []
    while queues:
        for path in list(queues.keys()):
            clips = queues.get(path, [])
            if not clips:
                queues.pop(path, None)
                continue
            start, dur = clips.pop(0)
            out.append((path, start, dur))
            if not clips:
                queues.pop(path, None)
    return out


def _sequence_group_waves(per_file: ClipQueue) -> ClipSequence:
    queues = _clone_clip_queue(per_file)
    files = list(queues.keys())
    random.shuffle(files)
    out: ClipSequence = []
    idx = 0
    total = len(files)
    while idx < total:
        remaining = total - idx
        if remaining == 1:
            group_size = 1
        else:
            group_size = random.randint(2, min(4, remaining))
        group_files = files[idx: idx + group_size]
        idx += group_size
        group_map: ClipQueue = {f: queues.pop(f, []) for f in group_files if queues.get(f)}
        # –µ—Å–ª–∏ —Ñ–∞–π–ª –æ–∫–∞–∑–∞–ª—Å—è –ø—É—Å—Ç—ã–º, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
        group_files = [f for f in group_files if group_map.get(f)]
        while group_files:
            for f in list(group_files):
                clips = group_map.get(f)
                if not clips:
                    group_files.remove(f)
                    continue
                start, dur = clips.pop(0)
                out.append((f, start, dur))
                if not clips:
                    group_files.remove(f)
    # –µ—Å–ª–∏ —á—Ç–æ-—Ç–æ –æ—Å—Ç–∞–ª–æ—Å—å (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ñ–∞–π–ª—ã –±–µ–∑ –≥—Ä—É–ø–ø) ‚Äî –¥–æ–±–∏–≤–∞–µ–º –∫–∞—Ä—É—Å–µ–ª—å—é
    if queues:
        out.extend(_sequence_carousel(queues))
    return out


def _sequence_burst_shuffle(per_file: ClipQueue) -> ClipSequence:
    queues = _clone_clip_queue(per_file)
    out: ClipSequence = []
    while True:
        candidates = [(f, len(clips)) for f, clips in queues.items() if clips]
        if not candidates:
            break
        total = sum(cnt for _, cnt in candidates)
        pick = random.randint(1, max(1, total))
        acc = 0
        chosen = candidates[0][0]
        for f, cnt in candidates:
            acc += cnt
            if pick <= acc:
                chosen = f
                break
        burst = random.randint(1, max(1, min(3, len(queues[chosen]))))
        for _ in range(burst):
            if not queues[chosen]:
                break
            start, dur = queues[chosen].pop(0)
            out.append((chosen, start, dur))
        if not queues[chosen]:
            queues.pop(chosen)
    return out


def _sequence_poi(per_file: ClipQueue) -> ClipSequence:
    out: ClipSequence = []
    for path, clips in per_file.items():
        for start, dur in sorted(clips, key=lambda x: x[0]):
            out.append((path, start, dur))
    return out


def _sequence_strata(per_file: ClipQueue) -> ClipSequence:
    """–í—ã–¥–∞—ë—Ç –≤—Å–µ –∫–ª–∏–ø—ã –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –ø–æ–¥—Ä—è–¥, –∑–∞—Ç–µ–º –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç –∫ —Å–ª–µ–¥—É—é—â–µ–º—É."""
    out: ClipSequence = []
    for path, clips in per_file.items():
        for start, dur in sorted(clips, key=lambda x: x[0]):
            out.append((path, start, dur))
    return out


SequenceBuilder = Callable[[ClipQueue], ClipSequence]


CLIP_SEQUENCE_ALGORITHMS: Dict[str, Dict[str, Any]] = {
    "carousel": {
        "short": "CAR",
        "title": "–ö–∞—Ä—É—Å–µ–ª—å",
        "description": "–ß–µ—Ä–µ–¥—É–µ—Ç –∫–ª–∏–ø—ã –≤—Å–µ—Ö –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ –ø–æ –∫—Ä—É–≥—É.",
        "builder": _sequence_carousel,
    },
    "waves": {
        "short": "WAV",
        "title": "–í–æ–ª–Ω—ã",
        "description": "–°–æ–±–∏—Ä–∞–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –≤ –Ω–µ–±–æ–ª—å—à–∏–µ –≥—Ä—É–ø–ø—ã –∏ –ø–µ—Ä–µ–º–µ—à–∏–≤–∞–µ—Ç –≤–Ω—É—Ç—Ä–∏ –∫–∞–∂–¥–æ–π –≤–æ–ª–Ω—ã.",
        "builder": _sequence_group_waves,
    },
    "bursts": {
        "short": "BST",
        "title": "–ë—ë—Ä—Å—Ç—ã",
        "description": "–î–µ–ª–∞–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–µ —Å–µ—Ä–∏–∏ –∫–ª–∏–ø–æ–≤ –∏–∑ –æ–¥–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞, –∑–∞—Ç–µ–º –ø–µ—Ä–µ—Å–∫–∞–∫–∏–≤–∞–µ—Ç –Ω–∞ –¥—Ä—É–≥–æ–π.",
        "builder": _sequence_burst_shuffle,
    },
    "poi": {
        "short": "POI",
        "title": "Points of Interest",
        "description": "–ò—â–µ—Ç –≥—Ä–æ–º–∫–∏–µ —É—á–∞—Å—Ç–∫–∏ –∞—É–¥–∏–æ –∏ –≤—ã—Ä–µ–∑–∞–µ—Ç –∫–ª–∏–ø—ã —Ä—è–¥–æ–º —Å –Ω–∏–º–∏, —Å–æ—Ö—Ä–∞–Ω—è—è —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—é.",
        "builder": _sequence_poi,
    },
    "strata": {
        "short": "LAY",
        "title": "–°–ª–æ–∏ –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫",
        "description": "–°–æ–±–∏—Ä–∞–µ—Ç –±–ª–æ–∫–∞–º–∏: –≤—ã–¥–∞—ë—Ç –≤—Å–µ –∫–ª–∏–ø—ã –ø–µ—Ä–≤–æ–≥–æ –≤–∏–¥–µ–æ, –ø–æ—Ç–æ–º –≤—Ç–æ—Ä–æ–≥–æ –∏ —Ç.–¥.",
        "builder": _sequence_strata,
    },
}

DEFAULT_CLIP_ALGO = "carousel"

CLIP_ALGO_CHOICE_MAP: Dict[str, str] = {}
for _key, _meta in CLIP_SEQUENCE_ALGORITHMS.items():
    CLIP_ALGO_CHOICE_MAP[_key.lower()] = _key
    short = (_meta.get("short") or "").lower()
    if short:
        CLIP_ALGO_CHOICE_MAP[short] = _key


def normalize_clip_algo_choice(choice: str) -> Optional[str]:
    if not choice:
        return None
    return CLIP_ALGO_CHOICE_MAP.get(choice.strip().lower())


def resolve_clip_algorithm(key: Optional[str]) -> Tuple[str, Dict[str, Any]]:
    if not key or key not in CLIP_SEQUENCE_ALGORITHMS:
        key = DEFAULT_CLIP_ALGO
    return key, CLIP_SEQUENCE_ALGORITHMS[key]


class ClipAlgorithmPicker:
    def __init__(self, total_slots: int):
        self.total_slots = max(1, total_slots)
        self.keys = list(CLIP_SEQUENCE_ALGORITHMS.keys())
        if not self.keys:
            raise RuntimeError("–ù–µ –∑–∞–¥–∞–Ω—ã –∞–ª–≥–æ—Ä–∏—Ç–º—ã –Ω–∞—Ä–µ–∑–∫–∏.")
        self.unique_quota = min(self.total_slots, len(self.keys))
        self.unique_deck = random.sample(self.keys, len(self.keys))
        self.unique_index = 0
        self.recycle: List[str] = []
        self._current: Optional[str] = None

    def _next_from_pool(self) -> str:
        if self.unique_index < self.unique_quota:
            key = self.unique_deck[self.unique_index]
            self.unique_index += 1
            return key
        if not self.recycle:
            self.recycle = random.sample(self.keys, len(self.keys))
        return self.recycle.pop()

    def current(self) -> str:
        if self._current is None:
            self._current = self._next_from_pool()
        return self._current

    def commit(self) -> None:
        self._current = None


@dataclass
class MusicSegment:
    index: int
    start: float
    end: float
    duration: float
    intensity: float


CLICK_SAMPLE_RATE = 44100
CLICK_DURATION_SECONDS = 0.05
CLICK_FREQUENCY_HZ = 1200.0
CLICK_AMPLITUDE = 12000


def sanitize_filename(text: str) -> str:
    clean = re.sub(r"[^\w\-. ]+", "_", text.strip())
    return clean or "music_project"


def parse_manifest_segments(manifest: Dict[str, Any]) -> List[MusicSegment]:
    analysis = manifest.get("analysis") or {}
    raw_segments = analysis.get("segments") or []
    segments: List[MusicSegment] = []
    for idx, seg in enumerate(raw_segments):
        try:
            start = float(seg.get("start") or 0.0)
            end = float(seg.get("end") or 0.0)
            duration = float(seg.get("duration") or (end - start))
            intensity = float(seg.get("intensity") or 0.0)
        except Exception:
            continue
        if duration <= 0:
            duration = max(0.5, end - start)
        segments.append(
            MusicSegment(
                index=idx,
                start=max(0.0, start),
                end=max(end, start),
                duration=max(0.1, duration),
                intensity=max(0.0, min(1.0, intensity)),
            )
        )
    return segments


def _build_click_track_samples(starts: List[float], total_duration: float) -> array:
    max_time = max(total_duration, max(starts or [0.0])) + CLICK_DURATION_SECONDS + 0.5
    total_samples = max(1, int(math.ceil(max_time * CLICK_SAMPLE_RATE)))
    buf = array("h", [0]) * total_samples
    click_len = max(1, int(CLICK_DURATION_SECONDS * CLICK_SAMPLE_RATE))
    for start in starts:
        if start < 0:
            continue
        start_sample = int(start * CLICK_SAMPLE_RATE)
        if start_sample >= total_samples:
            continue
        for i in range(click_len):
            idx = start_sample + i
            if idx >= total_samples:
                break
            sample_val = int(
                math.sin(2.0 * math.pi * CLICK_FREQUENCY_HZ * (i / CLICK_SAMPLE_RATE))
                * CLICK_AMPLITUDE
            )
            mixed = buf[idx] + sample_val
            if mixed > 32767:
                mixed = 32767
            elif mixed < -32768:
                mixed = -32768
            buf[idx] = mixed
    return buf


def _write_wave_file(path: Path, samples: array, sample_rate: int = CLICK_SAMPLE_RATE) -> None:
    with wave.open(str(path), "wb") as wf:
        wf.setnchannels(1)
        wf.setsampwidth(2)
        wf.setframerate(sample_rate)
        wf.writeframes(samples.tobytes())


def mix_audio_with_click_track(audio_path: Path, click_path: Path, output_path: Path) -> None:
    cmd = [
        FFMPEG_BIN,
        "-y",
        "-i",
        str(audio_path),
        "-i",
        str(click_path),
        "-filter_complex",
        "amix=inputs=2:normalize=0",
        "-c:a",
        "libmp3lame",
        str(output_path),
    ]
    subprocess.check_call(cmd)


def generate_musicprep_click_preview(project: Dict[str, Any]) -> Path:
    manifest_data = project.get("manifest_data")
    manifest_path = Path(project.get("manifest_path") or "")
    if not manifest_data and manifest_path.exists():
        manifest_data = json.loads(manifest_path.read_text(encoding="utf-8"))
        project["manifest_data"] = manifest_data
    segments = parse_manifest_segments(manifest_data or {})
    if not segments:
        raise ValueError("–í –ø—Ä–æ–µ–∫—Ç–µ –Ω–µ—Ç —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")
    audio_path = project.get("audio_path")
    if not audio_path:
        candidate = Path(project.get("dir") or MUSIC_PROJECTS_DIR)
        audio_path = candidate / "audio.mp3"
    audio_path = Path(audio_path)
    if not audio_path.exists():
        raise FileNotFoundError(f"–ù–µ –Ω–∞–π–¥–µ–Ω audio.mp3 –≤ –ø—Ä–æ–µ–∫—Ç–µ {project.get('slug')}.")

    starts = [seg.start for seg in segments]
    duration = max(ffprobe_duration_seconds(audio_path), segments[-1].end)
    tmp_parent = pick_temp_dir(TEMP_DIRS, min_free_bytes=500 * 1024**2)
    with tempfile.TemporaryDirectory(prefix="click_", dir=str(tmp_parent)) as tmpdir:
        tmp_root = Path(tmpdir)
        click_wav = tmp_root / "click_track.wav"
        samples = _build_click_track_samples(starts, duration)
        _write_wave_file(click_wav, samples)
        slug = sanitize_filename(project.get("slug") or project.get("name") or "project").replace(" ", "_")
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        out_dir = Path(project.get("dir") or (MUSIC_PROJECTS_DIR / slug))
        out_dir.mkdir(parents=True, exist_ok=True)
        output_path = out_dir / f"{slug}_clickcheck_{timestamp}.mp3"
        mix_audio_with_click_track(audio_path, click_wav, output_path)
    return output_path


def build_music_source_sequence(
    source_paths: List[Path],
    algo_key: str,
    total_segments: int,
) -> List[Path]:
    if not source_paths:
        raise ValueError("–ù–µ—Ç –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ –¥–ª—è –º—É–∑—ã–∫–∞–ª—å–Ω–æ–π –∫–æ–º–ø–∏–ª—è—Ü–∏–∏.")
    if total_segments <= 0:
        return []
    seq: List[Path] = []
    key = algo_key or DEFAULT_CLIP_ALGO
    files = source_paths[:]

    if key == "waves":
        random.shuffle(files)
        idx = 0
        while len(seq) < total_segments:
            group_size = random.randint(2, min(4, len(files)))
            group = files[idx:idx + group_size]
            if not group:
                random.shuffle(files)
                idx = 0
                continue
            for path in group:
                seq.append(path)
                if len(seq) >= total_segments:
                    break
            idx += group_size
            if idx >= len(files):
                idx = 0
                random.shuffle(files)
    elif key == "bursts":
        while len(seq) < total_segments:
            path = random.choice(source_paths)
            burst = random.randint(2, 4)
            for _ in range(burst):
                seq.append(path)
                if len(seq) >= total_segments:
                    break
    elif key == "strata":
        if not files:
            return []
        base = total_segments // len(files)
        rem = total_segments % len(files)
        for idx, path in enumerate(files):
            share = base + (1 if idx < rem else 0)
            if share <= 0:
                continue
            seq.extend([path] * share)
    else:
        idx = 0
        while len(seq) < total_segments:
            seq.append(files[idx % len(files)])
            idx += 1
    return seq[:total_segments]


def choose_random_source_rows(
    count: int,
    group_strategy: str = "max_group",
    preferred_group: Optional[Tuple[str, str]] = None,
    preferred_folder: Optional[str] = None,
) -> List[sqlite3.Row]:
    if count <= 0:
        raise ValueError("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å > 0")

    folder_norm = _normalize_path_prefix(preferred_folder) if preferred_folder else None

    def row_matches_folder(row: sqlite3.Row) -> bool:
        if not folder_norm:
            return True
        try:
            parent = Path(row["video_path"]).resolve(strict=False).parent
        except Exception:
            parent = Path(row["video_path"]).parent
        return _normalize_path_prefix(parent) == folder_norm

    unused = db_get_unused_sources_grouped()
    all_groups = db_get_all_sources_grouped()

    def fetch_group_rows(key: Tuple[str, str]) -> List[sqlite3.Row]:
        rows = all_groups.get(key)
        if not rows:
            rows = unused.get(key, [])
        filtered = [row for row in (rows or []) if row_matches_folder(row)]
        return filtered

    if preferred_group:
        rows = fetch_group_rows(preferred_group)
        if len(rows) < count:
            raise RuntimeError(
                f"–í –≤—ã–±—Ä–∞–Ω–Ω–æ–π –≥—Ä—É–ø–ø–µ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ (–µ—Å—Ç—å {len(rows)}, –Ω—É–∂–Ω–æ {count})."
            )
        random.shuffle(rows)
        return rows[:count]

    grouped = unused if unused else all_groups
    groups = list(grouped.items())
    if not groups:
        raise RuntimeError("–í –±–∞–∑–µ –Ω–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤.")

    if group_strategy == "random":
        random.shuffle(groups)
    else:
        groups.sort(key=lambda kv: -len(kv[1]))

    selected: List[sqlite3.Row] = []
    seen_dirs: Dict[Path, int] = {}

    for _, rows in groups:
        if len(selected) >= count:
            break
        random.shuffle(rows)
        for row in rows:
            if not row_matches_folder(row):
                continue
            try:
                path = Path(row["video_path"]).resolve()
                parent = path.parent
            except Exception:
                continue
            if not path.exists():
                continue
            if seen_dirs.get(parent, 0) >= PER_DIR_MAX_FIRST_PASS:
                continue
            selected.append(row)
            seen_dirs[parent] = seen_dirs.get(parent, 0) + 1
            if len(selected) >= count:
                break

    if len(selected) < count:
        leftovers: List[sqlite3.Row] = []
        for _, rows in groups:
            leftovers.extend(rows)
        random.shuffle(leftovers)
        for row in leftovers:
            if len(selected) >= count:
                break
            try:
                path = Path(row["video_path"])
            except Exception:
                continue
            if not path.exists():
                continue
            selected.append(row)

    if len(selected) < count:
        raise RuntimeError("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ –¥–ª—è –º—É–∑—ã–∫–∞–ª—å–Ω–æ–π –∫–æ–º–ø–∏–ª—è—Ü–∏–∏.")
    return selected[:count]


def pick_specific_source_rows(
    rows: List[sqlite3.Row],
    count: int,
    min_new_required: int = 0,
) -> List[sqlite3.Row]:
    if count <= 0:
        raise ValueError("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å > 0")
    existing: List[sqlite3.Row] = []
    for row in rows:
        try:
            path = Path(row["video_path"]).resolve()
        except Exception:
            continue
        if not path.exists():
            continue
        existing.append(row)
    if len(existing) < count:
        raise RuntimeError("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤.")

    min_new_required = max(0, int(min_new_required))
    new_rows = [row for row in existing if _is_unused_source_row(row)]
    if min_new_required and len(new_rows) < min_new_required:
        raise RuntimeError("–ú–µ–Ω—å—à–µ –Ω–æ–≤—ã—Ö –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤, —á–µ–º –∑–∞–ø—Ä–æ—à–µ–Ω–æ.")

    random.shuffle(new_rows)
    selected: List[sqlite3.Row] = []
    needed_new = min(min_new_required, count)
    if needed_new:
        selected.extend(new_rows[:needed_new])
    remaining = [row for row in existing if row not in selected]
    random.shuffle(remaining)
    while len(selected) < count and remaining:
        selected.append(remaining.pop())

    if len(selected) < count:
        raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±—Ä–∞—Ç—å –Ω—É–∂–Ω–æ–µ —á–∏—Å–ª–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.")

    random.shuffle(selected)
    return selected[:count]


def make_music_output_name(
    manifest_name: str,
    segments_count: int,
    algo_tag: str,
    orientation: str = "HOR",
    sources_count: int = 0,
    group_number: Optional[int] = None,
) -> Path:
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M")
    safe_name = sanitize_filename(manifest_name or "music")
    safe_name = safe_name.replace(" ", "_")
    orientation_tag = (orientation or "HOR").upper()
    segments_part = f"{segments_count}seg"
    sources_part = f"{max(1, sources_count)}fil"
    group_part = "??grp"
    if group_number is not None:
        try:
            group_idx = int(group_number)
            group_part = f"{group_idx}grp"
        except (TypeError, ValueError):
            pass
    base = (
        f"{timestamp}_{orientation_tag}_{group_part}_"
        f"{safe_name}_{segments_part}_{sources_part}_{algo_tag.upper()}"
    )
    candidate = OUTPUT_DIR / f"{base}.mp4"
    idx = 2
    while candidate.exists():
        candidate = OUTPUT_DIR / f"{base} ({idx}).mp4"
        idx += 1
    return candidate


def move_output_to_network_storage(local_path: Path, date_folder: Optional[str] = None) -> Tuple[Path, str]:
    resolved = local_path.resolve()
    if not resolved.exists():
        raise FileNotFoundError(f"–ò—Ç–æ–≥–æ–≤—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {resolved}")

    if not ENABLE_NETWORK_COPY:
        comment = (
            f"network_copy=disabled;original_path={resolved};"
            f"timestamp={datetime.now().isoformat(timespec='seconds')}"
        )
        return resolved, comment

    if not date_folder:
        date_folder = date.today().isoformat()
    target_dir = NETWORK_OUTPUT_ROOT / date_folder
    target_dir.mkdir(parents=True, exist_ok=True)

    destination = target_dir / resolved.name
    suffix = resolved.suffix
    stem = resolved.stem
    idx = 2
    while destination.exists():
        destination = target_dir / f"{stem} ({idx}){suffix}"
        idx += 1

    if resolved == destination:
        print(f"[OUTPUT] –§–∞–π–ª —É–∂–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ü–µ–ª–µ–≤–æ–π –ø–∞–ø–∫–µ: {destination}")
    else:
        print(f"[OUTPUT] –ü–µ—Ä–µ–Ω–æ—à—É —Ñ–∞–π–ª {resolved} -> {destination}")
        shutil.move(str(resolved), str(destination))

    comment = (
        f"network_path={destination};date_folder={date_folder};"
        f"moved_from={resolved};moved_at={datetime.now().isoformat(timespec='seconds')}"
    )
    return destination, comment


def mux_audio_with_video(video_path: Path, audio_path: Path, out_path: Path) -> None:
    cmd = [
        FFMPEG_BIN,
        "-y",
        "-i", str(video_path),
        "-i", str(audio_path),
        "-c:v", "copy",
        "-c:a", "aac",
        "-map", "0:v:0",
        "-map", "1:a:0",
        "-shortest",
        "-movflags", "+faststart",
        str(out_path),
    ]
    subprocess.check_call(cmd)


def make_music_synced_pmv(
    manifest_name: str,
    segments: List[MusicSegment],
    audio_path: Path,
    source_rows: List[sqlite3.Row],
    clip_algo_key: str,
    orientation: str = "HOR",
    group_number: Optional[int] = None,
) -> Tuple[Path, List[int], Tuple[str, Dict[str, Any]]]:
    if not segments:
        raise RuntimeError("–í –º–∞–Ω–∏—Ñ–µ—Å—Ç–µ –Ω–µ—Ç —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è –Ω–∞—Ä–µ–∑–∫–∏.")
    if not audio_path.exists():
        raise FileNotFoundError(f"MP3 –Ω–µ –Ω–∞–π–¥–µ–Ω: {audio_path}")

    source_paths: List[Path] = []
    source_ids: List[int] = []
    for row in source_rows:
        try:
            sid = int(row["id"])
            path = Path(row["video_path"])
        except Exception:
            continue
        if not path.exists():
            continue
        source_paths.append(path)
        source_ids.append(sid)
    if not source_paths:
        raise RuntimeError("–ù–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤ –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤.")

    resolved_key, algo_meta = resolve_clip_algorithm(clip_algo_key)
    total_segments = len(segments)
    sequence_sources = build_music_source_sequence(source_paths, resolved_key, total_segments)
    durations: Dict[Path, float] = {}
    for path in source_paths:
        durations[path] = float(ffprobe_duration_seconds(path))

    print(
        f"[MUSIC] Start sync render: project='{manifest_name}', segments={total_segments}, "
        f"sources={len(source_paths)}, algo={resolved_key}"
    )

    tmp_parent = pick_temp_dir(TEMP_DIRS, min_free_bytes=5 * 1024**3)
    tmp_root = Path(tempfile.mkdtemp(prefix="music_", dir=str(tmp_parent)))
    clip_meta: List[Dict[str, Any]] = []

    try:
        base_sequence = list(zip(segments, sequence_sources))
        for idx, (segment, primary_src) in enumerate(base_sequence, 1):
            seg_dur = max(0.3, segment.duration)
            candidate_sources = [primary_src] + [p for p in source_paths if p != primary_src]
            clip_created = False
            ext = ".ts" if USE_TS_CONCAT else ".mp4"
            clip_path = tmp_root / f"music_clip_{idx:04d}{ext}"

            for src_path in candidate_sources:
                video_dur = durations.get(src_path, 0.0)
                if video_dur <= 0.5:
                    continue

                max_start = max(0.0, video_dur - seg_dur - 0.5)
                if max_start <= 0:
                    actual_dur = min(seg_dur, max(0.3, video_dur - 0.2))
                    if actual_dur <= 0:
                        continue
                    start_pos = 0.0
                else:
                    actual_dur = seg_dur
                    start_pos = random.uniform(0.0, max_start)

                try:
                    extract_clip(src_path, start_pos, actual_dur, clip_path)
                    print(
                        f"[MUSIC] [{idx}/{total_segments}] {src_path.name} start={start_pos:.2f}s "
                        f"dur={actual_dur:.2f}s target={segment.duration:.2f}s intensity={segment.intensity:.2f}"
                    )
                    clip_meta.append(
                        {
                            "path": clip_path,
                            "duration": float(actual_dur),
                        }
                    )
                    clip_created = True
                    break
                except subprocess.CalledProcessError as err:
                    if clip_path.exists():
                        clip_path.unlink(missing_ok=True)
                    print(f"[MUSIC][WARN] extract failed on {src_path.name}: {err}")
                    try:
                        sid = db_get_source_id_by_path(src_path)
                        if sid is not None:
                            db_mark_source_problem(sid, f"music_extract_error")
                    except Exception:
                        pass
                    continue

            if not clip_created:
                print(f"[MUSIC][WARN] Segment {idx} skipped: –Ω–µ —É–¥–∞–ª–æ—Å—å –≤—ã—Ä–µ–∑–∞—Ç—å –∫–ª–∏–ø –Ω–∏ –∏–∑ –æ–¥–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞.")
                continue

        if not clip_meta:
            raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã—Ä–µ–∑–∞—Ç—å –∫–ª–∏–ø—ã –ø–æ –º—É–∑—ã–∫–∞–ª—å–Ω—ã–º —Å–µ–≥–º–µ–Ω—Ç–∞–º.")
        if GLITCH_EFFECTS_PER_VIDEO > 0 or TRANSITION_EFFECTS_PER_VIDEO > 0:
            processed_clips, video_profile = apply_video_fx(clip_meta, tmp_root)
            uniform_clips = transcode_clips_to_profile(
                processed_clips, tmp_root, video_profile
            )
        else:
            uniform_clips = [Path(meta["path"]) for meta in clip_meta]
        raw_video_path = tmp_root / "music_raw.mp4"
        print(f"[MUSIC] –ö–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏—è {len(uniform_clips)} –∫–ª–∏–ø–æ–≤...")
        concat_via_list(uniform_clips, raw_video_path)
        if raw_video_path.with_suffix(".mp4").exists():
            raw_video_path = raw_video_path.with_suffix(".mp4")

        algo_tag = algo_meta.get("short") or resolved_key
        final_path = make_music_output_name(
            manifest_name,
            len(segments),
            algo_tag,
            orientation=orientation,
            sources_count=len(source_paths),
            group_number=group_number,
        )
        print("[MUSIC] –ù–∞–∫–ª–∞–¥—ã–≤–∞—é –∞—É–¥–∏–æ–¥–æ—Ä–æ–∂–∫—É...")
        mux_audio_with_video(raw_video_path, audio_path, final_path)
        print(f"[MUSIC] –ì–æ—Ç–æ–≤–æ: {final_path}")
        return final_path, source_ids, (resolved_key, algo_meta)
    finally:
        shutil.rmtree(tmp_root, ignore_errors=True)


def extract_clip(src: Path, start: float, dur: int, dst: Path) -> None:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª–∏–ø–∞ –±–µ–∑ –ø–µ—Ä–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è. –î–ª—è TS –¥–æ–±–∞–≤–ª—è–µ–º –Ω—É–∂–Ω—ã–π bitstream-—Ñ–∏–ª—å—Ç—Ä.
    Start –º–æ–∂–µ—Ç –±—ã—Ç—å float. –î–æ–±–∞–≤–ª–µ–Ω -avoid_negative_ts make_zero –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω—ã—Ö —Ç–∞–π–º—Å—Ç–µ–º–ø–æ–≤."""
    if USE_TS_CONCAT and dst.suffix.lower() != ".ts":
        dst = dst.with_suffix(".ts")

    if USE_TS_CONCAT:
        vinfo = detect_video_info(src)
        vcodec = (vinfo.get("codec_name") or "").lower()
        if vcodec.startswith("h264") or vcodec == "avc1":
            bsf_v = "h264_mp4toannexb"
        elif vcodec in ("hevc", "h265") or vcodec.startswith(("hev1", "hvc1")):
            bsf_v = "hevc_mp4toannexb"
        else:
            # –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∫–æ–¥–µ–∫ ‚Äî –∫–æ–ø–∏—Ä—É–µ–º —Å—Ä–∞–∑—É –≤ MP4
            cmd = [
                FFMPEG_BIN,
                "-v", "error",
                "-y",
                "-ss", str(start),
                "-t", str(dur),
                "-i", str(src),
                "-c", "copy",
                "-avoid_negative_ts", "make_zero",
                "-movflags", "+faststart",
                str(dst.with_suffix(".mp4")),
            ]
            subprocess.check_call(cmd)
            return

        cmd = [
            FFMPEG_BIN,
            "-v", "error",
            "-y",
            "-ss", str(start),
            "-t", str(dur),
            "-i", str(src),
            "-c", "copy",
            "-bsf:v", bsf_v,
            "-avoid_negative_ts", "make_zero",
            "-f", "mpegts",
            str(dst),
        ]
        try:
            subprocess.check_call(cmd)
        except subprocess.CalledProcessError:
            fallback_cmd = [
                FFMPEG_BIN,
                "-v", "error",
                "-y",
                "-ss", str(start),
                "-t", str(dur),
                "-i", str(src),
                "-c", "copy",
                "-avoid_negative_ts", "make_zero",
                "-f", "mpegts",
                str(dst),
            ]
            try:
                subprocess.check_call(fallback_cmd)
            except subprocess.CalledProcessError:
                raise
    else:
        cmd = [
            FFMPEG_BIN,
            "-v", "error",
            "-y",
            "-ss", str(start),
            "-t", str(dur),
            "-i", str(src),
            "-c", "copy",
            "-avoid_negative_ts", "make_zero",
            "-movflags", "+faststart",
            str(dst),
        ]
        subprocess.check_call(cmd)


def concat_via_list(clips_paths: List[Path], out_path: Path) -> None:
    """
    –°–∫–ª–µ–∏–≤–∞–µ—Ç –∫–ª–∏–ø—ã –≤ –æ–¥–∏–Ω —Ñ–∞–π–ª.

    –§–∏—à–∫–∏:
    - –ë–æ–ª—å—à–µ –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–ª–∏–Ω–Ω—ã–π –∞—Ä–≥—É–º–µ–Ω—Ç –≤–∏–¥–∞ concat:...|...|...
      (–Ω–∞ Windows –æ–Ω –ª–µ–≥–∫–æ –ª–æ–º–∞–µ—Ç—Å—è).
    - –î–µ–ª–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Å–ø–∏—Å–æ–∫ (concat demuxer), –ø—É—Ç–∏ –ø–µ—Ä–µ–≤–æ–¥–∏–º –≤ –≤–∏–¥ —Å '/'.
    - –ï—Å–ª–∏ –æ–∂–∏–¥–∞–µ–º–∞—è .ts –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∏—â–µ–º .mp4 (—Ñ–æ–ª–±–µ–∫ –∏–∑ extract_clip).
    """
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ –∏–º—è –≤—ã–≤–æ–¥–∞
    if out_path.suffix.lower() != ".mp4":
        out_mp4 = out_path.with_suffix(".mp4")
    else:
        out_mp4 = out_path

    real_paths: List[Path] = []

    for p in clips_paths:
        # –±–∞–∑–æ–≤—ã–π –∫–∞–Ω–¥–∏–¥–∞—Ç ‚Äî –∫–∞–∫ –Ω–∞–º –µ–≥–æ –ø–µ—Ä–µ–¥–∞–ª–∏
        cand = p

        if not cand.exists():
            # –µ—Å–ª–∏ —Ç–∞–∫–æ–≥–æ –Ω–µ—Ç, –ø—Ä–æ–±—É–µ–º .ts / .mp4 —Ä—è–¥–æ–º
            alt_ts = p.with_suffix(".ts")
            alt_mp4 = p.with_suffix(".mp4")

            if alt_ts.exists():
                cand = alt_ts
            elif alt_mp4.exists():
                cand = alt_mp4
            else:
                raise FileNotFoundError(
                    f"–ù–µ –Ω–∞–π–¥–µ–Ω –∫–ª–∏–ø –¥–ª—è –∫–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏–∏: {p} "
                    f"(–ø—Ä–æ–±–æ–≤–∞–ª–∏ {alt_ts} –∏ {alt_mp4})"
                )

        real_paths.append(cand)

    if not real_paths:
        raise RuntimeError("–°–ø–∏—Å–æ–∫ –∫–ª–∏–ø–æ–≤ –¥–ª—è –∫–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏–∏ –ø—É—Å—Ç.")

    # –§–∞–π–ª-—Å–ø–∏—Å–æ–∫ –¥–ª—è concat demuxer
    list_file = out_mp4.parent / f"{out_mp4.stem}_concat_list.txt"

    with open(list_file, "w", encoding="utf-8") as f:
        for c in real_paths:
            # ffmpeg –Ω–∞ Windows –Ω–æ—Ä–º–∞–ª—å–Ω–æ –ø–æ–Ω–∏–º–∞–µ—Ç –ø—Ä—è–º—ã–µ —Å–ª—ç—à–∏
            p_str = str(c.resolve()).replace("\\", "/")
            f.write(f"file '{p_str}'\n")

    # –°–æ–±–∏—Ä–∞–µ–º –∫–æ–º–∞–Ω–¥—É ffmpeg
    cmd = [
        FFMPEG_BIN,
        "-v", "error",
        "-y",
        "-fflags", "+genpts",
        "-max_interleave_delta", "0",
        "-f", "concat",
        "-safe", "0",
        "-i", str(list_file),
        "-c", "copy",
        "-movflags", "+faststart",
    ]

    # –ï—Å–ª–∏ –º—ã —Ä–∞–±–æ—Ç–∞–µ–º —Å TS-–∫–ª–∏–ø–∞–º–∏ (USE_TS_CONCAT=True),
    # –æ—Å—Ç–∞–≤–ª—è–µ–º –±–∏—Ç—Å—Ç—Ä–∏–º-—Ñ–∏–ª—å—Ç—Ä –¥–ª—è AAC ‚Üí MP4.
    if USE_TS_CONCAT:
        cmd.extend(["-bsf:a", "aac_adtstoasc"])

    cmd.append(str(out_mp4))

    try:
        subprocess.check_call(cmd)
    finally:
        try:
            list_file.unlink()
        except OSError:
            pass


def pick_evenly_spaced_indices(total: int, count: int) -> List[int]:
    if count <= 0 or total <= 0:
        return []
    result: List[int] = []
    used: set[int] = set()
    step = total / (count + 1)
    for i in range(count):
        idx = int(round(step * (i + 1)))
        idx = max(0, min(total - 1, idx))
        while idx in used and idx < total - 1:
            idx += 1
        while idx in used and idx > 0:
            idx -= 1
        if idx not in used:
            used.add(idx)
            result.append(idx)
    return sorted(result)


def pick_positions_from_pool(pool: List[int], count: int) -> List[int]:
    if count <= 0 or not pool:
        return []
    sorted_pool = sorted(pool)
    positions = pick_evenly_spaced_indices(len(sorted_pool), count)
    return [sorted_pool[i] for i in positions if i < len(sorted_pool)]


def determine_fx_encoding_profile(sample_path: Path) -> Dict[str, str]:
    info = detect_video_info(sample_path)
    codec = (info.get("codec_name") or "").lower()
    pix_fmt = info.get("pix_fmt") or ""
    if not pix_fmt or not re.fullmatch(r"[A-Za-z0-9_]+", pix_fmt):
        pix_fmt = "yuv420p"
    fps_val = info.get("fps")
    try:
        fps = float(fps_val) if fps_val else 30.0
    except (TypeError, ValueError):
        fps = 30.0
    fps = fps if fps > 0 else 30.0
    if codec in {"hevc", "h265", "hvc1", "hev1"}:
        video_encoder = "libx265"
    else:
        video_encoder = "libx264"
    return {"video_encoder": video_encoder, "pix_fmt": pix_fmt, "fps": fps}


def create_glitch_clip(
    clip_meta: Dict[str, Any],
    tmp_root: Path,
    profile: Dict[str, str],
    duration: float = FX_GLITCH_DURATION,
) -> Optional[Path]:
    src_path = Path(clip_meta["path"])
    clip_dur = float(clip_meta.get("duration") or duration)
    duration = float(max(0.15, min(duration, clip_dur)))
    start = max(clip_dur - duration, 0.0)
    filters = [
        "rgbashift=rh=5:rv=-5:gh=-4:gv=4:bh=3:bv=-3,noise=alls=20:allf=t+u,eq=contrast=1.2:saturation=1.4",
        "tblend=all_mode='xor',hue=s=0,format=yuv420p",
        "noise=alls=30:allf=t+u,edgedetect=mode=colormix:high=0.2:low=0.05",
    ]
    vf = random.choice(filters)
    out_path = tmp_root / f"{src_path.stem}_glitch_{random.randrange(1_000_000)}.mp4"
    filter_complex = (
        f"[0:v]trim=start={start:.3f}:end={clip_dur:.3f},setpts=PTS-STARTPTS,"
        f"{vf},fps={profile.get('fps') or 30.0},format={profile.get('pix_fmt') or 'yuv420p'}[vout]"
    )
    cmd = [
        FFMPEG_BIN,
        "-v",
        "error",
        "-y",
        "-i",
        str(src_path),
        "-filter_complex",
        filter_complex,
        "-c:v",
        profile.get("video_encoder") or "libx264",
        "-preset",
        "veryfast",
        "-crf",
        "18",
        "-movflags",
        "+faststart",
        "-map",
        "[vout]",
        "-an",
        str(out_path),
    ]
    try:
        subprocess.check_call(cmd)
        return out_path
    except subprocess.CalledProcessError:
        if out_path.exists():
            out_path.unlink(missing_ok=True)
        return None


def create_transition_clip(
    prev_meta: Dict[str, Any],
    next_meta: Dict[str, Any],
    tmp_root: Path,
    profile: Dict[str, str],
    duration: float = FX_TRANSITION_DURATION,
) -> Optional[Path]:
    prev_path = Path(prev_meta["path"])
    next_path = Path(next_meta["path"])
    prev_dur = float(prev_meta.get("duration") or duration)
    next_dur = float(next_meta.get("duration") or duration)
    duration = float(min(duration, prev_dur, next_dur, 1.0))
    if duration < 0.15:
        return None
    start_prev = max(prev_dur - duration, 0.0)
    transition = random.choice(XFADE_TRANSITIONS) if XFADE_TRANSITIONS else "fade"
    out_path = tmp_root / f"transition_{prev_path.stem}_{next_path.stem}_{random.randrange(1_000_000)}.mp4"
    fps = profile.get("fps") or 30.0
    video_fmt = profile.get("pix_fmt") or "yuv420p"
    filter_complex = (
        f"[0:v]trim=start={start_prev:.3f}:end={prev_dur:.3f},setpts=PTS-STARTPTS,"
        f"fps={fps},format={video_fmt}[v0];"
        f"[1:v]trim=start=0:end={duration:.3f},setpts=PTS-STARTPTS,fps={fps},format={video_fmt}[v1];"
        f"[v0][v1]xfade=transition={transition}:duration={duration:.3f}:offset=0[vout]"
    )
    cmd = [
        FFMPEG_BIN,
        "-v",
        "error",
        "-y",
        "-i",
        str(prev_path),
        "-i",
        str(next_path),
        "-filter_complex",
        filter_complex,
        "-c:v",
        profile.get("video_encoder") or "libx264",
        "-preset",
        "veryfast",
        "-crf",
        "18",
        "-movflags",
        "+faststart",
        "-map",
        "[vout]",
        "-an",
        str(out_path),
    ]
    try:
        subprocess.check_call(cmd)
        return out_path
    except subprocess.CalledProcessError:
        if out_path.exists():
            out_path.unlink(missing_ok=True)
        return None


def apply_video_fx(
    clips_meta: List[Dict[str, Any]], tmp_root: Path
) -> Tuple[List[Path], Dict[str, str]]:
    if not clips_meta:
        return [], {"video_encoder": "libx264", "pix_fmt": "yuv420p", "fps": 30.0}
    total_seams = max(0, len(clips_meta) - 1)
    profile = determine_fx_encoding_profile(Path(clips_meta[0]["path"]))

    transition_positions = pick_evenly_spaced_indices(
        total_seams, min(TRANSITION_EFFECTS_PER_VIDEO, total_seams)
    )
    remaining_seams = [i for i in range(total_seams) if i not in transition_positions]
    glitch_positions = pick_positions_from_pool(
        remaining_seams, min(GLITCH_EFFECTS_PER_VIDEO, len(remaining_seams))
    )

    result_paths: List[Path] = []
    for idx, meta in enumerate(clips_meta):
        result_paths.append(Path(meta["path"]))
        if idx >= total_seams:
            continue
        seam_index = idx
        if seam_index in transition_positions:
            clip = create_transition_clip(
                meta, clips_meta[idx + 1], tmp_root, profile, FX_TRANSITION_DURATION
            )
            if clip:
                result_paths.append(clip)
        elif seam_index in glitch_positions:
            clip = create_glitch_clip(meta, tmp_root, profile, FX_GLITCH_DURATION)
            if clip:
                result_paths.append(clip)
    return result_paths, profile


def transcode_clips_to_profile(
    clips: List[Path],
    tmp_root: Path,
    profile: Dict[str, Any],
) -> List[Path]:
    uniform_paths: List[Path] = []
    fps = float(profile.get("fps") or 30.0)
    pix_fmt = profile.get("pix_fmt") or "yuv420p"
    video_encoder = profile.get("video_encoder") or "libx264"

    for idx, clip in enumerate(clips, 1):
        out_path = tmp_root / f"uniform_{idx:04d}.mp4"
        cmd = [
            FFMPEG_BIN,
            "-v",
            "error",
            "-y",
            "-i",
            str(clip),
            "-vf",
            f"fps={fps},format={pix_fmt}",
            "-c:v",
            video_encoder,
            "-preset",
            "veryfast",
            "-crf",
            "18",
            "-an",
            "-movflags",
            "+faststart",
            str(out_path),
        ]
        subprocess.check_call(cmd)
        uniform_paths.append(out_path)
    return uniform_paths


def make_output_name(
    selected_files: List[Path],
    target_seconds: int,
    big_parts: int,
    small_per_big: int,
    run_seed: Optional[int] = None,
    algo_tag: Optional[str] = None,
) -> Path:
    """
    –ò–º—è –≤–∏–¥–∞:
    YYYYMMDD - random_title - BUILD_NAME - <N>files - <M>min - <big_parts>big - <small_per_big>small - seed<seed>.mp4

    + –ì–ê–†–ê–ù–¢–ò–Ø: –µ—Å–ª–∏ —Ñ–∞–π–ª —Å —Ç–∞–∫–∏–º –∏–º–µ–Ω–µ–º —É–∂–µ –µ—Å—Ç—å, –¥–æ–±–∞–≤–ª—è–µ–º " (2)", " (3)" –∏ —Ç.–¥.
    """
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    today = datetime.now().strftime("%Y%m%d")
    random_title = db_get_random_name()

    # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤
    files_count = len(selected_files)

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ü–µ–ª–µ–≤—ã–µ —Å–µ–∫—É–Ω–¥—ã –≤ –º–∏–Ω—É—Ç—ã (–º–∏–Ω–∏–º—É–º 1)
    minutes = max(1, int(round(target_seconds / 60.0)))

    algo_part = f" - {algo_tag}" if algo_tag else ""
    seed_part = f" - seed{run_seed}" if run_seed is not None else ""

    base_stem = (
        f"{today} - {random_title} - {BUILD_NAME} - "
        f"{files_count}files - {minutes}min - {big_parts}big - {small_per_big}small{algo_part}{seed_part}"
    )

    candidate = OUTPUT_DIR / f"{base_stem}.mp4"
    if not candidate.exists():
        return candidate

    idx = 2
    while True:
        candidate = OUTPUT_DIR / f"{base_stem} ({idx}).mp4"
        if not candidate.exists():
            return candidate
        idx += 1



def estimate_required_bytes(total_seconds: int, assumed_mbps: int = 15) -> int:
    """–ì—Ä—É–±–∞—è –æ—Ü–µ–Ω–∫–∞ —Ç—Ä–µ–±—É–µ–º–æ–≥–æ –º–µ—Å—Ç–∞ (–±–∞–π—Ç—ã) –∏—Å—Ö–æ–¥—è –∏–∑ —Å—Ä–µ–¥–Ω–µ–≥–æ –±–∏—Ç—Ä–µ–π—Ç–∞ (~15 –ú–±–∏—Ç/—Å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)."""
    return int(total_seconds * (assumed_mbps * 1_000_000 / 8))


def make_pmv_from_files(
    selected_paths: List[Path],
    target_seconds: int,
    big_parts: int,
    small_per_big: int,
    clip_algo_key: Optional[str] = None,
) -> Path:
    if not selected_paths:
        raise ValueError("–ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –¥–ª—è PMV")

    # –°–∏–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ ‚Äî –º–µ–Ω—è–µ—Ç—Å—è –∫–∞–∂–¥—ã–π –∑–∞–ø—É—Å–∫; –¥–æ–±–∞–≤–ª—è–µ–º –≤ –∏–º—è —Ñ–∞–π–ª–∞
    global RANDOM_SEED
    run_seed = int(time.time())
    random.seed(run_seed)
    RANDOM_SEED = run_seed

    durations: Dict[Path, int] = {}
    valid_paths: List[Path] = []
    for p in selected_paths:
        try:
            if not p.exists():
                # –ø–æ–º–µ—á–∞–µ–º –∫–∞–∫ –ø—Ä–æ–±–ª–µ–º–Ω—ã–π –∏ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                try:
                    sid = db_get_source_id_by_path(p)
                    if sid is not None:
                        db_mark_source_problem(sid, "missing_file")
                except Exception:
                    pass
                continue
            d = int(ffprobe_duration_seconds(p))
            if d > 0:
                durations[p] = d
                valid_paths.append(p)
            else:
                try:
                    sid = db_get_source_id_by_path(p)
                    if sid is not None:
                        db_mark_source_problem(sid, "zero_duration")
                except Exception:
                    pass
        except Exception:
            try:
                sid = db_get_source_id_by_path(p)
                if sid is not None:
                    db_mark_source_problem(sid, "probe_error")
            except Exception:
                pass
            continue

    # –∑–∞–º–µ–Ω—è–µ–º —Å–ø–∏—Å–æ–∫ –Ω–∞ —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–µ –ø—É—Ç–∏
    selected_paths = valid_paths

    sum_dur = sum(durations.values())
    effective_target = min(target_seconds, sum_dur)
    if effective_target <= 0:
        raise RuntimeError("–¶–µ–ª–µ–≤–∞—è –¥–ª–∏–Ω–∞ –Ω—É–ª–µ–≤–∞—è –∏–ª–∏ —É —Ñ–∞–π–ª–æ–≤ –Ω—É–ª–µ–≤–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–µ—Å—Ç–∞: –æ—Ü–µ–Ω–∏–º —Ä–∞–∑–º–µ—Ä —Ñ–∏–Ω–∞–ª–∞ –∏ —Ä–µ–∑–µ—Ä–≤ –ø–æ–¥ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–ª–∏–ø—ã
    estimated_out = estimate_required_bytes(effective_target)
    if estimated_out > MAX_OUTPUT_BYTES:
        raise RuntimeError(
            f"–û—Ü–µ–Ω–æ—á–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∏—Ç–æ–≥–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞ –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ª–∏–º–∏—Ç 100 –ì–ë (‚âà{estimated_out/1024**3:.1f} –ì–ë)."
        )

    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    free_out = shutil.disk_usage(str(OUTPUT_DIR)).free
    if free_out < min(estimated_out, MAX_OUTPUT_BYTES):
        raise RuntimeError(
            f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –º–µ—Å—Ç–∞ –≤ –ø–∞–ø–∫–µ –≤—ã–≤–æ–¥–∞: –Ω—É–∂–Ω–æ ‚âà{estimated_out/1024**3:.1f} –ì–ë, –¥–æ—Å—Ç—É–ø–Ω–æ ‚âà{free_out/1024**3:.1f} –ì–ë."
        )

    per_file_alloc = allocate_equalish(effective_target, selected_paths, durations)
    resolved_algo_key, algo_meta = resolve_clip_algorithm(clip_algo_key)

    per_file_clips: Dict[Path, List[Tuple[int, int]]] = {}
    for f in selected_paths:
        alloc = per_file_alloc.get(f, 0)
        if alloc <= 0:
            continue
        clips = plan_for_file(f, alloc, big_parts, small_per_big, algo_key=resolved_algo_key)
        per_file_clips[f] = clips

    sequence = algo_meta["builder"](per_file_clips)
    if not sequence:
        raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–ø–ª–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫–ª–∏–ø–æ–≤")
    print(f"[CLIP-SEQ] –ê–ª–≥–æ—Ä–∏—Ç–º: {algo_meta['title']} ({resolved_algo_key})")

    tmp_parent = pick_temp_dir(TEMP_DIRS, min_free_bytes=max(5 * 1024**3, estimated_out * 2))
    tmp_root = Path(tempfile.mkdtemp(prefix="pmv_", dir=str(tmp_parent)))
    clips_paths: List[Path] = []

    # –ö—ç—à –∫–ª—é—á–µ–≤—ã—Ö –∫–∞–¥—Ä–æ–≤ –¥–ª—è –ø—Ä–∏–≤—è–∑–∫–∏ —Å—Ç–∞—Ä—Ç–æ–≤ –∫–ª–∏–ø–æ–≤
    keyframe_cache: Dict[Path, Dict[str, Any]] = {}
    KEYFRAME_INITIAL_WINDOW = 10.0
    KEYFRAME_MAX_WINDOW = 300.0
    KEYFRAME_LOOKAHEAD = 0.25

    def _cache_entry(src: Path) -> Dict[str, Any]:
        return keyframe_cache.setdefault(src, {"times": [], "full_scan": False})

    def _insert_keyframes(entry: Dict[str, Any], values: List[float]) -> None:
        if not values:
            return
        times: List[float] = entry["times"]
        for val in values:
            rounded = round(val, 6)
            idx = bisect_left(times, rounded)
            if idx >= len(times) or abs(times[idx] - rounded) > 1e-6:
                times.insert(idx, rounded)

    def _find_prev(entry: Dict[str, Any], t: float) -> Optional[float]:
        times: List[float] = entry["times"]
        if not times:
            return None
        idx = bisect_right(times, t)
        if idx:
            return times[idx - 1]
        return times[0]

    def _probe_keyframes(src: Path, start: Optional[float], end: Optional[float]) -> List[float]:
        cmd = [
            FFPROBE_BIN,
            "-v", "error",
            "-select_streams", "v:0",
            "-skip_frame", "nokey",
            "-show_entries", "frame=pkt_pts_time",
            "-of", "default=nokey=1:noprint_wrappers=1",
        ]
        if start is not None or end is not None:
            interval_start = 0.0 if start is None else max(0.0, start)
            interval_end = interval_start + 0.05
            if end is not None:
                interval_end = max(interval_end, end)
            cmd.extend(["-read_intervals", f"{interval_start:.3f}%{interval_end:.3f}"])
        cmd.append(str(src))
        try:
            out = subprocess.check_output(cmd, text=True)
        except Exception:
            return []
        found: List[float] = []
        for line in out.strip().splitlines():
            try:
                found.append(float(line.strip()))
            except Exception:
                continue
        return sorted(found)

    def get_prev_keyframe_time(src: Path, t: float) -> float:
        entry = _cache_entry(src)
        cached = _find_prev(entry, t)
        if cached is not None:
            return cached

        window = KEYFRAME_INITIAL_WINDOW
        while window <= KEYFRAME_MAX_WINDOW:
            window_start = max(0.0, t - window)
            window_end = max(t + KEYFRAME_LOOKAHEAD, window_start + 0.05)
            new_vals = _probe_keyframes(src, window_start, window_end)
            _insert_keyframes(entry, new_vals)
            cached = _find_prev(entry, t)
            if cached is not None or window_start <= 0:
                break
            window *= 2

        if cached is not None:
            return cached

        if not entry.get("full_scan"):
            full_vals = _probe_keyframes(src, None, None)
            _insert_keyframes(entry, full_vals)
            entry["full_scan"] = True
            cached = _find_prev(entry, t)
            if cached is not None:
                return cached

        return t

    try:
        total = len(sequence)
        for idx, (src, start, dur) in enumerate(sequence, 1):
            ext = ".ts" if USE_TS_CONCAT else ".mp4"
            out = tmp_root / f"clip_{idx:03d}{ext}"
            start_f = float(start)
            if SNAP_TO_KEYFRAMES:
                start_f = get_prev_keyframe_time(src, start_f)
            print(f"[{idx}/{total}] {src.name}: start={start_f:.3f}, dur={dur}")
            t0 = time.time()
            try:
                extract_clip(src, start_f, dur, out)
                print(f"  -> clip ok ({time.time() - t0:.1f}s)")
                clips_paths.append(out)
            except Exception as e:
                print(f"[ERROR] –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –∫–ª–∏–ø–∞ –∏–∑ {src}: {e}")
                try:
                    sid = db_get_source_id_by_path(src)
                    if sid is not None:
                        db_mark_source_problem(sid, f"extract_error={e}")
                except Exception:
                    pass
                continue

        if not clips_paths:
            raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –Ω–∏ –æ–¥–Ω–æ–≥–æ –∫–ª–∏–ø–∞ ‚Äî –≤—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –∑–∞–∫–æ–Ω—á–∏–ª–∏—Å—å –æ—à–∏–±–∫–∞–º–∏.")

        out_path = make_output_name(
            selected_files=selected_paths,
            target_seconds=target_seconds,
            big_parts=big_parts,
            small_per_big=small_per_big,
            run_seed=run_seed,
            algo_tag=algo_meta.get("short"),
        )
        concat_via_list(clips_paths, out_path)
        if out_path.with_suffix(".mp4").exists():
            out_path = out_path.with_suffix(".mp4")
        return out_path
    finally:
        shutil.rmtree(tmp_root, ignore_errors=True)


def autocreate_make_one_pairs(
    target_seconds: int,
    max_sources: int,
    min_sources: int,
    excluded_ids: set[int],
    big_parts: int = 5,
    small_per_big: int = 5,
    strategy: str = "max_group",
    clip_algo_key: Optional[str] = None,
) -> Optional[Tuple[Path, List[int], Tuple[str, str]]]:
    """
    –°–æ–∑–¥–∞—ë—Ç –æ–¥–Ω–æ PMV –∏–∑ –ü–ê–†: 1 –Ω–æ–≤—ã–π + 1 —Å—Ç–∞—Ä—ã–π –∏—Å—Ö–æ–¥–Ω–∏–∫, –ø–æ–ø–µ—Ä–µ–º–µ–Ω–Ω–æ.
    –ì—Ä—É–ø–ø—ã –ø–æ (codec,res). –ë–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ –∫–ª—é—á–∏, –≥–¥–µ –µ—Å—Ç—å –∏ –Ω–æ–≤—ã–µ, –∏ —Å—Ç–∞—Ä—ã–µ.
    """
    new_groups = db_get_unused_sources_grouped()
    old_groups = db_get_used_sources_grouped()
    if not new_groups or not old_groups:
        return None

    # –∫–ª—é—á–∏ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è
    common_keys = []
    for k in new_groups.keys():
        if k in old_groups:
            # —Ñ–∏–ª—å—Ç—Ä—É–µ–º excluded
            new_rows = [r for r in new_groups[k] if int(r["id"]) not in excluded_ids]
            old_rows = [r for r in old_groups[k] if int(r["id"]) not in excluded_ids]
            if new_rows and old_rows:
                common_keys.append((k, new_rows, old_rows))
    if not common_keys:
        return None

    # –≤—ã–±—Ä–∞—Ç—å –∫–ª—é—á –ø–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
    if strategy == "weighted_random":
        total = sum(min(len(nr), len(orows)) for _, nr, orows in common_keys)
        rnd = random.randint(1, max(1, total))
        acc = 0
        key, new_rows, old_rows = common_keys[0]
        for k, nr, orows in common_keys:
            acc += min(len(nr), len(orows))
            if rnd <= acc:
                key, new_rows, old_rows = k, nr, orows
                break
    elif strategy == "random":
        key, new_rows, old_rows = random.choice(common_keys)
    else:  # max_group –ø–æ ‚Äú–º–∏–Ω–∏–º—É–º—É –ø–∞—Ä—ã‚Äù
        key, new_rows, old_rows = max(common_keys, key=lambda t: min(len(t[1]), len(t[2])))

    # —Å–∫–æ–ª—å–∫–æ –ø–∞—Ä –º–æ–∂–µ–º –≤–∑—è—Ç—å
    max_pairs = min(len(new_rows), len(old_rows), max_sources // 2)
    need_pairs = max(1, (min_sources + 1) // 2)
    if max_pairs < need_pairs:
        return None

    # –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ –ø–∞–ø–∫–∞–º –¥–ª—è –Ω–æ–≤—ã—Ö –∏ —Å—Ç–∞—Ä—ã—Ö –æ—Ç–¥–µ–ª—å–Ω–æ
    def pick_diverse(rows: List[sqlite3.Row], count: int) -> List[sqlite3.Row]:
        dir_map: Dict[Path, List[sqlite3.Row]] = {}
        for r in rows:
            d = Path(r["video_path"]).resolve().parent
            dir_map.setdefault(d, []).append(r)
        for lst in dir_map.values():
            random.shuffle(lst)
        chosen: List[sqlite3.Row] = []
        taken: Dict[Path, int] = {d: 0 for d in dir_map}
        progressed = True
        while len(chosen) < count and progressed:
            progressed = False
            for d, lst in list(dir_map.items()):
                if taken[d] >= PER_DIR_MAX_FIRST_PASS:
                    continue
                if lst:
                    chosen.append(lst.pop())
                    taken[d] += 1
                    progressed = True
                    if len(chosen) >= count:
                        break
        if len(chosen) < count:
            leftovers: List[sqlite3.Row] = []
            for lst in dir_map.values():
                leftovers.extend(lst)
            random.shuffle(leftovers)
            for r in leftovers:
                chosen.append(r)
                if len(chosen) >= count:
                    break
        return chosen

    pick_n = max_pairs
    new_pick = pick_diverse(new_rows, pick_n)
    old_pick = pick_diverse(old_rows, pick_n)

    # —á–µ—Ä–µ–¥—É–µ–º: –Ω–æ–≤—ã–π, —Å—Ç–∞—Ä—ã–π
    chosen_rows: List[sqlite3.Row] = []
    for nr, orow in zip(new_pick, old_pick):
        chosen_rows.append(nr)
        chosen_rows.append(orow)
    # —É—Ä–µ–∑–∞–µ–º –¥–æ –ª–∏–º–∏—Ç–∞
    chosen_rows = chosen_rows[: max_sources]

    paths = [Path(r["video_path"]) for r in chosen_rows]
    source_ids = [int(r["id"]) for r in chosen_rows]

    out_path = make_pmv_from_files(paths, target_seconds, big_parts, small_per_big, clip_algo_key=clip_algo_key)
    out_path, move_comment = move_output_to_network_storage(out_path)
    pmv_tag = Path(out_path).name

    db_insert_compilation(out_path, source_ids, comments=move_comment)
    db_update_sources_pmv_list(source_ids, pmv_tag)
    excluded_ids.update(source_ids)

    return out_path, source_ids, key


def autocreate_pmv_batch(
    total_videos: int,
    minutes_each: int,
    max_sources: int,
    min_sources: int,
) -> str:
    """
    –î–µ–ª–∞–µ—Ç –¥–æ total_videos PMV:
    - —Å–Ω–∞—á–∞–ª–∞ –∏–∑ –ù–û–í–´–• (–Ω–µ—É—á–∞—Å—Ç–≤–æ–≤–∞–≤—à–∏—Ö), –ø–æ—Ç–æ–º –∏–∑ –°–¢–ê–†–´–•,
    - –ø—Ä–∏ —ç—Ç–æ–º:
        new_count  = ceil(total_videos / 2)
        old_count  = floor(total_videos / 2)
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á—ë—Ç.
    """
    target_seconds = max(60, minutes_each * 60)

    # —Å–∫–æ–ª—å–∫–æ –Ω—É–∂–Ω–æ –ø–æ–ø—ã—Ç–∞—Ç—å—Å—è —Å–¥–µ–ª–∞—Ç—å
    new_target = (total_videos + 1) // 2   # –æ–∫—Ä—É–≥–ª–µ–Ω–∏–µ –≤–≤–µ—Ä—Ö
    old_target = total_videos // 2         # –æ–∫—Ä—É–≥–ª–µ–Ω–∏–µ –≤–Ω–∏–∑

    created_new = 0
    created_old = 0

    excluded_new: set[int] = set()
    excluded_old: set[int] = set()

    log_lines: List[str] = []
    algo_picker = ClipAlgorithmPicker(total_videos)

    # -------- –ù–æ–≤—ã–µ (–∫–∞–∫ pmvnew) --------
    for i in range(new_target):
        algo_key = algo_picker.current()
        try:
            res = autocreate_make_one_pairs(
                target_seconds=target_seconds,
                max_sources=max_sources,
                min_sources=min_sources,
                excluded_ids=excluded_new,
                strategy=CURRENT_STRATEGY,
                clip_algo_key=algo_key,
            )
        except Exception as e:
            log_lines.append(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –Ω–æ–≤–æ–≥–æ PMV #{i+1}: {e}")
            break

        if not res:
            # –§–û–õ–ë–ï–ö: –ø—Ä–æ–±—É–µ–º —Å–æ–±—Ä–∞—Ç—å —Ç–æ–ª—å–∫–æ –∏–∑ –Ω–æ–≤—ã—Ö, –µ—Å–ª–∏ –ø–∞—Ä –Ω–µ –Ω–∞–±—Ä–∞–ª–æ—Å—å
            try:
                res = fallback_new_only_make_one(
                    target_seconds=target_seconds,
                    max_sources=max_sources,
                    min_sources=min_sources,
                    excluded_ids=excluded_new,
                    strategy=CURRENT_STRATEGY,
                    clip_algo_key=algo_key,
                )
            except Exception as e:
                log_lines.append(f"‚ùå –û—à–∏–±–∫–∞ (fallback new-only) –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –Ω–æ–≤–æ–≥–æ PMV #{i+1}: {e}")
                break

            if not res:
                if i == 0:
                    log_lines.append("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ –Ω–æ–≤–æ–≥–æ PMV ‚Äî –º–∞–ª–æ –Ω–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤.")
                else:
                    log_lines.append("‚ö†Ô∏è –ò—Å—á–µ—Ä–ø–∞–Ω –ø—É–ª –Ω–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ –¥–ª—è –Ω–æ–≤—ã—Ö PMV.")
                break

        out_path, src_ids, (codec, reso) = res
        algo_picker.commit()
        _, algo_meta = resolve_clip_algorithm(algo_key)
        created_new += 1
        log_lines.append(
            f"‚úÖ –ù–æ–≤–æ–µ PMV #{created_new}: {out_path.name} "
            f"(–≥—Ä—É–ø–ø–∞ {codec} {reso}, –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤: {len(src_ids)}, –∞–ª–≥–æ—Ä–∏—Ç–º: {algo_meta['short']})"
        )

    # -------- –°—Ç–∞—Ä—ã–µ (—É–∂–µ —É—á–∞—Å—Ç–≤–æ–≤–∞–≤—à–∏–µ) --------
    for i in range(old_target):
        algo_key = algo_picker.current()
        try:
            res = autocreate_make_one_pairs(
                target_seconds=target_seconds,
                max_sources=max_sources,
                min_sources=min_sources,
                excluded_ids=excluded_old,
                strategy=CURRENT_STRATEGY,
                clip_algo_key=algo_key,
            )
        except Exception as e:
            log_lines.append(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ PMV –∏–∑ —Å—Ç–∞—Ä—ã—Ö –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ #{i+1}: {e}")
            break

        if not res:
            if i == 0:
                log_lines.append("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ PMV –∏–∑ —Å—Ç–∞—Ä—ã—Ö –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤.")
            else:
                log_lines.append("‚ö†Ô∏è –ò—Å—á–µ—Ä–ø–∞–Ω –ø—É–ª —Å—Ç–∞—Ä—ã—Ö –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ –¥–ª—è PMV.")
            break

        out_path, src_ids, (codec, reso) = res
        algo_picker.commit()
        _, algo_meta = resolve_clip_algorithm(algo_key)
        created_old += 1
        log_lines.append(
            f"‚úÖ PMV –∏–∑ —Å—Ç–∞—Ä—ã—Ö –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ #{created_old}: {out_path.name} "
            f"(–≥—Ä—É–ø–ø–∞ {codec} {reso}, –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤: {len(src_ids)}, –∞–ª–≥–æ—Ä–∏—Ç–º: {algo_meta['short']})"
        )

    created_total = created_new + created_old

    header = (
        f"üèÅ –ê–≤—Ç–æ—Å–æ–∑–¥–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.\n"
        f"–ó–∞–ø—Ä–æ—à–µ–Ω–æ –≤–∏–¥–µ–æ: {total_videos}\n"
        f"–§–∞–∫—Ç–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞–Ω–æ: {created_total} "
        f"(–Ω–æ–≤—ã—Ö: {created_new}, –∏–∑ —Å—Ç–∞—Ä—ã—Ö: {created_old})."
    )

    if not log_lines:
        return header
    return header + "\n\n" + "\n".join(log_lines)


# =========================
# –¢–ï–õ–ï–ì–†–ê–ú-–ë–û–¢
# =========================

user_sessions: Dict[int, Dict] = {}


def check_access(update: Update) -> bool:
    uid = update.effective_user.id if update.effective_user else 0
    return uid == ALLOWED_USER_ID


async def unauthorized(update: Update) -> None:
    await update.effective_chat.send_message("‚õî –£ –≤–∞—Å –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ —ç—Ç–æ–º—É –±–æ—Ç—É.")



async def cmd_start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not check_access(update):
        return await unauthorized(update)

    text = (
        f"üëã –ü—Ä–∏–≤–µ—Ç! PMV-–±–æ—Ç {BUILD_NAME}.\n\n"
        "–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:\n"
        "/addfolder <–ø—É—Ç—å> ‚Äì –¥–æ–±–∞–≤–∏—Ç—å –ø–∞–ø–∫—É –∑–∞–≥—Ä—É–∑–∫–∏\n"
        "/folders ‚Äì –ø–æ–∫–∞–∑–∞—Ç—å –ø–∞–ø–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏\n"
        "/scan ‚Äì –ø—Ä–æ—Å–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –ø–∞–ø–∫–∏ –∏ –æ–±–Ω–æ–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤\n"
        "/scanignore ‚Äì –¥–æ–±–∞–≤–∏—Ç—å –ø–æ–¥–ø–∞–ø–∫—É –≤ —Å–ø–∏—Å–æ–∫ –∏—Å–∫–ª—é—á–µ–Ω–∏–π —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è\n\n"
        "/pmvnew ‚Äì —Å–æ–∑–¥–∞—Ç—å –Ω–æ–≤–æ–µ PMV –∏–∑ –µ—â—ë –ù–ï –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤\n"
        "/pmvold ‚Äì —Å–æ–∑–¥–∞—Ç—å PMV –∏–∑ –õ–Æ–ë–´–• –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ (–≤–∫–ª—é—á–∞—è —É–∂–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ)\n"
        "/autocreate ‚Äì –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ PMV –ø–æ –∑–∞–¥–∞–Ω–Ω—ã–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º\n"
        "/newcompmusic ‚Äì —Å–æ–±—Ä–∞—Ç—å PMV –ø–æ–¥ –º—É–∑—ã–∫—É –∏–∑ music_projects\n"
        "/musicprep ‚Äì –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç—Ä–µ–∫ –∏–∑ –ø–∞–ø–∫–∏ Music –∏ —Å–æ–∑–¥–∞—Ç—å –ø—Ä–æ–µ–∫—Ç\n"
        "/videofx ‚Äì –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–ª–∏—Ç—á–µ–π –∏ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ –º–µ–∂–¥—É –∫–ª–∏–ø–∞–º–∏\n"
        "/musicprepcheck ‚Äì —Å–æ–∑–¥–∞—Ç—å MP3 —Å–æ —â–µ–ª—á–∫–∞–º–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–µ–≥–º–µ–Ω—Ç–æ–≤\n"
        "/ratepmv ‚Äì –æ—Ü–µ–Ω–∏—Ç—å –≥–æ—Ç–æ–≤—ã–µ PMV –∏ –ø—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –≤–∏–¥–µ–æ –≤–Ω—É—Ç—Ä–∏\n"
        "/rategrp ‚Äì –æ—Ç–º–µ—Ç–∏—Ç—å –∏—Å—Ö–æ–¥–Ω–∏–∫–∏ —Ü–≤–µ—Ç–∞–º–∏ –≤–Ω—É—Ç—Ä–∏ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –≥—Ä—É–ø–ø—ã\n"
        "/compmv ‚Äî –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –∫ PMV\n"
        "/comvid ‚Äî –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –∫ –∏—Å—Ö–æ–¥–Ω–∏–∫—É\n"
        "/lookcom ‚Äî –ø—Ä–æ—Å–º–æ—Ç—Ä –≤—Å–µ—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏.\n"
        "/badfiles ‚Äî —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤\n"
        "/strategy [–∏–º—è] ‚Äî –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å/—É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –≤—ã–±–æ—Ä–∞ –≥—Ä—É–ø–ø (max_group, weighted_random, random)\n"
        "/move2oculus ‚Äî —Å–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —Ñ–∞–π–ª—ã –∏–∑ y:\\output –Ω–∞ Oculus —á–µ—Ä–µ–∑ ADB\n\n"
        "–ï—Å–ª–∏ adb –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø–æ—Å—Ç–∞–≤—å Platform Tools –≤ C:\\platform-tools –∏ –≤—ã–ø–æ–ª–Ω–∏ –≤ PowerShell:\n"
        "$env:Path += ';C:\\platform-tools'\n"
        "setx Path $env:Path\n"
    )
    await update.message.reply_text(text, reply_markup=build_main_reply_keyboard())

async def cmd_lookcom(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –ü–æ–∫–∞–∑–∞—Ç—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∫ –∫–æ–º–ø–∏–ª—è—Ü–∏—è–º –∏ –∏—Å—Ö–æ–¥–Ω–∏–∫–∞–º.
    """
    if not check_access(update):
        return await unauthorized(update)

    comp_rows = db_get_compilations_with_comments()
    src_rows = db_get_sources_with_comments()

    if not comp_rows and not src_rows:
        return await update.message.reply_text("–ü–æ–∫–∞ –Ω–µ—Ç –Ω–∏ –æ–¥–Ω–æ–≥–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è.")

    parts: List[str] = []

    if comp_rows:
        parts.append("üìÄ –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∫ –∫–æ–º–ø–∏–ª—è—Ü–∏—è–º:")
        for r in comp_rows:
            name = Path(r["video_path"]).name
            parts.append(f"- {name} (–¥–∞—Ç–∞: {r['pmv_date']}): {r['comments']}")

    if src_rows:
        if parts:
            parts.append("")  # –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞-—Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å
        parts.append("üéû –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∫ –∏—Å—Ö–æ–¥–Ω–∏–∫–∞–º:")
        for r in src_rows:
            parts.append(f"- {r['video_name']} (id={r['id']}): {r['comments']}")

    text = "\n".join(parts)
    if len(text) <= 4000:
        await update.message.reply_text(text)
        return

    chunk_size = 3800
    for i in range(0, len(text), chunk_size):
        await update.message.reply_text(text[i:i + chunk_size])



async def cmd_compmv(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –î–æ–±–∞–≤–∏—Ç—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –∫ –∫–æ–º–ø–∏–ª—è—Ü–∏–∏ (PMV).
    /compmv -> —Å–ø–∏—Å–æ–∫ PMV -> –Ω–æ–º–µ—Ä -> —Ç–µ–∫—Å—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è.
    """
    if not check_access(update):
        return await unauthorized(update)

    rows = db_get_all_compilations()
    if not rows:
        return await update.message.reply_text("–ü–æ–∫–∞ –Ω–µ—Ç –Ω–∏ –æ–¥–Ω–æ–π –∫–æ–º–ø–∏–ª—è—Ü–∏–∏.")

    lines = ["üé¨ –ö–æ–º–ø–∏–ª—è—Ü–∏–∏:"]
    for idx, r in enumerate(rows, 1):
        name = Path(r["video_path"]).name
        date_str = r["pmv_date"]
        lines.append(f"{idx}. {name} (–¥–∞—Ç–∞: {date_str}, id={r['id']})")

    lines.append("")
    lines.append("–ü—Ä–∏—à–ª–∏—Ç–µ –Ω–æ–º–µ—Ä PMV, –∫ –∫–æ—Ç–æ—Ä–æ–º—É —Ö–æ—Ç–∏—Ç–µ –¥–æ–±–∞–≤–∏—Ç—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π (–Ω–∞–ø—Ä–∏–º–µ—Ä: 2).")

    user_sessions[update.effective_user.id] = {
        "state": "compmv_choose",
        "pmv_rows": rows,
    }

    await update.message.reply_text("\n".join(lines))


async def cmd_addfolder(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not check_access(update):
        return await unauthorized(update)

    args = context.args
    if not args:
        return await update.message.reply_text("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /addfolder C:\\path\\to\\folder")

    folder = " ".join(args).strip().strip('"')
    p = Path(folder)
    if not p.exists() or not p.is_dir():
        return await update.message.reply_text(f"–ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {p}")

    db_add_upload_folder(str(p))
    await update.message.reply_text(f"‚úÖ –ü–∞–ø–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∞: {p}")


async def cmd_folders(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not check_access(update):
        return await unauthorized(update)

    rows = db_get_upload_folders(include_ignored=True)
    if not rows:
        return await update.message.reply_text("–ü–∞–ø–æ–∫ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–æ–∫–∞ –Ω–µ—Ç. –î–æ–±–∞–≤—å—Ç–µ —á–µ—Ä–µ–∑ /addfolder")

    active = [r for r in rows if not r["ignored"]]
    ignored = [r for r in rows if r["ignored"]]
    lines = ["üìÇ –ü–∞–ø–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏:"]
    if not active:
        lines.append("–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–∞–ø–æ–∫ –¥–ª—è —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è.")
    else:
        for r in active:
            lines.append(f"{r['id']}. {r['folder_path']} (—Å {r['date_added']})")
    if ignored:
        lines.append("")
        lines.append("üö´ –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º—ã–µ –ø–æ–¥–ø–∞–ø–∫–∏ (/scanignore):")
        for r in ignored:
            lines.append(f"{r['id']}. {r['folder_path']} (—Å {r['date_added']})")
    await update.message.reply_text("\n".join(lines))


async def cmd_scan(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not check_access(update):
        return await unauthorized(update)

    rows = db_get_upload_folders()
    if not rows:
        return await update.message.reply_text("–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–∞–ø–æ–∫. –î–æ–±–∞–≤—å—Ç–µ –µ—ë —á–µ—Ä–µ–∑ /addfolder")
    ignored_rows = db_get_scan_ignored_folders()

    await update.message.reply_text("–ù–∞—á–∏–Ω–∞—é –ø–µ—Ä–µ—Å–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –∫–∞—Ç–∞–ª–æ–≥–∏... —ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è.")

    env = ScanEnvironment(
        default_exts=DEFAULT_EXTS,
        normalize_path_str=_normalize_path_str,
        normalize_path_prefix=_normalize_path_prefix,
        is_path_under_prefixes=_is_path_under_prefixes,
        combine_comments=combine_comments,
        merge_pmv_lists=merge_pmv_lists,
        video_info_sort=video_info_sort,
        db_get_sources_full=db_get_sources_full,
        db_update_source_fields=db_update_source_fields,
        db_insert_source=db_insert_source,
        db_delete_sources_by_ids=db_delete_sources_by_ids,
        db_path=DB_PATH,
        backup_dir=SCRIPT_DIR / "old",
    )

    lines, _stats = run_scan(rows, ignored_rows, env)
    symlink_notes = sync_nas_symlinks()
    if symlink_notes:
        lines.append("")
        lines.extend(symlink_notes)
    await update.message.reply_text("\n".join(lines))

async def cmd_scanignore(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not check_access(update):
        return await unauthorized(update)

    user_id = update.effective_user.id
    user_sessions[user_id] = {
        "state": "scanignore_wait_path",
    }
    lines = [
        "–ü—Ä–∏—à–ª–∏—Ç–µ –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –ø–∞–ø–∫–∏, –∫–æ—Ç–æ—Ä—É—é –Ω—É–∂–Ω–æ –∏—Å–∫–ª—é—á–∏—Ç—å –∏–∑ /scan.",
        "–ú–æ–∂–Ω–æ —É–∫–∞–∑—ã–≤–∞—Ç—å –ø–æ–¥–ø–∞–ø–∫–∏ —É–∂–µ –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã—Ö –∫–∞—Ç–∞–ª–æ–≥–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä X:\\tor\\tmp).",
        "–ß—Ç–æ–±—ã –æ—Ç–º–µ–Ω–∏—Ç—å, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ /start –∏–ª–∏ –¥—Ä—É–≥—É—é –∫–æ–º–∞–Ω–¥—É.",
    ]
    await update.message.reply_text("\n".join(lines))

async def cmd_comvid(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –î–æ–±–∞–≤–∏—Ç—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –∫ –∏—Å—Ö–æ–¥–Ω–∏–∫—É.
    /comvid -> —Å–ø–∏—Å–æ–∫ –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ -> –Ω–æ–º–µ—Ä -> —Ç–µ–∫—Å—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è.
    """
    if not check_access(update):
        return await unauthorized(update)

    rows = db_get_all_sources()
    if not rows:
        return await update.message.reply_text("–í –±–∞–∑–µ –Ω–µ—Ç –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤.")

    lines = ["üé• –ò—Å—Ö–æ–¥–Ω–∏–∫–∏:"]
    # —á—Ç–æ–±—ã —Å–ø–∏—Å–æ–∫ –Ω–µ –±—ã–ª —Å–æ–≤—Å–µ–º –±–µ–∑—É–º–Ω—ã–º, –º–æ–∂–Ω–æ –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å, –Ω–æ –ø–æ –¢–ó –≤—ã–≤–æ–¥–∏–º –≤—Å–µ
    for idx, r in enumerate(rows, 1):
        name = r["video_name"]
        lines.append(f"{idx}. {name} (id={r['id']})")

    lines.append("")
    lines.append("–ü—Ä–∏—à–ª–∏—Ç–µ –Ω–æ–º–µ—Ä –≤–∏–¥–µ–æ, –∫ –∫–æ—Ç–æ—Ä–æ–º—É —Ö–æ—Ç–∏—Ç–µ –¥–æ–±–∞–≤–∏—Ç—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π (–Ω–∞–ø—Ä–∏–º–µ—Ä: 5).")

    user_sessions[update.effective_user.id] = {
        "state": "comvid_choose",
        "src_rows": rows,
    }

    await update.message.reply_text("\n".join(lines))

async def cmd_autocreate(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö PMV –ø–æ–¥—Ä—è–¥.

    –®–∞–≥–∏:
    1) –°–ø—Ä–æ—Å–∏—Ç—å, —Å–∫–æ–ª—å–∫–æ –≤–∏–¥–µ–æ —Å–æ–∑–¥–∞—Ç—å.
    2) –°–ø—Ä–æ—Å–∏—Ç—å –¥–ª–∏–Ω—É –∫–∞–∂–¥–æ–≥–æ (–≤ –º–∏–Ω—É—Ç–∞—Ö).
    3) –°–ø—Ä–æ—Å–∏—Ç—å –º–∞–∫—Å–∏–º—É–º –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ –Ω–∞ –æ–¥–Ω–æ PMV.
    4) –°–ø—Ä–æ—Å–∏—Ç—å –º–∏–Ω–∏–º—É–º –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ –Ω–∞ –æ–¥–Ω–æ PMV.
    5) –ó–∞—Ç–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏:
       - —Å–Ω–∞—á–∞–ª–∞ –¥–µ–ª–∞–µ—Ç –Ω—É–∂–Ω–æ–µ —á–∏—Å–ª–æ PMV –∏–∑ –ù–û–í–´–• –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ (–∫–∞–∫ pmvnew),
       - –∑–∞—Ç–µ–º –∏–∑ –°–¢–ê–†–´–• (—É–∂–µ —É—á–∞—Å—Ç–≤–æ–≤–∞–≤—à–∏—Ö –≤ –∫–æ–º–ø–∏–ª—è—Ü–∏—è—Ö),
       —Å–æ–±–ª—é–¥–∞—è –ø—Ä–æ–ø–æ—Ä—Ü–∏—é: –ø–æ–ª–æ–≤–∏–Ω–∞ –∏–∑ –Ω–æ–≤—ã—Ö, –ø–æ–ª–æ–≤–∏–Ω–∞ –∏–∑ —Å—Ç–∞—Ä—ã—Ö
       (–ø—Ä–∏ –Ω–µ—á—ë—Ç–Ω–æ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ ‚Äî +1 –∫ –Ω–æ–≤—ã–º).
    """
    if not check_access(update):
        return await unauthorized(update)

    user_id = update.effective_user.id

    user_sessions[user_id] = {
        "state": "autocreate_ask_count",
    }

    await update.message.reply_text(
        "üöÄ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ PMV.\n\n"
        "–°–∫–æ–ª—å–∫–æ –≤–∏–¥–µ–æ —Å–æ–∑–¥–∞—Ç—å? –í–≤–µ–¥–∏—Ç–µ —Ü–µ–ª–æ–µ —á–∏—Å–ª–æ (–Ω–∞–ø—Ä–∏–º–µ—Ä: 4)."
    )

def db_get_used_sources_grouped() -> Dict[Tuple[str, str], List[sqlite3.Row]]:
    """
    –ë–µ—Ä—ë—Ç –¢–û–õ–¨–ö–û —É–∂–µ —É—á–∞—Å—Ç–≤–æ–≤–∞–≤—à–∏–µ –≤ –∫–æ–º–ø–∏–ª—è—Ü–∏—è—Ö –∏—Å—Ö–æ–¥–Ω–∏–∫–∏ (pmv_list –Ω–µ –ø—É—Å—Ç–æ–π)
    –∏ –≥—Ä—É–ø–ø–∏—Ä—É–µ—Ç –ø–æ (codec, resolution).
    –≠—Ç–æ –ø—É–ª ¬´—Å—Ç–∞—Ä—ã—Ö¬ª –≤–∏–¥–µ–æ –¥–ª—è autocreate.
    """
    conn = get_conn()
    cur = conn.cursor()
    cur.execute(
        """
        SELECT * FROM sources
        WHERE pmv_list IS NOT NULL AND pmv_list != ''
        """
    )
    rows = cur.fetchall()
    conn.close()

    groups: Dict[Tuple[str, str], List[sqlite3.Row]] = {}
    for r in rows:
        codec = r["codec"] or "?"
        resolution = r["resolution"] or "??x??"
        key = (codec, resolution)
        groups.setdefault(key, []).append(r)
    return groups


def fallback_new_only_make_one(
    target_seconds: int,
    max_sources: int,
    min_sources: int,
    excluded_ids: set[int],
    big_parts: int = 5,
    small_per_big: int = 5,
    strategy: str = "max_group",
    clip_algo_key: Optional[str] = None,
) -> Optional[Tuple[Path, List[int], Tuple[str, str]]]:
    """–†–µ–∑–µ—Ä–≤: —Å–æ–∑–¥–∞—Ç—å PMV —Ç–æ–ª—å–∫–æ –∏–∑ –ù–û–í–´–• –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ (–±–µ–∑ –ø–∞—Ä),
    —Å –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏–µ–π –ø–æ –ø–∞–ø–∫–∞–º –∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π –≤—ã–±–æ—Ä–∞ –≥—Ä—É–ø–ø—ã."""
    groups = db_get_unused_sources_grouped()
    if not groups:
        return None

    # —Ñ–∏–ª—å—Ç—Ä excluded
    filtered: List[Tuple[Tuple[str, str], List[sqlite3.Row]]] = []
    for key, rows in groups.items():
        rem = [r for r in rows if int(r["id"]) not in excluded_ids]
        if rem:
            filtered.append((key, rem))
    if not filtered:
        return None

    # –≤—ã–±–æ—Ä –≥—Ä—É–ø–ø—ã –ø–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
    if strategy == "weighted_random":
        total = sum(len(rows) for _, rows in filtered)
        rnd = random.randint(1, max(1, total))
        acc = 0
        key, rows = filtered[0]
        for k, rws in filtered:
            acc += len(rws)
            if rnd <= acc:
                key, rows = k, rws
                break
    elif strategy == "random":
        key, rows = random.choice(filtered)
    else:
        key, rows = max(filtered, key=lambda kv: len(kv[1]))

    use_count = min(len(rows), max_sources)
    if use_count < 1 or len(rows) < max(1, min_sources):
        # best-effort: –µ—Å–ª–∏ –Ω–µ –¥–æ—Ç—è–≥–∏–≤–∞–µ–º –¥–æ –º–∏–Ω–∏–º—É–º–∞ ‚Äî –±–µ—Ä—ë–º —Å–∫–æ–ª—å–∫–æ –µ—Å—Ç—å
        use_count = min(len(rows), max_sources)
        if use_count < 1:
            return None

    # –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ –ø–∞–ø–∫–∞–º
    dir_map: Dict[Path, List[sqlite3.Row]] = {}
    for r in rows:
        d = Path(r["video_path"]).resolve().parent
        dir_map.setdefault(d, []).append(r)
    for lst in dir_map.values():
        random.shuffle(lst)

    chosen_rows: List[sqlite3.Row] = []
    taken: Dict[Path, int] = {d: 0 for d in dir_map}
    progressed = True
    while len(chosen_rows) < use_count and progressed:
        progressed = False
        for d, lst in list(dir_map.items()):
            if taken[d] >= PER_DIR_MAX_FIRST_PASS:
                continue
            if lst:
                chosen_rows.append(lst.pop())
                taken[d] += 1
                progressed = True
                if len(chosen_rows) >= use_count:
                    break
    if len(chosen_rows) < use_count:
        leftovers: List[sqlite3.Row] = []
        for lst in dir_map.values():
            leftovers.extend(lst)
        random.shuffle(leftovers)
        for r in leftovers:
            chosen_rows.append(r)
            if len(chosen_rows) >= use_count:
                break

    paths = [Path(r["video_path"]) for r in chosen_rows]
    source_ids = [int(r["id"]) for r in chosen_rows]

    out_path = make_pmv_from_files(paths, target_seconds, big_parts, small_per_big, clip_algo_key=clip_algo_key)
    out_path, move_comment = move_output_to_network_storage(out_path)
    pmv_tag = Path(out_path).name
    db_insert_compilation(out_path, source_ids, comments=move_comment)
    db_update_sources_pmv_list(source_ids, pmv_tag)
    excluded_ids.update(source_ids)
    return out_path, source_ids, key



async def cmd_pmvnew(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not check_access(update):
        return await unauthorized(update)

    groups = db_get_unused_sources_grouped()
    if not groups:
        return await update.message.reply_text("–ù–µ—Ç –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ –±–µ–∑ PMV. –°–Ω–∞—á–∞–ª–∞ –≤–æ—Å–ø–æ–ª—å–∑—É–π—Ç–µ—Å—å /scan.")

    group_entries = [
        SourceGroupEntry(key=key, rows=list(rows), unused_count=len(rows))
        for key, rows in groups.items()
    ]
    group_entries = sort_source_group_entries(group_entries)
    group_list: List[Tuple[Tuple[str, str], List[sqlite3.Row]]] = [
        (entry.key, entry.rows) for entry in group_entries
    ]

    lines = format_source_group_lines(
        group_entries, "–ù–∞–π–¥–µ–Ω—ã –≥—Ä—É–ø–ø—ã –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ (codec, resolution):"
    )
    lines.append("")
    lines.append("–û—Ç–≤–µ—Ç—å—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ–º —Å –Ω–æ–º–µ—Ä–æ–º –≥—Ä—É–ø–ø—ã, –∫–æ—Ç–æ—Ä—É—é –±—É–¥–µ–º –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å (–Ω–∞–ø—Ä–∏–º–µ—Ä: 1).")

    user_sessions[update.effective_user.id] = {
        "state": "choose_group",
        "groups": group_list,
    }

    await update.message.reply_text("\n".join(lines))

async def cmd_pmvold(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –ö–∞–∫ pmvnew, –Ω–æ –±–µ—Ä—ë—Ç –í–°–ï –∏—Å—Ö–æ–¥–Ω–∏–∫–∏, –∞ –Ω–µ —Ç–æ–ª—å–∫–æ —Ç–µ, —É –∫–æ—Ç–æ—Ä—ã—Ö pmv_list –ø—É—Å—Ç–æ–π.
    """
    if not check_access(update):
        return await unauthorized(update)

    groups = db_get_all_sources_grouped()
    if not groups:
        return await update.message.reply_text("–í –±–∞–∑–µ –Ω–µ—Ç –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤. –°–Ω–∞—á–∞–ª–∞ –≤–æ—Å–ø–æ–ª—å–∑—É–π—Ç–µ—Å—å /scan.")

    unused_groups = db_get_unused_sources_grouped()
    group_entries = [
        SourceGroupEntry(
            key=key,
            rows=list(rows),
            unused_count=len(unused_groups.get(key, [])),
        )
        for key, rows in groups.items()
    ]
    group_entries = sort_source_group_entries(group_entries)
    group_list: List[Tuple[Tuple[str, str], List[sqlite3.Row]]] = [
        (entry.key, entry.rows) for entry in group_entries
    ]

    lines = format_source_group_lines(
        group_entries,
        "–ù–∞–π–¥–µ–Ω—ã –≥—Ä—É–ø–ø—ã –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ (codec, resolution) ‚Äî –í–ö–õ–Æ–ß–ê–Ø —É–∂–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ:",
    )
    lines.append("")
    lines.append("–û—Ç–≤–µ—Ç—å—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ–º —Å –Ω–æ–º–µ—Ä–æ–º –≥—Ä—É–ø–ø—ã, –∫–æ—Ç–æ—Ä—É—é –±—É–¥–µ–º –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å (–Ω–∞–ø—Ä–∏–º–µ—Ä: 1).")

    user_sessions[update.effective_user.id] = {
        "state": "choose_group",
        "groups": group_list,
    }

    await update.message.reply_text("\n".join(lines))



async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not check_access(update):
        return await unauthorized(update)

    user_id = update.effective_user.id
    text = (update.message.text or "").strip()

    # –õ–æ–∫–∞–ª—å–Ω—ã–π —Ö–µ–ª–ø–µ—Ä, —Ä–µ–∂–µ—Ç –¥–ª–∏–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–∞ —á–∞—Å—Ç–∏
    async def reply_long(msg: str, chunk_size: int = 4000):
        if len(msg) <= chunk_size:
            await update.message.reply_text(msg)
            return
        for i in range(0, len(msg), chunk_size):
            await update.message.reply_text(msg[i:i + chunk_size])

    lowered_text = text.lower()
    if lowered_text in {"musicprep", "/musicprep"}:
        return await cmd_musicprep(update, context)
    if lowered_text in {"newcompmusic", "/newcompmusic"}:
        return await cmd_newcompmusic(update, context)
    if lowered_text in {"scan", "/scan"}:
        return await cmd_scan(update, context)
    if lowered_text in {"rategrp", "/rategrp"}:
        return await cmd_rategrp(update, context)
    if lowered_text in {"reports", "/reports", "–æ—Ç—á—ë—Ç—ã", "–æ—Ç—á–µ—Ç—ã"}:
        return await cmd_reports(update, context)
    if lowered_text in {"flagpmv", "/flagpmv", "find", "/find", "–Ω–∞–π—Ç–∏"}:
        return await cmd_find(update, context)
    if lowered_text in {"createrandompmv", "/createrandompmv"}:
        return await cmd_randompmv(update, context)

    sess = user_sessions.get(user_id)
    if not sess:
        return await reply_long(
            "–Ø –≤–∞—Å –Ω–µ –ø–æ–Ω—è–ª. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /pmvnew –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è PMV –∏–ª–∏ /scan –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤."
        )

    state = sess.get("state")

    if state == "scanignore_wait_path":
        candidate = text.strip().strip('"')
        if not candidate:
            return await reply_long("–ü—Ä–∏—à–ª–∏—Ç–µ –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ, –Ω–∞–ø—Ä–∏–º–µ—Ä X:\\\\tor\\\\tmp.")
        try:
            raw_path = Path(candidate)
            if not raw_path.is_absolute():
                raw_path = (SCRIPT_DIR / raw_path).resolve(strict=False)
            else:
                raw_path = raw_path.resolve(strict=False)
        except Exception as exc:
            return await reply_long(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–æ–±—Ä–∞—Ç—å –ø—É—Ç—å: {exc}")

        db_add_scan_ignore(str(raw_path))
        user_sessions.pop(user_id, None)

        note = ""
        if not raw_path.exists():
            note = "\n‚ö†Ô∏è –ü–∞–ø–∫–∞ –ø–æ–∫–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –Ω–æ –±—É–¥–µ—Ç –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è, –∫–æ–≥–¥–∞ –ø–æ—è–≤–∏—Ç—Å—è."
        return await reply_long(f"–ì–æ—Ç–æ–≤–æ. {raw_path} –±–æ–ª—å—à–µ –Ω–µ —Å–∫–∞–Ω–∏—Ä—É–µ—Ç—Å—è.{note}")

    if state in {
        "musicprep_wait_track",
        "musicprep_wait_seconds",
        "musicprep_wait_mode",
        "musicprep_wait_sensitivity",
        "newcompmusic_wait_project",
        "newcompmusic_wait_group",
        "newcompmusic_choose_duration",
        "newcompmusic_choose_groupmode",
        "newcompmusic_choose_color",
        "newcompmusic_wait_sources",
        "newcompmusic_wait_algo",
        "musicprepcheck_wait_project",
        "musicprep_ask_sensitivity",
    }:
        return await reply_long("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫–∏ –ø–æ–¥ —Å–æ–æ–±—â–µ–Ω–∏–µ–º –∏–ª–∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –∫–æ–º–∞–Ω–¥—É –∑–∞–Ω–æ–≤–æ.")

    if state == "randompmv_choose_orientation":
        choice = text.strip().upper()
        if choice == "–í–°–ï" or choice == "ALL":
            orientation_choice = None
        elif choice in NEWCOMPMUSIC_ORIENTATION_CHOICES:
            orientation_choice = choice
        else:
            return await reply_long("–í—ã–±–µ—Ä–∏—Ç–µ –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—é: VR, HOR, VER –∏–ª–∏ –í–°–ï.")
        sess["randompmv_orientation_preference"] = orientation_choice
        sess["state"] = "randompmv_wait_count"
        user_sessions[user_id] = sess
        label = choice if choice != "ALL" else "–í–°–ï"
        await update.message.reply_text(
            f"–û—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è –≤—ã–±—Ä–∞–Ω–∞: {label}. –¢–µ–ø–µ—Ä—å –≤—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–π.",
            reply_markup=build_randompmv_count_keyboard(),
        )
        return

    if state == "randompmv_wait_count":
        sess = sess or {}
        try:
            total_runs = int(text)
        except ValueError:
            return await reply_long("–ù—É–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å —Ü–µ–ª–æ–µ —á–∏—Å–ª–æ –æ—Ç 1 –¥–æ 30.")
        if total_runs < RANDOMPMV_MIN_BATCH:
            return await reply_long("–ù—É–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ —á–∏—Å–ª–æ.")
        total_runs = min(total_runs, RANDOMPMV_MAX_BATCH)
        sess["randompmv_total_runs"] = total_runs
        sess["state"] = "randompmv_wait_newcount"
        user_sessions[user_id] = sess
        await update.message.reply_text(
            "–°–∫–æ–ª—å–∫–æ –Ω–æ–≤—ã—Ö –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –≤ PMV? (0 = –ª—é–±—ã–µ)",
            reply_markup=build_randompmv_newcount_keyboard(),
        )
        return

    if state == "randompmv_wait_newcount":
        sess = sess or {}
        try:
            min_new = int(text)
        except ValueError:
            return await reply_long("–í–≤–µ–¥–∏—Ç–µ —Ü–µ–ª–æ–µ —á–∏—Å–ª–æ –Ω–æ–≤—ã—Ö –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ (0 –¥–æ–ø—É—Å–∫–∞–µ—Ç—Å—è).")
        if min_new < 0:
            return await reply_long("–ß–∏—Å–ª–æ –Ω–æ–≤—ã—Ö –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º.")
        total_runs = int(sess.get("randompmv_total_runs") or 0)
        if total_runs <= 0:
            user_sessions.pop(user_id, None)
            return await reply_long("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–π —á–µ—Ä–µ–∑ CreateRandomPMV.")
        user_sessions.pop(user_id, None)
        await update.message.reply_text(
            f"–ó–∞–ø—É—Å–∫–∞—é {total_runs} Random PMV (–Ω–æ–≤—ã—Ö ‚â• {min_new})..."
        )
        orientation_pref = sess.get("randompmv_orientation_preference")
        return await run_randompmv_batch(reply_long, user_id, total_runs, min_new, orientation_pref)


    if state in {"find_wait_term", "find_wait_choice"}:
        term = text.strip()
        if not term:
            return await reply_long("–ü—Ä–∏—à–ª–∏—Ç–µ —á–∞—Å—Ç—å –Ω–∞–∑–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞, –ø—Ä–∏–º–µ—Ä: 20251207 –∏–ª–∏ 0734.")
        matches = _search_find_matches(term)
        sess["find_matches"] = matches
        if not matches:
            sess["state"] = "find_wait_term"
            return await reply_long("–ù–µ –Ω–∞—à–ª–∞ PMV –ø–æ —ç—Ç–æ–º—É —Ñ—Ä–∞–≥–º–µ–Ω—Ç—É. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥—É—é —á–∞—Å—Ç—å –∏–º–µ–Ω–∏.")
        sess["state"] = "find_wait_choice"
        pmv_count = sum(1 for m in matches if m.get("type") == "pmv")
        src_count = sum(1 for m in matches if m.get("type") == "source")
        lines = ["–ù–∞—à–ª–∏—Å—å —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è. –í—ã–±–µ—Ä–∏—Ç–µ –Ω—É–∂–Ω—ã–π —Ñ–∞–π–ª –∫–Ω–æ–ø–∫–æ–π –Ω–∏–∂–µ."]
        lines.append(f"PMV: {pmv_count} ¬∑ –ò—Å—Ö–æ–¥–Ω–∏–∫–∏: {src_count}")
        for idx, match in enumerate(matches, 1):
            if match.get("type") == "pmv":
                lines.append(f"{idx}. PMV ¬∑ {match.get('stem')}")
            else:
                color = extract_color_emoji(match.get("comments"))
                prefix = f"{color} " if color else ""
                lines.append(f"{idx}. {prefix}{match.get('video_name')}")
        await update.message.reply_text(
            "\n".join(lines),
            reply_markup=build_find_keyboard(matches),
        )
        return

    # =========================
    # NEWCOMPMUSIC: –≤—ã–±–æ—Ä –º—É–∑—ã–∫–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞
    # =========================
    if state == "newcompmusic_choose_project":
        if not text.isdigit():
            return await reply_long("–ù—É–∂–Ω–æ –ø—Ä–∏—Å–ª–∞—Ç—å –Ω–æ–º–µ—Ä –ø—Ä–æ–µ–∫—Ç–∞ (—Ü–µ–ª–æ–µ —á–∏—Å–ª–æ).")
        idx = int(text)
        projects: List[Dict[str, Any]] = sess.get("music_projects") or []
        if not (1 <= idx <= len(projects)):
            return await reply_long("–ù–µ—Ç –ø—Ä–æ–µ–∫—Ç–∞ —Å —Ç–∞–∫–∏–º –Ω–æ–º–µ—Ä–æ–º. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")
        chosen = projects[idx - 1]
        manifest_data = chosen.get("manifest_data")
        if not manifest_data and chosen.get("manifest_path") and chosen["manifest_path"].exists():
            try:
                manifest_data = json.loads(chosen["manifest_path"].read_text(encoding="utf-8"))
                chosen["manifest_data"] = manifest_data
            except Exception as exc:
                return await reply_long(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å manifest.json: {exc}")
        parsed_segments = parse_manifest_segments(manifest_data or {})
        total_duration = chosen.get("duration")
        if total_duration is None and parsed_segments:
            total_duration = parsed_segments[-1].end
        seg_count = len(parsed_segments)
        minutes = (total_duration or 0.0) / 60.0 if total_duration else None

        groups = get_source_groups_prefer_unused()
        if not groups:
            return await reply_long("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –≥—Ä—É–ø–ø—ã –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤. –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ—Å–∫–∞–Ω–∏—Ä—É–π—Ç–µ /scan.")

        sess["state"] = "newcompmusic_choose_orientation"
        sess["music_selected"] = {
            "slug": chosen["slug"],
            "name": chosen["name"],
            "duration": total_duration,
            "segments": seg_count,
            "manifest": manifest_data,
            "audio_path": str(chosen.get("audio_path")) if chosen.get("audio_path") else None,
            "parsed_segments": parsed_segments,
        }
        lines = [
            f"–í—ã–±—Ä–∞–Ω –ø—Ä–æ–µ–∫—Ç: {chosen['name']} (slug: {chosen['slug']}).",
            f"–°–º–µ–Ω –∫–ª–∏–ø–æ–≤: {seg_count}",
        ]
        if minutes:
            lines.append(f"–ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å ‚âà {minutes:.1f} –º–∏–Ω—É—Ç.")
        group_entries = [
            SourceGroupEntry(key=key, rows=list(rows), unused_count=unused_count)
            for key, rows, unused_count in groups
        ]
        sorted_entries, orientation_map = sort_group_entries_with_orientation(group_entries)
        sess["music_group_orientations"] = orientation_map
        sess["music_groups_all"] = [
            (entry.key, entry.rows, entry.unused_count) for entry in sorted_entries
        ]
        sess["music_groups"] = []
        sess["music_orientation_preference"] = None
        lines.append("")
        lines.append("–í—ã–±–µ—Ä–∏—Ç–µ –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—é –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤: VR, HOR –∏–ª–∏ VER.")
        lines.append("–ü—Ä–∏—à–ª–∏—Ç–µ –æ–¥–Ω–æ –∏–∑ —ç—Ç–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π –∏–ª–∏ –Ω–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É –Ω–∏–∂–µ.")
        return await reply_long(
            "\n".join(lines),
            reply_markup=build_newcomp_orientation_keyboard(),
        )

    if state == "newcompmusic_choose_orientation":
        choice = text.strip().upper()
        if choice == "BACK":
            return await reply_long("–í—ã–±–æ—Ä —Å–±—Ä–æ—à–µ–Ω. –£–∫–∞–∂–∏—Ç–µ –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—é: VR, HOR –∏–ª–∏ VER.")
        if choice not in NEWCOMPMUSIC_ORIENTATION_CHOICES:
            return await reply_long("–í–≤–µ–¥–∏—Ç–µ VR, HOR –∏–ª–∏ VER.")
        all_groups = sess.get("music_groups_all") or []
        if not all_groups:
            return await reply_long("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –≥—Ä—É–ø–ø—ã. –ó–∞–ø—É—Å—Ç–∏—Ç–µ /newcompmusic –∑–∞–Ω–æ–≤–æ.")
        orientation_map = sess.get("music_group_orientations") or {}
        filtered = filter_groups_by_orientation(all_groups, orientation_map, choice)
        if not filtered:
            return await reply_long("–ù–µ—Ç –≥—Ä—É–ø–ø —Å —Ç–∞–∫–æ–π –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏–µ–π. –í—ã–±–µ—Ä–∏—Ç–µ –¥—Ä—É–≥–æ–π —Ä–µ–∂–∏–º.")
        sess["music_orientation_preference"] = choice
        sess["music_groups"] = filtered
        sess["state"] = "newcompmusic_choose_group"
        group_entries = [
            SourceGroupEntry(key=key, rows=list(rows), unused_count=unused)
            for key, rows, unused in filtered
        ]
        orientation_map = sess.get("music_group_orientations") or {}

        lines = _build_group_selection_lines(
            sess, group_entries, choice, prompt_kind="text"
        )
        return await reply_long("\n".join(lines))

    if state == "newcompmusic_choose_group":
        if not text.isdigit():
            return await reply_long("–ù—É–∂–Ω–æ –ø—Ä–∏—Å–ª–∞—Ç—å –Ω–æ–º–µ—Ä –≥—Ä—É–ø–ø—ã.")
        idx = int(text)
        groups: List[Tuple[Tuple[str, str], List[sqlite3.Row], int]] = sess.get("music_groups") or []
        if not (1 <= idx <= len(groups)):
            return await reply_long("–ù–µ—Ç –≥—Ä—É–ø–ø—ã —Å —Ç–∞–∫–∏–º –Ω–æ–º–µ—Ä–æ–º.")
        key, rows, unused_count = groups[idx - 1]
        if not rows:
            return await reply_long("–í –≤—ã–±—Ä–∞–Ω–Ω–æ–π –≥—Ä—É–ø–ø–µ –Ω–µ—Ç –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤. –í—ã–±–µ—Ä–∏—Ç–µ –¥—Ä—É–≥—É—é.")

        orientation_label = (sess.get("music_group_orientations") or {}).get(key)
        if not orientation_label:
            orientation_label = _resolution_orientation(key[1] or "")[0]
        sess["music_group_choice"] = {
            "key": key,
            "count": len(rows),
            "orientation": orientation_label,
            "total_count": len(rows),
            "unused_count": unused_count,
            "group_number": idx,
        }
        sess["music_group_rows"] = list(rows)
        sess["music_folder_only_new"] = False
        sess.pop("music_color_rows", None)
        sess["state"] = "newcompmusic_choose_groupmode"
        summary = [
            f"–ì—Ä—É–ø–ø–∞ {idx} –≤—ã–±—Ä–∞–Ω–∞: {key[0]} {key[1]} (–∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤: {len(rows)}).",
            "–ö–∞–∫ –±—É–¥–µ–º –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å –∏—Å—Ö–æ–¥–Ω–∏–∫–∏?",
        ]
        await reply_long("\n".join(summary))
        return await update.message.reply_text(
            "–í—ã–±–µ—Ä–∏—Ç–µ –≤–∞—Ä–∏–∞–Ω—Ç:",
            reply_markup=build_newcomp_groupmode_keyboard(),
        )

    if state == "newcompmusic_wait_folder":
        options: List[Dict[str, Any]] = sess.get("music_folder_options") or []
        if not text.isdigit():
            return await reply_long("–í—ã–±–µ—Ä–∏—Ç–µ –ø–æ–¥–ø–∞–ø–∫—É –∫–Ω–æ–ø–∫–∞–º–∏ –ø–æ–¥ —Å–æ–æ–±—â–µ–Ω–∏–µ–º –∏–ª–∏ –ø—Ä–∏—à–ª–∏—Ç–µ –µ—ë –Ω–æ–º–µ—Ä.")
        idx = int(text)
        if not (1 <= idx <= len(options)):
            return await reply_long("–ù–µ—Ç –ø–∞–ø–∫–∏ —Å —Ç–∞–∫–∏–º –Ω–æ–º–µ—Ä–æ–º. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")
        token = options[idx - 1]["token"]
        try:
            count, label = apply_newcomp_folder_choice(sess, token, next_state="newcompmusic_ask_sources")
        except ValueError as exc:
            return await reply_long(str(exc))
        project_info = sess.get("music_selected") or {}
        codec, res = sess.get("music_group_choice", {}).get("key") or ("?", "?")
        lines = [
            f"–ü–∞–ø–∫–∞ –≤—ã–±—Ä–∞–Ω–∞: {label} (–∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤: {count}).",
            f"–ì—Ä—É–ø–ø–∞: {codec} {res}.",
            "–°–∫–æ–ª—å–∫–æ –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ –∑–∞–¥–µ–π—Å—Ç–≤–æ–≤–∞—Ç—å? –ü—Ä–∏—à–ª–∏—Ç–µ —Ü–µ–ª–æ–µ —á–∏—Å–ª–æ (–Ω–∞–ø—Ä–∏–º–µ—Ä: 6).",
        ]
        return await reply_long("\n".join(lines))

    if state == "newcompmusic_ask_sources":
        try:
            sources_count = int(text)
            if sources_count <= 0:
                raise ValueError
        except ValueError:
            return await reply_long("–ù—É–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤.")
        available = int((sess.get("music_group_choice") or {}).get("count") or 0)
        info_line = None
        if available and sources_count > available:
            sources_count = available
            info_line = _source_limit_message(sess, available)

        sess["music_sources"] = sources_count
        sess["state"] = "newcompmusic_ask_algo"

        algo_parts = [
            f"{key} ({meta['title']})"
            for key, meta in CLIP_SEQUENCE_ALGORITHMS.items()
        ]
        base_line = f"–û–∫, –≤–æ–∑—å–º—ë–º {sources_count} –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤."
        if info_line:
            base_line = f"{info_line}\n{base_line}"
        msg = (
            f"√ê¬ì√ë¬Ä√ë¬É√ê¬ø√ê¬ø√ê¬∞ {key[0]} {key[1]} √ê¬≤√ë¬ã√ê¬±√ë¬Ä√ê¬∞√ê¬Ω√ê¬∞. "
            "√ê¬ù√ê¬æ√ê¬≤√ë¬ã√ë¬Ö √ê¬∏√ë¬Å√ë¬Ö√ê¬æ√ê¬¥√ê¬Ω√ê¬∏√ê¬∫√ê¬æ√ê¬≤ √ê¬Ω√ê¬µ√ë¬Ç, √ê¬≤√ë¬ã√ê¬±√ê¬µ√ë¬Ä√ê¬∏√ë¬Ç√ê¬µ √ë¬Ü√ê¬≤√ê¬µ√ë¬Ç √ê¬¥√ê¬ª√ë¬è √ê¬ø√ê¬µ√ë¬Ä√ê¬µ√ê¬æ√ë¬Ü√ê¬µ√ê¬Ω√ê¬∫√ê¬∏:"
        )
        await update.message.reply_text(
            msg, reply_markup=build_rategrp_rerate_keyboard(available)
        )
        return
        sess["rategrp_queue"] = queue
        sess["rategrp_total"] = len(queue)
        sess["rategrp_processed"] = 0
        sess["rategrp_queue_origin"] = "unrated"
        sess["state"] = "rategrp_rate_source"

        async def send_rategrp(msg: str, markup: Optional[InlineKeyboardMarkup] = None) -> None:
            await update.message.reply_text(msg, reply_markup=markup)

        await send_rategrp(f"–ì—Ä—É–ø–ø–∞ {key[0]} {key[1]} –≤—ã–±—Ä–∞–Ω–∞. –ù–µ–æ—Ü–µ–Ω—ë–Ω–Ω—ã—Ö –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤: {len(queue)}.")
        return await rategrp_send_next_prompt(sess, send_rategrp)

    if state == "rategrp_choose_rerate_color":
        color_key = normalize_rategrp_color_input(text)

        async def send_rategrp(msg: str, markup: Optional[InlineKeyboardMarkup] = None) -> None:
            await update.message.reply_text(msg, reply_markup=markup)

        if not color_key:
            rows = sess.get("rategrp_rerate_rows") or []
            available = _rategrp_available_colors(rows)
            if available:
                await send_rategrp(
                    "–í—ã–±–µ—Ä–∏—Ç–µ —Ü–≤–µ—Ç —Å –ø–æ–º–æ—â—å—é –∫–Ω–æ–ø–æ–∫ –Ω–∏–∂–µ.",
                    build_rategrp_rerate_keyboard(available),
                )
            else:
                await reply_long("–ù–µ—Ç –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ –¥–ª—è –ø–µ—Ä–µ–æ—Ü–µ–Ω–∫–∏. –í—ã–±–µ—Ä–∏—Ç–µ –¥—Ä—É–≥—É—é –≥—Ä—É–ø–ø—É.")
            return
        if await _rategrp_start_rerate(sess, color_key, send_rategrp):
            return
        return

    if state == "rategrp_rate_source":
        color_key = normalize_rategrp_color_input(text)
        if not color_key:
            return await reply_long(f"–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫–∏ {RATEGRP_COLOR_PROMPT} –∏–ª–∏ –ø—Ä–∏—à–ª–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ü–≤–µ—Ç–∞.")

        async def send_rategrp(msg: str, markup: Optional[InlineKeyboardMarkup] = None) -> None:
            await update.message.reply_text(msg, reply_markup=markup)

        return await rategrp_apply_rating(sess, color_key, send_rategrp)
    # ====== MUSICPREP: –≤—ã–±–æ—Ä —Ç—Ä–µ–∫–∞ –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ ======
    if state == "musicprep_choose_file":
        if not text.isdigit():
            return await reply_long("–ù—É–∂–Ω–æ –ø—Ä–∏—Å–ª–∞—Ç—å –Ω–æ–º–µ—Ä —Ç—Ä–µ–∫–∞.")
        files = sess.get("music_files") or []
        idx = int(text)
        if not (1 <= idx <= len(files)):
            return await reply_long("–ù–µ—Ç —Ç—Ä–µ–∫–∞ —Å —Ç–∞–∫–∏–º –Ω–æ–º–µ—Ä–æ–º.")
        sess["musicprep_file"] = files[idx - 1]
        sess["state"] = "musicprep_ask_name"
        return await reply_long("–í–≤–µ–¥–∏—Ç–µ –∏–º—è –ø—Ä–æ–µ–∫—Ç–∞ (–∏–ª–∏ –æ—Å—Ç–∞–≤—å—Ç–µ –ø—É—Å—Ç—ã–º).")

    if state == "musicprep_ask_name":
        sess["musicprep_name"] = text.strip() or None
        sess["state"] = "musicprep_ask_segment"
        mod = load_music_generator_module()
        default_seg = getattr(mod, "DEFAULT_TARGET_SEGMENT", 1.0)
        return await reply_long(
            f"–£–∫–∞–∂–∏—Ç–µ –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–≥–º–µ–Ω—Ç–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö "
            f"(–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é {default_seg})."
        )

    if state == "musicprep_ask_segment":
        mod = load_music_generator_module()
        default_seg = getattr(mod, "DEFAULT_TARGET_SEGMENT", 1.0)
        try:
            segment_len = float(text)
            if segment_len < 0:
                raise ValueError
        except ValueError:
            segment_len = default_seg
        sess["musicprep_segment"] = segment_len
        sess["state"] = "musicprep_ask_mode"
        modes = getattr(mod, "SEGMENT_MODES", ("beat",))
        return await reply_long(
            "–í—ã–±–µ—Ä–∏—Ç–µ –∞–ª–≥–æ—Ä–∏—Ç–º —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø–æ –º—É–∑—ã–∫–µ "
            f"(–¥–æ—Å—Ç—É–ø–Ω—ã: {', '.join(modes)})."
        )

    if state == "musicprep_ask_mode":
        mod = load_music_generator_module()
        modes = getattr(mod, "SEGMENT_MODES", ("beat",))
        mode = text.strip().lower() or getattr(mod, "DEFAULT_SEGMENT_MODE", modes[0])
        if mode not in modes:
            return await reply_long("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ä–µ–∂–∏–º. –ü–æ–≤—Ç–æ—Ä–∏—Ç–µ –≤–≤–æ–¥.")
        sess["musicprep_selected_mode"] = mode
        options = get_musicprep_sensitivity_options(mode)
        if options:
            sess["musicprep_sensitivity_options"] = options
            sess["state"] = "musicprep_ask_sensitivity"
            lines = [
                f"–ê–ª–≥–æ—Ä–∏—Ç–º {mode} –≤—ã–±—Ä–∞–Ω.",
                "–í—ã–±–µ—Ä–∏—Ç–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞–Ω–∞–ª–∏–∑–∞:",
            ]
            for idx, opt in enumerate(options, 1):
                lines.append(f"{idx}. {opt['label']} ‚Äî {opt['description']}")
            lines.append("–ü—Ä–∏—à–ª–∏—Ç–µ –Ω–æ–º–µ—Ä –∏–ª–∏ –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ.")
            return await reply_long("\n".join(lines))

        async def send(msg: str) -> None:
            await reply_long(msg)

        return await finalize_musicprep_project(send, sess, user_id, mode)

    if state == "musicprep_ask_sensitivity":
        options: List[Dict[str, Any]] = sess.get("musicprep_sensitivity_options") or []
        mode = sess.get("musicprep_selected_mode") or "beat"
        if not options:
            sess["state"] = "musicprep_ask_mode"
            return await reply_long("–ü–æ–≤—Ç–æ—Ä–∏—Ç–µ –≤—ã–±–æ—Ä –∞–ª–≥–æ—Ä–∏—Ç–º–∞ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏.")

        choice = text.strip().lower()
        selected: Optional[Dict[str, Any]] = None
        if choice.isdigit():
            idx = int(choice) - 1
            if 0 <= idx < len(options):
                selected = options[idx]
        if not selected:
            for opt in options:
                if choice in {opt["key"].lower(), opt["label"].lower()}:
                    selected = opt
                    break
        if not selected:
            return await reply_long("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≤–∞—Ä–∏–∞–Ω—Ç. –ü—Ä–∏—à–ª–∏—Ç–µ –Ω–æ–º–µ—Ä –∏–∑ —Å–ø–∏—Å–∫–∞.")

        analysis_kwargs = selected.get("analysis_kwargs") or {}

        async def send(msg: str) -> None:
            await reply_long(msg)

        return await finalize_musicprep_project(send, sess, user_id, mode, analysis_kwargs)

    # ====== MUSICPREP: –≤—ã–±–æ—Ä —Ç—Ä–µ–∫–∞ –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ ======
    if state == "musicprep_choose_file":
        if not text.isdigit():
            return await reply_long("–ù—É–∂–Ω–æ –ø—Ä–∏—Å–ª–∞—Ç—å –Ω–æ–º–µ—Ä —Ç—Ä–µ–∫–∞.")
        files = sess.get("music_files") or []
        idx = int(text)
        if not (1 <= idx <= len(files)):
            return await reply_long("–ù–µ—Ç —Ç—Ä–µ–∫–∞ —Å —Ç–∞–∫–∏–º –Ω–æ–º–µ—Ä–æ–º.")
        sess["musicprep_file"] = files[idx - 1]
        sess["state"] = "musicprep_ask_name"
        return await reply_long("–í–≤–µ–¥–∏—Ç–µ –∏–º—è –ø—Ä–æ–µ–∫—Ç–∞ (–∏–ª–∏ –æ—Å—Ç–∞–≤—å—Ç–µ –ø—É—Å—Ç—ã–º).")

    if state == "musicprep_ask_name":
        sess["musicprep_name"] = text.strip() or None
        sess["state"] = "musicprep_ask_segment"
        mod = load_music_generator_module()
        default_seg = getattr(mod, "DEFAULT_TARGET_SEGMENT", 1.0)
        return await reply_long(
            f"–£–∫–∞–∂–∏—Ç–µ –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–≥–º–µ–Ω—Ç–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö "
            f"(–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é {default_seg})."
        )

    if state == "musicprep_ask_segment":
        mod = load_music_generator_module()
        default_seg = getattr(mod, "DEFAULT_TARGET_SEGMENT", 1.0)
        try:
            segment_len = float(text)
            if segment_len < 0:
                raise ValueError
        except ValueError:
            segment_len = default_seg
        sess["musicprep_segment"] = segment_len
        sess["state"] = "musicprep_ask_mode"
        modes = getattr(mod, "SEGMENT_MODES", ("beat",))
        return await reply_long(
            "–í—ã–±–µ—Ä–∏—Ç–µ –∞–ª–≥–æ—Ä–∏—Ç–º —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø–æ –º—É–∑—ã–∫–µ "
            f"(–¥–æ—Å—Ç—É–ø–Ω—ã: {', '.join(modes)})."
        )

    if state == "musicprep_ask_mode":
        mod = load_music_generator_module()
        modes = getattr(mod, "SEGMENT_MODES", ("beat",))
        mode = text.strip().lower() or getattr(mod, "DEFAULT_SEGMENT_MODE", modes[0])
        if mode not in modes:
            return await reply_long("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ä–µ–∂–∏–º. –ü–æ–≤—Ç–æ—Ä–∏—Ç–µ –≤–≤–æ–¥.")
        sess["musicprep_selected_mode"] = mode
        options = get_musicprep_sensitivity_options(mode)
        if options:
            sess["musicprep_sensitivity_options"] = options
            sess["state"] = "musicprep_ask_sensitivity"
            lines = [
                f"–ê–ª–≥–æ—Ä–∏—Ç–º {mode} –≤—ã–±—Ä–∞–Ω.",
                "–í—ã–±–µ—Ä–∏—Ç–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞–Ω–∞–ª–∏–∑–∞:",
            ]
            for idx, opt in enumerate(options, 1):
                lines.append(f"{idx}. {opt['label']} ‚Äî {opt['description']}")
            lines.append("–ü—Ä–∏—à–ª–∏—Ç–µ –Ω–æ–º–µ—Ä –∏–ª–∏ –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ.")
            return await reply_long("\n".join(lines))

        async def send(msg: str) -> None:
            await reply_long(msg)

        return await finalize_musicprep_project(send, sess, user_id, mode)

    # =========================
    # AUTOCREATE: –¥–∏–∞–ª–æ–≥
    # =========================

    # –®–∞–≥ 1: —Å–∫–æ–ª—å–∫–æ –≤–∏–¥–µ–æ —Å–æ–∑–¥–∞—Ç—å
    if state == "autocreate_ask_count":
        try:
            count = int(text)
            if count <= 0:
                raise ValueError
        except ValueError:
            return await reply_long("–ù—É–∂–Ω–æ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ —Ü–µ–ª–æ–µ —á–∏—Å–ª–æ ‚Äî —Å–∫–æ–ª—å–∫–æ –≤–∏–¥–µ–æ —Å–æ–∑–¥–∞—Ç—å (–Ω–∞–ø—Ä–∏–º–µ—Ä: 4).")

        sess["autocreate_total_videos"] = count
        sess["state"] = "autocreate_ask_length"

        return await reply_long(
            f"–û–∫, —Å–æ–∑–¥–∞—ë–º –¥–æ {count} –≤–∏–¥–µ–æ.\n"
            "–¢–µ–ø–µ—Ä—å –≤–≤–µ–¥–∏—Ç–µ –¥–ª–∏–Ω—É –ö–ê–ñ–î–û–ì–û –≤–∏–¥–µ–æ –≤ –º–∏–Ω—É—Ç–∞—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä: 15)."
        )

    # –®–∞–≥ 2: –¥–ª–∏–Ω–∞ –∫–∞–∂–¥–æ–≥–æ –≤–∏–¥–µ–æ
    if state == "autocreate_ask_length":
        try:
            minutes = int(text)
            if minutes <= 0:
                raise ValueError
        except ValueError:
            minutes = DEFAULT_TARGET_MINUTES

        sess["autocreate_minutes"] = minutes
        sess["state"] = "autocreate_ask_max_sources"

        return await reply_long(
            f"–ñ–µ–ª–∞–µ–º–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å PMV –æ–∫–æ–ª–æ {minutes} –º–∏–Ω—É—Ç.\n"
            "–¢–µ–ø–µ—Ä—å –≤–≤–µ–¥–∏—Ç–µ –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ –Ω–∞ –æ–¥–Ω–æ –≤–∏–¥–µ–æ (–Ω–∞–ø—Ä–∏–º–µ—Ä: 10)."
        )

    if state == "autocreate_ask_max_sources":
        try:
            max_sources = int(text)
            if max_sources <= 0:
                raise ValueError
        except ValueError:
            max_sources = 10

        min_sources = max_sources
        total_videos = sess.get("autocreate_total_videos", 1)
        minutes = sess.get("autocreate_minutes", DEFAULT_TARGET_MINUTES)

        user_sessions.pop(user_id, None)

        await reply_long(
            f"–ó–∞–ø—É—Å–∫–∞—é –ø–∞–∫–µ—Ç–Ω—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∏–∑ {total_videos} PMV.\n"
            f"–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫–∞–∂–¥–æ–≥–æ: ~{minutes} –º–∏–Ω—É—Ç.\n"
            f"–ò—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ –Ω–∞ –æ–¥–Ω–æ –≤–∏–¥–µ–æ: –º–∏–Ω–∏–º—É–º {min_sources}, –º–∞–∫—Å–∏–º—É–º {max_sources}.\n"
            "–ü–æ–ø—Ä–æ–±—É—é —Å–æ–±—Ä–∞—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ (–∫–∞–∫ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º) —Ä–æ–ª–∏–∫–∏, "
            "–Ω–∞—Å–∫–æ–ª—å–∫–æ —ç—Ç–æ –ø–æ–ª—É—á–∏—Ç—Å—è. –ù—É —á—Ç–æ, –ø–æ–µ—Ö–∞–ª–∏..."
        )

        try:
            report = autocreate_pmv_batch(
                total_videos=total_videos,
                minutes_each=minutes,
                max_sources=max_sources,
                min_sources=min_sources,
            )
        except Exception as e:
            return await reply_long(f"–û–π, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –ø–∞–∫–µ—Ç–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ PMV: {e}")

        return await reply_long(report)

    # =========================
    # –î–ê–õ–¨–®–ï ‚Äî –í–°–Ø –°–¢–ê–†–ê–Ø –õ–û–ì–ò–ö–ê
    # =========================

    # ====== –®–∞–≥ 1: –≤—ã–±–æ—Ä –≥—Ä—É–ø–ø—ã ======
    if state == "choose_group":
        if not text.isdigit():
            return await reply_long("–ù—É–∂–Ω–æ –ø—Ä–æ—Å—Ç–æ —á–∏—Å–ª–æ ‚Äî –Ω–æ–º–µ—Ä –≥—Ä—É–ø–ø—ã.")
        idx = int(text)
        groups: List[Tuple[Tuple[str, str], List[sqlite3.Row]]] = sess["groups"]
        if not (1 <= idx <= len(groups)):
            return await reply_long("–ù–µ–≤–µ—Ä–Ω—ã–π –Ω–æ–º–µ—Ä –≥—Ä—É–ø–ø—ã.")
        key, rows = groups[idx - 1]
        codec, res = key

        sess["state"] = "choose_files"
        sess["current_group"] = key
        sess["current_rows"] = rows

        lines = [f"–í—ã–±—Ä–∞–Ω–∞ –≥—Ä—É–ø–ø–∞: {codec} {res}. –§–∞–π–ª—ã:"]
        for i, r in enumerate(rows, 1):
            lines.append(f"{i}. {Path(r['video_path']).name} (id={r['id']})")
        lines.append("")
        lines.append("–û—Ç–≤–µ—Ç—å—Ç–µ: 'all' —á—Ç–æ–±—ã –≤–∑—è—Ç—å –≤—Å–µ, –ª–∏–±–æ –Ω–æ–º–µ—Ä–∞ —Ñ–∞–π–ª–æ–≤ —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª (–Ω–∞–ø—Ä–∏–º–µ—Ä: 1 3 5).")
        return await reply_long("\n".join(lines))

    # ====== –®–∞–≥ 2: –≤—ã–±–æ—Ä —Ñ–∞–π–ª–æ–≤ ======
    if state == "choose_files":
        rows: List[sqlite3.Row] = sess["current_rows"]

        if text.lower() in {"all", "–≤—Å–µ"}:
            selected_rows = rows
        else:
            parts = text.replace(",", " ").split()
            idxs = []
            for p in parts:
                if not p.isdigit():
                    continue
                v = int(p)
                if 1 <= v <= len(rows):
                    idxs.append(v - 1)
            if not idxs:
                return await reply_long(
                    "–ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –Ω–æ–º–µ—Ä–∞. –ù–∞–ø–∏—à–∏—Ç–µ 'all' –∏–ª–∏ –Ω–æ–º–µ—Ä–∞ —Ñ–∞–π–ª–æ–≤ —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª."
                )
            selected_rows = [rows[i] for i in idxs]

        if not selected_rows:
            return await reply_long("–ü—É—Å—Ç–æ–π –≤—ã–±–æ—Ä. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")

        sess["state"] = "choose_length"
        sess["selected_rows"] = selected_rows

        names = ", ".join(Path(r["video_path"]).name for r in selected_rows)
        msg = (
            f"–í—ã–±—Ä–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(selected_rows)}.\n"
            f"–ò–º–µ–Ω–∞: {names}\n\n"
            "–¢–µ–ø–µ—Ä—å –≤–≤–µ–¥–∏—Ç–µ –∂–µ–ª–∞–µ–º—É—é –¥–ª–∏–Ω—É –∏—Ç–æ–≥–æ–≤–æ–≥–æ PMV –≤ –ú–ò–ù–£–¢–ê–• (–Ω–∞–ø—Ä–∏–º–µ—Ä: 15)."
        )
        return await reply_long(msg)

    # ====== –®–∞–≥ 3: –≤—ã–±–æ—Ä –¥–ª–∏–Ω—ã ======
    if state == "choose_length":
        try:
            minutes = int(text)
            if minutes <= 0:
                raise ValueError
        except ValueError:
            minutes = DEFAULT_TARGET_MINUTES

        sess["target_minutes"] = minutes
        sess["state"] = "choose_big_parts"

        return await reply_long(
            f"–û–∫, —Ü–µ–ª–µ–≤–∞—è –¥–ª–∏–Ω–∞ ~{minutes} –º–∏–Ω—É—Ç.\n"
            "–°–∫–æ–ª—å–∫–æ –ë–û–õ–¨–®–ò–• —á–∞—Å—Ç–µ–π –Ω–∞ –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª (big_parts)? (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 5)"
        )

    # ====== –®–∞–≥ 4: –≤—ã–±–æ—Ä big_parts ======
    if state == "choose_big_parts":
        try:
            big_parts = int(text)
            if big_parts <= 0:
                raise ValueError
        except ValueError:
            big_parts = 5

        sess["big_parts"] = big_parts
        sess["state"] = "choose_small_parts"

        return await reply_long(
            f"big_parts = {big_parts}\n"
            "–°–∫–æ–ª—å–∫–æ –ú–ê–õ–ï–ù–¨–ö–ò–• –∫–ª–∏–ø–æ–≤ –≤ –∫–∞–∂–¥–æ–π –±–æ–ª—å—à–æ–π —á–∞—Å—Ç–∏ (small_per_big)? (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 5)"
        )

    # ====== –®–∞–≥ 5: –≤—ã–±–æ—Ä small_per_big –∏ –∑–∞–ø—É—Å–∫ –Ω–∞—Ä–µ–∑–∫–∏ ======
    if state == "choose_small_parts":
        try:
            small_per_big = int(text)
            if small_per_big <= 0:
                raise ValueError
        except ValueError:
            small_per_big = 5

        minutes = sess["target_minutes"]
        selected_rows: List[sqlite3.Row] = sess["selected_rows"]
        big_parts = sess["big_parts"]

        target_seconds = minutes * 60

        await reply_long(
            f"–û–∫, –¥–µ–ª–∞–µ–º PMV ~{minutes} –º–∏–Ω—É—Ç.\n"
            f"big_parts = {big_parts}, small_per_big = {small_per_big}, —Ñ–∞–π–ª–æ–≤: {len(selected_rows)}.\n"
            "–ù–∞—á–∏–Ω–∞—é –Ω–∞—Ä–µ–∑–∫—É, –ø–æ–¥–æ–∂–¥–∏—Ç–µ..."
        )

        paths = [Path(r["video_path"]) for r in selected_rows]
        source_ids = [int(r["id"]) for r in selected_rows]

        user_sessions.pop(user_id, None)

        manual_algo_key = random.choice(list(CLIP_SEQUENCE_ALGORITHMS.keys()))
        manual_algo_key, manual_algo_meta = resolve_clip_algorithm(manual_algo_key)

        move_comment = ""
        try:
            out_path = make_pmv_from_files(
                paths,
                target_seconds,
                big_parts,
                small_per_big,
                clip_algo_key=manual_algo_key,
            )
            out_path, move_comment = move_output_to_network_storage(out_path)
        except Exception as e:
            return await reply_long(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ PMV: {e}")

        pmv_tag = Path(out_path).name
        db_insert_compilation(out_path, source_ids, comments=move_comment)
        db_update_sources_pmv_list(source_ids, pmv_tag)

        return await reply_long(
            f"‚úÖ –ì–æ—Ç–æ–≤–æ!\n–§–∞–π–ª: {out_path}\n"
            f"–ê–ª–≥–æ—Ä–∏—Ç–º –∫–ª–∏–ø–æ–≤: {manual_algo_meta['title']} ({manual_algo_meta['short']}).\n"
            f"PMV –∑–∞–ø–∏—Å–∞–Ω –≤ –±–∞–∑—É, –∏—Å—Ö–æ–¥–Ω–∏–∫–∏ –ø–æ–º–µ—á–µ–Ω—ã –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ."
        )

def apply_pmv_rating(
    row_obj: Union[sqlite3.Row, Dict[str, Any]],
    rating: int,
) -> Tuple[Dict[str, Any], str]:
    """
    –ü–æ–º–µ—á–∞–µ—Ç PMV –æ—Ü–µ–Ω–∫–æ–π –∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø–µ—Ä–µ–Ω–æ—Å–∏—Ç —Ñ–∞–π–ª –≤ –ø–∞–ø–∫—É rating_<–æ—Ü–µ–Ω–∫–∞>.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—É—é –∑–∞–ø–∏—Å—å –∏ –∏–º—è —Ñ–∞–π–ª–∞ –¥–ª—è –ª–æ–≥–æ–≤/–æ—Ç–≤–µ—Ç–æ–≤.
    """
    row = dict(row_obj)
    pmv_id = int(row["id"])
    old_path = Path(row["video_path"])
    pmv_name = old_path.name

    db_append_compilation_comment(pmv_id, f"pmv_rating={rating}")

    try:
        rating_dir = NETWORK_OUTPUT_ROOT / f"rating_{rating}"
        rating_dir.mkdir(parents=True, exist_ok=True)

        new_path = rating_dir / old_path.name
        if old_path.resolve() != new_path.resolve():
            shutil.move(str(old_path), str(new_path))

            conn = get_conn()
            cur = conn.cursor()
            cur.execute(
                "UPDATE compilations SET video_path = ? WHERE id = ?",
                (str(new_path.resolve()), pmv_id),
            )
            conn.commit()
            conn.close()

            row["video_path"] = str(new_path.resolve())
    except Exception as e:
        db_append_compilation_comment(pmv_id, f"move_error={e}")

    return row, pmv_name


def apply_pmv_rating_pairs(
    pmv_rows: List[sqlite3.Row],
    pairs: Iterable[Tuple[int, int]],
) -> Tuple[List[str], List[str]]:
    """
    –ü—Ä–∏–º–µ–Ω—è–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–∞—Ä (–Ω–æ–º–µ—Ä, –æ—Ü–µ–Ω–∫–∞) –∫ —Å–ø–∏—Å–∫—É PMV.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–≤–∞ —Å–ø–∏—Å–∫–∞ —Å—Ç—Ä–æ–∫: —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –∏ –æ—à–∏–±–∫–∏.
    """
    success_lines: List[str] = []
    error_lines: List[str] = []
    total = len(pmv_rows)

    for idx_val, rating_val in pairs:
        if rating_val < 1 or rating_val > 5:
            error_lines.append(f"PMV ‚Ññ{idx_val}: –æ—Ü–µ–Ω–∫–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å 1-5.")
            continue
        if not (1 <= idx_val <= total):
            error_lines.append(f"PMV ‚Ññ{idx_val}: —Ç–∞–∫–æ–≥–æ –Ω–æ–º–µ—Ä–∞ –Ω–µ—Ç (–≤—Å–µ–≥–æ {total}).")
            continue

        try:
            _, pmv_name = apply_pmv_rating(pmv_rows[idx_val - 1], rating_val)
        except Exception as exc:
            error_lines.append(f"PMV ‚Ññ{idx_val}: –æ—à–∏–±–∫–∞ {exc}.")
            continue

        success_lines.append(f"{pmv_name} ‚Üí {rating_val}/5")

    return success_lines, error_lines


async def process_ratepmv_choice(
    sess: Dict[str, Any],
    idx: int,
    rating: int,
    reply_long: Callable[[str], Awaitable[None]],
) -> Optional[bool]:
    if rating < 1 or rating > 5:
        return await reply_long("–û—Ü–µ–Ω–∫–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –æ—Ç 1 –¥–æ 5.")

    pmv_rows: List[sqlite3.Row] = sess.get("pmv_rows") or []
    if not pmv_rows:
        return await reply_long("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Å–ø–∏—Å–æ–∫ PMV –¥–ª—è –æ—Ü–µ–Ω–∫–∏.")
    if not (1 <= idx <= len(pmv_rows)):
        return await reply_long("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –Ω–æ–º–µ—Ä PMV.")

    row_obj = pmv_rows[idx - 1]
    row, pmv_name = apply_pmv_rating(row_obj, rating)

    sess["state"] = "ratepmv_confirm_sources"
    sess["chosen_pmv"] = row
    sess["pmv_rating"] = rating

    await reply_long(
        f"–í—ã –≤—ã–±—Ä–∞–ª–∏ PMV ‚Ññ{idx}: {pmv_name}\n"
        f"–û—Ü–µ–Ω–∫–∞ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–∞: {rating}/5.\n"
        f"–§–∞–π–ª –ø–µ—Ä–µ–Ω–µ—Å—ë–Ω –≤ rating_{rating}.\n\n"
        "–ù–∞–ø–∏—à–∏—Ç–µ, –±—É–¥–µ—Ç–µ –ª–∏ –æ—Ü–µ–Ω–∏–≤–∞—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏ (–¥–∞/–Ω–µ—Ç)."
    )
    return True

# ====== RATEPMV: –≤—ã–±–æ—Ä PMV –∏ –æ–±—â–µ–π –æ—Ü–µ–Ω–∫–∏ ======
    if state == "ratepmv_choose_pmv":
        tokens = text.replace(",", " ").split()
        digits = [t for t in tokens if t.isdigit()]
        if len(digits) < 2:
            return await reply_long(
                "–£–∫–∞–∂–∏ —Ö–æ—Ç—è –±—ã –æ–¥–Ω—É –ø–∞—Ä—É `<–Ω–æ–º–µ—Ä> <–æ—Ü–µ–Ω–∫–∞ 1-5>` (–Ω–∞–ø—Ä–∏–º–µ—Ä: `2 5` –∏–ª–∏ `1 5 2 4`)."
            )

        numbers = [int(t) for t in digits]
        if len(numbers) == 2:
            idx, rating = numbers
            return await process_ratepmv_choice(sess, idx, rating, reply_long)

        if len(numbers) % 2 != 0:
            return await reply_long(
                "–í –ø–∞–∫–µ—Ç–Ω–æ–º —Ä–µ–∂–∏–º–µ –Ω—É–∂–Ω–æ —á—ë—Ç–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∏—Å–µ–ª ‚Äî –Ω–æ–º–µ—Ä PMV –∏ –æ—Ü–µ–Ω–∫–∞ 1-5."
            )

        pmv_rows: List[sqlite3.Row] = sess.get("pmv_rows") or []
        if not pmv_rows:
            return await reply_long("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Å–ø–∏—Å–æ–∫ PMV –¥–ª—è –æ—Ü–µ–Ω–∫–∏.")

        await reply_long("–ü—Ä–∏–Ω—è–ª –ø–∞–∫–µ—Ç, –≤—ã—Å—Ç–∞–≤–ª—è—é –æ—Ü–µ–Ω–∫–∏...")

        rating_pairs = [
            (numbers[i], numbers[i + 1]) for i in range(0, len(numbers), 2)
        ]
        success_lines, error_lines = apply_pmv_rating_pairs(pmv_rows, rating_pairs)

        if not success_lines:
            msg = "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∏ –æ–¥–Ω—É –ø–∞—Ä—É. –ü—Ä–æ–≤–µ—Ä—å –Ω–æ–º–µ—Ä–∞ –∏ –æ—Ü–µ–Ω–∫–∏."
            if error_lines:
                msg += "\n" + "\n".join(error_lines)
            return await reply_long(msg)

        user_sessions.pop(user_id, None)

        lines = [
            f"‚úÖ –ü–∞–∫–µ—Ç–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞, –æ–±–Ω–æ–≤–ª–µ–Ω–æ PMV: {len(success_lines)}.",
            "–£—Å–ø–µ—à–Ω–æ –æ—Ç–º–µ—á–µ–Ω—ã:",
        ]
        lines.extend(f"- {entry}" for entry in success_lines)
        if error_lines:
            lines.append("")
            lines.append("‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω—ã:")
            lines.extend(f"- {entry}" for entry in error_lines)
        lines.append("")
        lines.append("–û—Ü–µ–Ω–∫–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –≤ –ø–∞–∫–µ—Ç–Ω–æ–º —Ä–µ–∂–∏–º–µ –Ω–µ —Å—Ç–∞–≤—è—Ç—Å—è ‚Äî –æ—Ç–ø—Ä–∞–≤—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π PMV –æ—Ç–¥–µ–ª—å–Ω–æ, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ.")
        return await reply_long("\n".join(lines))

    # ====== RATEPMV: —Å–ø—Ä–æ—Å–∏—Ç—å, –æ—Ü–µ–Ω–∏–≤–∞—Ç—å –ª–∏ –∏—Å—Ö–æ–¥–Ω–∏–∫–∏ ======
    if state == "ratepmv_confirm_sources":
        answer = text.lower()
        if answer not in {"–¥–∞", "–¥", "yes", "y", "–Ω–µ—Ç", "–Ω–µ", "no", "n"}:
            return await reply_long("–û—Ç–≤–µ—Ç—å—Ç–µ '–¥–∞' –∏–ª–∏ '–Ω–µ—Ç'.")

        if answer in {"–Ω–µ—Ç", "–Ω–µ", "no", "n"}:
            user_sessions.pop(user_id, None)
            return await reply_long("‚úÖ –û—Ü–µ–Ω–∫–∞ PMV —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞.")

        chosen_pmv: sqlite3.Row | dict = sess["chosen_pmv"]
        pmv_id = int(chosen_pmv["id"])
        source_ids_str = chosen_pmv["source_ids"] or ""
        src_ids = [int(x) for x in source_ids_str.split(",") if x.strip().isdigit()]

        if not src_ids:
            user_sessions.pop(user_id, None)
            return await reply_long(
                "–í —ç—Ç–æ–π –∫–æ–º–ø–∏–ª—è—Ü–∏–∏ –Ω–µ –Ω–∞—à–ª–æ—Å—å –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ (source_ids –ø—É—Å—Ç—ã–µ)."
            )

        conn = get_conn()
        cur = conn.cursor()
        q_marks = ",".join("?" for _ in src_ids)
        cur.execute(f"SELECT * FROM sources WHERE id IN ({q_marks})", src_ids)
        src_rows = cur.fetchall()
        conn.close()

        if not src_rows:
            user_sessions.pop(user_id, None)
            return await reply_long(
                "–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏—Å—Ö–æ–¥–Ω–∏–∫–∏ –≤ –±–∞–∑–µ. –û—Ü–µ–Ω–∫–∞ PMV —É–∂–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞."
            )

        src_map = {r["id"]: r for r in src_rows}
        ordered_sources = [src_map[sid] for sid in src_ids if sid in src_map]

        # üî• –ù–û–í–û–ï: –≤—ã–∫–∏–¥—ã–≤–∞–µ–º —Ç–µ –∏—Å—Ö–æ–¥–Ω–∏–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —É–∂–µ –æ—Ü–µ–Ω–µ–Ω—ã –¥–ª—è –≠–¢–û–ì–û PMV
        unrated_sources = []
        already_rated = 0
        marker = f"pmv#{pmv_id}_rating="
        for r in ordered_sources:
            comments = (r["comments"] or "")
            if marker in comments:
                already_rated += 1
            else:
                unrated_sources.append(r)

        if not unrated_sources:
            user_sessions.pop(user_id, None)
            return await reply_long(
                "–í—Å–µ –∏—Å—Ö–æ–¥–Ω–∏–∫–∏ –≤ —ç—Ç–æ–π –∫–æ–º–ø–∏–ª—è—Ü–∏–∏ —É–∂–µ –∏–º–µ—é—Ç –æ—Ü–µ–Ω–∫–∏ –¥–ª—è —ç—Ç–æ–≥–æ PMV. ‚úÖ"
            )

        sess["state"] = "ratepmv_sources_scores"
        sess["sources_rows"] = unrated_sources

        lines = []
        if already_rated:
            lines.append(f"–ß–∞—Å—Ç—å –≤–∏–¥–µ–æ —É–∂–µ –æ—Ü–µ–Ω–µ–Ω–∞ –¥–ª—è —ç—Ç–æ–≥–æ PMV: –ø—Ä–æ–ø—É—â–µ–Ω–æ {already_rated} —à—Ç.")
        lines.append("–û—Ü–µ–Ω–∏–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –≤–∏–¥–µ–æ –≤ —ç—Ç–æ–π –∫–æ–º–ø–∏–ª—è—Ü–∏–∏:")
        for i, r in enumerate(unrated_sources, 1):
            lines.append(f"{i}. {r['video_name']} (id={r['id']})")
        lines.append("")
        lines.append(
            "–ü—Ä–∏—à–ª–∏—Ç–µ –æ—Ü–µ–Ω–∫–∏ —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª, –Ω–∞–ø—Ä–∏–º–µ—Ä: `5 3 4 1 5`.\n"
            "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ü–µ–Ω–æ–∫ –º–æ–∂–µ—Ç –±—ã—Ç—å –º–µ–Ω—å—à–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –≤–∏–¥–µ–æ ‚Äî "
            "–ª–∏—à–Ω–∏–µ –≤–∏–¥–µ–æ –æ—Å—Ç–∞–Ω—É—Ç—Å—è –±–µ–∑ –æ—Ü–µ–Ω–∫–∏."
        )
        return await reply_long("\n".join(lines))

    # ====== RATEPMV: –ø—Ä–∏—ë–º –æ—Ü–µ–Ω–æ–∫ –ø–æ –∫–∞–∂–¥–æ–º—É –∏—Å—Ö–æ–¥–Ω–∏–∫—É ======
    if state == "ratepmv_sources_scores":
        parts = text.replace(",", " ").split()
        ratings: List[int] = []
        for p in parts:
            if not p.isdigit():
                continue
            v = int(p)
            if 1 <= v <= 5:
                ratings.append(v)

        if not ratings:
            return await reply_long(
                "–ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ –æ—Ç 1 –¥–æ 5. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑."
            )

        sources_rows: List[sqlite3.Row] = sess["sources_rows"]
        chosen_pmv: sqlite3.Row | dict = sess["chosen_pmv"]
        pmv_id = int(chosen_pmv["id"])

        for src_row, rate in zip(sources_rows, ratings):
            sid = int(src_row["id"])
            db_append_source_comment(sid, f"pmv#{pmv_id}_rating={rate}")

        user_sessions.pop(user_id, None)
        return await reply_long(
            f"‚úÖ –û—Ü–µ–Ω–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã.\n"
            f"–í–∏–¥–µ–æ –æ—Ü–µ–Ω–µ–Ω–æ: {len(ratings)} –∏–∑ {len(sources_rows)} (–≤ —ç—Ç–æ–π —Å–µ—Å—Å–∏–∏)."
        )

    # ====== COMPMV: –≤—ã–±–æ—Ä PMV ======
    if state == "compmv_choose":
        if not text.isdigit():
            return await reply_long("–ù—É–∂–Ω–æ –ø—Ä–æ—Å—Ç–æ —á–∏—Å–ª–æ ‚Äî –Ω–æ–º–µ—Ä PMV.")

        idx = int(text)
        pmv_rows: List[sqlite3.Row] = sess["pmv_rows"]
        if not (1 <= idx <= len(pmv_rows)):
            return await reply_long("–ù–µ–≤–µ—Ä–Ω—ã–π –Ω–æ–º–µ—Ä PMV.")

        row = pmv_rows[idx - 1]
        pmv_id = int(row["id"])
        pmv_name = Path(row["video_path"]).name
        

        sess["state"] = "compmv_enter_comment"
        sess["chosen_pmv_id"] = pmv_id

        return await reply_long(
            f"–í—ã –≤—ã–±—Ä–∞–ª–∏ PMV: {pmv_name} (id={pmv_id}).\n"
            "–¢–µ–ø–µ—Ä—å –ø—Ä–∏—à–ª–∏—Ç–µ —Ç–µ–∫—Å—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è."
        )

    # ====== COMPMV: –≤–≤–æ–¥ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è ======
    if state == "compmv_enter_comment":
        pmv_id = sess.get("chosen_pmv_id")
        comment_text = text.strip()
        if not comment_text:
            return await reply_long("–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –ø—É—Å—Ç–æ–π. –ü—Ä–∏—à–ª–∏—Ç–µ –Ω–µ–ø—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç.")

        db_append_compilation_comment(pmv_id, comment_text)

        user_sessions.pop(user_id, None)
        return await reply_long("‚úÖ –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –∫ –∫–æ–º–ø–∏–ª—è—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω—ë–Ω.")

    # ====== COMVID: –≤—ã–±–æ—Ä –∏—Å—Ö–æ–¥–Ω–∏–∫–∞ ======
    if state == "comvid_choose":
        if not text.isdigit():
            return await reply_long("–ù—É–∂–Ω–æ –ø—Ä–æ—Å—Ç–æ —á–∏—Å–ª–æ ‚Äî –Ω–æ–º–µ—Ä –≤–∏–¥–µ–æ.")

        idx = int(text)
        src_rows: List[sqlite3.Row] = sess["src_rows"]
        if not (1 <= idx <= len(src_rows)):
            return await reply_long("–ù–µ–≤–µ—Ä–Ω—ã–π –Ω–æ–º–µ—Ä –≤–∏–¥–µ–æ.")

        row = src_rows[idx - 1]
        src_id = int(row["id"])
        src_name = row["video_name"]

        sess["state"] = "comvid_enter_comment"
        sess["chosen_src_id"] = src_id

        return await reply_long(
            f"–í—ã –≤—ã–±—Ä–∞–ª–∏ –≤–∏–¥–µ–æ: {src_name} (id={src_id}).\n"
            "–¢–µ–ø–µ—Ä—å –ø—Ä–∏—à–ª–∏—Ç–µ —Ç–µ–∫—Å—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è."
        )

    # ====== COMVID: –≤–≤–æ–¥ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è ======
    if state == "comvid_enter_comment":
        src_id = sess.get("chosen_src_id")
        comment_text = text.strip()
        if not comment_text:
            return await reply_long("–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –ø—É—Å—Ç–æ–π. –ü—Ä–∏—à–ª–∏—Ç–µ –Ω–µ–ø—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç.")

        db_append_source_comment(src_id, comment_text)

        user_sessions.pop(user_id, None)
        return await reply_long("‚úÖ –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –∫ –∏—Å—Ö–æ–¥–Ω–∏–∫—É —Å–æ—Ö—Ä–∞–Ω—ë–Ω.")

    # –ï—Å–ª–∏ —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫
    await reply_long("–ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫ —Å —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º –¥–∏–∞–ª–æ–≥–∞. –ó–∞–ø—É—Å—Ç–∏—Ç–µ /pmvnew –∏–ª–∏ /autocreate –∑–∞–Ω–æ–≤–æ.")
    user_sessions.pop(user_id, None)


async def handle_callback(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    query = update.callback_query
    if not check_access(update):
        await query.answer("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–∞", show_alert=True)
        return await unauthorized(update)

    user_id = query.from_user.id if query.from_user else 0
    data = (query.data or "").strip()
    sess = user_sessions.get(user_id)

    if not sess:
        await query.answer("–°–µ—Å—Å–∏—è —É—Å—Ç–∞—Ä–µ–ª–∞", show_alert=True)
        return

    if data.startswith("report_group:"):
        if sess.get("state") != "reports_wait_choice":
            await query.answer("–°–Ω–∞—á–∞–ª–∞ –æ—Ç–∫—Ä–æ–π—Ç–µ –º–µ–Ω—é –æ—Ç—á—ë—Ç–æ–≤.", show_alert=True)
            return
        color_key = data.split(":", 1)[1]
        report_env = ReportEnvironment(
            db_get_groups=db_get_all_sources_grouped,
            color_choices=RATEGRP_COLOR_CHOICES,
        )
        text = build_color_group_report(report_env, color_key)
        await query.answer("–ì–æ—Ç–æ–≤–æ")
        await query.message.reply_text(text)
        return

    if data.startswith("randompmv_orient:"):
        if not sess or sess.get("state") != "randompmv_choose_orientation":
            return await query.answer("–°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ CreateRandomPMV", show_alert=True)
        choice = data.split(":", 1)[1].upper()
        if choice == "ALL":
            orientation_choice = None
            label = "–í–°–ï"
        elif choice in NEWCOMPMUSIC_ORIENTATION_CHOICES:
            orientation_choice = choice
            label = choice
        else:
            return await query.answer("–ù–µ –ø–æ–Ω—è–ª –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—é", show_alert=True)
        sess["randompmv_orientation_preference"] = orientation_choice
        sess["state"] = "randompmv_wait_count"
        user_sessions[user_id] = sess
        await query.answer(f"–û—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è: {label}")
        await query.message.reply_text(
            f"–û—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è –≤—ã–±—Ä–∞–Ω–∞: {label}. –¢–µ–ø–µ—Ä—å –≤—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–π.",
            reply_markup=build_randompmv_count_keyboard(),
        )
        return

    if data.startswith("randompmv_count:"):
        if not sess or sess.get("state") != "randompmv_wait_count":
            return await query.answer("–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–π —Å–µ—Å—Å–∏–∏ CreateRandomPMV", show_alert=True)
        try:
            total_runs = int(data.split(":", 1)[1])
        except ValueError:
            return await query.answer("–ù–µ –ø–æ–Ω—è–ª –≤—ã–±—Ä–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ", show_alert=True)
        total_runs = max(RANDOMPMV_MIN_BATCH, min(total_runs, RANDOMPMV_MAX_BATCH))
        sess["randompmv_total_runs"] = total_runs
        sess["state"] = "randompmv_wait_newcount"
        user_sessions[user_id] = sess
        await query.answer("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—É—Å–∫–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ")
        await query.message.reply_text(
            "–°–∫–æ–ª—å–∫–æ –Ω–æ–≤—ã—Ö –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –≤–∫–ª—é—á–∞—Ç—å –≤ –∫–∞–∂–¥—ã–π PMV? (0 = –ª—é–±—ã–µ)",
            reply_markup=build_randompmv_newcount_keyboard(),
        )
        return

    if data.startswith("randompmv_newcount:"):
        if not sess or sess.get("state") != "randompmv_wait_newcount":
            return await query.answer("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ PMV", show_alert=True)
        try:
            min_new = int(data.split(":", 1)[1])
        except ValueError:
            return await query.answer("–ù–µ –ø–æ–Ω—è–ª –≤—ã–±—Ä–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ", show_alert=True)
        if min_new < 0:
            return await query.answer("–ß–∏—Å–ª–æ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º", show_alert=True)
        total_runs = int(sess.get("randompmv_total_runs") or 0)
        if total_runs <= 0:
            user_sessions.pop(user_id, None)
            return await query.answer("–°–µ—Å—Å–∏—è CreateRandomPMV —Å–±—Ä–æ—à–µ–Ω–∞", show_alert=True)

        async def send_from_query(message: str) -> None:
            await query.message.reply_text(message)

        user_sessions.pop(user_id, None)
        await query.answer(f"–ó–∞–ø—É—Å–∫–∞—é {total_runs} Random PMV")
        await query.message.reply_text(
            f"–ó–∞–ø—É—Å–∫–∞—é {total_runs} Random PMV (–Ω–æ–≤—ã—Ö ‚â• {min_new})..."
        )
        orientation_pref = sess.get("randompmv_orientation_preference")
        return await run_randompmv_batch(send_from_query, user_id, total_runs, min_new, orientation_pref)

    if data.startswith("find_pick:"):
        if not sess.get("find_mode"):
            return await query.answer("–°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –∫–æ–º–∞–Ω–¥—É ¬´–ù–∞–π—Ç–∏¬ª.", show_alert=True)
        try:
            idx = int(data.split(":", 1)[1])
        except ValueError:
            return await query.answer("–ù–µ –ø–æ–Ω—è–ª –Ω–æ–º–µ—Ä", show_alert=True)
        matches: List[Dict[str, Any]] = sess.get("find_matches") or []
        if not (0 <= idx < len(matches)):
            return await query.answer("–ù–µ—Ç —Ç–∞–∫–æ–≥–æ PMV –≤ —Å–ø–∏—Å–∫–µ", show_alert=True)

        async def send_find(message: str, markup: Optional[InlineKeyboardMarkup] = None) -> None:
            await query.message.reply_text(message, reply_markup=markup)

        await query.answer("–û—Ç–∫—Ä—ã–≤–∞—é PMV")
        await query.message.edit_reply_markup(None)
        entry = matches[idx]
        if entry.get("type") == "pmv":
            return await _start_find_pmv_queue(sess, entry, send_find)
        if entry.get("type") == "source":
            rows = db_get_sources_by_ids([entry["id"]])
            if not rows:
                return await query.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏—Å—Ö–æ–¥–Ω–∏–∫ –≤ –±–∞–∑–µ.")
            return await _start_find_single_source(sess, rows[0], send_find)
        return await query.message.reply_text("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞.")

    if data == "find_retry":
        if not sess.get("find_mode"):
            return await query.answer("–°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ ¬´–ù–∞–π—Ç–∏¬ª.", show_alert=True)
        sess["state"] = "find_wait_term"
        sess["find_matches"] = []
        await query.answer("–í–≤–µ–¥–∏—Ç–µ –¥—Ä—É–≥–æ–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç –∏–º–µ–Ω–∏")
        return await query.message.reply_text(
            "–ü—Ä–∏—à–ª–∏—Ç–µ –Ω–æ–≤—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç –∏–º–µ–Ω–∏ PMV. –ù–∞–ø—Ä–∏–º–µ—Ä, –¥–∞—Ç—É 20251207 –∏–ª–∏ –≤—Ä–µ–º—è 0734."
        )

    if data.startswith("ratepmv_select:"):
        if sess.get("state") != "ratepmv_choose_pmv":
            return await query.answer("–°–µ–π—á–∞—Å –Ω–µ –∂–¥—É –≤—ã–±–æ—Ä PMV", show_alert=True)
        try:
            idx = int(data.split(":", 1)[1])
        except ValueError:
            return await query.answer("–ù–µ –ø–æ–Ω—è–ª –Ω–æ–º–µ—Ä", show_alert=True)
        pmv_rows: List[sqlite3.Row] = sess.get("pmv_rows") or []
        if not (1 <= idx <= len(pmv_rows)):
            return await query.answer("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –Ω–æ–º–µ—Ä PMV", show_alert=True)
        row = pmv_rows[idx - 1]
        name = Path(row["video_path"]).name
        sess["state"] = "ratepmv_wait_rating"
        sess["ratepmv_selected_idx"] = idx
        await query.answer("PMV –≤—ã–±—Ä–∞–Ω–æ")
        await query.message.reply_text(
            f"PMV ‚Ññ{idx}: {name}\n–í—ã–±–µ—Ä–∏ –æ—Ü–µ–Ω–∫—É 1-5:",
            reply_markup=build_ratepmv_score_keyboard(),
        )
        return

    if data.startswith("ratepmv_rate:"):
        if sess.get("state") != "ratepmv_wait_rating":
            return await query.answer("–°–µ–π—á–∞—Å –Ω–µ –∂–¥—É –æ—Ü–µ–Ω–∫—É", show_alert=True)
        try:
            rating = int(data.split(":", 1)[1])
        except ValueError:
            return await query.answer("–ù–µ –ø–æ–Ω—è–ª –æ—Ü–µ–Ω–∫—É", show_alert=True)
        idx = int(sess.get("ratepmv_selected_idx") or 0)
        if idx <= 0:
            return await query.answer("–ù–µ—Ç –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ PMV", show_alert=True)

        async def send_from_query(message: str) -> None:
            await query.message.reply_text(message)

        await query.answer(f"–û—Ü–µ–Ω–∫–∞: {rating}")
        await process_ratepmv_choice(sess, idx, rating, send_from_query)
        sess.pop("ratepmv_selected_idx", None)
        return

    if data.startswith("ratepmv_bulk:"):
        if sess.get("state") not in {"ratepmv_choose_pmv", "ratepmv_wait_rating"}:
            return await query.answer("–ü–∞–∫–µ—Ç–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Å–µ–π—á–∞—Å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞", show_alert=True)
        try:
            rating = int(data.split(":", 1)[1])
        except ValueError:
            return await query.answer("–ù–µ –ø–æ–Ω—è–ª –æ—Ü–µ–Ω–∫—É", show_alert=True)
        if rating < 1 or rating > 5:
            return await query.answer("–û—Ü–µ–Ω–∫–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å 1-5", show_alert=True)

        pmv_rows: List[sqlite3.Row] = sess.get("pmv_rows") or []
        if not pmv_rows:
            return await query.answer("–ù–µ—Ç —Å–ø–∏—Å–∫–∞ PMV", show_alert=True)

        await query.answer("–ü—Ä–∏–º–µ–Ω—è—é –ø–∞–∫–µ—Ç–Ω—É—é –æ—Ü–µ–Ω–∫—É‚Ä¶")

        pairs = [(idx + 1, rating) for idx in range(len(pmv_rows))]
        success_lines, error_lines = apply_pmv_rating_pairs(pmv_rows, pairs)

        if not success_lines:
            msg = "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–∏–º–µ–Ω–∏—Ç—å –ø–∞–∫–µ—Ç–Ω—É—é –æ—Ü–µ–Ω–∫—É."
            if error_lines:
                msg += "\n" + "\n".join(error_lines)
            return await query.message.reply_text(msg)

        user_sessions.pop(user_id, None)

        lines = [
            f"‚úÖ –í—Å–µ –ø–æ–∫–∞–∑–∞–Ω–Ω—ã–µ PMV –ø–æ–ª—É—á–∏–ª–∏ –æ—Ü–µ–Ω–∫—É {rating}/5: {len(success_lines)} —à—Ç.",
            "–£—Å–ø–µ—à–Ω–æ –æ—Ç–º–µ—á–µ–Ω—ã:",
        ]
        lines.extend(f"- {entry}" for entry in success_lines)
        if error_lines:
            lines.append("")
            lines.append("‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω—ã:")
            lines.extend(f"- {entry}" for entry in error_lines)
        lines.append("")
        lines.append("–û—Ü–µ–Ω–∫–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –Ω–µ —Å—Ç–∞–≤–∏–ª–∏—Å—å. –ï—Å–ª–∏ –Ω—É–∂–Ω–æ ‚Äî –≤—ã–±–µ—Ä–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π PMV –æ—Ç–¥–µ–ª—å–Ω–æ.")
        await query.message.reply_text("\n".join(lines))
        return

    if data == "rategrp_from_pmv":
        if sess.get("state") != "rategrp_choose_orientation":
            return await query.answer("–≠—Ç–∞ –æ–ø—Ü–∏—è –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –≤ –Ω–∞—á–∞–ª–µ –∫–æ–º–∞–Ω–¥—ã rategrp.", show_alert=True)

        async def send_rategrp(msg: str, markup: Optional[InlineKeyboardMarkup] = None) -> None:
            await query.message.reply_text(msg, reply_markup=markup)

        success = await _start_rategrp_from_pmv(sess, send_rategrp)
        if success:
            await query.answer("–ü–æ–∫–∞–∑—ã–≤–∞—é –∏—Å—Ö–æ–¥–Ω–∏–∫–∏ –∏–∑ PMV")
        else:
            await query.answer("–ù–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤", show_alert=True)
        return

    if data.startswith("musicprep_show:"):
        mode = data.split(":", 1)[1]
        show_used = mode == "used"
        sess["state"] = "musicprep_wait_track"
        text, keyboard = build_musicprep_track_keyboard(sess, show_used=show_used)
        try:
            await query.edit_message_text(text, reply_markup=keyboard)
        except Exception:
            await query.message.reply_text(text, reply_markup=keyboard)
        return await query.answer()

    if data.startswith("musicprep_track:"):
        tracks = sess.get("music_tracks") or {}
        token = data.split(":", 1)[1]
        info = tracks.get(token)
        if not info:
            return await query.answer("–¢—Ä–µ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω", show_alert=True)
        path = Path(info["path"])
        _, title = extract_track_title_components(path)
        prefix = slugify_token(title or path.stem)
        sess["musicprep_file"] = str(path)
        sess["musicprep_project_prefix"] = prefix
        sess.pop("musicprep_project_partial", None)
        sess["state"] = "musicprep_wait_seconds"
        await query.answer("–¢—Ä–µ–∫ –≤—ã–±—Ä–∞–Ω")
        await query.message.reply_text(
            f"–¢—Ä–µ–∫ –≤—ã–±—Ä–∞–Ω: {path.name}\n"
            f"–ü—Ä–µ—Ñ–∏–∫—Å –ø—Ä–æ–µ–∫—Ç–∞: {prefix}\n"
            "–í—ã–±–µ—Ä–∏—Ç–µ –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–≥–º–µ–Ω—Ç–∞:",
            reply_markup=build_musicprep_seconds_keyboard(),
        )
        return

    if data.startswith("musicprep_seconds:"):
        if sess.get("state") not in {"musicprep_wait_seconds", "musicprep_wait_mode"}:
            return await query.answer("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ —Ç—Ä–µ–∫", show_alert=True)
        try:
            seconds = int(data.split(":", 1)[1])
        except ValueError:
            return await query.answer("–ù–µ–≤–µ—Ä–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ", show_alert=True)
        prefix = sess.get("musicprep_project_prefix") or "project"
        partial = f"{prefix}_{seconds}"
        sess["musicprep_segment"] = float(seconds)
        sess["musicprep_project_partial"] = partial
        sess["state"] = "musicprep_wait_mode"
        await query.answer(f"{seconds} —Å–µ–∫.")
        if seconds == 0:
            length_line = "–î–ª–∏–Ω–∞ —Å–µ–≥–º–µ–Ω—Ç–∞: –∞–≤—Ç–æ (–º–∏–Ω–∏–º—É–º –Ω–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω)."
        else:
            length_line = f"–î–ª–∏–Ω–∞ —Å–µ–≥–º–µ–Ω—Ç–∞: {seconds} —Å–µ–∫."
        await query.message.reply_text(
            f"{length_line}\n"
            f"–ò–º—è –ø—Ä–æ–µ–∫—Ç–∞ —Å—Ç–∞–Ω–µ—Ç: {partial}_<algo>\n"
            "–í—ã–±–µ—Ä–∏—Ç–µ –∞–ª–≥–æ—Ä–∏—Ç–º —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏:",
            reply_markup=build_musicprep_mode_keyboard(),
        )
        return

    if data.startswith("musicprep_mode:"):
        if sess.get("state") != "musicprep_wait_mode":
            return await query.answer("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ —Å–µ–≥–º–µ–Ω—Ç—ã", show_alert=True)

        mode = data.split(":", 1)[1]
        if mode not in {"beat", "onset", "uniform"}:
            return await query.answer("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ä–µ–∂–∏–º", show_alert=True)

        sess["musicprep_selected_mode"] = mode
        options = get_musicprep_sensitivity_options(mode)
        if options:
            sess["musicprep_sensitivity_options"] = options
            sess["state"] = "musicprep_wait_sensitivity"
            await query.answer("–ê–ª–≥–æ—Ä–∏—Ç–º –≤—ã–±—Ä–∞–Ω")
            await query.message.reply_text(
                "–í—ã–±–µ—Ä–∏—Ç–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞–Ω–∞–ª–∏–∑–∞:",
                reply_markup=build_musicprep_sensitivity_keyboard(mode),
            )
            return

        await query.answer("–ó–∞–ø—É—Å–∫–∞—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é‚Ä¶")

        async def send(msg: str) -> None:
            await query.message.reply_text(msg)

        return await finalize_musicprep_project(send, sess, user_id, mode)

    if data.startswith("musicprep_sens:"):
        if sess.get("state") != "musicprep_wait_sensitivity":
            return await query.answer("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –∞–ª–≥–æ—Ä–∏—Ç–º", show_alert=True)
        parts = data.split(":", 2)
        if len(parts) != 3:
            return await query.answer("–ù–µ–≤–µ—Ä–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä", show_alert=True)
        _, mode, key = parts
        options = get_musicprep_sensitivity_options(mode)
        selected = next((opt for opt in options if opt["key"] == key), None)
        if not selected:
            return await query.answer("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≤–∞—Ä–∏–∞–Ω—Ç", show_alert=True)
        sess["state"] = None
        await query.answer("–ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤—ã–±—Ä–∞–Ω–∞")

        async def send(msg: str) -> None:
            await query.message.reply_text(msg)

        return await finalize_musicprep_project(
            send, sess, user_id, mode, selected.get("analysis_kwargs") or {}
        )

    if data.startswith("musicprepcheck_project:"):
        if sess.get("state") != "musicprepcheck_wait_project":
            return await query.answer("–°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏ /musicprepcheck", show_alert=True)
        slug = data.split(":", 1)[1]
        projects_map: Dict[str, Dict[str, Any]] = sess.get("musicprepcheck_projects") or {}
        project = projects_map.get(slug)
        if not project:
            return await query.answer("–ü—Ä–æ–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω", show_alert=True)
        await query.answer("–ì–æ—Ç–æ–≤–ª—é —â–µ–ª—á–∫–∏‚Ä¶")
        try:
            output_path = generate_musicprep_click_preview(project)
        except Exception as exc:
            return await query.message.reply_text(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å MP3 —Å–æ —â–µ–ª—á–∫–∞–º–∏: {exc}")

        caption = f"–©–µ–ª—á–∫–∏ –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞ {project.get('name') or slug}"
        try:
            with output_path.open("rb") as fh:
                await context.bot.send_document(
                    chat_id=update.effective_chat.id,
                    document=fh,
                    filename=output_path.name,
                    caption=caption,
                )
        except Exception:
            await query.message.reply_text(f"–§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {output_path}")
        else:
            await query.message.reply_text(f"–ì–æ—Ç–æ–≤–æ. –§–∞–π–ª: {output_path}")
        return

    if data.startswith("newcomp_show:"):
        mode = data.split(":", 1)[1]
        show_used = mode == "used"
        if show_used and not sess.get("music_projects_duration_filter"):
            async def send_duration(text: str, markup: Optional[InlineKeyboardMarkup] = None) -> None:
                try:
                    await query.edit_message_text(text, reply_markup=markup)
                except Exception:
                    await query.message.reply_text(text, reply_markup=markup)

            await prompt_newcomp_duration(sess, send_duration)
            await query.answer()
            return
        sess["state"] = "newcompmusic_wait_project"
        text, keyboard = build_newcomp_project_keyboard(sess, show_used=show_used)
        try:
            await query.edit_message_text(text, reply_markup=keyboard)
        except Exception:
            await query.message.reply_text(text, reply_markup=keyboard)
        return await query.answer()

    if data == "newcomp_bucket_menu":
        async def send_duration(text: str, markup: Optional[InlineKeyboardMarkup] = None) -> None:
            try:
                await query.edit_message_text(text, reply_markup=markup)
            except Exception:
                await query.message.reply_text(text, reply_markup=markup)

        await prompt_newcomp_duration(sess, send_duration)
        return await query.answer()

    if data.startswith("newcomp_bucket:"):
        bucket = data.split(":", 1)[1]
        valid_keys = {key for key, _, _, _ in NEWCOMPMUSIC_DURATION_BUCKETS}
        if bucket not in valid_keys:
            return await query.answer("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å", show_alert=True)
        sess["music_projects_duration_filter"] = bucket
        sess["state"] = "newcompmusic_wait_project"
        text, keyboard = build_newcomp_project_keyboard(sess, show_used=True)
        try:
            await query.edit_message_text(text, reply_markup=keyboard)
        except Exception:
            await query.message.reply_text(text, reply_markup=keyboard)
        return await query.answer("–§–∏–ª—å—Ç—Ä –æ–±–Ω–æ–≤–ª—ë–Ω")

    if data.startswith("newcomp_project:"):
        projects_map: Dict[str, Dict[str, Any]] = sess.get("music_projects_map") or {}
        token = data.split(":", 1)[1]
        chosen = projects_map.get(token)
        if not chosen:
            return await query.answer("–ü—Ä–æ–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω", show_alert=True)

        manifest_data = chosen.get("manifest_data")
        manifest_path = chosen.get("manifest_path")
        if not manifest_data and manifest_path and Path(manifest_path).exists():
            try:
                manifest_data = json.loads(Path(manifest_path).read_text(encoding="utf-8"))
                chosen["manifest_data"] = manifest_data
            except Exception as exc:
                return await query.answer(f"–û—à–∏–±–∫–∞ manifest.json: {exc}", show_alert=True)

        parsed_segments = parse_manifest_segments(manifest_data or {})
        total_duration = chosen.get("duration")
        if total_duration is None and parsed_segments:
            total_duration = parsed_segments[-1].end
        seg_count = len(parsed_segments)
        minutes = (total_duration / 60.0) if total_duration else None

        groups = get_source_groups_prefer_unused()
        if not groups:
            return await query.answer("–ù–µ—Ç –≥—Ä—É–ø–ø –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤. –°–Ω–∞—á–∞–ª–∞ /scan.", show_alert=True)

        sess["state"] = "newcompmusic_choose_orientation"
        sess["music_selected"] = {
            "slug": chosen.get("slug"),
            "name": chosen.get("name"),
            "duration": total_duration,
            "segments": seg_count,
            "manifest": manifest_data,
            "audio_path": str(chosen.get("audio_path")) if chosen.get("audio_path") else None,
            "parsed_segments": parsed_segments,
        }
        group_entries = [
            SourceGroupEntry(key=key, rows=list(rows), unused_count=unused_count)
            for key, rows, unused_count in groups
        ]
        sorted_entries, orientation_map = sort_group_entries_with_orientation(group_entries)
        sess["music_group_orientations"] = orientation_map
        sess["music_groups_all"] = [
            (entry.key, entry.rows, entry.unused_count) for entry in sorted_entries
        ]
        sess["music_groups"] = []
        sess["music_orientation_preference"] = None

        lines = [
            f"–í—ã–±—Ä–∞–Ω –ø—Ä–æ–µ–∫—Ç: {chosen['name']} (slug: {chosen['slug']}).",
            f"–°–º–µ–Ω –∫–ª–∏–ø–æ–≤: {seg_count}",
        ]
        if minutes:
            lines.append(f"–ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å ‚âà {minutes:.1f} –º–∏–Ω—É—Ç.")
        lines.append("")
        lines.append("–í—ã–±–µ—Ä–∏—Ç–µ –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—é –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤: VR, HOR –∏–ª–∏ VER.")

        await query.answer("–ü—Ä–æ–µ–∫—Ç –≤—ã–±—Ä–∞–Ω")
        await query.message.reply_text(
            "\n".join(lines),
            reply_markup=build_newcomp_orientation_keyboard(),
        )
        return

    if data.startswith("newcomp_orient:"):
        if sess.get("state") != "newcompmusic_choose_orientation":
            return await query.answer("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–æ–µ–∫—Ç", show_alert=True)
        target = data.split(":", 1)[1].upper()
        if target not in NEWCOMPMUSIC_ORIENTATION_CHOICES:
            return await query.answer("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ä–µ–∂–∏–º", show_alert=True)
        all_groups = sess.get("music_groups_all") or []
        if not all_groups:
            return await query.answer("–°–ø–∏—Å–æ–∫ –≥—Ä—É–ø–ø –ø—É—Å—Ç. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –∫–æ–º–∞–Ω–¥—É –∑–∞–Ω–æ–≤–æ.", show_alert=True)
        orientation_map = sess.get("music_group_orientations") or {}
        filtered = filter_groups_by_orientation(all_groups, orientation_map, target)
        if not filtered:
            return await query.answer("–ù–µ—Ç –≥—Ä—É–ø–ø –≤ —ç—Ç–æ–π –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏–∏.", show_alert=True)
        sess["music_orientation_preference"] = target
        sess["music_groups"] = filtered
        sess["state"] = "newcompmusic_wait_group"
        group_entries = [
            SourceGroupEntry(key=key, rows=list(rows), unused_count=unused)
            for key, rows, unused in filtered
        ]
        msg_lines = _build_group_selection_lines(
            sess, group_entries, target, prompt_kind="inline"
        )
        await query.answer("–û—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è –≤—ã–±—Ä–∞–Ω–∞")
        await query.message.reply_text(
            "\n".join(msg_lines),
            reply_markup=build_numeric_keyboard("newcomp_group", len(filtered)),
        )
        return

    if data.startswith("rategrp_orient:"):
        if sess.get("state") != "rategrp_choose_orientation":
            return await query.answer("–°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ /rategrp", show_alert=True)
        target = data.split(":", 1)[1].upper()
        if target not in NEWCOMPMUSIC_ORIENTATION_CHOICES:
            return await query.answer("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ä–µ–∂–∏–º", show_alert=True)
        all_groups = sess.get("rategrp_groups_all") or []
        if not all_groups:
            return await query.answer("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –≥—Ä—É–ø–ø. –ó–∞–ø—É—Å—Ç–∏—Ç–µ /rategrp –∑–∞–Ω–æ–≤–æ.", show_alert=True)
        orientation_map = sess.get("rategrp_group_orientations") or {}
        filtered = filter_groups_by_orientation(all_groups, orientation_map, target)
        if not filtered:
            return await query.answer("–ù–µ—Ç –≥—Ä—É–ø–ø –≤ —ç—Ç–æ–π –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏–∏.", show_alert=True)
        sess["rategrp_orientation_preference"] = target
        sess["rategrp_groups"] = filtered
        sess["state"] = "rategrp_choose_group"
        group_entries = [
            SourceGroupEntry(key=key, rows=list(rows), unused_count=unused)
            for key, rows, unused in filtered
        ]
        msg_lines = format_rategrp_group_prompt(sess, group_entries, target, prompt_kind="inline")
        await query.answer("–û—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è –≤—ã–±—Ä–∞–Ω–∞")
        await query.message.reply_text(
            "\n".join(msg_lines),
            reply_markup=build_numeric_keyboard("rategrp_group", len(filtered)),
        )
        return

    if data.startswith("rategrp_group:"):
        if sess.get("state") != "rategrp_choose_group":
            return await query.answer("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—é", show_alert=True)
        try:
            idx = int(data.split(":", 1)[1])
        except ValueError:
            return await query.answer("–ù–µ–≤–µ—Ä–Ω—ã–π –Ω–æ–º–µ—Ä –≥—Ä—É–ø–ø—ã", show_alert=True)
        groups = sess.get("rategrp_groups") or []
        if not (1 <= idx <= len(groups)):
            return await query.answer("–ù–µ—Ç –≥—Ä—É–ø–ø—ã —Å —Ç–∞–∫–∏–º –Ω–æ–º–µ—Ä–æ–º", show_alert=True)
        key, rows, _ = groups[idx - 1]
        rows = [dict(row) for row in rows]
        orientation_label = (sess.get("rategrp_group_orientations") or {}).get(key)
        if not orientation_label:
            orientation_label = _resolution_orientation(key[1] or "")[0]
        sess["rategrp_group_choice"] = {
            "key": key,
            "label": f"{key[0]} {key[1]}",
            "orientation": orientation_label,
        }
        sess["rategrp_rerate_rows"] = rows
        queue = _prepare_rategrp_queue(rows)
        if not queue:
            available = _rategrp_available_colors(rows)
            if not available:
                return await query.answer("–í —ç—Ç–æ–π –≥—Ä—É–ø–ø–µ –Ω–µ—Ç –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤.", show_alert=True)
            sess["state"] = "rategrp_choose_rerate_color"
            await query.answer("–í—ã–±–µ—Ä–∏—Ç–µ —Ü–≤–µ—Ç –¥–ª—è –ø–µ—Ä–µ–æ—Ü–µ–Ω–∫–∏")

            async def send_rategrp(msg: str, markup: Optional[InlineKeyboardMarkup] = None) -> None:
                await query.message.reply_text(msg, reply_markup=markup)

            await send_rategrp(
                f"–ì—Ä—É–ø–ø–∞ {key[0]} {key[1]} –≤—ã–±—Ä–∞–Ω–∞. –ù–æ–≤—ã—Ö –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ –Ω–µ—Ç, –≤—ã–±–µ—Ä–∏—Ç–µ —Ü–≤–µ—Ç –¥–ª—è –ø–µ—Ä–µ–æ—Ü–µ–Ω–∫–∏:",
                build_rategrp_rerate_keyboard(available),
            )
            return
        sess["rategrp_queue"] = queue
        sess["rategrp_total"] = len(queue)
        sess["rategrp_processed"] = 0
        sess["rategrp_queue_origin"] = "unrated"
        sess["state"] = "rategrp_rate_source"

        async def send_rategrp(msg: str, markup: Optional[InlineKeyboardMarkup] = None) -> None:
            await query.message.reply_text(msg, reply_markup=markup)

        await query.answer("–ì—Ä—É–ø–ø–∞ –≤—ã–±—Ä–∞–Ω–∞")
        await send_rategrp(f"–ì—Ä—É–ø–ø–∞ {key[0]} {key[1]} –≤—ã–±—Ä–∞–Ω–∞. –ù–µ–æ—Ü–µ–Ω—ë–Ω–Ω—ã—Ö –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤: {len(queue)}.")
        return await rategrp_send_next_prompt(sess, send_rategrp)

    if data.startswith("rategrp_color:"):
        if sess.get("state") != "rategrp_rate_source":
            return await query.answer("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –≥—Ä—É–ø–ø—É", show_alert=True)
        color_key = data.split(":", 1)[1]
        choice = RATEGRP_COLOR_CHOICES.get(color_key)
        if not choice:
            return await query.answer("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ü–≤–µ—Ç", show_alert=True)

        async def send_rategrp(msg: str, markup: Optional[InlineKeyboardMarkup] = None) -> None:
            await query.message.reply_text(msg, reply_markup=markup)

        await query.answer(f"–û—Ç–º–µ—á–µ–Ω–æ {choice['emoji']}")
        return await rategrp_apply_rating(sess, color_key, send_rategrp)

    if data.startswith("rategrp_rerate_color:"):
        if sess.get("state") != "rategrp_choose_rerate_color":
            return await query.answer("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –≥—Ä—É–ø–ø—É", show_alert=True)
        color_key = data.split(":", 1)[1]

        async def send_rategrp(msg: str, markup: Optional[InlineKeyboardMarkup] = None) -> None:
            await query.message.reply_text(msg, reply_markup=markup)

        success = await _rategrp_start_rerate(sess, color_key, send_rategrp)
        if success:
            await query.answer("–ó–∞–ø—É—Å–∫–∞—é –ø–µ—Ä–µ–æ—Ü–µ–Ω–∫—É")
        else:
            await query.answer("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞—á–∞—Ç—å –ø–µ—Ä–µ–æ—Ü–µ–Ω–∫—É", show_alert=True)
        return

    if data == "rategrp_rerate_back":
        if sess.get("state") != "rategrp_choose_rerate_color":
            return await query.answer("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –≥—Ä—É–ø–ø—É", show_alert=True)
        sess["state"] = "rategrp_choose_group"
        groups = sess.get("rategrp_groups") or []
        orientation = sess.get("rategrp_orientation_preference") or "?"
        group_entries = [
            SourceGroupEntry(key=key, rows=list(rows), unused_count=unused) for key, rows, unused in groups
        ]
        lines = format_rategrp_group_prompt(sess, group_entries, orientation, prompt_kind="inline")
        keyboard = build_numeric_keyboard("rategrp_group", len(groups)) if groups else None
        await query.message.reply_text("\n".join(lines), reply_markup=keyboard)
        return await query.answer("–í—ã–±–µ—Ä–∏—Ç–µ –¥—Ä—É–≥—É—é –≥—Ä—É–ø–ø—É")

    if data.startswith("newcomp_group:"):
        if sess.get("state") != "newcompmusic_wait_group":
            return await query.answer("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–æ–µ–∫—Ç", show_alert=True)
        try:
            idx = int(data.split(":", 1)[1])
        except ValueError:
            return await query.answer("–ù–µ–≤–µ—Ä–Ω—ã–π –Ω–æ–º–µ—Ä –≥—Ä—É–ø–ø—ã", show_alert=True)
        groups: List[Tuple[Tuple[str, str], List[sqlite3.Row], int]] = sess.get("music_groups") or []
        if not (1 <= idx <= len(groups)):
            return await query.answer("–ù–µ—Ç –≥—Ä—É–ø–ø—ã —Å —Ç–∞–∫–∏–º –Ω–æ–º–µ—Ä–æ–º", show_alert=True)
        key, rows, unused_count = groups[idx - 1]
        if not rows:
            return await query.answer("–ì—Ä—É–ø–ø–∞ –ø—É—Å—Ç–∞—è", show_alert=True)

        orientation_label = (sess.get("music_group_orientations") or {}).get(key)
        if not orientation_label:
            orientation_label = _resolution_orientation(key[1] or "")[0]
        sess["music_group_choice"] = {
            "key": key,
            "count": len(rows),
            "orientation": orientation_label,
            "total_count": len(rows),
            "unused_count": unused_count,
            "group_number": idx,
        }
        sess["music_group_rows"] = list(rows)
        sess["music_folder_only_new"] = False
        sess.pop("music_color_rows", None)
        sess["state"] = "newcompmusic_choose_groupmode"

        await query.answer("–ì—Ä—É–ø–ø–∞ –≤—ã–±—Ä–∞–Ω–∞")
        await query.message.reply_text(
            "–ì—Ä—É–ø–ø–∞ –≤—ã–±—Ä–∞–Ω–∞. –ö–∞–∫ –±—É–¥–µ–º –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å –∏—Å—Ö–æ–¥–Ω–∏–∫–∏?",
            reply_markup=build_newcomp_groupmode_keyboard(),
        )
        return

    if data.startswith("newcomp_folder:"):
        if sess.get("state") != "newcompmusic_wait_folder":
            return await query.answer("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –≥—Ä—É–ø–ø—É", show_alert=True)
        token = data.split(":", 1)[1]
        try:
            count, label = apply_newcomp_folder_choice(
                sess, token, next_state="newcompmusic_wait_sources"
            )
        except ValueError as exc:
            return await query.answer(str(exc), show_alert=True)

        choice = sess.get("music_group_choice") or {}
        codec, res = choice.get("key") or ("?", "?")
        project_info = sess.get("music_selected") or {}
        segs = project_info.get("segments")
        duration = project_info.get("duration")
        duration_minutes = (duration / 60.0) if duration else None

        msg_lines = [
            f"–ü–∞–ø–∫–∞ –≤—ã–±—Ä–∞–Ω–∞: {label} (–∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤: {count}).",
            f"–ì—Ä—É–ø–ø–∞: {codec} {res}.",
        ]
        if duration_minutes:
            msg_lines.append(f"–ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø—Ä–æ–µ–∫—Ç–∞ ‚âà {duration_minutes:.1f} –º–∏–Ω—É—Ç.")
        if segs is not None:
            msg_lines.append(f"–°–º–µ–Ω –∫–ª–∏–ø–æ–≤: {segs}.")
        msg_lines.append("–í—ã–±–µ—Ä–∏—Ç–µ, —Å–∫–æ–ª—å–∫–æ –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ –∑–∞–¥–µ–π—Å—Ç–≤–æ–≤–∞—Ç—å:")

        await query.answer("–ü–∞–ø–∫–∞ –≤—ã–±—Ä–∞–Ω–∞")
        await query.message.reply_text(
            "\n".join(msg_lines),
            reply_markup=build_newcomp_sources_keyboard(),
        )
        return

    if data == "newcomp_folder_back":
        if sess.get("state") != "newcompmusic_wait_folder":
            return await query.answer("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –≥—Ä—É–ø–ø—É", show_alert=True)
        groups = sess.get("music_groups") or []
        if not groups:
            return await query.answer("–ù–µ—Ç —Å–ø–∏—Å–∫–∞ –≥—Ä—É–ø–ø. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –∑–∞–Ω–æ–≤–æ.", show_alert=True)
        sess["state"] = "newcompmusic_wait_group"
        sess.pop("music_group_choice", None)
        sess.pop("music_group_rows", None)
        sess.pop("music_color_rows", None)
        sess["music_folder_only_new"] = False
        orientation_label = sess.get("music_orientation_preference") or "?"
        group_entries = [
            SourceGroupEntry(key=key, rows=list(rows), unused_count=unused)
            for key, rows, unused in groups
        ]
        msg_lines = _build_group_selection_lines(
            sess, group_entries, orientation_label, prompt_kind="inline"
        )
        await query.answer("–í—ã–±–µ—Ä–∏—Ç–µ –¥—Ä—É–≥—É—é –≥—Ä—É–ø–ø—É")
        await query.message.reply_text(
            "\n".join(msg_lines),
            reply_markup=build_numeric_keyboard("newcomp_group", len(groups)),
        )
        return

    if data.startswith("newcomp_groupmode:"):
        if sess.get("state") != "newcompmusic_choose_groupmode":
            return await query.answer("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –≥—Ä—É–ø–ø—É", show_alert=True)
        mode = data.split(":", 1)[1]
        rows = sess.get("music_group_rows") or []
        if not rows:
            return await query.answer("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –≥—Ä—É–ø–ø—É.", show_alert=True)
        if mode == "folders":
            available = _count_rows_for_folder_mode(rows, False)
            if available == 0:
                return await query.answer("–í –≤—ã–±—Ä–∞–Ω–Ω–æ–π –≥—Ä—É–ø–ø–µ –Ω–µ—Ç –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤.", show_alert=True)
            sess["music_color_rows"] = None
            sess["music_color_choice"] = None
            sess["music_color_autotag"] = None
            group_choice = sess.get("music_group_choice") or {}
            total = group_choice.get("total_count")
            if total:
                group_choice["count"] = total
            sess["music_group_choice"] = group_choice
            sess["music_folder_only_new"] = False
            sess["state"] = "newcompmusic_wait_folder"
            msg_text, keyboard = compose_newcomp_folder_prompt(sess)
            await query.answer("–ü–æ–∫–∞–∑—ã–≤–∞—é –ø–∞–ø–∫–∏")
            await query.message.reply_text(msg_text, reply_markup=keyboard)
            return
        if mode == "colors":
            counts, unrated = _compute_rategrp_color_counts(rows)
            total_colored = sum(counts.values())
            if total_colored == 0:
                return await query.answer("–í —ç—Ç–æ–π –≥—Ä—É–ø–ø–µ –Ω–µ—Ç –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ —Å –æ—Ü–µ–Ω–∫–∞–º–∏.", show_alert=True)
            green_emoji = RATEGRP_COLOR_CHOICES["green"]["emoji"]
            yellow_emoji = RATEGRP_COLOR_CHOICES["yellow"]["emoji"]
            red_emoji = RATEGRP_COLOR_CHOICES["red"]["emoji"]
            combo_counts = {
                "green_new": len(_filter_green_new_rows(rows)),
                "green_yellow": len(
                    _filter_rows_by_color(rows, {green_emoji, yellow_emoji}, include_unrated=False)
                ),
                "green_yellow_red": len(
                    _filter_rows_by_color(
                        rows,
                        {green_emoji, yellow_emoji, red_emoji},
                        include_unrated=False,
                    )
                ),
            }
            sess["state"] = "newcompmusic_choose_color"
            await query.answer("–í—ã–±–µ—Ä–∏—Ç–µ —Ü–≤–µ—Ç")
            await query.message.reply_text(
                "–í—ã–±–µ—Ä–∏—Ç–µ —Ü–≤–µ—Ç –æ—Ü–µ–Ω–∫–∏:",
                reply_markup=build_newcomp_color_keyboard(counts, unrated, combo_counts),
            )
            return
        return await query.answer("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ä–µ–∂–∏–º", show_alert=True)

    if data == "newcomp_color_back":
        if sess.get("state") != "newcompmusic_choose_color":
            return await query.answer("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º", show_alert=True)
        sess["state"] = "newcompmusic_choose_groupmode"
        sess.pop("music_color_rows", None)
        sess.pop("music_color_choice", None)
        sess.pop("music_color_autotag", None)
        group_choice = sess.get("music_group_choice") or {}
        total = group_choice.get("total_count")
        if total:
            group_choice["count"] = total
        sess["music_group_choice"] = group_choice
        await query.answer("–í–æ–∑–≤—Ä–∞—â–∞—é –≤—ã–±–æ—Ä")
        await query.message.reply_text(
            "–ö–∞–∫ –±—É–¥–µ–º –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å –∏—Å—Ö–æ–¥–Ω–∏–∫–∏?",
            reply_markup=build_newcomp_groupmode_keyboard(),
        )
        return

    if data.startswith("newcomp_color:"):
        if sess.get("state") != "newcompmusic_choose_color":
            return await query.answer("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º", show_alert=True)
        color_key = data.split(":", 1)[1]
        rows = sess.get("music_group_rows") or []
        choice = RATEGRP_COLOR_CHOICES.get(color_key)
        include_unrated = False
        allowed: Set[str] = set()
        if choice:
            emoji = choice["emoji"]
            allowed = {emoji}
            filtered = _filter_rows_by_color(rows, allowed, include_unrated=False)
        elif color_key == "green_new":
            allowed = {RATEGRP_COLOR_CHOICES["green"]["emoji"]}
            filtered = _filter_green_new_rows(rows)
            include_unrated = True
        elif color_key == "green_yellow":
            allowed = {
                RATEGRP_COLOR_CHOICES["green"]["emoji"],
                RATEGRP_COLOR_CHOICES["yellow"]["emoji"],
            }
            filtered = _filter_rows_by_color(rows, allowed, include_unrated=False)
        elif color_key == "green_yellow_red":
            allowed = {
                RATEGRP_COLOR_CHOICES["green"]["emoji"],
                RATEGRP_COLOR_CHOICES["yellow"]["emoji"],
                RATEGRP_COLOR_CHOICES["red"]["emoji"],
            }
            filtered = _filter_rows_by_color(rows, allowed, include_unrated=False)
        else:
            return await query.answer("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ü–≤–µ—Ç", show_alert=True)
        emoji_label = (
            choice["emoji"]
            if choice
            else {
                "green_new": f"{RATEGRP_COLOR_CHOICES['green']['emoji']}+üÜï",
                "green_yellow": f"{RATEGRP_COLOR_CHOICES['green']['emoji']}+{RATEGRP_COLOR_CHOICES['yellow']['emoji']}",
                "green_yellow_red": f"{RATEGRP_COLOR_CHOICES['green']['emoji']}+{RATEGRP_COLOR_CHOICES['yellow']['emoji']}+{RATEGRP_COLOR_CHOICES['red']['emoji']}",
            }.get(color_key, "?")
        )
        if not filtered:
            return await query.answer("–ù–µ—Ç –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ —Å —Ç–∞–∫–æ–π –æ—Ü–µ–Ω–∫–æ–π.", show_alert=True)
        sess["music_color_rows"] = filtered
        sess["music_color_choice"] = emoji_label
        autotag = None
        if include_unrated:
            autotag_emoji = RATEGRP_COLOR_CHOICES["green"]["emoji"]
            autotag_ids: List[int] = []
            for row in filtered:
                if _rategrp_row_color(row) is None:
                    try:
                        autotag_ids.append(int(row["id"]))
                    except Exception:
                        continue
            if autotag_ids:
                autotag = {"emoji": autotag_emoji, "ids": autotag_ids}
        else:
            autotag = None
        sess["music_color_autotag"] = autotag
        group_choice = sess.get("music_group_choice") or {}
        group_choice["count"] = len(filtered)
        sess["music_group_choice"] = group_choice
        sess["state"] = "newcompmusic_wait_sources"
        codec, res = group_choice.get("key") or ("?", "?")
        msg_lines = [
            f"–í—ã–±—Ä–∞–Ω —Ü–≤–µ—Ç {emoji_label}: {len(filtered)} –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤.",
            f"–ì—Ä—É–ø–ø–∞: {codec} {res}.",
            "–°–∫–æ–ª—å–∫–æ –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ –∑–∞–¥–µ–π—Å—Ç–≤–æ–≤–∞—Ç—å? –ü—Ä–∏—à–ª–∏—Ç–µ —á–∏—Å–ª–æ –∏–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ –Ω–∞ –∫–ª–∞–≤–∏–∞—Ç—É—Ä–µ.",
        ]
        await query.answer("–¶–≤–µ—Ç –≤—ã–±—Ä–∞–Ω")
        await query.message.reply_text(
            "\n".join(msg_lines),
            reply_markup=build_newcomp_sources_keyboard(),
        )
        return

    if data.startswith("newcomp_folder_mode:"):
        if sess.get("state") != "newcompmusic_wait_folder":
            return await query.answer("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –≥—Ä—É–ø–ø—É", show_alert=True)
        mode = data.split(":", 1)[1]
        target_unused_only = mode == "new"
        current = bool(sess.get("music_folder_only_new"))
        if target_unused_only == current:
            return await query.answer("–≠—Ç–æ—Ç —Ä–µ–∂–∏–º —É–∂–µ –∞–∫—Ç–∏–≤–µ–Ω.")
        rows = sess.get("music_group_rows") or []
        if not rows:
            return await query.answer("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏—Å—Ö–æ–¥–Ω–∏–∫–∏ –≥—Ä—É–ø–ø—ã.", show_alert=True)
        total_count = _count_rows_for_folder_mode(rows, target_unused_only)
        if target_unused_only and total_count == 0:
            return await query.answer("–ù–æ–≤—ã—Ö –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ –≤ —ç—Ç–æ–π –≥—Ä—É–ø–ø–µ –Ω–µ—Ç.", show_alert=True)
        sess["music_folder_only_new"] = target_unused_only
        msg_text, keyboard = compose_newcomp_folder_prompt(sess)
        notice = "–ü–æ–∫–∞–∑—ã–≤–∞—é —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ." if target_unused_only else "–í–æ–∑–≤—Ä–∞—â–∞—é –≤—Å–µ –∏—Å—Ö–æ–¥–Ω–∏–∫–∏."
        await query.answer(notice)
        await query.message.reply_text(msg_text, reply_markup=keyboard)
        return

    if data.startswith("newcomp_sources:"):
        if sess.get("state") != "newcompmusic_wait_sources":
            return await query.answer("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –≥—Ä—É–ø–ø—É", show_alert=True)
        try:
            count = int(data.split(":", 1)[1])
        except ValueError:
            return await query.answer("–ù–µ–≤–µ—Ä–Ω–æ–µ —á–∏—Å–ª–æ", show_alert=True)
        available = int((sess.get("music_group_choice") or {}).get("count") or 0)
        info_line = None
        if available and count > available:
            count = available
            info_line = _source_limit_message(sess, available)
        sess["music_sources"] = count
        sess["state"] = "newcompmusic_wait_algo"

        await query.answer("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–±—Ä–∞–Ω–æ" if not info_line else "–ë–µ—Ä—ë–º –º–∞–∫—Å–∏–º—É–º")
        algo_desc = ", ".join(f"{meta['short']} ({meta['title']})" for meta in CLIP_SEQUENCE_ALGORITHMS.values())
        msg_lines = []
        if info_line:
            msg_lines.append(info_line)
        msg_lines.append(f"–û–∫, –≤–æ–∑—å–º—ë–º {count} –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤.")
        msg_lines.append(
            f"–í—ã–±–µ—Ä–∏—Ç–µ –º–µ—Ç–æ–¥ —Ä–∞–Ω–¥–æ–º–∏–∑–∞—Ü–∏–∏ –∫–ª–∏–ø–æ–≤: {algo_desc}",
        )
        await query.message.reply_text(
            "\n".join(msg_lines),
            reply_markup=build_newcomp_algo_keyboard(),
        )
        return

    if data.startswith("newcomp_algo:"):
        if sess.get("state") != "newcompmusic_wait_algo":
            return await query.answer("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤", show_alert=True)
        short = data.split(":", 1)[1]
        resolved_key = normalize_clip_algo_choice(short)
        if not resolved_key:
            return await query.answer("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º", show_alert=True)

        async def send_from_query(message: str) -> None:
            await query.message.reply_text(message)

        await query.answer("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è‚Ä¶")
        return await run_newcompmusic_generation(send_from_query, sess, resolved_key, user_id)

    await query.answer("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–Ω–æ–ø–∫–∞", show_alert=True)


async def cmd_badfiles(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not check_access(update):
        return await unauthorized(update)

    rows = db_get_problem_sources()
    if not rows:
        return await update.message.reply_text("–ü—Ä–æ–±–ª–µ–º–Ω—ã–µ —Ñ–∞–π–ª—ã –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã.")

    lines = ["‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º–Ω—ã–µ –∏—Å—Ö–æ–¥–Ω–∏–∫–∏:"]
    for r in rows:
        lines.append(f"- id={r['id']}: {r['video_name']} ‚Äî {r['video_path']}")
    await update.message.reply_text("\n".join(lines))


async def cmd_strategy(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not check_access(update):
        return await unauthorized(update)

    global CURRENT_STRATEGY

    args = context.args
    if not args:
        return await update.message.reply_text(
            "–¢–µ–∫—É—â–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è: " + CURRENT_STRATEGY + "\n–î–æ—Å—Ç—É–ø–Ω—ã–µ: " + ", ".join(ALLOWED_STRATEGIES)
        )

    name = args[0].strip().lower()
    if name not in ALLOWED_STRATEGIES:
        return await update.message.reply_text(
            "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è. –î–æ—Å—Ç—É–ø–Ω—ã–µ: " + ", ".join(ALLOWED_STRATEGIES)
        )

    CURRENT_STRATEGY = name
    return await update.message.reply_text(f"–û–∫, —Å—Ç—Ä–∞—Ç–µ–≥–∏—è —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞: {CURRENT_STRATEGY}")


async def cmd_videofx(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not check_access(update):
        return await unauthorized(update)

    global GLITCH_EFFECTS_PER_VIDEO, TRANSITION_EFFECTS_PER_VIDEO

    args = context.args
    if not args:
        return await update.message.reply_text(
            "–¢–µ–∫—É—â–∏–µ –≤–∏–∑—É–∞–ª—å–Ω—ã–µ —ç—Ñ—Ñ–µ–∫—Ç—ã:\n"
            f"- –≥–ª–∏—Ç—á-–≤—Å—Ç–∞–≤–æ–∫: {GLITCH_EFFECTS_PER_VIDEO}\n"
            f"- –ø–µ—Ä–µ—Ö–æ–¥–æ–≤: {TRANSITION_EFFECTS_PER_VIDEO}\n\n"
            "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /videofx <–≥–ª–∏—Ç—á–µ–π> <–ø–µ—Ä–µ—Ö–æ–¥–æ–≤>, –Ω–∞–ø—Ä–∏–º–µ—Ä /videofx 6 3."
        )

    try:
        glitches = max(0, int(args[0]))
        transitions = max(
            0, int(args[1]) if len(args) > 1 else TRANSITION_EFFECTS_PER_VIDEO
        )
    except ValueError:
        return await update.message.reply_text(
            "–ù—É–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å —Ü–µ–ª—ã–µ —á–∏—Å–ª–∞: /videofx <–≥–ª–∏—Ç—á–µ–π> <–ø–µ—Ä–µ—Ö–æ–¥–æ–≤>"
        )

    GLITCH_EFFECTS_PER_VIDEO = glitches
    TRANSITION_EFFECTS_PER_VIDEO = transitions
    return await update.message.reply_text(
        f"–ì–æ—Ç–æ–≤–æ. –ì–ª–∏—Ç—á–µ–π: {GLITCH_EFFECTS_PER_VIDEO}, –ø–µ—Ä–µ—Ö–æ–¥–æ–≤: {TRANSITION_EFFECTS_PER_VIDEO}."
    )



async def cmd_ratepmv(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not check_access(update):
        return await unauthorized(update)

    rows = db_get_all_compilations()
    if not rows:
        return await update.message.reply_text("–ü–æ—Ö–æ–∂–µ, –ø–æ–∫–∞ –Ω–µ—Ç –≥–æ—Ç–æ–≤—ã—Ö PMV –∏ –æ—Ü–µ–Ω–∏–≤–∞—Ç—å –Ω–µ—á–µ–≥–æ.")

    unrated = []
    for r in rows:
        comments = (r["comments"] or "").lower()
        if "pmv_rating=" not in comments:
            unrated.append(r)

    if not unrated:
        return await update.message.reply_text("–í—Å–µ PMV —É–∂–µ –ø–æ–ª—É—á–∏–ª–∏ –æ—Ü–µ–Ω–∫–∏! üî•")

    unrated_sorted = sorted(
        unrated,
        key=lambda row: ((row["pmv_date"] or ""), int(row["id"] or 0)),
    )
    display_rows = unrated_sorted[:10]
    remaining = max(0, len(unrated_sorted) - len(display_rows))

    lines = [f"–ë–µ–∑ –æ—Ü–µ–Ω–∫–∏ –æ—Å—Ç–∞–ª–æ—Å—å PMV: {len(unrated_sorted)}."]
    if remaining > 0:
        lines.append(f"–ü–æ–∫–∞–∑—ã–≤–∞—é 10 —Å–∞–º—ã—Ö —Å—Ç–∞—Ä—ã—Ö, –µ—â—ë –∂–¥—É—Ç —Å–≤–æ–µ–π –æ—á–µ—Ä–µ–¥–∏: {remaining}.")
    lines.append("")
    for idx, r in enumerate(display_rows, 1):
        name = Path(r["video_path"]).name
        date_str = r["pmv_date"]
        lines.append(f"{idx}. {name} (–¥–∞—Ç–∞: {date_str}, id={r['id']})")

    lines.append("")
    lines.append("–ú–æ–∂–µ—à—å –≤—ã–±—Ä–∞—Ç—å PMV –∫–Ω–æ–ø–∫–æ–π –∏–ª–∏ –ø—Ä–∏—Å–ª–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–º `<–Ω–æ–º–µ—Ä> <–æ—Ü–µ–Ω–∫–∞ 1-5>` (–ø—Ä–∏–º–µ—Ä: `2 5`).")
    lines.append("–î–ª—è –ø–∞–∫–µ—Ç–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ –æ—Ç–ø—Ä–∞–≤—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–∞—Ä –ø–æ–¥—Ä—è–¥: `<1 5 2 4 3 5>` –∏–ª–∏ –Ω–∞–∂–º–∏ –∫–Ω–æ–ø–∫—É `-> –≤—Å–µ–º` —Å–æ —Å–Ω–∏–∑—É –∫–ª–∞–≤–∏–∞—Ç—É—Ä—ã.")

    user_sessions[update.effective_user.id] = {
        "state": "ratepmv_choose_pmv",
        "pmv_rows": display_rows,
    }

    await update.message.reply_text(
        "\n".join(lines),
        reply_markup=build_ratepmv_pmv_keyboard(display_rows),
    )




def get_source_groups_prefer_unused() -> List[Tuple[Tuple[str, str], List[sqlite3.Row], int]]:
    unused = db_get_unused_sources_grouped()
    all_groups = db_get_all_sources_grouped()
    all_keys = set(all_groups.keys()) | set(unused.keys())
    entries: List[SourceGroupEntry] = []

    for key in all_keys:
        rows_all = all_groups.get(key) or []
        if len(rows_all) <= 5:
            continue
        unused_count = len(unused.get(key) or [])
        entries.append(SourceGroupEntry(key=key, rows=list(rows_all), unused_count=unused_count))

    sorted_entries = sort_source_group_entries(entries)
    return [(entry.key, entry.rows, entry.unused_count) for entry in sorted_entries]


async def cmd_newcompmusic(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not check_access(update):
        return await unauthorized(update)

    projects = load_music_projects()
    if not projects:
        return await update.message.reply_text(
            "–ü–∞–ø–∫–∞ music_projects –ø—É—Å—Ç–∞. –°–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞–π—Ç–µ –ø—Ä–æ–µ–∫—Ç—ã —á–µ—Ä–µ–∑ music_guided_generator.py."
        )

    project_map: Dict[str, Dict[str, Any]] = {}
    unused_tokens: List[str] = []
    used_tokens: List[str] = []
    for idx, proj in enumerate(projects, 1):
        token = f"mp{idx}"
        project_map[token] = proj
        if proj.get("usage_count"):
            used_tokens.append(token)
        else:
            unused_tokens.append(token)

    session_payload = {
        "state": "newcompmusic_wait_project",
        "music_projects_map": project_map,
        "music_projects_unused": unused_tokens,
        "music_projects_used": used_tokens,
        "music_projects": projects,
        "music_projects_duration_filter": None,
    }
    user_sessions[update.effective_user.id] = session_payload

    show_used = not unused_tokens and bool(used_tokens)
    if show_used and not session_payload.get("music_projects_duration_filter"):
        async def send_duration(text: str, markup: Optional[InlineKeyboardMarkup] = None) -> None:
            await update.message.reply_text(text, reply_markup=markup)

        await prompt_newcomp_duration(session_payload, send_duration)
        return

    text, keyboard = build_newcomp_project_keyboard(session_payload, show_used=show_used)
    await update.message.reply_text(text, reply_markup=keyboard)


async def cmd_randompmv(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not check_access(update):
        return await unauthorized(update)

    user_sessions[update.effective_user.id] = {
        "state": "randompmv_choose_orientation",
    }
    msg = (
        "CreateRandomPMV: —Å–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏ –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—é –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ (VR / HOR / VER / –í–°–ï), "
        "–∑–∞—Ç–µ–º —É–∫–∞–∂–∏, —Å–∫–æ–ª—å–∫–æ –ø—Ä–æ–µ–∫—Ç–æ–≤ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å (5-30), "
        "–∞ –ø–æ—Å–ª–µ –∑–∞–¥–∞–π –º–∏–Ω–∏–º—É–º –Ω–æ–≤—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ (0-60) –¥–ª—è –∫–∞–∂–¥–æ–≥–æ PMV. "
        "–ë–æ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–¥–±–µ—Ä—ë—Ç –≥—Ä—É–ø–ø—ã –∏ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –ø–æ–¥ —ç—Ç–∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è."
    )
    await update.message.reply_text(msg, reply_markup=build_randompmv_orientation_keyboard())


async def cmd_rategrp(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not check_access(update):
        return await unauthorized(update)

    groups = get_source_groups_prefer_unused()
    if not groups:
        return await update.message.reply_text("–ù–µ—Ç –≥—Ä—É–ø–ø –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤. –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ—Å–∫–∞–Ω–∏—Ä—É–π—Ç–µ /scan.")

    group_entries = [
        SourceGroupEntry(key=key, rows=list(rows), unused_count=unused_count)
        for key, rows, unused_count in groups
    ]
    sorted_entries, orientation_map = sort_group_entries_with_orientation(group_entries)

    session_payload = {
        "state": "rategrp_choose_orientation",
        "rategrp_group_orientations": orientation_map,
        "rategrp_groups_all": [
            (entry.key, entry.rows, entry.unused_count) for entry in sorted_entries
        ],
        "rategrp_groups": [],
        "rategrp_orientation_preference": None,
    }
    user_sessions[update.effective_user.id] = session_payload

    lines = [
        "–ö–æ–º–∞–Ω–¥–∞ rategrp: –æ—Ü–µ–Ω–∫–∞ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤ —Ü–≤–µ—Ç–∞–º–∏.",
        "–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—é –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤: VR, HOR –∏–ª–∏ VER,",
        "–∏–ª–∏ –Ω–∞–∂–º–∏—Ç–µ ¬´–ò–ó PMV¬ª, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å —Å–ª—É—á–∞–π–Ω—ã–µ –Ω–µ–æ—Ü–µ–Ω—ë–Ω–Ω—ã–µ –∏—Å—Ö–æ–¥–Ω–∏–∫–∏ –∏–∑ —Å–≤–µ–∂–∏—Ö PMV.",
    ]
    await update.message.reply_text(
        "\n".join(lines),
        reply_markup=build_rategrp_orientation_keyboard(),
    )


async def cmd_reports(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not check_access(update):
        return await unauthorized(update)

    user_sessions[update.effective_user.id] = {
        "state": "reports_wait_choice",
    }
    await update.message.reply_text(
        "–í—ã–±–µ—Ä–∏—Ç–µ –æ—Ç—á—ë—Ç –ø–æ —Ü–≤–µ—Ç—É –∏ –≥—Ä—É–ø–ø–∞–º.",
        reply_markup=build_reports_keyboard(),
    )


async def cmd_find(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not check_access(update):
        return await unauthorized(update)
    user_id = update.effective_user.id
    user_sessions[user_id] = {
        "state": "find_wait_term",
        "find_mode": True,
        "find_matches": [],
    }
    await update.message.reply_text(
        "–ü—Ä–∏—à–ª–∏—Ç–µ —á–∞—Å—Ç—å –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞, –¥–∞—Ç—ã –∏–ª–∏ –æ—Ç–º–µ—Ç–∫–∏ –≤—Ä–µ–º–µ–Ω–∏. "
        "–Ø –Ω–∞–π–¥—É —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å—Ä–µ–¥–∏ –≥–æ—Ç–æ–≤—ã—Ö PMV –∏ —Å—Ä–µ–¥–∏ –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤.",
    )


async def cmd_musicprep(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not check_access(update):
        return await unauthorized(update)

    files = list_music_input_files()
    if not files:
        return await update.message.reply_text(
            f"–ü–∞–ø–∫–∞ {MUSIC_INPUT_DIR} –ø—É—Å—Ç–∞. –î–æ–±–∞–≤—å—Ç–µ —Ç—É–¥–∞ MP3/FLAC/M4A –∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ –∫–æ–º–∞–Ω–¥—É."
        )

    usage_map = collect_music_track_usage()
    track_map: Dict[str, Dict[str, Any]] = {}
    unused_tokens: List[str] = []
    used_tokens: List[str] = []

    for idx, path in enumerate(sorted(files, key=lambda p: p.name.lower()), 1):
        token = f"mt{idx}"
        norm = _normalize_path_str(path)
        count = usage_map.get(norm, 0)
        track_map[token] = {
            "path": str(path),
            "usage": count,
        }
        if count:
            used_tokens.append(token)
        else:
            unused_tokens.append(token)

    session_payload = {
        "state": "musicprep_wait_track",
        "music_tracks": track_map,
        "music_tracks_unused": unused_tokens,
        "music_tracks_used": used_tokens,
    }
    user_sessions[update.effective_user.id] = session_payload

    show_used = not unused_tokens and bool(used_tokens)
    text, keyboard = build_musicprep_track_keyboard(session_payload, show_used=show_used)
    await update.message.reply_text(text, reply_markup=keyboard)


async def cmd_musicprepcheck(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not check_access(update):
        return await unauthorized(update)

    projects = load_music_projects()
    if not projects:
        return await update.message.reply_text(
            "–ü–∞–ø–∫–∞ music_projects –ø—É—Å—Ç–∞. –°–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞–π—Ç–µ –ø—Ä–æ–µ–∫—Ç—ã —á–µ—Ä–µ–∑ music_guided_generator.py."
        )

    project_map: Dict[str, Dict[str, Any]] = {}
    for proj in projects:
        slug = proj.get("slug") or sanitize_filename(proj.get("name") or "project")
        project_map[slug] = proj
    keyboard = build_musicprepcheck_keyboard(projects)
    user_sessions[update.effective_user.id] = {
        "state": "musicprepcheck_wait_project",
        "musicprepcheck_projects": project_map,
    }

    await update.message.reply_text(
        "–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–æ–µ–∫—Ç, –∏ —è —Å–≥–µ–Ω–µ—Ä–∏—Ä—É—é MP3 —Å–æ —â–µ–ª—á–∫–∞–º–∏ –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º –∞–Ω–∞–ª–∏–∑–∞.",
        reply_markup=keyboard,
    )


async def cmd_move2oculus(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not check_access(update):
        return await unauthorized(update)

    script_path = SCRIPT_DIR / "move2oculus.py"
    if not script_path.exists():
        return await update.message.reply_text("move2oculus.py –Ω–µ –Ω–∞–π–¥–µ–Ω —Ä—è–¥–æ–º —Å–æ —Å–∫—Ä–∏–ø—Ç–æ–º.")

    await update.message.reply_text("–ó–∞–ø—É—Å–∫–∞—é —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é —Å Oculus. –ü–æ–¥–æ–∂–¥–∏—Ç–µ, —ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç...")

    process = await asyncio.create_subprocess_exec(
        sys.executable,
        str(script_path),
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.PIPE,
    )

    stdout_lines: List[str] = []
    stderr_lines: List[str] = []
    chunk_size = 3500
    output_queue: asyncio.Queue[Tuple[str, str]] = asyncio.Queue()

    async def send_chunks(msg: str) -> None:
        if not msg:
            return
        for i in range(0, len(msg), chunk_size):
            await update.message.reply_text(msg[i : i + chunk_size])

    async def read_stream(stream, label: str, collector: List[str]) -> None:
        while True:
            line = await stream.readline()
            if not line:
                break
            text = line.decode(errors="ignore").rstrip()
            if not text:
                continue
            collector.append(text)
            await output_queue.put((label, text))

    async def pump_output() -> None:
        while True:
            label, text = await output_queue.get()
            prefix = "STDOUT" if label == "stdout" else "STDERR"
            await send_chunks(f"{prefix}: {text}")
            output_queue.task_done()

    stdout_task = asyncio.create_task(read_stream(process.stdout, "stdout", stdout_lines))
    stderr_task = asyncio.create_task(read_stream(process.stderr, "stderr", stderr_lines))
    pump_task = asyncio.create_task(pump_output())

    await process.wait()
    await stdout_task
    await stderr_task
    await output_queue.join()
    pump_task.cancel()
    with contextlib.suppress(asyncio.CancelledError):
        await pump_task

    returncode = process.returncode or 0
    if returncode == 0:
        header = "‚úÖ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞."
    else:
        header = f"‚ùå –û—à–∏–±–∫–∞ (–∫–æ–¥ {returncode})."

    tail_stdout = "\n".join(stdout_lines[-20:])
    tail_stderr = "\n".join(stderr_lines[-20:])
    parts = [header]
    if tail_stdout:
        parts.append("–ü–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è:\n" + tail_stdout)
    if tail_stderr:
        parts.append("STDERR (–ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å—Ç—Ä–æ–∫–∏):\n" + tail_stderr)
    await send_chunks("\n\n".join(parts))


# =========================
# MAIN
# =========================

def main() -> None:
    print(f"–ó–∞–ø—É—Å–∫ PMV Telegram Bot {BUILD_NAME}")
    init_db()
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    app = ApplicationBuilder().token(TELEGRAM_BOT_TOKEN).build()

    # Command handlers
    app.add_handler(CommandHandler("start", cmd_start))
    app.add_handler(CommandHandler("addfolder", cmd_addfolder))
    app.add_handler(CommandHandler("folders", cmd_folders))
    app.add_handler(CommandHandler("scan", cmd_scan))
    app.add_handler(CommandHandler("scanignore", cmd_scanignore))
    app.add_handler(CommandHandler("pmvnew", cmd_pmvnew))
    app.add_handler(CommandHandler("ratepmv", cmd_ratepmv))
    app.add_handler(CommandHandler("badfiles", cmd_badfiles))
    app.add_handler(CommandHandler("strategy", cmd_strategy))
    app.add_handler(CommandHandler("videofx", cmd_videofx))
    app.add_handler(CommandHandler("pmvold", cmd_pmvold))
    app.add_handler(CommandHandler("compmv", cmd_compmv))
    app.add_handler(CommandHandler("comvid", cmd_comvid))
    app.add_handler(CommandHandler("lookcom", cmd_lookcom))
    app.add_handler(CommandHandler("autocreate", cmd_autocreate))
    app.add_handler(CommandHandler("newcompmusic", cmd_newcompmusic))
    app.add_handler(CommandHandler("createrandompmv", cmd_randompmv))
    app.add_handler(CommandHandler("rategrp", cmd_rategrp))
    app.add_handler(CommandHandler("reports", cmd_reports))
    app.add_handler(CommandHandler("find", cmd_find))
    app.add_handler(CommandHandler("musicprep", cmd_musicprep))
    app.add_handler(CommandHandler("musicprepcheck", cmd_musicprepcheck))
    app.add_handler(CommandHandler("move2oculus", cmd_move2oculus))
    app.add_handler(CallbackQueryHandler(handle_callback))

    # Text handler
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))


    app.run_polling()


if __name__ == "__main__":
    main()
